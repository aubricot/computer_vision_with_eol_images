{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/aubricot/computer_vision_with_eol_images/blob/master/object_detection_for_image_tagging%20/flower_fruit/flower_fruit_generate_tags_yolov3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j-PBcUKyc95M"
      },
      "source": [
        "# Using YOLO v3 pre-trained on Google Open Images to add flower/fruit tags to plant images\n",
        "---\n",
        "*Last Updated 8 June 2023*   \n",
        "Using a YOLOv3 model (downloaded from [here](https://github.com/AlexeyAB/darknet) ) pre-trained on [Google Open Images](https://storage.googleapis.com/openimages/web/visualizer/index.html?set=train&type=detection&c=%2Fm%2F03vt0) as a method to do customized, large-scale image processing. EOL Angiosperm images will be tagged for flower/fruit present using object detection. Tags will further extend EOLv3 image search functions.\n",
        "\n",
        "Notes:   \n",
        "* Run code blocks by pressing play button in brackets on left\n",
        "* Change parameters using form fields on right (find details at corresponding lines of code by searching '#@param')\n",
        "\n",
        "References:   \n",
        "* Check out [AlexeyAB's darknet repo](https://github.com/AlexeyAB/darknet) for Colab tutorials like [this one](https://colab.research.google.com/drive/12QusaaRj_lUwCGDvQNfICpa7kA7_a2dE)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fX9LGz3Ydu27"
      },
      "source": [
        "## Installs & Imports\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q5lC8PSbGCyN"
      },
      "outputs": [],
      "source": [
        "#@title Choose where to save results\n",
        "import os\n",
        "\n",
        "# Use dropdown menu on right\n",
        "save = \"in Colab runtime (files deleted after each session)\" #@param [\"in my Google Drive\", \"in Colab runtime (files deleted after each session)\"]\n",
        "\n",
        "# Mount google drive to export image tagging file(s)\n",
        "if 'Google Drive' in save:\n",
        "    from google.colab import drive\n",
        "    drive.mount('/content/drive', force_remount=True)\n",
        "\n",
        "# Type in the path to your project wd in form field on right\n",
        "basewd = \"/content/drive/MyDrive/train\" #@param [\"/content/drive/MyDrive/train\"] {allow-input: true}\n",
        "\n",
        "# Type in the folder that you want to contain TF2 files\n",
        "folder = \"darknet\" #@param [\"darknet\"] {allow-input: true}\n",
        "cwd = basewd + '/' + folder\n",
        "\n",
        "# Download helper_funcs folder\n",
        "!pip3 -q install --upgrade gdown\n",
        "!gdown 1-BaybePbv810CTuHrF8JGRJfuEsHRQYH\n",
        "!tar -xzvf helper_funcs.tar.gz -C .\n",
        "\n",
        "# Install requirements.txt\n",
        "!pip3 -q install -r requirements.txt\n",
        "print('\\n\\n\\n \\033[91m If ERROR from pip dependency solver listed above, restart runtime then run this cell again to refresh installed package versions.')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y3Gil1IhrUC9"
      },
      "outputs": [],
      "source": [
        "#@title Set up directory structure & make darknet\n",
        "!python setup.py $cwd $basewd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yDdbBYnp2nCK"
      },
      "outputs": [],
      "source": [
        "#@title Import libraries\n",
        "\n",
        "# For importing/exporting files, working with arrays, etc\n",
        "import glob\n",
        "import pathlib\n",
        "import six.moves.urllib as urllib\n",
        "import sys\n",
        "import tarfile\n",
        "import zipfile\n",
        "import numpy as np \n",
        "import csv\n",
        "import time\n",
        "import pandas as pd\n",
        "\n",
        "# For downloading images\n",
        "!apt-get -qq install aria2\n",
        "\n",
        "# For drawing onto and plotting images\n",
        "import matplotlib.pyplot as plt\n",
        "import cv2\n",
        "%matplotlib inline\n",
        "%config InlineBackend.figure_format = 'svg'\n",
        "sys.path.append('/content')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fuZL4TGzitNZ"
      },
      "source": [
        "### Prepare object detection functions and settings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wqoLKpXveeAt"
      },
      "outputs": [],
      "source": [
        "#@title Define functions\n",
        "from wrangle_data import read_datafile, imShow\n",
        "\n",
        "# Display full URLs in outputs so you can click them and inspect images\n",
        "pd.set_option('display.max_colwidth', None)\n",
        "\n",
        "# Define start and stop indices in EOL bundle for running inference   \n",
        "def set_start_stop(df):\n",
        "    # To test with a tiny subset, use 5 random bundle images\n",
        "    if \"tiny subset\" in run:\n",
        "        start=np.random.choice(a=1000, size=1)[0]\n",
        "        stop=start+5\n",
        "    # To run inference on 4 batches of 5k images each\n",
        "    elif \"_a.\" in outfpath: # batch a is from 0-5000\n",
        "        start=0\n",
        "        stop=5000\n",
        "    elif \"_b.\" in outfpath: # batch b is from 5000-1000\n",
        "        start=5000\n",
        "        stop=10000\n",
        "    elif \"_c.\" in outfpath: # batch c is from 10000-15000\n",
        "        start=10000\n",
        "        stop=15000\n",
        "    elif \"_d.\" in outfpath: # batch d is from 15000-20000\n",
        "        start=15000\n",
        "        stop=20000\n",
        "    \n",
        "    return start, stop\n",
        "\n",
        "# For uploading an image from url\n",
        "# Modified from https://www.pyimagesearch.com/2015/03/02/convert-url-to-image-with-python-and-opencv/\n",
        "def url_to_image(url):\n",
        "    resp = urllib.request.urlopen(url)\n",
        "    image = np.asarray(bytearray(resp.read()), dtype=\"uint8\")\n",
        "    image = cv2.imdecode(image, cv2.IMREAD_COLOR)\n",
        "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "    im_h, im_w = image.shape[:2]\n",
        " \n",
        "    return image\n",
        "\n",
        "# Combine individual prediction files for each image to all_predictions.txt\n",
        "def combine_predictions(imgs_dir):\n",
        "    # Delete inference images file list\n",
        "    !rm $outfpath\n",
        "    # Combine inference text files for each image and save to all_predictions.txt\n",
        "    fns = os.listdir(imgs_dir)\n",
        "    with open('data/results/all_predictions.txt', 'w') as outfile:\n",
        "        header = \"class_id x y w h img_id\"\n",
        "        outfile.write(header + \"\\n\")\n",
        "        for fn in fns:\n",
        "            if '.txt' in fn:\n",
        "                with open('data/imgs/'+fn) as infile:\n",
        "                    lines = infile.readlines()\n",
        "                    newlines = [''.join([x.strip(), ' ' + os.path.splitext(fn)[0] + '\\n']) for x in lines]\n",
        "                    outfile.writelines(newlines)\n",
        "    # Load all_predictions.txt\n",
        "    df = pd.read_csv('data/results/all_predictions.txt')\n",
        "    print(\"Model predictions: \\n\", df.head())\n",
        "\n",
        "    return df\n",
        "\n",
        "# Combine tagging files for batches A-D\n",
        "def combine_tag_files(tags_fpath):\n",
        "    # Combine tag files for batches A-D\n",
        "    fpath =  os.path.splitext(tags_fpath)[0]\n",
        "    base = fpath.rsplit('_',1)[0] + '_'\n",
        "    exts = ['a.tsv', 'b.tsv', 'c.tsv', 'd.tsv'] \n",
        "    all_filenames = [base + e for e in exts]\n",
        "    df = pd.concat([pd.read_csv(f, sep='\\t', header=0, na_filter = False) for f in all_filenames], ignore_index=True)\n",
        "    # Choose desired columns for tagging\n",
        "    df = df[['url', 'img_id', 'class_id']]\n",
        "    df.rename(columns={'url': 'eolMediaURL', 'img_id': 'identifier', 'class_id': 'tag'}, inplace=True)\n",
        "    print(\"\\nNew concatenated dataframe with all 4 batches: \\n\", df[['eolMediaURL', 'tag']].head())\n",
        "\n",
        "    return df\n",
        "\n",
        "def add_class_names(all_predictions):\n",
        "    # Model predictions with number-coded classes\n",
        "    numbered_tags = pd.read_csv(all_predictions, header=0, sep=\" \")\n",
        "    numbered_tags.class_id = numbered_tags.class_id - 1 # python counts from 0, Yolo from 1\n",
        "    print(\"\\nModel predictions by class id (number): \\n\", numbered_tags)\n",
        "\n",
        "    # Add class names to model predictions\n",
        "    classes = pd.read_table('data/openimages.names')\n",
        "    classes.columns = ['name']\n",
        "    classes_dict = pd.Series(classes.name.values, index=classes.index).to_dict()\n",
        "    tags = numbered_tags.copy()\n",
        "    tags.replace({\"class_id\":classes_dict}, inplace=True)\n",
        "    tags['class_id'] = tags['class_id'].astype(str)\n",
        "    print(\"\\nModel predictions by class id (name): \\n\", tags)\n",
        "\n",
        "    return tags\n",
        "\n",
        "# Add EOL media URL's to named image tags\n",
        "def add_eolMediaURLs(tags, bundle):\n",
        "    # Read in EOL 20k image url bundle\n",
        "    bundle = read_datafile(bundle)\n",
        "    bundle.columns = ['url']\n",
        "    \n",
        "    # Map eolMediaURLs to tags using image filenames\n",
        "    img_fns = bundle['url'].apply(lambda x: os.path.splitext((os.path.basename(x)))[0])\n",
        "    bundle['img_id'] = img_fns\n",
        "    # Make datatypes consistent for bundle and tags\n",
        "    bundle['img_id'] = bundle['img_id'].astype(\"string\")\n",
        "    tags['img_id'] = tags['img_id'].astype(\"string\")\n",
        "    # Add URLs to tags with img_id as a key\n",
        "    final_tags = tags.merge(bundle, on='img_id')\n",
        "    final_tags.reset_index(drop=True, inplace=True)\n",
        "    final_tags.drop_duplicates(inplace=True, ignore_index=True)\n",
        "    print(\"\\nModel predictions with EOL media URL's added: \\n\", final_tags.head())\n",
        "\n",
        "    return final_tags\n",
        "\n",
        "# Set filename for saving classification results\n",
        "def set_outpath(tags_file):\n",
        "    tags_file = os.path.splitext(tags_file)[0]\n",
        "    outpath = cwd + '/data/results/' + tags_file + '.tsv'\n",
        "    print(\"Saving results to: \\n\", outpath)\n",
        "\n",
        "    return outpath"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cKovA4-aifP5"
      },
      "source": [
        "## Generate tags for images\n",
        "---\n",
        "Run EOL 20k image bundles through pre-trained object detection models and save results in 4 batches (A-D). "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YdNG8YEWaqsX"
      },
      "source": [
        "#### Test: Run individual image through by filename and display results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kIDpIFWsOZo5"
      },
      "outputs": [],
      "source": [
        "#@title Run with sample EOL Angiosperm image (To test with your own image, upload file to data/imgs and update fn formfield)\n",
        "\n",
        "# Run with sample EOL image\n",
        "# Define filepath to image\n",
        "fn = \"542.8209936861.jpg\" #@param [\"542.8209936861.jpg\"] {allow-input: true}\n",
        "img_fpath = 'data/imgs/' + fn\n",
        "\n",
        "# Download image\n",
        "%cd $cwd\n",
        "%cd data/imgs\n",
        "!gdown 1A7dHlbnAlRS-pHwS2QHg--HzTQc1CLx3\n",
        "%cd $cwd\n",
        "\n",
        "# Run darknet and show bounding box coordinates\n",
        "!./darknet detector test cfg/openimages.data cfg/yolov3-openimages.cfg yolov3-openimages.weights {img_fpath}\n",
        "\n",
        "# Display detection results\n",
        "print(\"\\nObject detection results:\")\n",
        "imShow('predictions.jpg')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wjTgajd3keAi"
      },
      "source": [
        "### Generate tags: Run inference on EOL images & save results for tagging - Run 4X for batches A-D\n",
        "Use 20K EOL Angiosperm image bundle to identify present flowers and fruits. Results are saved to [tags_file].tsv. Run this section 4 times (to make batches A-D) of 5K images each to incrementally save in case of Colab timeouts."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zCxtKyRPij8R"
      },
      "outputs": [],
      "source": [
        "#@title Enter EOL image bundle and choose inference settings. Change **tags_file** for each batch A-D\n",
        "%cd $cwd\n",
        "\n",
        "# Load in EOL Angiosperm 20k image bundle\n",
        "bundle = \"https://editors.eol.org/other_files/bundle_images/files/images_for_Angiosperms_20K_breakdown_download_000030.txt\" #@param [\"https://editors.eol.org/other_files/bundle_images/files/images_for_Angiosperms_20K_breakdown_download_000030.txt\"] {allow-input: true}\n",
        "df = read_datafile(bundle)\n",
        "print(\"EOL image bundle with {} images: \\n{}\".format(len(df), df.head()))\n",
        "\n",
        "# Test pipeline with a smaller subset than 5k images?\n",
        "run = \"test with tiny subset\" #@param [\"test with tiny subset\", \"for all images\"]\n",
        "\n",
        "# Display detection results on images?\n",
        "display_results = \"yes (use this option if testing tiny subsets; only works for \\u003C50 images)\" #@param [\"yes (use this option if testing tiny subsets; only works for \\u003C50 images)\", \"no (use this option if running batches)\"]\n",
        "\n",
        "# Take 5k subset of bundle for running inference\n",
        "# Change filename for each batch\n",
        "tags_file = \"flower_fruit_tags_d\" #@param [\"flower_fruit_tags_a\", \"flower_fruit_tags_b\", \"flower_fruit_tags_c\", \"flower_fruit_tags_d\"] {allow-input: true}\n",
        "tags_file = tags_file + \".txt\"\n",
        "imgs_dir = \"data/imgs/\"\n",
        "outfpath = imgs_dir + tags_file\n",
        "print(\"\\nSaving tagging results to: \\n{}\".format(outfpath))\n",
        "\n",
        "# Add 5k subset of image bundle urls as column in tags file\n",
        "start, stop = set_start_stop(df)\n",
        "df = df.iloc[start:stop]\n",
        "df.to_csv(outfpath, sep='\\n', index=False, header=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eKUThVvV-66K"
      },
      "outputs": [],
      "source": [
        "#@title Run inference (Note: YOLO cannot parse images from URL, so images are temporarily downloaded) \n",
        "# Note: Takes 7-10 min per 5k imgs, aria2 downloads 16imgs at a time\n",
        "%cd $imgs_dir\n",
        "!aria2c -x 16 -s 1 -i $tags_file\n",
        "\n",
        "# Check how many images downloaded\n",
        "print(\"Number of files downloaded to Google Drive: \")\n",
        "len([1 for x in list(os.scandir('.')) if x.is_file()])-1 # -1 because .txt file contains image filenames\n",
        "\n",
        "# Move tags file used for downloading images to data/img_info/\n",
        "%cd $cwd\n",
        "!mv data/imgs/*.txt data/img_info/\n",
        "\n",
        "# Make a new list of successfully downloaded image files for running inference\n",
        "inf_imgs = imgs_dir + tags_file\n",
        "with open(inf_imgs, 'w', encoding='utf-8') as f:\n",
        "    # Walk through data/imgs/ to list files\n",
        "    for dir, dirs, files in os.walk(imgs_dir):\n",
        "        files = [fn for fn in files]\n",
        "        for fn in files:\n",
        "            if 'txt' not in fn:\n",
        "                out = \"data/imgs/\" + fn\n",
        "                f.writelines(out + '\\n')\n",
        "\n",
        "# Inspect textfile of images for inference\n",
        "df = pd.read_table(inf_imgs, header=None, sep='\\r')\n",
        "print(\"\\nNumber of valid images ready for inference in {}: {}\".format(inf_imgs, len(df)))\n",
        "\n",
        "# Run darknet with flag to not show bounding box coordinates\n",
        "!./darknet detector test cfg/openimages.data cfg/yolov3-openimages.cfg yolov3-openimages.weights -dont_show -save_labels < {outfpath}\n",
        "\n",
        "print(\"\\n\\n~~~\\nInference complete! Post-process inference results in next code blocks before running these steps for remaining batches A-D.\\n~~~\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H5RHwpgKmMMb"
      },
      "outputs": [],
      "source": [
        "#@title Post-process detection results for each batch\n",
        "\n",
        "# Combine individual prediction files for each image to all_predictions.txt\n",
        "df = combine_predictions(imgs_dir)\n",
        "\n",
        "# Delete inference text files and images (only needed them for inference)\n",
        "!rm -r data/imgs/*\n",
        "\n",
        "# Add class names to numeric image tags\n",
        "tags = add_class_names('data/results/all_predictions.txt')\n",
        "\n",
        "# Add EOL media URL's from bundle to image tags df\n",
        "final_tags = add_eolMediaURLs(tags, bundle)\n",
        "\n",
        "# Save final tags to file\n",
        "outpath = set_outpath(tags_file)\n",
        "final_tags.to_csv(outpath, sep=\"\\t\", index=False)\n",
        "\n",
        "print(\"\\n\\n~~~\\nPost-processing complete! Run above steps for remaining batches A-D before proceeding to next steps.\\n~~~\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o7N0hAHDFpN_"
      },
      "source": [
        "## Combine tags for 5k image batches A-D\n",
        "---\n",
        "After running steps above for each image batch, combine tag files to one 20k tag dataset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qbm0_nfQFtkI"
      },
      "outputs": [],
      "source": [
        "#@title Define parameters for converting detected classes to desired image tags\n",
        "%cd $cwd\n",
        "\n",
        "# Write header row of output tagging file\n",
        "# Enter any filename from 4 batches of tagging files\n",
        "tags_file = \"flower_fruit_tags_d\" #@param [\"flower_fruit_tags_d\"] {allow-input: true}\n",
        "tags_fpath = \"data/results/\" + tags_file + \".tsv\"\n",
        "\n",
        "# Combine exported model predictions and confidence values for all batches\n",
        "df = combine_tag_files(tags_fpath)\n",
        "\n",
        "# Filter for desired classes\n",
        "# These classes will be kept as is\n",
        "filter1 = ['Flower', 'Fruit'] #@param\n",
        "pattern1 = '|'.join(filter1)\n",
        "# These classes will be converted to 'reproductive structures present' (flowers/fruits)\n",
        "filter2 = ['Food'] #@param\n",
        "pattern2 = '|'.join(filter2)\n",
        "\n",
        "# Set all detections for 'Food' to 'Reproductive structures present'\n",
        "print(\"\\nNo. tags matching filtered class(es) {}: {}\\n\".format(pattern2, len(df[df.tag.str.match(pattern2)])))\n",
        "df.loc[df.tag.str.match(pattern2), 'tag'] = 'Reproductive structures present'\n",
        "\n",
        "# Remove all detections that aren't 'Flower', 'Fruit', or 'Reproductive structures present'\n",
        "print(\"\\nNo. tags matching filtered class(es) {}: {}\\n\".format(filter1, len(df[df.tag.str.match(pattern1)])))\n",
        "print(\"\\nTags matching filtered class(es): \\n\", df[df.tag.str.match(pattern1)])\n",
        "\n",
        "patterns = '|'.join(['Flower', 'Fruit', 'Reproductive structures present'])\n",
        "print(\"\\nNo. tags not matching filtered classes: \\n\", len(df.tag[~df.tag.str.match(patterns)]))\n",
        "print(\"\\nTags not matching filtered classes: \\n\", df[~df.tag.str.match(patterns)])\n",
        "df.loc[~df.tag.str.match(patterns), 'tag'] = 'None'\n",
        "\n",
        "# Write results to tsv\n",
        "outpath = 'data/results/' + tags_file.rsplit('_', 1)[0] + '_final.tsv'\n",
        "df.to_csv(outpath, sep='\\t', index=False)\n",
        "print(\"\\n\\nFinal tagging file {}: \\n{}\".format(outpath, df.head()))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vmmCI1jCVNxl"
      },
      "source": [
        "## Display tagging results on images\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "7NN4fOicvcl0"
      },
      "outputs": [],
      "source": [
        "#@title Adjust start index and display up to 50 images with their tags\n",
        "# Suppress warning about too many figures opened\n",
        "plt.rcParams.update({'figure.max_open_warning': 0})\n",
        "\n",
        "# Set number of seconds to timeout if image url taking too long to open\n",
        "import socket\n",
        "socket.setdefaulttimeout(10)\n",
        "\n",
        "# Adjust start index using slider\n",
        "start = 0 #@param {type:\"slider\", min:0, max:5000, step:50}\n",
        "stop = min((start+50), len(df))\n",
        "\n",
        "# Loop through images\n",
        "for i, row in df.iloc[start:stop].iterrows():\n",
        "    try:\n",
        "        # Read in image \n",
        "        url = df['eolMediaURL'][i]\n",
        "        img = url_to_image(url)\n",
        "\n",
        "        # Fetch image tag\n",
        "        tag = df['tag'][i]\n",
        "  \n",
        "        # Display progress message after each image is loaded\n",
        "        print('Successfully loaded {} of {} images'.format(i+1, (stop-start)))\n",
        "\n",
        "        # Plot image with tag\n",
        "        _, ax = plt.subplots(figsize=(10, 10))\n",
        "        ax.imshow(img)\n",
        "        plt.axis('off')\n",
        "        plt.title('{}) Tag: {}'.format(i+1, tag))\n",
        "\n",
        "    except:\n",
        "        print('Check if URL from {} is valid'.format(url))"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}