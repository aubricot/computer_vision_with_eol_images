{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "train_tf_ssd_rcnn.ipynb",
      "provenance": [],
      "private_outputs": true,
      "collapsed_sections": [
        "G7amcDYcQpf0",
        "VgG3-2LslczI",
        "Sz7aVQVUSecK"
      ],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python2",
      "display_name": "Python 2"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/aubricot/object_detection_for_image_cropping/blob/master/train_tf_ssd_rcnn.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SWrXhn1qKWm_",
        "colab_type": "text"
      },
      "source": [
        "# Training Tensorflow Object Detection models\n",
        "---   \n",
        "*Last Updated 29 January 2020*  \n",
        "Use images and bounding box coordinates to train Faster-RCNN and SSD Object Detection Models implemented in Tensorflow to detect bats from EOL images.\n",
        "\n",
        "Datasets exported from [preprocessing.ipynb](https://colab.research.google.com/github/aubricot/object_detection_for_image_cropping/blob/master/preprocessing.ipynb) were already downloaded to Google Drive in preprocessing.ipynb. \n",
        "\n",
        "For each 24 hour period on Google Colab, you have up to 12 hours of GPU access. Training the object detection model on bats took 30 hours split into 3 days.\n",
        "\n",
        "Make sure to set the runtime to Python 2 with GPU Hardware Accelerator.    \n",
        "\n",
        "References:   \n",
        "[Official Tensorflow Object Detection API Instructions](https://tensorflow-object-detection-api-tutorial.readthedocs.io/en/latest/training.html)   \n",
        "[Medium Blog on training using Tensorflow Object Detection API in Colab](https://medium.com/analytics-vidhya/training-an-object-detection-model-with-tensorflow-api-using-google-colab-4f9a688d5e8b)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "smQWTwI7k4Bf",
        "colab_type": "text"
      },
      "source": [
        "## Installs (run this every time)\n",
        "---\n",
        "Install the Tensorflow Object Detection API directly to this Colab notebook."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0mAC7PfUrWX1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Mount google drive to import/export files\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "No18RpXIAgGL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Download, compile and build all ingredients for the Tensorflow Object Detection API\n",
        "# These steps take a couple of minutes and print a lot of output\n",
        "\n",
        "# Make a working directory train/ in your Google Drive and include the path here (all paths in other sections stay the same)\n",
        "import os\n",
        "%cd drive/My Drive/fall19_smithsonian_informatics/train\n",
        "if not os.path.exists(\"tf_models\"):\n",
        "  !mkdir tf_models\n",
        "%cd tf_models\n",
        "\n",
        "# Install Tensorflow Object Detection API\n",
        "import pathlib\n",
        "if not pathlib.Path(\"models\").exists():\n",
        "  !git clone https://github.com/tensorflow/models.git\n",
        "\n",
        "# Clone the COCO API repository to your Google Drive\n",
        "if not pathlib.Path(\"pycocotools\").exists():\n",
        "  !git clone https://github.com/cocodataset/cocoapi.git\n",
        "  # Move needed folders to tf_models/pycocotools and delete remaining contents of cocoapi/ to save space\n",
        "  !cd cocoapi/PythonAPI; make; cp -r pycocotools ../..\n",
        "  !rm -rf cocoapi\n",
        "\n",
        "# Install libraries\n",
        "!apt-get install -qq protobuf-compiler python-tk\n",
        "!pip install -q Cython contextlib2 pillow lxml matplotlib PyDrive\n",
        "\n",
        "# Compile object detection api using Google Protobuf\n",
        "%cd models/research\n",
        "!protoc object_detection/protos/*.proto --python_out=.\n",
        "\n",
        "# Update system path variables\n",
        "os.environ['PYTHONPATH'] = ':/drive/My Drive/fall19_smithsonian_informatics/train/tf_models/models/research/:/drive/My Drive/fall19_smithsonian_informatics/train/tf_models/models/research/slim/'\n",
        "!echo $PYTHONPATH\n",
        "\n",
        "import sys\n",
        "print(sys.path)\n",
        "sys.path.append(\"/usr/local/lib/python2.7/dist-packages/tensorflow/contrib/slim\")\n",
        "print(sys.path)\n",
        "\n",
        "# Build slim\n",
        "!python slim/setup.py build\n",
        "!python slim/setup.py install\n",
        "\n",
        "# Copy slim to specified directories to avoid errors in model_builder_test.py\n",
        "!cp -R models/research/slim/ /usr/local/lib/python2.7/dist-packages/object_detection-0.1-py2.7.egg/\n",
        "if not os.path.exists(\"object_detection/slim/nets\"):\n",
        "  !cp -R slim/nets/ object_detection/\n",
        "\n",
        "# Test build of model\n",
        "!python object_detection/builders/model_builder_test.py"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G7amcDYcQpf0",
        "colab_type": "text"
      },
      "source": [
        "## Other preparation for training (only need to run these once)\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VgG3-2LslczI",
        "colab_type": "text"
      },
      "source": [
        "### Download and extract pre-trained model   "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YaLxacTBZnM1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Download pre-trained model from Tensorflow Object Detection Model Zoo\n",
        "# SSD and Faster-RCNN both included as options below\n",
        "# modified from https://github.com/RomRoc/objdet_train_tensorflow_colab/blob/master/objdet_custom_tf_colab.ipynb\n",
        "\n",
        "# cd to train/\n",
        "#%cd train\n",
        "%cd ../../..\n",
        "\n",
        "import os\n",
        "import shutil\n",
        "import glob\n",
        "import urllib\n",
        "import tarfile\n",
        "\n",
        "# Make folders for your training files for each model\n",
        "# RCNN Model\n",
        "if not (os.path.exists('tf_models/train_demo')):\n",
        "  !mkdir tf_models/train_demo\n",
        "if not (os.path.exists('tf_models/train_demo/rcnn')):\n",
        "  !mkdir tf_models/train_demo/rcnn\n",
        "if not (os.path.exists('tf_models/train_demo/rcnn/pretrained_model')):\n",
        "  !mkdir tf_models/train_demo/rcnn/pretrained_model\n",
        "if not (os.path.exists('tf_models/train_demo/rcnn/finetuned_model')):\n",
        "  !mkdir tf_models/train_demo/rcnn/finetuned_model\n",
        "if not (os.path.exists('tf_models/train_demo/rcnn/trained')):\n",
        "  !mkdir tf_models/train_demo/rcnn/trained\n",
        "# Download the model\n",
        "MODEL = 'faster_rcnn_resnet50_coco_2018_01_28'\n",
        "MODEL_FILE = MODEL + '.tar.gz'\n",
        "DOWNLOAD_BASE = 'http://download.tensorflow.org/models/object_detection/'\n",
        "DEST_DIR = 'tf_models/train_demo/rcnn/pretrained_model'\n",
        "if not (os.path.exists(MODEL_FILE)):\n",
        "  opener = urllib.URLopener()\n",
        "  opener.retrieve(DOWNLOAD_BASE + MODEL_FILE, MODEL_FILE)\n",
        "\n",
        "tar = tarfile.open(MODEL_FILE)\n",
        "tar.extractall()\n",
        "tar.close()\n",
        "\n",
        "os.remove(MODEL_FILE)\n",
        "if (os.path.exists(DEST_DIR)):\n",
        "  shutil.rmtree(DEST_DIR)\n",
        "os.rename(MODEL, DEST_DIR)\n",
        "\n",
        "# SSD Model\n",
        "if not (os.path.exists('tf_models/train_demo/ssd')):\n",
        "  !mkdir tf_models/train_demo/ssd\n",
        "if not (os.path.exists('tf_models/train_demo/ssd/pretrained_model')):\n",
        "  !mkdir tf_models/train_demo/ssd/pretrained_model\n",
        "if not (os.path.exists('tf_models/train_demo/ssd/finetuned_model')):\n",
        "  !mkdir tf_models/train_demo/ssd/finetuned_model\n",
        "if not (os.path.exists('tf_models/train_demo/ssd/trained')):\n",
        "  !mkdir tf_models/train_demo/ssd/trained\n",
        "# Download the model\n",
        "MODEL = 'ssd_resnet50_v1_fpn_shared_box_predictor_640x640_coco14_sync_2018_07_03'\n",
        "MODEL_FILE = MODEL + '.tar.gz'\n",
        "DOWNLOAD_BASE = 'http://download.tensorflow.org/models/object_detection/'\n",
        "DEST_DIR = 'tf_models/train_demo/ssd/pretrained_model'\n",
        "if not (os.path.exists(MODEL_FILE)):\n",
        "  opener = urllib.URLopener()\n",
        "  opener.retrieve(DOWNLOAD_BASE + MODEL_FILE, MODEL_FILE)\n",
        "\n",
        "tar = tarfile.open(MODEL_FILE)\n",
        "tar.extractall()\n",
        "tar.close()\n",
        "\n",
        "os.remove(MODEL_FILE)\n",
        "if (os.path.exists(DEST_DIR)):\n",
        "  shutil.rmtree(DEST_DIR)\n",
        "os.rename(MODEL, DEST_DIR)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Sz7aVQVUSecK",
        "colab_type": "text"
      },
      "source": [
        "### Convert training data to tf.record format"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ygJPRnpHTuLl",
        "colab_type": "text"
      },
      "source": [
        "1) Download generate_tfrecord.py from [GitHub](https://github.com/aubricot/object_detection_for_image_cropping/blob/master/generate_tfrecord.py)\n",
        "\n",
        "2) Modify the file for your train dataset: \n",
        "*   update label names to your class(es) at line 34\n",
        "        # TO-DO replace this with label map\n",
        "        def class_text_to_int(row_label):\n",
        "          if row_label == 'Chiroptera':\n",
        "            return 1\n",
        "          else:\n",
        "            None\n",
        "*   update the filepath where you want your train tf.record file to save at line 88\n",
        "        # TO-DO replace path with your filepath\n",
        "        def main(_):\n",
        "            writer = tf.python_io.TFRecordWriter('/content/drive/My Drive/[yourfilepath]/tf.record')\n",
        "*   upload modified generate_tfrecord.py file to train/\n",
        "\n",
        "3) Proceed with steps below to generate tf.record files for your test and train datasets"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zRr1MLxSICf_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Convert crops_train to tf.record format for train data\n",
        "# Modified from https://tensorflow-object-detection-api-tutorial.readthedocs.io/en/latest/training.html\n",
        "!python generate_tfrecord.py --csv_input='/content/drive/My Drive/fall19_smithsonian_informatics/train/chiroptera_crops_train.csv'  --output_path= \"/content/drive/My Drive/fall19_smithsonian_informatics/train/images/tf.record\"  --image_dir=\"/content/drive/My Drive/fall19_smithsonian_informatics/train/images\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9kFe9D21WGog",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Convert crops_test to tf.record format for test data\n",
        "# Modified from https://tensorflow-object-detection-api-tutorial.readthedocs.io/en/latest/training.html\n",
        "!python generate_tfrecord.py --csv_input='/content/drive/My Drive/fall19_smithsonian_informatics/train/chiroptera_crops_test.csv'  --output_path= \"/content/drive/My Drive/fall19_smithsonian_informatics/train/test_img/tf.record\"  --image_dir=\"/content/drive/My Drive/fall19_smithsonian_informatics/train/test_img\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "naEjBRiGu-3e",
        "colab_type": "text"
      },
      "source": [
        "## Train\n",
        "--- "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EufHObsuuswu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Track training checkpoints in external window\n",
        "# Modified from https://www.dlology.com/blog/quick-guide-to-run-tensorboard-in-google-colab/\n",
        "LOG_DIR = 'training'\n",
        "get_ipython().system_raw(\n",
        "    'tensorboard --logdir {} --host 0.0.0.0 --port 6006 &'\n",
        "    .format(LOG_DIR)\n",
        ")\n",
        "# Install\n",
        "! npm install -g localtunnel\n",
        "! npm i -g npm\n",
        "# Tunnel port 6006 (TensorBoard assumed running)\n",
        "get_ipython().system_raw('lt --port 6006 >> url1.txt 2>&1 &')\n",
        "# Get url\n",
        "! cat url1.txt"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DScMtAYQ_Vib",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Make label_map.pbtxt file for one class\n",
        "## this doesnt work...need to figure out way to make this like labelmap.pbtxt\n",
        "!echo \"item {\\n id: 1\\n name: 'Chiroptera'\\n}\" > label_map.pbtxt"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6cUfcn0kpRX2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# cd to train/\n",
        "#%cd train\n",
        "%cd ../../.."
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B55tKxoL5aRM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Modified from https://github.com/RomRoc/objdet_train_tensorflow_colab/blob/master/objdet_custom_tf_colab.ipynb\n",
        "# To train on rcnn or ssd, change the pipline_config_path to the appropriate config file\n",
        "import matplotlib\n",
        "matplotlib.use('Agg')\n",
        "\n",
        "!python tf_models/models/research/object_detection/model_main.py \\\n",
        "    --pipeline_config_path=tf_models/models/research/object_detection/samples/configs/ssd_resnet50_v1_fpn_shared_box_predictor_640x640_coco14_sync_2018_07_03_bats.config \\\n",
        "    --alsologtostderr \\\n",
        "    --num_train_steps=190000 \\\n",
        "    --num_eval_steps=500 \\\n",
        "    --model_dir=tf_models/train_demo/ssd/trained/ \\"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e9jOTBgzYzMB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Export trained model\n",
        "# Modified from https://github.com/RomRoc/objdet_train_tensorflow_colab/blob/master/objdet_custom_tf_colab.ipynb\n",
        "# Adjust pipeline_config_path and output_directory when switching between ssd and faster rcnn\n",
        "%cd train\n",
        "\n",
        "lst = os.listdir('tf_models/train_demo/ssd/trained')\n",
        "lf = filter(lambda k: 'model.ckpt-' in k, lst)\n",
        "last_model = sorted(lf)[-1].replace('.meta', '')\n",
        "\n",
        "!python tf_models/models/research/object_detection/export_inference_graph.py \\\n",
        "    --input_type=image_tensor \\\n",
        "    --pipeline_config_path=tf_models/models/research/object_detection/samples/configs/ssd/ssd_resnet50_v1_fpn_shared_box_predictor_640x640_coco14_sync_2018_07_03_bats.config \\\n",
        "    --output_directory=tf_models/train_demo/rcnn/finetuned_model \\\n",
        "    --trained_checkpoint_prefix=tf_models/train_demo/ssd/trained/$last_model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kGx_08UcmtOF",
        "colab_type": "text"
      },
      "source": [
        "### Test trained model on test images\n",
        "--- "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zlg-GTnKKRa3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%tensorflow_version 1.0\n",
        "\n",
        "import tensorflow as tf \n",
        "tf.compat.v1.enable_eager_execution()\n",
        "\n",
        "# For importing/exporting files, working with arrays, etc\n",
        "import os\n",
        "import pathlib\n",
        "import six.moves.urllib as urllib\n",
        "import sys\n",
        "import tarfile\n",
        "import zipfile\n",
        "import numpy as np \n",
        "import csv\n",
        "import matplotlib\n",
        "import time\n",
        "import pandas as pd\n",
        "\n",
        "# For downloading the images\n",
        "import tempfile\n",
        "from six.moves.urllib.request import urlopen\n",
        "from six import BytesIO\n",
        "from collections import defaultdict\n",
        "from io import StringIO\n",
        "\n",
        "# For drawing onto and plotting the images\n",
        "import matplotlib.pyplot as plt\n",
        "from PIL import Image\n",
        "from PIL import ImageColor\n",
        "from PIL import ImageDraw\n",
        "from PIL import ImageFont\n",
        "from PIL import ImageOps\n",
        "\n",
        "import cv2\n",
        "\n",
        "from IPython.display import display\n",
        "\n",
        "sys.path.append(\"tf_models/models/research/\")\n",
        "from object_detection.utils import ops as utils_ops\n",
        "from object_detection.utils import label_map_util\n",
        "from object_detection.utils import visualization_utils as vis_util\n",
        "%matplotlib inline"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8n_alUkLZ1gl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Load in trained model files\n",
        "%cd train\n",
        "\n",
        "# Path to frozen detection graph. This is the actual model that is used for the object detection.\n",
        "# SSD Model\n",
        "PATH_TO_CKPT = 'tf_models/train_demo/ssd/finetuned_model' + '/frozen_inference_graph.pb'\n",
        "# Faster RCNN Model\n",
        "#PATH_TO_CKPT = 'tf_models/train_demo/rcnn/finetuned_model' + '/frozen_inference_graph.pb'\n",
        "\n",
        "# List of the strings that is used to add correct label for each box.\n",
        "PATH_TO_LABELS = 'labelmap.pbtxt'\n",
        "\n",
        "NUM_CLASSES = 1\n",
        "    \n",
        "detection_graph = tf.Graph()\n",
        "with detection_graph.as_default():\n",
        "  od_graph_def = tf.compat.v1.GraphDef()\n",
        "  with tf.io.gfile.GFile(PATH_TO_CKPT, 'rb') as fid:\n",
        "    serialized_graph = fid.read()\n",
        "    od_graph_def.ParseFromString(serialized_graph)\n",
        "    tf.import_graph_def(od_graph_def, name='')\n",
        "    \n",
        "label_map = label_map_util.load_labelmap(PATH_TO_LABELS)\n",
        "categories = label_map_util.convert_label_map_to_categories(label_map, max_num_classes=NUM_CLASSES, use_display_name=True)\n",
        "category_index = label_map_util.create_category_index(categories)\n",
        "\n",
        "def load_image_into_numpy_array(image):\n",
        "  (im_width, im_height) = image.size\n",
        "  return np.array(image.getdata()).reshape(\n",
        "      (im_height, im_width, 3)).astype(np.uint8)\n",
        "\n",
        "# If you want to test the code with your images, just add path to the images to the TEST_IMAGE_PATHS.\n",
        "PATH_TO_TEST_IMAGES_DIR = 'test_images/'\n",
        "names = os.listdir(PATH_TO_TEST_IMAGES_DIR)\n",
        "#TEST_IMAGE_PATHS = [ os.path.join(PATH_TO_TEST_IMAGES_DIR, 'image{}.jpg'.format(i)) for i in range(1, 2) ]\n",
        "TEST_IMAGE_PATHS = [os.path.join(PATH_TO_TEST_IMAGES_DIR, name) for name in names]\n",
        "print(TEST_IMAGE_PATHS)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_Vvi4-2fm2qe",
        "colab_type": "text"
      },
      "source": [
        "## Define function for object detection\n",
        "---   \n",
        "Use a Tensorflow session to detect objects using pre-trained models and display the results of detection."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q9FZsaZkaPUz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def show_inference(image_np_expanded):\n",
        "  with detection_graph.as_default():\n",
        "    with tf.Session(graph=detection_graph) as sess:\n",
        "      # Definite input and output Tensors for detection_graph\n",
        "      image_tensor = detection_graph.get_tensor_by_name('image_tensor:0')\n",
        "      # Each box represents a part of the image where a particular object was detected.\n",
        "      detection_boxes = detection_graph.get_tensor_by_name('detection_boxes:0')\n",
        "      #max_boxes_to_draw = detection_boxes.shape[0] # add this line and remove (i) and (ii) below to show multiple detection boxes\n",
        "      # Each score represent how level of confidence for each of the objects.\n",
        "      # Score is shown on the result image, together with the class label.\n",
        "      detection_scores = detection_graph.get_tensor_by_name('detection_scores:0')\n",
        "      detection_classes = detection_graph.get_tensor_by_name('detection_classes:0')\n",
        "      num_detections = detection_graph.get_tensor_by_name('num_detections:0')\n",
        "      min_score_thresh = .7\n",
        "\n",
        "      # Actual detection.\n",
        "      (boxes, scores, classes, num) = sess.run(\n",
        "          [detection_boxes, detection_scores, detection_classes, num_detections],\n",
        "          feed_dict={image_tensor: image_np_expanded})\n",
        "      \n",
        "      # Visualization of the results of a detection.\n",
        "      vis_util.visualize_boxes_and_labels_on_image_array(\n",
        "          image_np,\n",
        "          np.squeeze(boxes),\n",
        "          np.squeeze(classes).astype(np.int32),\n",
        "          np.squeeze(scores),\n",
        "          category_index,\n",
        "          use_normalized_coordinates=True,\n",
        "          min_score_thresh=.7,\n",
        "          max_boxes_to_draw=1,\n",
        "          line_thickness=8)\n",
        "      \n",
        "      plt.figure()\n",
        "      plt.imshow(image_np)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CjE-Gh5ann4E",
        "colab_type": "text"
      },
      "source": [
        "## Load in test images and run them through the trained object detector\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iSPrkTKAglMZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Loops through first 5 image urls from the text file\n",
        "for image_path in TEST_IMAGE_PATHS[:20]:\n",
        " \n",
        "    # Record inference time\n",
        "    image = Image.open(image_path)\n",
        "    image_np = load_image_into_numpy_array(image)\n",
        "    # the array based representation of the image will be used later in order to prepare the\n",
        "    # result image with boxes and labels on it.\n",
        "    # Expand dimensions since the model expects images to have shape: [1, None, None, 3]\n",
        "    image_np_expanded = np.expand_dims(image_np, axis=0)\n",
        "    start_time = time.time()\n",
        "    show_inference(image_np_expanded)\n",
        "    end_time = time.time()\n",
        "    #print('Detection complete in {} of 145 test images'.format(i+1))\n",
        "\n",
        "    #add way to plot mAP\n",
        "    #plt.title('{}) Inference time: {}'.format(i+1, format(end_time-start_time, '.2f'))) "
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}