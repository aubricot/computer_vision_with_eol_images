{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.8"
    },
    "colab": {
      "name": "COLAB_object_detection_for_image_cropping_yolo_v3.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/aubricot/object_detection_for_image_cropping/blob/master/object_detection_for_image_cropping_yolo.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4Rnwb_rgmJZB",
        "colab_type": "text"
      },
      "source": [
        "# Using YOLO in Darkflow to detect birds from images\n",
        "---\n",
        "*Last Updated 9 December 2019*   \n",
        "Using YOLO via Darkflow as a method to do customized, large-scale image processing. Using the location and dimensions of the detected birds, images will be cropped to square dimensions that are centered and padded around the detection box. Pre-trained models are used for \"out of the box\" inference on images of birds of varying dimensions and resolutions, but will be modified and fine-tuned in future efforts for other taxonomic groups.\n",
        "\n",
        "This notebook is meant to be run enitrely in Google Colab and doesn't require any software installations or downloads to your local machine. To get started, just click the \"Open in Colab\" button. \n",
        "\n",
        "Note: Darkflow is currently only compatible with YOLO v1 and v2."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iJz5m4BKmJZD",
        "colab_type": "text"
      },
      "source": [
        "## Installs\n",
        "---\n",
        "Install required libraries directly to this Colab notebook."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yps_toNBmJZG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Make sure you are using Python 3.6\n",
        "# Install packages using pip\n",
        "!python --version\n",
        "!pip install tensorflow-gpu==1.15.0rc2\n",
        "!pip install cython\n",
        "!pip install opencv-python"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tTDwgHVFmJZH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Download darkflow (the tensorflow implementation of YOLO)\n",
        "import os\n",
        "import pathlib\n",
        "\n",
        "\n",
        "if \"darkflow-master\" in pathlib.Path.cwd().parts:\n",
        "  while \"darkflow-master\" in pathlib.Path.cwd().parts:\n",
        "    os.chdir('..')\n",
        "elif not pathlib.Path(\"darkflow-master\").exists():\n",
        "  !git clone --depth 1 https://github.com/thtrieu/darkflow.git"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "phxADa5YQu8N",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Compile darkflow\n",
        "%cd darkflow\n",
        "!python setup.py build_ext --inplace"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_vL-yNjfRsAP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Change darkflow to darkflow-master to distinguish between folder names\n",
        "%cd ../\n",
        "!mv darkflow darkflow-master"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yWAbU5tW1ONu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# (Optional) Mount google drive to export detection results as tsv\n",
        "# You can also test everything without running this chunk, detection results just won't be exported\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nwKdj73Wpnlz",
        "colab_type": "text"
      },
      "source": [
        "### Imports   \n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QSLXg6G7mJZP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%cd darkflow-master\n",
        "\n",
        "%tensorflow_version 1.15.0rc2\n",
        "import tensorflow as tf\n",
        "print(tf.__version__)\n",
        "\n",
        "# For importing/exporting files, working with arrays, etc\n",
        "import pathlib\n",
        "import time\n",
        "import csv\n",
        "import urllib\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "# For the actual object detection\n",
        "from darkflow.net.build import TFNet\n",
        "\n",
        "# For drawing onto and plotting the images\n",
        "import matplotlib.pyplot as plt\n",
        "import cv2\n",
        "%config InlineBackend.figure_format = 'svg'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X2fF0fSxmJZR",
        "colab_type": "text"
      },
      "source": [
        "### Model Preparation\n",
        "---   \n",
        "**Uploads**: The models are already in darkflow/cfg, but the pre-trained weights associated with these models need to be uploaded to this notebook from https://drive.google.com/drive/folders/0B1tW_VtY7onidEwyQ2FtQVplWEU. \n",
        "\n",
        "**\"Flowing\" images through the model**: Ignore the warning messages about deprecated names, they still work at the time this last updated. Code for parameters is based on https://github.com/thtrieu/darkflow (\"Using darkflow from another python application\").\n",
        "\n",
        "Your output should be a table of values like those shown below:\n",
        "\n",
        "Source | Train? | Layer description                | Output size\n",
        "------- |:--------:|:----------------------------------:| ---------------\n",
        "       |        | input                            | (?, 448, 448, 3)\n",
        " Load  |  Yep!  | scale to (-1, 1)                 | (?, 448, 448, 3)\n",
        " Load  |  Yep!  | conv 3x3p1_1    leaky            | (?, 448, 448, 16)\n",
        "\n",
        "**Define boxing function**: You can adjust the parameters so that bounding boxes are only shown for certain confidence or class values. Here boxes are shown when confidence > 0.45 and object class is 'bird'. This function is modified from here https://gist.github.com/deep-diver/40f092ad56525189674a86b6fde6d304."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7SXQ5bjUzA0u",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Upload yolo.weights, pre-trained weights file (for YOLO v2) from Google drive \n",
        "# For directions to upload other weights files, see the wiki for this repository\n",
        "weights = 'yolo'\n",
        "weights_file = weights + '.weights'\n",
        "if not os.path.exists('weights_file'):\n",
        "  !gdown --id 0B1tW_VtY7oniTnBYYWdqSHNGSUU\n",
        "  !mkdir bin\n",
        "  !mv yolo.weights bin"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5ZtuRfxoH060",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Upload yolo-tiny.weights\n",
        "weights = 'yolo-tiny'\n",
        "weights_file = weights + '.weights'\n",
        "if not os.path.exists('weights_file'):\n",
        "  !gdown --id 0B1tW_VtY7onibmdQWE1zVERxcjQ\n",
        "  !mv yolo-tiny.weights bin"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5b9QiWRfCZF3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Move yolo-tiny.cfg model from cfg/v1 to cfg/\n",
        "# File from https://github.com/cvjena/darknet/blob/master/cfg/yolo-tiny.cfg\n",
        "!mv cfg/v1/yolo-tiny.cfg cfg"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "268I2Ev_mJZL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Test installation, you should see an output with different parameters for flow\n",
        "%cd darkflow-master\n",
        "!pwd\n",
        "!python flow --h"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R2wnfMcDmJZS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Define parameters for \"flow\"ing the images through the model\n",
        "# Can change model and weights files here, tiny-yolo is faster but less accurate\n",
        "params = {\n",
        "    'model': 'cfg/yolo.cfg',\n",
        "    'load': 'bin/yolo.weights',\n",
        "    'threshold': 0.45, \n",
        "    'gpu': 1.0\n",
        "}\n",
        "\n",
        "# Run the model\n",
        "tfnet = TFNet(params)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9Ta5pbiYysKg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# For uploading an image from url\n",
        "# Modified from https://www.pyimagesearch.com/2015/03/02/convert-url-to-image-with-python-and-opencv/\n",
        "def url_to_image(url):\n",
        "  resp = urllib.request.urlopen(url)\n",
        "  image = np.asarray(bytearray(resp.read()), dtype=\"uint8\")\n",
        "  image = cv2.imdecode(image, cv2.IMREAD_COLOR)\n",
        "  image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        " \n",
        "  return image"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qSsyvhFrmJZX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# For drawing bounding boxes around detected objects on images\n",
        "def boxing(image, predictions):\n",
        "    newImage = np.copy(image)\n",
        "    im_height, im_width, im_depth = image.shape\n",
        "        \n",
        "    for result in predictions:\n",
        "        xmin = result['topleft']['x']\n",
        "        ymin = result['topleft']['y']\n",
        "\n",
        "        xmax = result['bottomright']['x']\n",
        "        ymax = result['bottomright']['y']\n",
        "\n",
        "        confidence = result['confidence']\n",
        "        label = result['label'] + \" \" + str(round(confidence, 3))\n",
        "\n",
        "        # only show boxes that are above .1 confidence and for the label, bird\n",
        "        if confidence > 0.45 and result['label'] == 'bird' :\n",
        "            # draw boxes on images\n",
        "            fontScale = min(im_width,im_height)/(600)\n",
        "            newImage = cv2.rectangle(newImage, (xmin, ymax), (xmax, ymin), (255, 0, 157), 3)\n",
        "            newImage = cv2.putText(newImage, label, (xmin, ymax-5), cv2.FONT_HERSHEY_SIMPLEX, fontScale, (153, 255, 255), 5, cv2.LINE_AA)\n",
        "\n",
        "            # optional: if mounted to drive, export detection results to sample_crops_yolo.tsv\n",
        "            # must make empty sample_crops_yolo.tsv file in your drive first and paste the path to it below\n",
        "            if os.path.exists('/content/drive/My Drive/fall19_smithsonian_informatics/sample_crops_yolo_1.tsv'):\n",
        "              with open('/content/drive/My Drive/fall19_smithsonian_informatics/sample_crops_yolo_20000imgc.tsv', 'a') as out_file:\n",
        "                  tsv_writer = csv.writer(out_file, delimiter='\\t')\n",
        "                  #crop_width = xmax-xmin\n",
        "                  #crop_height = ymax-ymin\n",
        "                  tsv_writer.writerow([image_url, im_height, im_width, \n",
        "                            xmin, ymin, xmax, ymax])\n",
        "            \n",
        "        else:\n",
        "          print(\"No birds detected in {}.\".format(image_url))\n",
        "    return newImage"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "1zL-PctVuqZv"
      },
      "source": [
        "## Load in sample images and 'flow' them through the object detector\n",
        "---\n",
        "You can either **A) Load individual images in by URL**, or for large image batches or **B) Load multiple images from a text file of image URLs**. Other methods for importing to Google Colab are listed [here](https://colab.research.google.com/notebooks/io.ipynb#scrollTo=XDg9OBaYqRMd). "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7gd4TbiOEXff",
        "colab_type": "text"
      },
      "source": [
        "**A) Load individual images in by URL**\n",
        "Load in images by URL and run the image detector for all images. Plotted results include the image with bounding box around detected objects (birds), class type, and confidence score. Inference times are printed above images. If you \"mounted\" your Google Drive during \"Installs\", the bounding box coordinates will also be written to 'sample_crops_yolo.tsv'."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lke_VvPzt71m",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "image_urls = [\"https://content.eol.org/data/media/7e/9c/7a/542.15445377044.jpg\",\n",
        "              \"https://content.eol.org/data/media/81/1c/0d/542.7816025222.jpg\",\n",
        "              \"https://content.eol.org/data/media/7e/3c/0b/542.10578857864.jpg\"]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qNsodQP3t_o5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for image_url in image_urls:\n",
        "  image = url_to_image(image_url)\n",
        "\n",
        "  # Use YOLO for object detection  \n",
        "  # Record inference time\n",
        "  start_time = time.time()\n",
        "  result = tfnet.return_predict(image)\n",
        "  end_time = time.time()\n",
        "\n",
        "  # Plot and show detection boxes on images\n",
        "  _, ax = plt.subplots(figsize=(10, 10))\n",
        "  ax.imshow(boxing(image, result))\n",
        "\n",
        "  # Display inference time above images\n",
        "  plt.title('Inference time: {}'.format(format(end_time-start_time, '.2f')))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WStwvg5GmJZZ",
        "colab_type": "text"
      },
      "source": [
        "**B) Load multiple images from a text file of image URLs**\n",
        "Load in multiple images from a text file of URLS and run the image detector for all images. Plotted results include the image with bounding box around detected objects (birds), class type, and confidence score. Inference times are printed above images. If you \"mounted\" your Google Drive during \"Installs\", the bounding box coordinates will also be written to 'sample_crops_yolo.tsv'."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gukCG-BVA6hm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "urls = 'https://editors.eol.org/other_files/bundle_images/files/images_for_Aves_20K_breakdown_download_000001.txt'\n",
        "df1 = pd.read_csv(urls)\n",
        "df1.columns = [\"link\"]\n",
        "pd.DataFrame.head(df1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": false,
        "id": "UbyA9e1omJZZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Loops through first 5 image urls from the text file\n",
        "for i, row in df1.head(5).itertuples(index=True, name='Pandas'):\n",
        "\n",
        "# For ranges of rows or all rows, use the commands below\n",
        "# Can be useful if running batch jobs\n",
        "#for i, row in df1.iloc[500:800].iterrows():\n",
        "#for i, row in df1.itertuples(index=True, name='Pandas'):\n",
        "#for i, row in df1.tail(5).itertuples(index=True, name='Pandas'):\n",
        "\n",
        "  try:\n",
        "    # Record inference time\n",
        "    start_time = time.time()\n",
        "    image_url = df1.get_value(i, \"link\")\n",
        "    image = url_to_image(image_url)\n",
        "    # Detection\n",
        "    result = tfnet.return_predict(image)\n",
        "    end_time = time.time()\n",
        "    # Draw boxes on images\n",
        "    boxing(image, result)\n",
        "  \n",
        "    # If running detection on >50 images, do not display detection results\n",
        "    # Instead run below command to track progress\n",
        "    #print('Detection complete in {} of 1,000 images'.format(i+1))\n",
        "  \n",
        "  except:\n",
        "    print('Error: check if web address is valid')\n",
        "  \n",
        "  # Plot and show detection boxes on images\n",
        "  # Hashtag out this portion if running detection on >50 images\n",
        "  _, ax = plt.subplots(figsize=(10, 10))\n",
        "  ax.imshow(boxing(image, result))\n",
        "  plt.title('{}) Inference time: {}'.format(i+1, format(end_time-start_time, '.2f')))\n",
        "  plt.close()"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}
