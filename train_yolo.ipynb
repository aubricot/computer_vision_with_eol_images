{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.8"
    },
    "colab": {
      "name": "train_yolo.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "X2fF0fSxmJZR"
      ],
      "toc_visible": true,
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/aubricot/object_detection_for_image_cropping/blob/master/train_yolo.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4Rnwb_rgmJZB",
        "colab_type": "text"
      },
      "source": [
        "# Training YOLO in Darkflow to detect bats from EOL images\n",
        "---\n",
        "*Last Updated 3 February 2020*   \n",
        "Use images and annotation files to train YOLO in Darkflow to detect bats from EOL images.\n",
        "\n",
        "Datasets exported from [preprocessing.ipynb](https://colab.research.google.com/github/aubricot/object_detection_for_image_cropping/blob/master/preprocessing.ipynb) were converted to xml formatted annotation files before use in this notebook. Images were already downloaded to Google Drive in preprocessing.ipynb. Annotations should be uploaded to Google Drive before using this notebook. Exported detection results (json files) can be used to calculate model precision for comparison with Faster-RCNN and SSD models using [calculate_error_mAP.ipynb](https://colab.research.google.com/github/aubricot/object_detection_for_image_cropping/blob/master/calculate_error_mAP.ipynb). \n",
        "\n",
        "Notes:   \n",
        "* For each 24 hour period on Google Colab, you have up to 12 hours of GPU access. Training the object detection model on bats took 30 hours split into 3 days.\n",
        "\n",
        "* Make sure to set the runtime to Python 2 with GPU Hardware Accelerator.   \n",
        "\n",
        "References:   \n",
        "* [Official Darkflow training instructions](https://github.com/thtrieu/darkflow)   \n",
        "* [Medium Blog on training using YOLO via Darkflow in Colab](https://medium.com/coinmonks/detecting-custom-objects-in-images-video-using-yolo-with-darkflow-1ff119fa002f)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iJz5m4BKmJZD",
        "colab_type": "text"
      },
      "source": [
        "## Installs\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yWAbU5tW1ONu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Mount google drive to import/export files\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yj3-JKOsIPtc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Change to your working directory\n",
        "%cd drive/My Drive/fall19_smithsonian_informatics/train\n",
        "\n",
        "# Install libraries\n",
        "# Make sure you are using Python 3.6\n",
        "!python --version\n",
        "!pip install tensorflow-gpu==1.15.0rc2\n",
        "!pip install cython\n",
        "!pip install opencv-python"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wKYxuyq5Ib_f",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Download darkflow (the tensorflow implementation of YOLO)\n",
        "import os\n",
        "import pathlib\n",
        "import shutil \n",
        "\n",
        "if os.path.exists(\"darkflow-master\"):\n",
        "  %cd darkflow-master/darkflow\n",
        "  !pwd\n",
        "\n",
        "elif not os.path.exists(\"darkflow-master\"):\n",
        "    !git clone --depth 1 https://github.com/thtrieu/darkflow.git\n",
        "    # Compile darkflow\n",
        "    %cd darkflow\n",
        "    !python setup.py build_ext --inplace\n",
        "    # Rename darkflow to darkflow-master to distinguish between folder names\n",
        "    shutil.move('/content/drive/My Drive/fall19_smithsonian_informatics/train/darkflow', \n",
        "              '/content/drive/My Drive/fall19_smithsonian_informatics/train/darkflow-master')\n",
        "\n",
        "# Change wd to darkflow-master\n",
        "%cd ../"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nwKdj73Wpnlz",
        "colab_type": "text"
      },
      "source": [
        "### Imports   \n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QSLXg6G7mJZP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%cd darkflow-master\n",
        "\n",
        "# For importing/exporting files, working with arrays, etc\n",
        "from google.colab import files\n",
        "import os\n",
        "import pathlib\n",
        "import imageio\n",
        "import time\n",
        "import csv\n",
        "import urllib\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "# For the actual object detection\n",
        "from darkflow.net.build import TFNet\n",
        "\n",
        "# For drawing onto and plotting the images\n",
        "import matplotlib.pyplot as plt\n",
        "import cv2\n",
        "%config InlineBackend.figure_format = 'svg'\n",
        "%matplotlib inline"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X2fF0fSxmJZR",
        "colab_type": "text"
      },
      "source": [
        "### Model Preparation (only need to run these once)\n",
        "---   \n",
        "For detailed instructions on training YOLO using a custom dataset, see the [Darkflow GitHub Repository](https://github.com/thtrieu/darkflow)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "268I2Ev_mJZL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Test installation, you should see an output with different parameters for flow\n",
        "!python flow --h"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7SXQ5bjUzA0u",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Upload yolo.weights, pre-trained weights file (for YOLO v2) from Google drive \n",
        "weights = 'bin/yolo'\n",
        "weights_file = weights + '.weights'\n",
        "if not os.path.exists('weights_file'): # why is this downloading when the path exists?\n",
        "  !gdown --id 0B1tW_VtY7oniTnBYYWdqSHNGSUU\n",
        "  !mkdir bin\n",
        "  !mv yolo.weights bin"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OXLOezJnT7O6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Make new label file/overwrite existing labels.txt downloaded with darkflow\n",
        "!echo \"Chiroptera\" > labels.txt\n",
        "\n",
        "# Download model config file edited for training darkflow to identify bats (yolo-1c = yolo to identify 1 class)\n",
        "config = 'yolo-1c'\n",
        "mod_config = config + '.cfg'\n",
        "if not os.path.exists('mod_config'):\n",
        "  %cd train/darkflow-master/cfg\n",
        "  !gdown --id 1bjt5Mqvf4AZSLNARgtgmZsfHZSyFj2yx"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w3ouL5RM-mpX",
        "colab_type": "text"
      },
      "source": [
        "## Train the model\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pn4U3HOTgPVX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Train yolo-1c using pre-trained weights at yolo.weights for basal layers, last layer will be trained from scracth to detect bats\n",
        "# Change the dataset and annotation directories to your paths in GoogleDrive\n",
        "%cd darkflow-master\n",
        "!python flow --model cfg/yolo-1c.cfg --train --trainer adam --load bin/yolo.weights --gpu 0.8 --epoch 3000 --dataset \"/content/drive/My Drive/fall19_smithsonian_informatics/train/images\" --annotation \"test/training/annotations\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LZoKtS-xhbQm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# For training the model starting from specified checkpoint\n",
        "# change --load 750 to the number of steps of your most recent checkpoint file\n",
        "#--pbLoad .pb --metaLoad .meta\n",
        "!python flow --load -1 --model cfg/yolo-1c.cfg --train --savepb --trainer adam --gpu 0.8 --epoch 3000 --dataset \"/content/drive/My Drive/fall19_smithsonian_informatics/train/images\" --annotation \"test/training/annotations\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UqA_lW7tbLeH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Save the last checkpoint to protobuf file\n",
        "!python flow --model cfg/yolo-1c.cfg --load -1 --savepb"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5GhWXLLlPNrr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Export detection results as json files fo calculating mAP in calculate_error_mAP.ipynb\n",
        "!python flow --pbLoad built_graph/yolo-1c.pb --gpu 0.8 --metaLoad built_graph/yolo-1c.meta --imgdir \"/content/drive/My Drive/fall19_smithsonian_informatics/train/test_images\" --json"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "1zL-PctVuqZv"
      },
      "source": [
        "## Load in test images and run them through the trained object detector\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2PXMk2Rtsnk-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# For loading images into computer-readable format\n",
        "def load_image_into_numpy_array(image):\n",
        "  (im_width, im_height) = image.size\n",
        "  return np.array(image.getdata()).reshape((im_height, im_width, 3)).astype(np.uint8)\n",
        "\n",
        "# For drawing bounding boxes around detected objects on images\n",
        "def boxing(image, predictions):\n",
        "    newImage = np.copy(image)\n",
        "    im_height, im_width, im_depth = image.shape\n",
        "\n",
        "    # Oraganize results of object detection for plotting and export\n",
        "    for result in predictions:\n",
        "        xmin = result['topleft']['x']\n",
        "        ymin = result['topleft']['y']\n",
        "\n",
        "        xmax = result['bottomright']['x']\n",
        "        ymax = result['bottomright']['y']\n",
        "\n",
        "        confidence = result['confidence']\n",
        "        label = result['label'] + \" \" + str(round(confidence, 3))\n",
        "\n",
        "        # only show boxes that are above set confidence and for the label Chiroptera\n",
        "        if confidence > 0 and result['label'] == 'Chiroptera' :\n",
        "            # draw boxes on images\n",
        "            fontScale = min(im_width,im_height)/(600)\n",
        "            newImage = cv2.rectangle(newImage, (xmin, ymax), (xmax, ymin), (255, 0, 157), 3)\n",
        "            newImage = cv2.putText(newImage, label, (xmin, ymax-5), cv2.FONT_HERSHEY_SIMPLEX, fontScale, (153, 255, 255), 5, cv2.LINE_AA)\n",
        "\n",
        "    return newImage\n",
        "\n",
        "# Define parameters for \"flow\"ing the images through the model\n",
        "params = {\n",
        "    'model': 'cfg/yolo-1c.cfg',\n",
        "    'load': 'bin/yolo.weights',\n",
        "    'gpu': 0.8,\n",
        "    #'threshold': 0.1, \n",
        "    'pbLoad': 'built_graph/yolo-1c.pb', \n",
        "    'metaLoad': 'built_graph/yolo-1c.meta' \n",
        "}\n",
        "\n",
        "# Run the model\n",
        "tfnet = TFNet(params)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": false,
        "id": "UbyA9e1omJZZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Test trained model on test images\n",
        "from PIL import Image\n",
        "\n",
        "# Update path to your test images\n",
        "PATH_TO_TEST_IMAGES_DIR = '/content/drive/My Drive/fall19_smithsonian_informatics/train/test_images'\n",
        "names = os.listdir(PATH_TO_TEST_IMAGES_DIR)\n",
        "TEST_IMAGE_PATHS = [os.path.join(PATH_TO_TEST_IMAGES_DIR, name) for name in names]\n",
        "\n",
        "# Loops through first 5 image urls from the text file\n",
        "for im_num, im_path in enumerate(TEST_IMAGE_PATHS[:5], start=1):\n",
        "\n",
        "    # Record inference time\n",
        "    start_time = time.time()\n",
        "    image = Image.open(im_path)\n",
        "    image_np = load_image_into_numpy_array(image)\n",
        "    # Detection\n",
        "    result = tfnet.return_predict(image_np)\n",
        "    end_time = time.time()\n",
        "    # Draw boxes on images\n",
        "    boxing(image_np, result)\n",
        "  \n",
        "    # If running detection on >50 images, do not display detection results\n",
        "    # Instead run below command to track progress\n",
        "    print('Detection complete in {} of 145 test images'.format(im_num))\n",
        "\n",
        "    # Plot and show detection boxes on images\n",
        "    # Hashtag out this portion if running detection on >50 images\n",
        "    _, ax = plt.subplots(figsize=(10, 10))\n",
        "    ax.imshow(boxing(image_np, result))\n",
        "    plt.title('{}) Inference time: {}'.format(im_num, format(end_time-start_time, '.2f')))\n",
        "    #plt.close()"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}