{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.8"
    },
    "colab": {
      "name": "image_augmentation.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/aubricot/object_detection_for_image_cropping/blob/master/image_augmentation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4Rnwb_rgmJZB",
        "colab_type": "text"
      },
      "source": [
        "# Image augmentation to diversify and increase the amount of training data for object detection\n",
        "---\n",
        "*Last Updated 15 January 2020*   \n",
        "Image augmentation with the [imgaug library](https://github.com/aleju/imgaug) is used to increase training data sample size and diversity to reduce overfitting when training our object detection model. Instead of creating image annotations from scratch, EOL user-generated cropping coordinates are used and the resulting augmented bounding boxes and images will be converted to the neccessary annotation formats to train YOLO via darkflow, SSD and Faster-RCNN object detection models.\n",
        "\n",
        "After exporting resulting augmented box coordinates from this notebook, test displaying them using [coordinates_display_test.ipynb](https://colab.research.google.com/github/aubricot/object_detection_for_image_cropping/blob/master/coordinates_display_test.ipynb). If they are not as expected, modify data cleaning steps in the section **Tidy combined dataset** below until the desired results are achieved. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iJz5m4BKmJZD",
        "colab_type": "text"
      },
      "source": [
        "## Installs\n",
        "---\n",
        "Install required libraries directly to this Colab notebook."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "01UXykSJp610",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Install libraries for augmenting and displaying images\n",
        "!pip install imgaug\n",
        "!pip install pillow\n",
        "!pip install scipy==1.1.0"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yWAbU5tW1ONu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Mount google drive to import/export files\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nwKdj73Wpnlz",
        "colab_type": "text"
      },
      "source": [
        "### Imports   \n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QSLXg6G7mJZP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Change to your training directory within Google Drive\n",
        "%cd drive/My Drive/fall19_smithsonian_informatics/train\n",
        "\n",
        "# For importing/exporting files, working with arrays, etc\n",
        "import pathlib\n",
        "import os\n",
        "import imageio\n",
        "import time\n",
        "import csv\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from urllib.request import urlopen\n",
        "from scipy.misc import imread\n",
        "\n",
        "# For augmenting the images and bounding boxes\n",
        "import imgaug as ia\n",
        "import imgaug.augmenters as iaa\n",
        "from imgaug.augmentables.bbs import BoundingBox, BoundingBoxesOnImage\n",
        "\n",
        "# For drawing onto and plotting the images\n",
        "import matplotlib.pyplot as plt\n",
        "import cv2\n",
        "%config InlineBackend.figure_format = 'svg'\n",
        "%matplotlib inline"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "1zL-PctVuqZv"
      },
      "source": [
        "## Import images and cropping coordinates to be augmented\n",
        "--- "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OEBgPVe6_lGK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Read in EOL images and user-generated cropping coordinates (used as bounding boxes here)\n",
        "crops = pd.read_csv('/content/drive/My Drive/fall19_smithsonian_informatics/train/chiroptera_crops.tsv', sep='\\t', header=0)\n",
        "crops.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NQMissGFWUz5",
        "colab_type": "text"
      },
      "source": [
        "## Augment a single image   \n",
        "--- "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J2bmK-mINdmw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# First display original/un-augmented image and cropping coordinates to test that the libraries are installed properly\n",
        "\n",
        "# Import image from URL\n",
        "# Use imread instead of imageio.imread to load images from URL and get consistent output type and shape\n",
        "i = 2\n",
        "url = crops.get_value(i, \"obj_url\")\n",
        "print(url)\n",
        "with urlopen(url) as file:\n",
        "    image = imread(file, mode='RGB') # RGB mode so B/W and color images have same array shape\n",
        "\n",
        "# Import and reformat bounding box coordinates\n",
        "bb  = ia.BoundingBox(x1=crops.xmin[2].astype(int), y1=crops.ymin[2].astype(int), \n",
        "        x2=crops.xmax[2].astype(int), y2=crops.ymax[2].astype(int))        \n",
        "bb = BoundingBoxesOnImage([bb], shape=image.shape)\n",
        "\n",
        "# Draw box on image\n",
        "imagewbox = cv2.rectangle(image, (bb.bounding_boxes[0].x1, bb.bounding_boxes[0].y1), \n",
        "                      (bb.bounding_boxes[0].x2, bb.bounding_boxes[0].y2), \n",
        "                      (255, 0, 157), 3)\n",
        "\n",
        "# Plot image with box\n",
        "_, ax = plt.subplots(figsize=(10, 10))\n",
        "ax.imshow(imagewbox)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r76-qzXlxIe-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Next test augmenting a single image and its crop coordinates and display the results\n",
        "\n",
        "# For image augmentation\n",
        "from imgaug import augmenters as iaa\n",
        "\n",
        "# Import image from URL\n",
        "# Use imread instead of imageio.imread to load images from URL and get consistent output type and shape\n",
        "i = 2\n",
        "url = crops.get_value(i, \"obj_url\")\n",
        "print(url)\n",
        "with urlopen(url) as file:\n",
        "    image = imread(file, mode='RGB')\n",
        "\n",
        "# Import bounding box coordinates\n",
        "bb  = ia.BoundingBox(x1=crops.xmin[i].astype(int), y1=crops.ymin[i].astype(int), \n",
        "        x2=crops.xmax[i].astype(int), y2=crops.ymax[i].astype(int))        \n",
        "bb = BoundingBoxesOnImage([bb], shape=image.shape)\n",
        "\n",
        "# Define image augmentation pipeline\n",
        "# modified from https://github.com/aleju/imgaug\n",
        "seq = iaa.Sequential([\n",
        "    iaa.Crop(px=(1, 16), keep_size=True), # crop by 1-16px, resize resulting image to orig dims\n",
        "    iaa.Affine(rotate=(-25, 25)), # rotate -25 to 25 degrees\n",
        "    iaa.GaussianBlur(sigma=(0, 3.0)) # blur using gaussian kernel with sigma of 0-3\n",
        "])\n",
        "\n",
        "# Augment image using defined settings in seq\n",
        "image_aug, bb_aug = seq.augment(image=image, bounding_boxes=bb)\n",
        "\n",
        "# Draw box on image\n",
        "imagewbox = cv2.rectangle(image_aug, (bb_aug.bounding_boxes[0].x1.astype(int), bb_aug.bounding_boxes[0].y1.astype(int)), \n",
        "                      (bb_aug.bounding_boxes[0].x2.astype(int), bb_aug.bounding_boxes[0].y2.astype(int)), \n",
        "                      (255, 0, 157), 3) # change box color and thickness\n",
        "\n",
        "# Display augmented image and bounding box\n",
        "_, ax = plt.subplots(figsize=(10, 10))\n",
        "ax.imshow(imagewbox)\n",
        "# Show url above image to aid with troubleshooting\n",
        "plt.title('{}) Image from {}'.format(format(i+1, '.0f'), url))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cGMDGahzm44x",
        "colab_type": "text"
      },
      "source": [
        "## Augment multiple images  \n",
        "---   \n",
        "  "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "P31JjHddVSEm",
        "colab": {}
      },
      "source": [
        "# Augment multple images and cropping coordinates and display them\n",
        "# Will also download augmented images and bounding boxes to your Google Drive\n",
        "\n",
        "# For image augmentation\n",
        "from imgaug import augmenters as iaa\n",
        "\n",
        "# Set number of seconds to timeout if image url taking too long to open\n",
        "import socket\n",
        "socket.setdefaulttimeout(10)\n",
        "\n",
        "# Optional: set seed to make augmentations reproducible across runs, otherwise will be random each time\n",
        "ia.seed(1) \n",
        "\n",
        "# For saving images to Google Drive\n",
        "from scipy import misc\n",
        "\n",
        "# Define image augmentation pipeline\n",
        "# modified from https://github.com/aleju/imgaug\n",
        "seq = iaa.Sequential([\n",
        "    iaa.Crop(px=(1, 16), keep_size=False), # crop by 1-16px, resize resulting image to orig dims\n",
        "    iaa.Affine(rotate=(-25, 25)), # rotate -25 to 25 degrees\n",
        "    iaa.GaussianBlur(sigma=(0, 3.0)) # blur using gaussian kernel with sigma of 0-3\n",
        "])\n",
        "\n",
        "# Write header of crops_aug.tsv before looping through crops for remaining data\n",
        "if os.path.exists('/content/drive/My Drive/fall19_smithsonian_informatics/train'):\n",
        "        with open('/content/drive/My Drive/fall19_smithsonian_informatics/train/chiroptera_crops_aug.tsv', 'a') as out_file:\n",
        "            tsv_writer = csv.writer(out_file, delimiter='\\t')\n",
        "            tsv_writer.writerow([\"data_object_id\",\t\"obj_url\",\t\"height\",\t\"width\",\t\"xmin\",\n",
        "                                 \"ymin\",\t\"xmax\",\t\"ymax\",\t\"filename\",\t\"path\",\t\"name\"])\n",
        "\n",
        "# Loop to perform image augmentation for each image in crops\n",
        "# First test on 5 images from crops\n",
        "for i, row in crops.head(5).iterrows():\n",
        "# Next run on all rows\n",
        "#for i, row in crops.iterrows():\n",
        "  try:\n",
        "    # Import image from url\n",
        "    # Use imread instead of imageio.imread to load images from url and get consistent output type and shape\n",
        "    url = crops.get_value(i, \"obj_url\")\n",
        "    with urlopen(url) as file:\n",
        "      image = imread(file, mode='RGB')\n",
        "\n",
        "    # Import bounding box coordinates\n",
        "    bb  = ia.BoundingBox(x1=crops.xmin[i].astype(int), y1=crops.ymin[i].astype(int), \n",
        "        x2=crops.xmax[i].astype(int), y2=crops.ymax[i].astype(int))        \n",
        "    bb = BoundingBoxesOnImage([bb], shape=image.shape)\n",
        "    \n",
        "    # Augment image using settings defined above in seq\n",
        "    image_aug, bb_aug = seq.augment(image=image, bounding_boxes=bb)\n",
        "    \n",
        "    # Define augmentation results needed in exported dataset\n",
        "    pathbase = '/content/drive/My Drive/fall19_smithsonian_informatics/train/images/'\n",
        "    path_aug = pathbase + str(crops.data_object_id[i]) + '_aug' + '.jpg'\n",
        "    filename_aug = str(crops.data_object_id[i]) + '_aug' + '.jpg'\n",
        "    obj_id = crops.data_object_id[i]\n",
        "    height, width, depth = image_aug.shape\n",
        "    xmin_aug = bb_aug.bounding_boxes[0].x1.astype(int)\n",
        "    ymin_aug = bb_aug.bounding_boxes[0].y1.astype(int)\n",
        "    xmax_aug = bb_aug.bounding_boxes[0].x2.astype(int)\n",
        "    ymax_aug = bb_aug.bounding_boxes[0].y2.astype(int)\n",
        "    name = str(\"Chiroptera\")\n",
        "\n",
        "    # Export augmented images to Google Drive\n",
        "    misc.imsave(path_aug, image_aug)\n",
        "    \n",
        "    # Draw augmented bounding box and image\n",
        "    # Only use this for 20-30 images, otherwise hashtag out\n",
        "    imagewbox = cv2.rectangle(image_aug, (xmin_aug, ymin_aug), \n",
        "                      (xmax_aug, ymax_aug), \n",
        "                      (255, 0, 157), 3) # change box color and thickness\n",
        "    _, ax = plt.subplots(figsize=(10, 10))\n",
        "    ax.imshow(imagewbox)\n",
        "    plt.title('{}) Successfully augmented image from {}'.format(format(i+1, '.0f'), url))\n",
        "    \n",
        "    # Export augmentation results to crops_aug.tsv\n",
        "    if os.path.exists('/content/drive/My Drive/fall19_smithsonian_informatics/train'):\n",
        "        with open('/content/drive/My Drive/fall19_smithsonian_informatics/train/chiroptera_crops_aug.tsv', 'a') as out_file:\n",
        "            tsv_writer = csv.writer(out_file, delimiter='\\t')\n",
        "            tsv_writer.writerow([crops.data_object_id[i], crops.obj_url[i], height, width,\n",
        "                                 xmin_aug, ymin_aug, xmax_aug, ymax_aug, filename_aug, path_aug, name])\n",
        "    \n",
        "    # Display message to track augmentation process by image\n",
        "    print('{}) Successfully augmented image from {}'.format(format(i+1, '.0f'), url))\n",
        "  \n",
        "  except:\n",
        "    print('{}) Error: check if web address for image from {} is valid'.format(format(i+1, '.0f'), url))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "zSaSmJC8hc-j",
        "colab": {}
      },
      "source": [
        "# Download un-augmented images to your Google Drive \n",
        "# All images will need to be stored together for training in future notebooks\n",
        "\n",
        "# For saving images to Google Drive\n",
        "from scipy import misc\n",
        "\n",
        "# Set number of seconds to timeout if image url taking too long to open\n",
        "import socket\n",
        "socket.setdefaulttimeout(10)\n",
        "\n",
        "for i, row in crops.iterrows():\n",
        "  try:\n",
        "    # Import image from url\n",
        "    # Use imread instead of imageio.imread to load images from url and get consistent output type and shape\n",
        "    url = crops.get_value(i, \"obj_url\")\n",
        "    with urlopen(url) as file:\n",
        "      image = imread(file, mode='RGB')\n",
        "\n",
        "    # Define paths and filenames for augmented and unaugmented images\n",
        "    pathbase = '/content/drive/My Drive/fall19_smithsonian_informatics/train/images/'\n",
        "    path = pathbase + str(crops.data_object_id[i]) + '.jpg'\n",
        "    filename = str(crops.data_object_id[i]) + '.jpg'\n",
        "     \n",
        "    # Export augmented images to Google Drive\n",
        "    misc.imsave(path, image)\n",
        "  \n",
        "    # Display message to track augmentation process by image\n",
        "    print('{}) Successfully downloaded image from {} to Google Drive'.format(format(i+1, '.0f'), url))\n",
        "  \n",
        "  except:\n",
        "    print('{}) Error: check if web address for image from {} is valid'.format(format(i+1, '.0f'), url))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tdW2BS2tLcdD",
        "colab_type": "text"
      },
      "source": [
        "## Combine augmented and un-augmented bounding box and image data\n",
        "---   "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s2p52DyDH5jv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Create new df with un-augmented/original bounding boxes and images that is formatted the same as the augmented data\n",
        "\n",
        "# Write header of crops_notaug.tsv before looping through crops for other data\n",
        "if os.path.exists('/content/drive/My Drive/fall19_smithsonian_informatics/train'):\n",
        "        with open('/content/drive/My Drive/fall19_smithsonian_informatics/train/chiroptera_crops_notaug.tsv', 'a') as out_file:\n",
        "            tsv_writer = csv.writer(out_file, delimiter='\\t')\n",
        "            tsv_writer.writerow([\"data_object_id\",\t\"obj_url\",\t\"height\",\t\"width\",\t\"xmin\",\n",
        "                                 \"ymin\",\t\"xmax\",\t\"ymax\",\t\"filename\",\t\"path\",\t\"name\"])\n",
        "\n",
        "# Loop through crops to get images and bounding boxes\n",
        "for i, row in crops.iterrows():\n",
        "  try:\n",
        "    # Import images from crops\n",
        "    # Use imread instead of imageio.imread to load images from url and get consistent output type and shape\n",
        "    url = crops.get_value(i, \"obj_url\")\n",
        "    with urlopen(url) as file:\n",
        "      image = imread(file, mode='RGB')\n",
        "    height, width, depth = image.shape\n",
        "    pathbase = '/content/drive/My Drive/fall19_smithsonian_informatics/train/images/'\n",
        "    path = pathbase + str(crops.data_object_id[i]) + '.jpg'\n",
        "    filename = str(crops.data_object_id[i]) + '.jpg'\n",
        "    name = str(\"Chiroptera\")\n",
        "    \n",
        "    # Write results to crops_notaug.tsv\n",
        "    if os.path.exists('/content/drive/My Drive/fall19_smithsonian_informatics/train'):\n",
        "        with open('/content/drive/My Drive/fall19_smithsonian_informatics/train/chiroptera_crops_notaug.tsv', 'a') as out_file:\n",
        "            tsv_writer = csv.writer(out_file, delimiter='\\t')\n",
        "            tsv_writer.writerow([crops.data_object_id[i], crops.obj_url[i], height, width, \n",
        "                                 crops.xmin[i], crops.ymin[i], crops.xmax[i], crops.ymax[i], filename, path, name])\n",
        "    \n",
        "    # Display message to track augmentation process by image\n",
        "    print('{}) Successfully loaded image from {}'.format(format(i+1, '.0f'), url))\n",
        "  \n",
        "  except:\n",
        "    print('{}) Error: check if web address for image from {} is valid'.format(format(i+1, '.0f'), url))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IcoddLLP8l1t",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Combine augmented and un-augmented datasets\n",
        "\n",
        "# File names to be combined\n",
        "all_filenames = [\"/content/drive/My Drive/fall19_smithsonian_informatics/train/chiroptera_crops_aug.tsv\",\n",
        "                 \"/content/drive/My Drive/fall19_smithsonian_informatics/train/chiroptera_crops_notaug.tsv\"]\n",
        "\n",
        "# Combine all files in the list\n",
        "combined = pd.concat([pd.read_csv(f, sep='\\t') for f in all_filenames])\n",
        "\n",
        "# Export to tsv\n",
        "combined.to_csv( \"/content/drive/My Drive/fall19_smithsonian_informatics/train/chiroptera_crops_all.tsv\", index=False, sep='\\t')\n",
        "print(combined.head())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XmN3ztbhMrni",
        "colab_type": "text"
      },
      "source": [
        "## Tidy combined dataset   \n",
        "---   "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6yJvWJ7_CbX1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Read in crops_all.tsv from above\n",
        "allcrops = pd.read_csv( \"/content/drive/My Drive/fall19_smithsonian_informatics/train/chiroptera_crops_all.tsv\", sep='\\t')\n",
        "print(allcrops.head())\n",
        "\n",
        "# Set negative values to 0\n",
        "allcrops.xmin[allcrops.xmin < 0] = 0\n",
        "allcrops.ymin[allcrops.ymin < 0] = 0\n",
        "\n",
        "# Remove out of bounds cropping dimensions\n",
        "for i, row in allcrops.iterrows():\n",
        "    # When crop height > image height, set crop height equal to image height:\n",
        "    if allcrops.ymax[i] > allcrops.height[i]:\n",
        "            allcrops.ymin[i] = 0\n",
        "            allcrops.ymax[i] = allcrops.height[i]\n",
        "\n",
        "for i, row in allcrops.iterrows(): \n",
        "    # When crop width > image width, set crop width equal to image width:\n",
        "    if allcrops.xmax[i] > allcrops.width[i]:\n",
        "        allcrops.xmin[i] = 0\n",
        "        allcrops.xmax[i] = allcrops.width[i]\n",
        "\n",
        "# Write results to tsv\n",
        "allcrops.to_csv('/content/drive/My Drive/fall19_smithsonian_informatics/train/chiroptera_crops_all_transf.tsv', sep='\\t', index=False)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}