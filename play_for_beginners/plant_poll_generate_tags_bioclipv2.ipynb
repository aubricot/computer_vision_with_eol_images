{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/aubricot/computer_vision_with_eol_images/blob/master/play_for_beginners/plant_poll_generate_tags_bioclipv2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j-PBcUKyc95M"
      },
      "source": [
        "# Demo: Using BIOCLIP v2 to add plant-pollinator co-occurrence tags for ladybugs, beetles, and insects in plant images\n",
        "---\n",
        "*Last Updated 7 September 2025*  \n",
        "-Runs in Python 3 with BIOCLIPv2-   \n",
        "\n",
        "Using BIOCLIPv2, a vision foundation model (https://arxiv.org/abs/2311.18803) implemented with [pybioclip](https://github.com/Imageomics/pybioclip/tree/main) and trained on [Tree of Life 10M images](https://huggingface.co/datasets/imageomics/TreeOfLife-10M) as a method to do customized, large-scale image processing. EOL Angiosperm images will be tagged if insect visitors are present using object detection. Tags will further extend EOLv3 image search functions.\n",
        "\n",
        "Notes:   \n",
        "* Run code blocks by pressing play button in brackets on left\n",
        "* Change parameters using form fields on right (find details at corresponding lines of code by searching '#@param')\n",
        "\n",
        "References:   \n",
        "* Code modified from the [Imageomics pybioclip tutorial](https://imageomics.github.io/pybioclip/python-tutorial/)\n",
        "* Check out [Imageomics pybioclip repo](https://github.com/Imageomics/pybioclip/tree/main) for more documetation and tutorials"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fX9LGz3Ydu27"
      },
      "source": [
        "## Installs & Imports\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q5lC8PSbGCyN"
      },
      "outputs": [],
      "source": [
        "#@title Choose where to save results\n",
        "import os\n",
        "\n",
        "# Use dropdown menu on right\n",
        "save = \"in Colab runtime (files deleted after each session)\" #@param [\"in my Google Drive\", \"in Colab runtime (files deleted after each session)\"]\n",
        "\n",
        "# Mount google drive to export image tagging file(s)\n",
        "if 'Google Drive' in save:\n",
        "    from google.colab import drive\n",
        "    drive.mount('/content/drive', force_remount=True)\n",
        "\n",
        "# Download helper_funcs folder\n",
        "!pip3 -q install --upgrade gdown\n",
        "!gdown 1TtL_NvD4oOXJaiqKfQs_qULuNAZDsF2J\n",
        "!tar -xzvf helper_funcs.tar.gz -C .\n",
        "\n",
        "# Install requirements.txt\n",
        "!pip3 -q install -r requirements.txt\n",
        "print('\\n\\n\\n \\033[91m If ERROR from pip dependency solver listed above, please check through conflicting version dependencies and/or open an issue on the CV for EOL images Github: https://github.com/aubricot/computer_vision_with_eol_images/issues. \\033[0m')\n",
        "\n",
        "# Set up directory structure\n",
        "basewd = \"/content/drive/MyDrive/train\"\n",
        "cwd = basewd + '/' + 'bioclip2'\n",
        "if not os.path.exists(cwd):\n",
        "    os.makedirs(cwd)\n",
        "    os.chdir(cwd)\n",
        "    os.makedirs('data/imgs')\n",
        "    os.makedirs('data/img_info')\n",
        "    os.makedirs('data/results')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yDdbBYnp2nCK"
      },
      "outputs": [],
      "source": [
        "#@title Import libraries\n",
        "\n",
        "# Install pybioclip\n",
        "!pip install pybioclip\n",
        "\n",
        "# For importing/exporting files, working with arrays, etc\n",
        "import glob\n",
        "import pathlib\n",
        "import six.moves.urllib as urllib\n",
        "import sys\n",
        "import tarfile\n",
        "import zipfile\n",
        "import numpy as np\n",
        "import csv\n",
        "import time\n",
        "import pandas as pd\n",
        "from bioclip import TreeOfLifeClassifier, Rank\n",
        "from PIL import Image\n",
        "\n",
        "# For downloading images\n",
        "!apt-get -qq install aria2\n",
        "\n",
        "# For drawing onto and plotting images\n",
        "import matplotlib.pyplot as plt\n",
        "import cv2\n",
        "%matplotlib inline\n",
        "%config InlineBackend.figure_format = 'svg'\n",
        "sys.path.append('/content')\n",
        "\n",
        "# Define EOL CV custom functions\n",
        "from wrangle_data import *"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cKovA4-aifP5"
      },
      "source": [
        "## Generate tags for images\n",
        "---\n",
        "Run EOL 20k image bundles through pre-trained object detection models and save results in 4 batches (A-D) of 5000 images each."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kIDpIFWsOZo5"
      },
      "outputs": [],
      "source": [
        "#@title Test: Run with sample EOL Angiosperm image (To test with your own image, upload file to data/imgs and update fn formfield)\n",
        "\n",
        "# Run with sample EOL image\n",
        "# Define image filepath and name\n",
        "fn = \"542.6248219776.jpg\" #@param [\"542.6248219776.jpg\"] {allow-input: true}\n",
        "img_fpath = 'data/imgs/' + fn\n",
        "\n",
        "# Download image\n",
        "%cd $cwd\n",
        "%cd data/imgs\n",
        "!gdown 1WVafbU3htUUiSo-Qvs3sA1Y0Medz4o7D\n",
        "%cd $cwd\n",
        "\n",
        "# Load in Tree of Life Classifier\n",
        "classifier = TreeOfLifeClassifier()\n",
        "\n",
        "# Run inference on image\n",
        "predictions = classifier.predict(img_fpath, Rank.SPECIES)\n",
        "\n",
        "# Filter predictions that contain \"Arthropoda\"\n",
        "filter = \"Arthropoda\"\n",
        "filtered_pred = [p for p in predictions if p.get('phylum')==filter]\n",
        "\n",
        "# Build figure title based on filtered predictions\n",
        "if filtered_pred:\n",
        "    top = filtered_pred[0]\n",
        "    label = \"Insect Present - \" + top[\"phylum\"] + \": \" + top[\"order\"]\n",
        "    score = top['score']\n",
        "    title = f\"{label} ({score:.2f})\"\n",
        "else:\n",
        "    title = f\"No {filter} prediction found\"\n",
        "\n",
        "# Show image with predictions\n",
        "plt.figure(figsize=(6, 6))\n",
        "plt.imshow(Image.open(img_fpath))\n",
        "plt.axis('off')\n",
        "plt.title(title, fontsize=14)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wjTgajd3keAi"
      },
      "source": [
        "### Generate tags: Run inference on EOL images & save results for tagging - Run 4X for batches A-D\n",
        "Use 20K EOL Angiosperm image bundle to identify possible pollinators that are present. Results are saved to [tags_file].tsv. Run this section 4 times (to make batches A-D) of 5K images each to incrementally save in case of Colab timeouts."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zCxtKyRPij8R"
      },
      "outputs": [],
      "source": [
        "#@title Enter EOL image bundle and choose inference settings. Change **tags_file** for each batch A-D\n",
        "%cd $cwd\n",
        "\n",
        "# Load in EOL Angiosperm 20k image bundle\n",
        "bundle = \"https://editors.eol.org/other_files/bundle_images/files/images_for_Angiosperms_20K_breakdown_download_000030.txt\" #@param [\"https://editors.eol.org/other_files/bundle_images/files/images_for_Angiosperms_20K_breakdown_download_000030.txt\"] {allow-input: true}\n",
        "df = read_datafile(bundle)\n",
        "print(\"EOL image bundle with {} images: \\n{}\".format(len(df), df.head()))\n",
        "\n",
        "# Test pipeline with a smaller subset than 5k images?\n",
        "run = \"test with tiny subset\" # @param [\"test with tiny subset\"]\n",
        "\n",
        "# Display detection results on images?\n",
        "display_results = \"yes (use this option if testing tiny subsets; only works for \\u003C50 images)\" # @param [\"yes (use this option if testing tiny subsets; only works for <50 images)\"]\n",
        "\n",
        "# Take 5k subset of bundle for running inference\n",
        "# Change filename for each batch\n",
        "tags_file = \"plant_poll_coocc_tags_c\" #@param [\"plant_poll_coocc_tags_a\", \"plant_poll_coocc_tags_b\", \"plant_poll_coocc_tags_c\", \"plant_poll_coocc_tags_d\"] {allow-input: true}\n",
        "tags_file = tags_file + \".txt\"\n",
        "imgs_dir = \"data/imgs/\"\n",
        "outfpath = imgs_dir + tags_file\n",
        "print(\"\\nSaving tagging results to: \\n{}\".format(outfpath))\n",
        "\n",
        "# Add 5k subset of image bundle urls as column in tags file\n",
        "start, stop, cutoff = set_start_stop(run, df)\n",
        "df = df.iloc[start:stop]\n",
        "df.to_csv(outfpath, sep='\\n', index=False, header=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eKUThVvV-66K"
      },
      "outputs": [],
      "source": [
        "#@title Run inference for batches A-D\n",
        "# Note: YOLO cannot parse images from URL, so images are temporarily downloaded\n",
        "# Note: Takes 7-10 min per 5k imgs, aria2 downloads 16imgs at a time\n",
        "%cd $imgs_dir\n",
        "!aria2c -x 16 -s 1 -i $tags_file\n",
        "\n",
        "# Verify that downloaded images are valid files\n",
        "valid_image_count = 0\n",
        "invalid_image_count = 0\n",
        "for entry in os.scandir('.'):\n",
        "    if entry.is_file() and not entry.name.endswith('.txt'):\n",
        "        try:\n",
        "            with Image.open(entry.path) as img:\n",
        "                img.verify()  # Checks for integrity of image\n",
        "            valid_image_count += 1\n",
        "        except Exception as e:\n",
        "            print(f\"Invalid image file deleted: {entry.name}\")\n",
        "            os.remove(entry.path)\n",
        "            invalid_image_count += 1\n",
        "print(f\"\\nImage validation complete. {valid_image_count} valid images, {invalid_image_count} invalid images removed.\")\n",
        "\n",
        "\n",
        "# Check how many images downloaded\n",
        "print(\"Number of files downloaded to Google Drive: \")\n",
        "print(valid_image_count)\n",
        "if (valid_image_count < cutoff) and (\"tiny subset\" not in run):\n",
        "    print(\"\\n\\n\\n \\033[93m WARNING: Less than {} files were downloaded. This is likely due to broken EOL image bundle URLs.\")\n",
        "\n",
        "# Move tags file used for downloading images to data/img_info/\n",
        "%cd $cwd\n",
        "!mv data/imgs/*.txt data/img_info/\n",
        "\n",
        "# Make a new list of successfully downloaded image files for running inference\n",
        "inf_imgs = imgs_dir + tags_file\n",
        "with open(inf_imgs, 'w', encoding='utf-8') as f:\n",
        "    # Walk through data/imgs/ to list files\n",
        "    for dir, dirs, files in os.walk(imgs_dir):\n",
        "        files = [fn for fn in files]\n",
        "        for fn in files:\n",
        "            if 'txt' not in fn:\n",
        "                out = \"data/imgs/\" + fn\n",
        "                f.writelines(out + '\\n')\n",
        "\n",
        "# Inspect textfile of images for inference\n",
        "df = pd.read_table(inf_imgs, header=None, sep='\\r')\n",
        "print(\"\\nNumber of valid images ready for inference in {}: {}\".format(inf_imgs, len(df)))\n",
        "\n",
        "# Load in Tree of Life Classifier\n",
        "classifier = TreeOfLifeClassifier()\n",
        "\n",
        "# Run inference on image\n",
        "img_fpaths = df[0].to_list()\n",
        "predictions = classifier.predict(img_fpaths, Rank.SPECIES)\n",
        "pred_df = pd.DataFrame(predictions)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Filter predictions that contain \"Arthropoda\"\n",
        "filter = \"Arthropoda\" # @param [\"Arthropoda\"] {\"allow-input\":true}\n",
        "\n",
        "# Group predictions by image (assuming one-to-many: multiple predictions per image)\n",
        "grouped = pred_df.groupby('file_name')\n",
        "\n",
        "for img_fpath, group in grouped:\n",
        "    # Filter Arthropoda predictions for this image\n",
        "    filtered_pred = group[group['phylum'] == filter].sort_values(by='score', ascending=False)\n",
        "\n",
        "    # Build title based on grouped, filtered predictions\n",
        "    if not filtered_pred.empty:\n",
        "        top = filtered_pred.iloc[0]\n",
        "        label = f\"Insect Present - {top['phylum']}: {top['order']}\"\n",
        "        score = top['score']\n",
        "        title = f\"{label} ({score:.2f})\"\n",
        "    else:\n",
        "        title = f\"No {filter} prediction found\"\n",
        "\n",
        "    # Display image with title\n",
        "    try:\n",
        "        img = Image.open(img_fpath)\n",
        "        plt.figure(figsize=(6, 6))\n",
        "        plt.imshow(img)\n",
        "        plt.axis('off')\n",
        "        plt.title(title, fontsize=14)\n",
        "        plt.show()\n",
        "    except Exception as e:\n",
        "        print(f\"Could not open image {img_fpath}: {e}\")\n",
        "\n",
        "print(\"\\n\\n~~~\\n \\033[92m Inference complete! \\033[0m \\n~~~\")"
      ],
      "metadata": {
        "id": "EkNnptM1BORO"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}