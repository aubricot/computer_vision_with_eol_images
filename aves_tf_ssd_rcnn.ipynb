{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "aves_tf_ssd_rcnn.ipynb",
      "provenance": [],
      "private_outputs": true,
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python2",
      "display_name": "Python 2"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/aubricot/object_detection_for_image_cropping/blob/master/aves_tf_ssd_rcnn.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SWrXhn1qKWm_",
        "colab_type": "text"
      },
      "source": [
        "# Using Faster-RCNN and SSD in Tensorflow to detect birds from images   \n",
        "---   \n",
        "*Last Updated 9 December 2019*   \n",
        "Using Faster-RCNN and SSD as methods to do customized, large-scale image processing with Tensorflow. Using the location and dimensions of the detected birds, images will be cropped to square dimensions that are centered and padded around the detection box. Pre-trained models are used for \"out of the box\" inference on images of birds of varying dimensions and resolutions, but will be modified and fine-tuned in future efforts for other taxonomic groups.\n",
        "\n",
        "This notebook is meant to be run enitrely in Google Colab and doesn't require any software installations or downloads to your local machine. To get started, just click the \"Open in Colab\" button. \n",
        "\n",
        "It is modified from [here](https://medium.com/@nickbortolotti/tensorflow-object-detection-api-in-5-clicks-from-colaboratory-843b19a1edf1). The [Tensorflow Object Detection API Tutorial](https://github.com/tensorflow/models/tree/master/research/object_detection) was also used as a reference. Tensorflow Object Detection API is meant for building models for custom object detection, see more information here: [Tensorflow Object Detection API](https://tensorflow-object-detection-api-tutorial.readthedocs.io/en/latest/install.html#tensorflow-models-installation). "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "smQWTwI7k4Bf",
        "colab_type": "text"
      },
      "source": [
        "## Installs\n",
        "---\n",
        "Install the Tensorflow Object Detection API directly to this Colab notebook."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XnBVJiIzYune",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!git clone https://github.com/tensorflow/models.git\n",
        "!apt-get -qq install libprotobuf-java protobuf-compiler\n",
        "!protoc ./models/research/object_detection/protos/string_int_label_map.proto --python_out=.\n",
        "!cp -R models/research/object_detection/ object_detection/\n",
        "!rm -rf models"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jvpJJUDTkct3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Mount google drive to export image cropping coordinate file(s)\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qwWt0kSihqCv",
        "colab_type": "text"
      },
      "source": [
        "### Imports   \n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YspILW_rZu0v",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%tensorflow_version 1.0\n",
        "\n",
        "import tensorflow as tf \n",
        "tf.compat.v1.enable_eager_execution()\n",
        "\n",
        "# For importing/exporting files, working with arrays, etc\n",
        "import os\n",
        "import pathlib\n",
        "import six.moves.urllib as urllib\n",
        "import sys\n",
        "import tarfile\n",
        "import zipfile\n",
        "import numpy as np \n",
        "import csv\n",
        "import matplotlib\n",
        "import time\n",
        "import pandas as pd\n",
        "\n",
        "# For downloading the images\n",
        "import tempfile\n",
        "from six.moves.urllib.request import urlopen\n",
        "from six import BytesIO\n",
        "from collections import defaultdict\n",
        "from io import StringIO\n",
        "\n",
        "# For drawing onto and plotting the images\n",
        "import matplotlib.pyplot as plt\n",
        "from PIL import Image\n",
        "from PIL import ImageColor\n",
        "from PIL import ImageDraw\n",
        "from PIL import ImageFont\n",
        "from PIL import ImageOps\n",
        "\n",
        "import cv2\n",
        "\n",
        "from IPython.display import display\n",
        "\n",
        "from object_detection.utils import ops as utils_ops\n",
        "from object_detection.utils import label_map_util\n",
        "from object_detection.utils import visualization_utils as vis_util"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kGx_08UcmtOF",
        "colab_type": "text"
      },
      "source": [
        "### Model Preparation\n",
        "--- \n",
        "Configure the model to use and select needed elements to use the Object Detection API."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8n_alUkLZ1gl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# What model to download. Can choose between SSD or Faster RCNN by commenting out/in the different MODEL_NAME(s) below\n",
        "# SSD Model\n",
        "#MODEL_NAME = 'ssd_resnet50_v1_fpn_shared_box_predictor_640x640_coco14_sync_2018_07_03'\n",
        "\n",
        "# Faster RCNN Model\n",
        "MODEL_NAME = 'faster_rcnn_resnet50_coco_2018_01_28'\n",
        "\n",
        "MODEL_FILE = MODEL_NAME + '.tar.gz'\n",
        "DOWNLOAD_BASE = 'http://download.tensorflow.org/models/object_detection/'\n",
        "\n",
        "# Path to frozen detection graph. This is the actual model that is used for the object detection.\n",
        "PATH_TO_CKPT = MODEL_NAME + '/frozen_inference_graph.pb'\n",
        "\n",
        "# List of the strings that is used to add correct label for each box.\n",
        "PATH_TO_LABELS = os.path.join('object_detection/data', 'mscoco_label_map.pbtxt')\n",
        "\n",
        "NUM_CLASSES = 90\n",
        "\n",
        "opener = urllib.request.URLopener()\n",
        "opener.retrieve(DOWNLOAD_BASE + MODEL_FILE, MODEL_FILE)\n",
        "tar_file = tarfile.open(MODEL_FILE)\n",
        "for file in tar_file.getmembers():\n",
        "  file_name = os.path.basename(file.name)\n",
        "  if 'frozen_inference_graph.pb' in file_name:\n",
        "    tar_file.extract(file, os.getcwd())\n",
        "    \n",
        "detection_graph = tf.Graph()\n",
        "with detection_graph.as_default():\n",
        "  od_graph_def = tf.compat.v1.GraphDef()\n",
        "  with tf.io.gfile.GFile(PATH_TO_CKPT, 'rb') as fid:\n",
        "    serialized_graph = fid.read()\n",
        "    od_graph_def.ParseFromString(serialized_graph)\n",
        "    tf.import_graph_def(od_graph_def, name='')\n",
        "    \n",
        "label_map = label_map_util.load_labelmap(PATH_TO_LABELS)\n",
        "categories = label_map_util.convert_label_map_to_categories(label_map, max_num_classes=NUM_CLASSES, use_display_name=True)\n",
        "category_index = label_map_util.create_category_index(categories)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CjE-Gh5ann4E",
        "colab_type": "text"
      },
      "source": [
        "## Run test images through object detector\n",
        "--- "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_Vvi4-2fm2qe",
        "colab_type": "text"
      },
      "source": [
        "### Prepare object detection functions and settings"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q9FZsaZkaPUz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# For loading images into computer-readable format\n",
        "def load_image_into_numpy_array(image):\n",
        "  (im_width, im_height) = image.size\n",
        "  return np.array(image.getdata()).reshape(\n",
        "      (im_height, im_width, 3)).astype(np.uint8)\n",
        "\n",
        "# Function for loading images from urls\n",
        "def url_to_image(url):\n",
        "  resp = urllib.request.urlopen(url)\n",
        "  image = np.asarray(bytearray(resp.read()), dtype=\"uint8\")\n",
        "  image = cv2.imdecode(image, cv2.IMREAD_COLOR)\n",
        "  image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "  return image\n",
        "\n",
        "def show_inference(image_np_expanded):\n",
        "  with detection_graph.as_default():\n",
        "    with tf.Session(graph=detection_graph) as sess:\n",
        "      # Definite input and output Tensors for detection_graph\n",
        "      image_tensor = detection_graph.get_tensor_by_name('image_tensor:0')\n",
        "      # Each box represents a part of the image where a particular object was detected.\n",
        "      detection_boxes = detection_graph.get_tensor_by_name('detection_boxes:0')\n",
        "      # Each score represent how level of confidence for each of the objects.\n",
        "      detection_scores = detection_graph.get_tensor_by_name('detection_scores:0')\n",
        "      detection_classes = detection_graph.get_tensor_by_name('detection_classes:0')\n",
        "      num_detections = detection_graph.get_tensor_by_name('num_detections:0')\n",
        "      # Optional: adjust score confidence threshold for display\n",
        "      #min_score_thresh = .7\n",
        "\n",
        "      # Actual detection.\n",
        "      (boxes, scores, classes, num) = sess.run(\n",
        "          [detection_boxes, detection_scores, detection_classes, num_detections],\n",
        "          feed_dict={image_tensor: image_np_expanded})\n",
        "      \n",
        "      # Visualization of the results of a detection\n",
        "      # Modified from https://github.com/tensorflow/models/issues/4682\n",
        "      im_height, im_width, im_depth = image_np.shape\n",
        "      ymin = int((boxes[0][0][0]*im_height))\n",
        "      xmin = int((boxes[0][0][1]*im_width))\n",
        "      ymax = int((boxes[0][0][2]*im_height))\n",
        "      xmax = int((boxes[0][0][3]*im_width))\n",
        "      newImage = np.copy(image_np)\n",
        "      newImage = cv2.rectangle(newImage, (xmin, ymax), (xmax, ymin), (255, 0, 157), 3)\n",
        "      # Add labels to boxes\n",
        "      #newImage = cv2.putText(newImage, label, (xmin, ymax-5), cv2.FONT_HERSHEY_SIMPLEX, fontScale, (153, 255, 255), 5, cv2.LINE_AA)\n",
        "\n",
        "      return newImage"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qaHbhJ8vnzIo",
        "colab_type": "text"
      },
      "source": [
        "### Run images (from individual URLs) through object detector\n",
        "Load in images by URL and run the image detector for all images. Plotted results include the image with bounding box around detected objects (birds), class type, and confidence score. Inference times are printed above images."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BQgwjTjXWdLh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "image_urls = [\"https://content.eol.org/data/media/7e/9c/7a/542.15445377044.jpg\",\n",
        "              \"https://content.eol.org/data/media/81/1c/0d/542.7816025222.jpg\",\n",
        "              \"https://content.eol.org/data/media/7e/3c/0b/542.10578857864.jpg\"]\n",
        "\n",
        "for im_num, image_url in enumerate(image_urls, start=1):\n",
        "    # Load in image\n",
        "    image_np = url_to_image(image_url)\n",
        "    image_np_expanded = np.expand_dims(image_np, axis=0)\n",
        "    # Record inference time\n",
        "    start_time = time.time()\n",
        "    # Detection and draw boxes on image\n",
        "    show_inference(image_np_expanded)\n",
        "    end_time = time.time()\n",
        "    # Display progress message after each image\n",
        "    print('Detection complete in {} of 3 images'.format(im_num))\n",
        "    \n",
        "    # Plot and show detection boxes on images\n",
        "    # If running detection on >50 images, comment out this portion\n",
        "    _, ax = plt.subplots(figsize=(10, 10))\n",
        "    ax.imshow(show_inference(image_np_expanded))\n",
        "    plt.title('{}) Inference time: {}'.format(im_num, format(end_time-start_time, '.2f')))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PVpMaZ3on72u",
        "colab_type": "text"
      },
      "source": [
        "## Run EOL image bundles through the trained object detector & save results for cropping\n",
        "---\n",
        "Display resulting detection boxes on images and save their coordinates to aves_det_crops.tsv for use cropping EOL images. \n",
        "\n",
        "Plotted results include the image with bounding box around detected objects (birds), class type, and confidence score. Inference times are printed above images. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bzIroqwEns8N",
        "colab_type": "text"
      },
      "source": [
        "### Prepare object detection functions and settings"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ET7clqAPnqJX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# For loading images into computer-readable format\n",
        "def load_image_into_numpy_array(image):\n",
        "  (im_width, im_height) = image.size\n",
        "  return np.array(image.getdata()).reshape(\n",
        "      (im_height, im_width, 3)).astype(np.uint8)\n",
        "\n",
        "# Function for loading images from urls\n",
        "def url_to_image(url):\n",
        "  resp = urllib.request.urlopen(url)\n",
        "  image = np.asarray(bytearray(resp.read()), dtype=\"uint8\")\n",
        "  image = cv2.imdecode(image, cv2.IMREAD_COLOR)\n",
        "  image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "  return image\n",
        "\n",
        "def show_inference(image_np_expanded):\n",
        "  with detection_graph.as_default():\n",
        "    with tf.Session(graph=detection_graph) as sess:\n",
        "      # Definite input and output Tensors for detection_graph\n",
        "      image_tensor = detection_graph.get_tensor_by_name('image_tensor:0')\n",
        "      # Each box represents a part of the image where a particular object was detected.\n",
        "      detection_boxes = detection_graph.get_tensor_by_name('detection_boxes:0')\n",
        "      # Each score represent how level of confidence for each of the objects.\n",
        "      detection_scores = detection_graph.get_tensor_by_name('detection_scores:0')\n",
        "      detection_classes = detection_graph.get_tensor_by_name('detection_classes:0')\n",
        "      num_detections = detection_graph.get_tensor_by_name('num_detections:0')\n",
        "      # Optional: adjust score confidence threshold for display\n",
        "      #min_score_thresh = .7\n",
        "\n",
        "      # Actual detection.\n",
        "      (boxes, scores, classes, num) = sess.run(\n",
        "          [detection_boxes, detection_scores, detection_classes, num_detections],\n",
        "          feed_dict={image_tensor: image_np_expanded})\n",
        "      \n",
        "      # Visualization of the results of a detection\n",
        "      # Modified from https://github.com/tensorflow/models/issues/4682\n",
        "      im_height, im_width, im_depth = image_np.shape\n",
        "      ymin = int((boxes[0][0][0]*im_height))\n",
        "      xmin = int((boxes[0][0][1]*im_width))\n",
        "      ymax = int((boxes[0][0][2]*im_height))\n",
        "      xmax = int((boxes[0][0][3]*im_width))\n",
        "      newImage = np.copy(image_np)\n",
        "      newImage = cv2.rectangle(newImage, (xmin, ymax), (xmax, ymin), (255, 0, 157), 3)\n",
        "      # Add labels to boxes\n",
        "      #newImage = cv2.putText(newImage, label, (xmin, ymax-5), cv2.FONT_HERSHEY_SIMPLEX, fontScale, (153, 255, 255), 5, cv2.LINE_AA)\n",
        "\n",
        "      # Export bounding boxes to drive\n",
        "      with open('/content/drive/My Drive/fall19_smithsonian_informatics/train/aves_det_crops_1000.tsv', 'a') as out_file:\n",
        "                  tsv_writer = csv.writer(out_file, delimiter='\\t')\n",
        "                  crop_width = xmax-xmin\n",
        "                  crop_height = ymax-ymin\n",
        "                  tsv_writer.writerow([image_url, im_height, im_width, \n",
        "                            xmin, ymin, xmax, ymax])\n",
        "      return newImage"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NaLCtgkEgirm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Use URLs from EOL image URL bundles\n",
        "# Comment out to use either 1000 or 20000 image bundles\n",
        "#1000 images\n",
        "urls = 'https://editors.eol.org/other_files/bundle_images/files/images_for_Aves_breakdown_download_000001.txt'\n",
        "#20000 images\n",
        "#urls = 'https://editors.eol.org/other_files/bundle_images/files/images_for_Aves_20K_breakdown_download_000001.txt'\n",
        "\n",
        "df = pd.read_csv(urls)\n",
        "df.columns = [\"link\"]\n",
        "pd.DataFrame.head(df)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z-CPYWIpkTSQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Prepare cropping coordinates output file\n",
        "# cd to train/\n",
        "%cd drive/My Drive/fall19_smithsonian_informatics/train\n",
        "\n",
        "# Write header row of output cropping coordinates file\n",
        "with open('/content/drive/My Drive/fall19_smithsonian_informatics/train/aves_det_crops_1000.tsv', 'a') as out_file:\n",
        "                  tsv_writer = csv.writer(out_file, delimiter='\\t')\n",
        "                  tsv_writer.writerow([\"image_url\", \"im_height\", \"im_width\", \n",
        "                            \"xmin\", \"ymin\", \"xmax\", \"ymax\"])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iSPrkTKAglMZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Run images through model for object detection\n",
        "from PIL import Image\n",
        "\n",
        "# Set number of seconds to timeout if image url taking too long to open\n",
        "import socket\n",
        "socket.setdefaulttimeout(10)\n",
        "\n",
        "# Loops through first 5 image urls from the text file\n",
        "for i, row in df.head(5).itertuples(index=True, name='Pandas'):\n",
        "\n",
        "# For ranges of rows or all rows, use df.iloc\n",
        "# Can be useful if running detection in batches\n",
        "#for i, row in df.iloc[:5000].iterrows():\n",
        "\n",
        "  try:\n",
        "    # Load in image\n",
        "    image_url = df.get_value(i, \"link\")\n",
        "    image_np = url_to_image(image_url)\n",
        "    image_np_expanded = np.expand_dims(image_np, axis=0)\n",
        "    # Record inference time\n",
        "    start_time = time.time()\n",
        "    # Detection and draw boxes on image\n",
        "    show_inference(image_np_expanded)\n",
        "    end_time = time.time()\n",
        "    # Display progress message after each image\n",
        "    print('Detection complete in {} of 1000 images'.format(i+1))\n",
        "    \n",
        "    # Plot and show detection boxes on images\n",
        "    # If running detection on >50 images, comment out this portion\n",
        "    #_, ax = plt.subplots(figsize=(10, 10))\n",
        "    #ax.imshow(show_inference(image_np_expanded))\n",
        "    #plt.title('{}) Inference time: {}'.format(i+1, format(end_time-start_time, '.2f')))\n",
        "\n",
        "  except:\n",
        "    print('Check if URL from {} is valid'.format(image_url))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "11WVwKxc0R0N",
        "colab_type": "text"
      },
      "source": [
        "### Get inference info for test images to compare object detection model times for YOLO, SSD, and Faster-RCNN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LY6qlZzu1chN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "urls = 'https://editors.eol.org/other_files/bundle_images/files/images_for_Aves_breakdown_download_000001.txt'\n",
        "df = pd.read_csv(urls)\n",
        "df.columns = [\"link\"]\n",
        "pd.DataFrame.head(df)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X2oenjWL0TFJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from PIL import Image\n",
        "import os\n",
        "\n",
        "# For exporting inference times\n",
        "inf_time = []\n",
        "img_urls = []\n",
        "im_dims = []\n",
        "\n",
        "# Loops through first 5 image urls from the text file\n",
        "for i, row in df.head(145).itertuples(index=True, name='Pandas'):\n",
        "#for i, row in df.head(5).itertuples(index=True, name='Pandas'):\n",
        "  \n",
        "  try:\n",
        "    # Use YOLO for object detection  \n",
        "    image_url = df.get_value(i, \"link\")\n",
        "    image_path = download_and_convert_image(image_url)\n",
        "    image = Image.open(image_path)\n",
        "    image_np = load_image_into_numpy_array(image)\n",
        "    image_np_expanded = np.expand_dims(image_np, axis=0)\n",
        "    # Record inference time\n",
        "    start_time = time.time()\n",
        "    # Actual detection\n",
        "    show_inference(image_np_expanded)\n",
        "    end_time = time.time()\n",
        "    # Display progress message after each image\n",
        "    print('Detection complete in {} of 145 test images'.format(i+1))\n",
        "    \n",
        "    # Record inference time, image name and image dimensions to export\n",
        "    inf_time.append(end_time-start_time)\n",
        "    img_urls.append(image_url)\n",
        "    im_dims.append(image_np.shape)\n",
        "  \n",
        "  except:\n",
        "    print('Error: check if web address {} is valid'.format(image_url))\n",
        "    \n",
        "inf_times = pd.DataFrame(([inf_time, img_urls, im_dims]))\n",
        "inf_times = inf_times.transpose()\n",
        "inf_times.to_csv(\"aves_inference_times_rcnn.csv\", index=False, header=(\"time (sec)\", \"filepath\", \"image_dims (h, w, d)\"))\n",
        "print(inf_times.head())"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}