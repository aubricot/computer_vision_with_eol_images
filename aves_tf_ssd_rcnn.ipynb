{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "aves_tf_ssd_rcnn.ipynb",
      "provenance": [],
      "private_outputs": true,
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python2",
      "display_name": "Python 2"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/aubricot/object_detection_for_image_cropping/blob/master/aves_tf_ssd_rcnn.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SWrXhn1qKWm_",
        "colab_type": "text"
      },
      "source": [
        "# Using Faster-RCNN and SSD in Tensorflow to detect birds from images   \n",
        "---   \n",
        "*Last Updated 9 December 2019*   \n",
        "Using Faster-RCNN and SSD as methods to do customized, large-scale image processing with Tensorflow. Using the location and dimensions of the detected birds, images will be cropped to square dimensions that are centered and padded around the detection box. Pre-trained models are used for \"out of the box\" inference on images of birds of varying dimensions and resolutions, but will be modified and fine-tuned in future efforts for other taxonomic groups.\n",
        "\n",
        "This notebook is meant to be run enitrely in Google Colab and doesn't require any software installations or downloads to your local machine. To get started, just click the \"Open in Colab\" button. \n",
        "\n",
        "It is modified from [here](https://medium.com/@nickbortolotti/tensorflow-object-detection-api-in-5-clicks-from-colaboratory-843b19a1edf1). The [Tensorflow Object Detection API Tutorial](https://github.com/tensorflow/models/tree/master/research/object_detection) was also used as a reference. Tensorflow Object Detection API is meant for building models for custom object detection, see more information here: [Tensorflow Object Detection API](https://tensorflow-object-detection-api-tutorial.readthedocs.io/en/latest/install.html#tensorflow-models-installation). "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "smQWTwI7k4Bf",
        "colab_type": "text"
      },
      "source": [
        "## Installs\n",
        "---\n",
        "Install the Tensorflow Object Detection API directly to this Colab notebook."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XnBVJiIzYune",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!git clone https://github.com/tensorflow/models.git\n",
        "!apt-get -qq install libprotobuf-java protobuf-compiler\n",
        "!protoc ./models/research/object_detection/protos/string_int_label_map.proto --python_out=.\n",
        "!cp -R models/research/object_detection/ object_detection/\n",
        "!rm -rf models"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qwWt0kSihqCv",
        "colab_type": "text"
      },
      "source": [
        "### Imports   \n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YspILW_rZu0v",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%tensorflow_version 1.0\n",
        "\n",
        "import tensorflow as tf \n",
        "tf.compat.v1.enable_eager_execution()\n",
        "\n",
        "# For importing/exporting files, working with arrays, etc\n",
        "import os\n",
        "import pathlib\n",
        "import six.moves.urllib as urllib\n",
        "import sys\n",
        "import tarfile\n",
        "import zipfile\n",
        "import numpy as np \n",
        "import csv\n",
        "import matplotlib\n",
        "import time\n",
        "import pandas as pd\n",
        "\n",
        "# For downloading the images\n",
        "import tempfile\n",
        "from six.moves.urllib.request import urlopen\n",
        "from six import BytesIO\n",
        "from collections import defaultdict\n",
        "from io import StringIO\n",
        "\n",
        "# For drawing onto and plotting the images\n",
        "import matplotlib.pyplot as plt\n",
        "from PIL import Image\n",
        "from PIL import ImageColor\n",
        "from PIL import ImageDraw\n",
        "from PIL import ImageFont\n",
        "from PIL import ImageOps\n",
        "\n",
        "import cv2\n",
        "\n",
        "from IPython.display import display\n",
        "\n",
        "from object_detection.utils import ops as utils_ops\n",
        "from object_detection.utils import label_map_util\n",
        "from object_detection.utils import visualization_utils as vis_util"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kGx_08UcmtOF",
        "colab_type": "text"
      },
      "source": [
        "### Model Preparation\n",
        "--- \n",
        "Configure the model to use and select needed elements to use the Object Detection API."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8n_alUkLZ1gl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# What model to download. Can choose between SSD or Faster RCNN by commenting out/in the different MODEL_NAME(s) below\n",
        "# SSD Model\n",
        "# MODEL_NAME = 'ssd_resnet50_v1_fpn_shared_box_predictor_640x640_coco14_sync_2018_07_03'\n",
        "\n",
        "# Faster RCNN Model\n",
        "MODEL_NAME = 'faster_rcnn_resnet50_coco_2018_01_28'\n",
        "\n",
        "MODEL_FILE = MODEL_NAME + '.tar.gz'\n",
        "DOWNLOAD_BASE = 'http://download.tensorflow.org/models/object_detection/'\n",
        "\n",
        "# Path to frozen detection graph. This is the actual model that is used for the object detection.\n",
        "PATH_TO_CKPT = MODEL_NAME + '/frozen_inference_graph.pb'\n",
        "\n",
        "# List of the strings that is used to add correct label for each box.\n",
        "PATH_TO_LABELS = os.path.join('object_detection/data', 'mscoco_label_map.pbtxt')\n",
        "\n",
        "NUM_CLASSES = 90\n",
        "\n",
        "opener = urllib.request.URLopener()\n",
        "opener.retrieve(DOWNLOAD_BASE + MODEL_FILE, MODEL_FILE)\n",
        "tar_file = tarfile.open(MODEL_FILE)\n",
        "for file in tar_file.getmembers():\n",
        "  file_name = os.path.basename(file.name)\n",
        "  if 'frozen_inference_graph.pb' in file_name:\n",
        "    tar_file.extract(file, os.getcwd())\n",
        "    \n",
        "detection_graph = tf.Graph()\n",
        "with detection_graph.as_default():\n",
        "  od_graph_def = tf.compat.v1.GraphDef()\n",
        "  with tf.io.gfile.GFile(PATH_TO_CKPT, 'rb') as fid:\n",
        "    serialized_graph = fid.read()\n",
        "    od_graph_def.ParseFromString(serialized_graph)\n",
        "    tf.import_graph_def(od_graph_def, name='')\n",
        "    \n",
        "label_map = label_map_util.load_labelmap(PATH_TO_LABELS)\n",
        "categories = label_map_util.convert_label_map_to_categories(label_map, max_num_classes=NUM_CLASSES, use_display_name=True)\n",
        "category_index = label_map_util.create_category_index(categories)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PbXKPFiWh1jG",
        "colab_type": "text"
      },
      "source": [
        "## Define functions to load in sample images\n",
        "--- "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UMPG4y0dbQC1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def load_image_into_numpy_array(image):\n",
        "  (im_width, im_height) = image.size\n",
        "  return np.array(image.getdata()).reshape(\n",
        "      (im_height, im_width, 3)).astype(np.uint8)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "34bm0jdz_xTx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def download_and_convert_image(url, display=False):\n",
        "  _, filename = tempfile.mkstemp(suffix=\".jpg\")\n",
        "  response = urlopen(url)\n",
        "  image_data = response.read()\n",
        "  image_data = BytesIO(image_data)\n",
        "  pil_image = Image.open(image_data)\n",
        "  pil_image_rgb = pil_image.convert(\"RGB\")\n",
        "  pil_image_rgb.save(filename, format=\"JPEG\", quality=90)\n",
        "  if display:\n",
        "    display_image(pil_image)\n",
        "  return filename"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_Vvi4-2fm2qe",
        "colab_type": "text"
      },
      "source": [
        "## Define function for object detection\n",
        "---   \n",
        "Use a Tensorflow session to detect objects using pre-trained models and display the results of detection."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q9FZsaZkaPUz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def show_inference(image_np_expanded):\n",
        "  with detection_graph.as_default():\n",
        "    with tf.Session(graph=detection_graph) as sess:\n",
        "      # Definite input and output Tensors for detection_graph\n",
        "      image_tensor = detection_graph.get_tensor_by_name('image_tensor:0')\n",
        "      # Each box represents a part of the image where a particular object was detected.\n",
        "      detection_boxes = detection_graph.get_tensor_by_name('detection_boxes:0')\n",
        "      #max_boxes_to_draw = detection_boxes.shape[0] # add this line and remove (i) and (ii) below to show multiple detection boxes\n",
        "      # Each score represent how level of confidence for each of the objects.\n",
        "      # Score is shown on the result image, together with the class label.\n",
        "      detection_scores = detection_graph.get_tensor_by_name('detection_scores:0')\n",
        "      detection_classes = detection_graph.get_tensor_by_name('detection_classes:0')\n",
        "      num_detections = detection_graph.get_tensor_by_name('num_detections:0')\n",
        "      min_score_thresh = .7\n",
        "\n",
        "      # Actual detection.\n",
        "      (boxes, scores, classes, num) = sess.run(\n",
        "          [detection_boxes, detection_scores, detection_classes, num_detections],\n",
        "          feed_dict={image_tensor: image_np_expanded})\n",
        "      \n",
        "      # Visualization of the results of a detection.\n",
        "      vis_util.visualize_boxes_and_labels_on_image_array(\n",
        "          image_np,\n",
        "          np.squeeze(boxes),\n",
        "          np.squeeze(classes).astype(np.int32),\n",
        "          np.squeeze(scores),\n",
        "          category_index,\n",
        "          use_normalized_coordinates=True,\n",
        "          min_score_thresh=.7,\n",
        "          max_boxes_to_draw=1,\n",
        "          line_thickness=8)\n",
        "      \n",
        "      plt.figure()\n",
        "      plt.imshow(image_np)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CjE-Gh5ann4E",
        "colab_type": "text"
      },
      "source": [
        "## Load in sample images and run them through the object detector\n",
        "---\n",
        "You can either **A) Load individual images in by URL**, or for large image batches or **B) Load multiple images from a text file of image URLs**. Other methods for importing to Google Colab are listed [here](https://colab.research.google.com/notebooks/io.ipynb#scrollTo=XDg9OBaYqRMd). "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qaHbhJ8vnzIo",
        "colab_type": "text"
      },
      "source": [
        "**A) Load individual images in by URL**\n",
        "Load in images by URL and run the image detector for all images. Plotted results include the image with bounding box around detected objects (birds), class type, and confidence score. Inference times are printed above images."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LC_YlxTobeZo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "image_urls = [\"https://content.eol.org/data/media/7e/9c/7a/542.15445377044.jpg\",\n",
        "              \"https://content.eol.org/data/media/81/1c/0d/542.7816025222.jpg\",\n",
        "              \"https://content.eol.org/data/media/7e/3c/0b/542.10578857864.jpg\"]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BQgwjTjXWdLh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for image_url in image_urls:\n",
        "      image_path = download_and_convert_image(image_url)\n",
        "      image = Image.open(image_path)\n",
        "      # The array based representation of the image is needed for detection\n",
        "      image_np = load_image_into_numpy_array(image)\n",
        "      # Expand dimensions since the model expects images to have shape: [1, None, None, 3]\n",
        "      image_np_expanded = np.expand_dims(image_np, axis=0)\n",
        "      start_time = time.time()\n",
        "      # Detection function\n",
        "      show_inference(image_np_expanded)\n",
        "      end_time = time.time()\n",
        "      # Display inference time above images\n",
        "      plt.title('Inference time: {}'.format(format(end_time-start_time, '.2f')))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PVpMaZ3on72u",
        "colab_type": "text"
      },
      "source": [
        "**B) Load multiple images from a text file of image URLs** Load in multiple images from a text file of URLS and run the image detector for all images. Plotted results include the image with bounding box around detected objects (birds), class type, and confidence score. Inference times are printed above images. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NaLCtgkEgirm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "urls = 'https://editors.eol.org/other_files/bundle_images/files/images_for_Aves_breakdown_download_000001.txt'\n",
        "df1 = pd.read_csv(urls)\n",
        "df1.columns = [\"link\"]\n",
        "pd.DataFrame.head(df1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iSPrkTKAglMZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Loops through first 5 image urls from the text file\n",
        "for i, row in df1.head(5).itertuples(index=True, name='Pandas'):\n",
        "  \n",
        "    # Use YOLO for object detection  \n",
        "    # Record inference time\n",
        "    image_url = df1.get_value(i, \"link\")\n",
        "    image_path = download_and_convert_image(image_url)\n",
        "    image = Image.open(image_path)\n",
        "    image_np = load_image_into_numpy_array(image)\n",
        "    # the array based representation of the image will be used later in order to prepare the\n",
        "    # result image with boxes and labels on it.\n",
        "    # Expand dimensions since the model expects images to have shape: [1, None, None, 3]\n",
        "    image_np_expanded = np.expand_dims(image_np, axis=0)\n",
        "    start_time = time.time()\n",
        "    show_inference(image_np_expanded)\n",
        "    end_time = time.time()\n",
        "    plt.title('{}) Inference time: {}'.format(i+1, format(end_time-start_time, '.2f'))) "
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}
