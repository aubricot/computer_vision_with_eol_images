{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.8"
    },
    "colab": {
      "name": "aves_yolo.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/aubricot/computer_vision_with_eol_images/blob/master/object_detection_for_image_cropping/aves/aves_generate_crops_yolo.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4Rnwb_rgmJZB"
      },
      "source": [
        "# Using YOLO v2 in Darkflow to detect birds from images\n",
        "---\n",
        "*Last Updated 16 March 2020*   \n",
        "-Darkflow builds are no longer being updated. As a result, this notebook is left in its state from March 2020. Functions may become deprecated or lose functionality. For updated inference with Aves, refer to Tensorflow notebooks-\n",
        "\n",
        "Using YOLO via Darkflow as a method to do customized, large-scale image processing. Using the location and dimensions of the detected birds, images will be cropped to square dimensions that are centered and padded around the detection box. Pre-trained models are used for \"out of the box\" inference on images of birds."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iJz5m4BKmJZD"
      },
      "source": [
        "## Installs\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yWAbU5tW1ONu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "55d03a34-08f6-44d7-e2b4-ff6ed2350002"
      },
      "source": [
        "# Mount google drive to export detection results as tsv\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QW2sYEc47x5A",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "23cf35fb-0eaa-4125-c2f3-cd47a62ec833"
      },
      "source": [
        "# Change to your working directory within Google Drive\n",
        "%cd drive/My Drive/train\n",
        "\n",
        "# Make sure you are using Python 3.6\n",
        "# Install packages using pip\n",
        "!python --version\n",
        "!pip install tensorflow-gpu==1.15.0rc2\n",
        "!pip install cython\n",
        "!pip install opencv-python"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/My Drive/train\n",
            "Python 3.6.9\n",
            "Collecting tensorflow-gpu==1.15.0rc2\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ce/0e/381cf036b512cca3adf8abbffe514470b1422edd4048c1190928cfb16fbe/tensorflow_gpu-1.15.0rc2-cp36-cp36m-manylinux2010_x86_64.whl (411.5MB)\n",
            "\u001b[K     |████████████████████████████████| 411.5MB 42kB/s \n",
            "\u001b[?25hRequirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.15.0rc2) (0.10.0)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.15.0rc2) (3.3.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.15.0rc2) (1.1.0)\n",
            "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.15.0rc2) (1.32.0)\n",
            "Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.15.0rc2) (1.12.1)\n",
            "Collecting keras-applications>=1.0.8\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/71/e3/19762fdfc62877ae9102edf6342d71b28fbfd9dea3d2f96a882ce099b03f/Keras_Applications-1.0.8-py3-none-any.whl (50kB)\n",
            "\u001b[K     |████████████████████████████████| 51kB 8.8MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy<2.0,>=1.16.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.15.0rc2) (1.19.5)\n",
            "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.15.0rc2) (1.1.2)\n",
            "Collecting tensorflow-estimator==1.15.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/de/62/2ee9cd74c9fa2fa450877847ba560b260f5d0fb70ee0595203082dafcc9d/tensorflow_estimator-1.15.1-py2.py3-none-any.whl (503kB)\n",
            "\u001b[K     |████████████████████████████████| 512kB 55.4MB/s \n",
            "\u001b[?25hRequirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.15.0rc2) (0.8.1)\n",
            "Requirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.15.0rc2) (3.12.4)\n",
            "Collecting gast==0.2.2\n",
            "  Downloading https://files.pythonhosted.org/packages/4e/35/11749bf99b2d4e3cceb4d55ca22590b0d7c2c62b9de38ac4a4a7f4687421/gast-0.2.2.tar.gz\n",
            "Requirement already satisfied: google-pasta>=0.1.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.15.0rc2) (0.2.0)\n",
            "Collecting tensorboard<1.16.0,>=1.15.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/1e/e9/d3d747a97f7188f48aa5eda486907f3b345cd409f0a0850468ba867db246/tensorboard-1.15.0-py3-none-any.whl (3.8MB)\n",
            "\u001b[K     |████████████████████████████████| 3.8MB 55.0MB/s \n",
            "\u001b[?25hRequirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.15.0rc2) (0.36.2)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.15.0rc2) (1.15.0)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras-applications>=1.0.8->tensorflow-gpu==1.15.0rc2) (2.10.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf>=3.6.1->tensorflow-gpu==1.15.0rc2) (53.0.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow-gpu==1.15.0rc2) (3.3.3)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow-gpu==1.15.0rc2) (1.0.1)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from markdown>=2.6.8->tensorboard<1.16.0,>=1.15.0->tensorflow-gpu==1.15.0rc2) (3.4.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard<1.16.0,>=1.15.0->tensorflow-gpu==1.15.0rc2) (3.7.4.3)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard<1.16.0,>=1.15.0->tensorflow-gpu==1.15.0rc2) (3.4.0)\n",
            "Building wheels for collected packages: gast\n",
            "  Building wheel for gast (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for gast: filename=gast-0.2.2-cp36-none-any.whl size=7540 sha256=cd8db42216007229a2c80206b695fc884fa73b38c376c7cd60e352a815b39e03\n",
            "  Stored in directory: /root/.cache/pip/wheels/5c/2e/7e/a1d4d4fcebe6c381f378ce7743a3ced3699feb89bcfbdadadd\n",
            "Successfully built gast\n",
            "\u001b[31mERROR: tensorflow 2.4.1 has requirement gast==0.3.3, but you'll have gast 0.2.2 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: tensorflow 2.4.1 has requirement tensorboard~=2.4, but you'll have tensorboard 1.15.0 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: tensorflow 2.4.1 has requirement tensorflow-estimator<2.5.0,>=2.4.0, but you'll have tensorflow-estimator 1.15.1 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: tensorflow-probability 0.12.1 has requirement gast>=0.3.2, but you'll have gast 0.2.2 which is incompatible.\u001b[0m\n",
            "Installing collected packages: keras-applications, tensorflow-estimator, gast, tensorboard, tensorflow-gpu\n",
            "  Found existing installation: tensorflow-estimator 2.4.0\n",
            "    Uninstalling tensorflow-estimator-2.4.0:\n",
            "      Successfully uninstalled tensorflow-estimator-2.4.0\n",
            "  Found existing installation: gast 0.3.3\n",
            "    Uninstalling gast-0.3.3:\n",
            "      Successfully uninstalled gast-0.3.3\n",
            "  Found existing installation: tensorboard 2.4.1\n",
            "    Uninstalling tensorboard-2.4.1:\n",
            "      Successfully uninstalled tensorboard-2.4.1\n",
            "Successfully installed gast-0.2.2 keras-applications-1.0.8 tensorboard-1.15.0 tensorflow-estimator-1.15.1 tensorflow-gpu-1.15.0rc2\n",
            "Requirement already satisfied: cython in /usr/local/lib/python3.6/dist-packages (0.29.21)\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.6/dist-packages (4.1.2.30)\n",
            "Requirement already satisfied: numpy>=1.11.3 in /usr/local/lib/python3.6/dist-packages (from opencv-python) (1.19.5)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tTDwgHVFmJZH"
      },
      "source": [
        "# Download and build darkflow (the tensorflow implementation of YOLO)\n",
        "import os\n",
        "import pathlib\n",
        "\n",
        "if \"darkflow-master\" in pathlib.Path.cwd().parts:\n",
        "  while \"darkflow-master\" in pathlib.Path.cwd().parts:\n",
        "    os.chdir('..')\n",
        "elif not pathlib.Path(\"darkflow-master\").exists():\n",
        "  !git clone --depth 1 https://github.com/thtrieu/darkflow.git\n",
        "  # Compile darkflow\n",
        "  %cd darkflow\n",
        "  !python setup.py build_ext --inplace\n",
        "  # Change darkflow to darkflow-master to distinguish between folder names\n",
        "  %cd ../\n",
        "  !mv darkflow darkflow-master"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nwKdj73Wpnlz"
      },
      "source": [
        "### Imports   \n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QSLXg6G7mJZP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "51d9468b-7be3-4a98-8cde-097f2fae3fcc"
      },
      "source": [
        "%cd darkflow-master\n",
        "\n",
        "%tensorflow_version 1.15.0rc2\n",
        "import tensorflow as tf\n",
        "print(tf.__version__)\n",
        "\n",
        "# For importing/exporting files, working with arrays, etc\n",
        "import pathlib\n",
        "import time\n",
        "import csv\n",
        "import urllib\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "# For the actual object detection\n",
        "from darkflow.net.build import TFNet\n",
        "\n",
        "# For drawing onto and plotting the images\n",
        "import matplotlib.pyplot as plt\n",
        "import cv2\n",
        "%config InlineBackend.figure_format = 'svg'"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/My Drive/train/darkflow-master\n",
            "`%tensorflow_version` only switches the major version: 1.x or 2.x.\n",
            "You set: `1.15.0rc2`. This will be interpreted as: `1.x`.\n",
            "\n",
            "\n",
            "TensorFlow 1.x selected.\n",
            "1.15.2\n",
            "WARNING:tensorflow:\n",
            "The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
            "For more information, please see:\n",
            "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
            "  * https://github.com/tensorflow/addons\n",
            "  * https://github.com/tensorflow/io (for I/O related ops)\n",
            "If you depend on functionality not listed there, please file an issue.\n",
            "\n",
            "WARNING:tensorflow:From /content/drive/My Drive/train/darkflow-master/darkflow/net/build.py:15: The name tf.train.RMSPropOptimizer is deprecated. Please use tf.compat.v1.train.RMSPropOptimizer instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/drive/My Drive/train/darkflow-master/darkflow/net/build.py:16: The name tf.train.AdadeltaOptimizer is deprecated. Please use tf.compat.v1.train.AdadeltaOptimizer instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/drive/My Drive/train/darkflow-master/darkflow/net/build.py:17: The name tf.train.AdagradOptimizer is deprecated. Please use tf.compat.v1.train.AdagradOptimizer instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/drive/My Drive/train/darkflow-master/darkflow/net/build.py:18: The name tf.train.AdagradDAOptimizer is deprecated. Please use tf.compat.v1.train.AdagradDAOptimizer instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/drive/My Drive/train/darkflow-master/darkflow/net/build.py:19: The name tf.train.MomentumOptimizer is deprecated. Please use tf.compat.v1.train.MomentumOptimizer instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/drive/My Drive/train/darkflow-master/darkflow/net/build.py:20: The name tf.train.AdamOptimizer is deprecated. Please use tf.compat.v1.train.AdamOptimizer instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/drive/My Drive/train/darkflow-master/darkflow/net/build.py:21: The name tf.train.FtrlOptimizer is deprecated. Please use tf.compat.v1.train.FtrlOptimizer instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/drive/My Drive/train/darkflow-master/darkflow/net/build.py:22: The name tf.train.GradientDescentOptimizer is deprecated. Please use tf.compat.v1.train.GradientDescentOptimizer instead.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X2fF0fSxmJZR"
      },
      "source": [
        "### Model Preparation\n",
        "---   \n",
        "**Uploads**: The models are already in darkflow/cfg, but the pre-trained weights associated with these models need to be uploaded to this notebook from https://drive.google.com/drive/folders/0B1tW_VtY7onidEwyQ2FtQVplWEU. \n",
        "\n",
        "**\"Flowing\" images through the model**: Ignore the warning messages about deprecated names, they still work at the time this last updated. Code for parameters is based on https://github.com/thtrieu/darkflow (\"Using darkflow from another python application\").\n",
        "\n",
        "Your output should be a table of values like those shown below:\n",
        "\n",
        "Source | Train? | Layer description                | Output size\n",
        "------- |:--------:|:----------------------------------:| ---------------\n",
        "       |        | input                            | (?, 448, 448, 3)\n",
        " Load  |  Yep!  | scale to (-1, 1)                 | (?, 448, 448, 3)\n",
        " Load  |  Yep!  | conv 3x3p1_1    leaky            | (?, 448, 448, 16)\n",
        "\n",
        "**Define boxing function**: You can adjust the parameters so that bounding boxes are only shown for certain confidence or class values. Here boxes are shown when confidence > 0.45 and object class is 'bird'. This function is modified from here https://gist.github.com/deep-diver/40f092ad56525189674a86b6fde6d304."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "268I2Ev_mJZL"
      },
      "source": [
        "# Test installation, you should see an output with different parameters for flow\n",
        "%cd darkflow-master\n",
        "!python flow --h"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R2wnfMcDmJZS"
      },
      "source": [
        "# Upload yolo.weights, pre-trained weights file (for YOLO v2) from Google drive \n",
        "# For directions to upload other weights files, see the wiki for this repository\n",
        "weights = 'yolo'\n",
        "weights_file = weights + '.weights'\n",
        "if not os.path.exists('weights_file'):\n",
        "  !gdown --id 0B1tW_VtY7oniTnBYYWdqSHNGSUU\n",
        "  !mkdir bin\n",
        "  !mv yolo.weights bin\n",
        "\n",
        "# Define parameters for \"flow\"ing the images through the model\n",
        "# Can change detection confidence threshold here\n",
        "params = {\n",
        "    'model': 'cfg/yolo.cfg',\n",
        "    'load': 'bin/yolo.weights',\n",
        "    'threshold': 0.45, \n",
        "    'gpu': 1.0\n",
        "}\n",
        "\n",
        "# Run the model\n",
        "tfnet = TFNet(params)\n",
        "\n",
        "# For uploading an image from url\n",
        "# Modified from https://www.pyimagesearch.com/2015/03/02/convert-url-to-image-with-python-and-opencv/\n",
        "def url_to_image(url):\n",
        "  resp = urllib.request.urlopen(url)\n",
        "  image = np.asarray(bytearray(resp.read()), dtype=\"uint8\")\n",
        "  image = cv2.imdecode(image, cv2.IMREAD_COLOR)\n",
        "  image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        " \n",
        "  return image\n",
        "\n",
        "# For drawing bounding boxes around detected objects on images\n",
        "def boxing(image, predictions):\n",
        "    newImage = np.copy(image)\n",
        "    im_height, im_width, im_depth = image.shape\n",
        "        \n",
        "    for result in predictions:\n",
        "        xmin = result['topleft']['x']\n",
        "        ymin = result['topleft']['y']\n",
        "\n",
        "        xmax = result['bottomright']['x']\n",
        "        ymax = result['bottomright']['y']\n",
        "\n",
        "        confidence = result['confidence']\n",
        "        label = result['label'] + \" \" + str(round(confidence, 3))\n",
        "\n",
        "        # only show boxes that are above .1 confidence and for the label, bird\n",
        "        if confidence > 0.45 and result['label'] == 'bird' :\n",
        "            # draw boxes on images\n",
        "            fontScale = min(im_width,im_height)/(600)\n",
        "            newImage = cv2.rectangle(newImage, (xmin, ymax), (xmax, ymin), (255, 0, 157), 3)\n",
        "            newImage = cv2.putText(newImage, label, (xmin, ymax-5), cv2.FONT_HERSHEY_SIMPLEX, fontScale, (153, 255, 255), 5, cv2.LINE_AA)\n",
        "\n",
        "            # Optional: if mounted to Drive, export detection results to aves_det_crops_1000.tsv\n",
        "            # Note: if performing detection on larger image batches, can break up files into multiple parts aves_det_crops_2000_a.tsv\n",
        "            if os.path.exists('/content/drive/My Drive/fall19_smithsonian_informatics/aves_det_crops_1000.tsv'):\n",
        "              with open('/content/drive/My Drive/fall19_smithsonian_informatics/aves_det_crops_1000.tsv', 'a') as out_file:\n",
        "                  tsv_writer = csv.writer(out_file, delimiter='\\t')\n",
        "                  tsv_writer.writerow([image_url, im_height, im_width, \n",
        "                            xmin, ymin, xmax, ymax])\n",
        "            \n",
        "        else:\n",
        "          print(\"No birds detected in {}.\".format(image_url))\n",
        "    return newImage"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1zL-PctVuqZv"
      },
      "source": [
        "## Load in sample images and 'flow' them through the object detector\n",
        "---\n",
        "You can either **A) Load individual images in by URL**, or for large image batches or **B) Load multiple images from a text file of image URLs**. Other methods for importing to Google Colab are listed [here](https://colab.research.google.com/notebooks/io.ipynb#scrollTo=XDg9OBaYqRMd). "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7gd4TbiOEXff"
      },
      "source": [
        "**A) Load individual images in by URL**\n",
        "Load in images by URL and run the image detector for all images. Plotted results include the image with bounding box around detected objects (birds), class type, and confidence score. Inference times are printed above images. If you \"mounted\" your Google Drive during \"Installs\", the bounding box coordinates will also be written to 'sample_crops_yolo.tsv'."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lke_VvPzt71m"
      },
      "source": [
        "image_urls = [\"https://content.eol.org/data/media/7e/9c/7a/542.15445377044.jpg\",\n",
        "              \"https://content.eol.org/data/media/81/1c/0d/542.7816025222.jpg\",\n",
        "              \"https://content.eol.org/data/media/7e/3c/0b/542.10578857864.jpg\"]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qNsodQP3t_o5"
      },
      "source": [
        "for image_url in image_urls:\n",
        "  image = url_to_image(image_url)\n",
        "\n",
        "  # Use YOLO for object detection  \n",
        "  # Record inference time\n",
        "  start_time = time.time()\n",
        "  result = tfnet.return_predict(image)\n",
        "  end_time = time.time()\n",
        "\n",
        "  # Plot and show detection boxes on images\n",
        "  _, ax = plt.subplots(figsize=(10, 10))\n",
        "  ax.imshow(boxing(image, result))\n",
        "\n",
        "  # Display inference time above images\n",
        "  plt.title('Inference time: {}'.format(format(end_time-start_time, '.2f')))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WStwvg5GmJZZ"
      },
      "source": [
        "**B) Load multiple images (from EOL image URL bundles) through object detector**   \n",
        "Load in multiple images from a text file of URLS and run the image detector for all images. Plotted results include the image with bounding box around detected objects (birds), class type, and confidence score. Inference times are printed above images. If you \"mounted\" your Google Drive during \"Installs\", the bounding box coordinates will also be written to 'sample_crops_yolo.tsv'."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gukCG-BVA6hm"
      },
      "source": [
        "# For 1000 or 20000 image datasets, change link below\n",
        "# 1000 Aves images\n",
        "urls = 'https://editors.eol.org/other_files/bundle_images/files/images_for_Aves_breakdown_download_000001.txt'\n",
        "# 20000 Aves images\n",
        "#urls = 'https://editors.eol.org/other_files/bundle_images/files/images_for_Aves_20K_breakdown_download_000001.txt'\n",
        "df = pd.read_csv(urls)\n",
        "df.columns = [\"link\"]\n",
        "pd.DataFrame.head(df)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NUcRnRmzwJnP"
      },
      "source": [
        "# Write header row of output crops file\n",
        "# For 1000 or 20000 image datasets, change filename here and in \"Prepare object detection functions and settings -> def boxing -> Export detection results\" above\n",
        "# Note: if performing detection on larger image batches, can break up files into multiple parts, ex: aves_det_crops_20000_a.tsv for df.iloc[0:5000].iterrows() below\n",
        "with open('/content/drive/My Drive/fall19_smithsonian_informatics/aves_det_crops_1000.tsv', 'a') as out_file:\n",
        "                  tsv_writer = csv.writer(out_file, delimiter='\\t')\n",
        "                  tsv_writer.writerow([\"image_url\", \"im_height\", \"im_width\", \n",
        "                            \"xmin\", \"ymin\", \"xmax\", \"ymax\"])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": false,
        "id": "UbyA9e1omJZZ"
      },
      "source": [
        "# Loops through first 5 image urls from the text file\n",
        "for i, row in df.head(5).itertuples(index=True, name='Pandas'):\n",
        "\n",
        "# For ranges of rows or all rows, use the commands below\n",
        "# Note: can be useful if running large image batches through in multiple parts\n",
        "#for i, row in df.iloc[0:5000].iterrows():\n",
        "#for i, row in df.iterrows():\n",
        "\n",
        "  try:\n",
        "    # Record inference time\n",
        "    start_time = time.time()\n",
        "    image_url = df.get_value(i, \"link\")\n",
        "    image = url_to_image(image_url)\n",
        "    # Detection\n",
        "    result = tfnet.return_predict(image)\n",
        "    end_time = time.time()\n",
        "    # Draw boxes on images\n",
        "    boxing(image, result)\n",
        "    # Display progress message after each image\n",
        "    print('Detection complete in {} of 1,000 images'.format(i+1))\n",
        "  \n",
        "  except:\n",
        "    print('Error: check if web address {} is valid'.format(image_url))\n",
        "  \n",
        "  # Plot and show detection boxes on images\n",
        "  # If running detection on >50 images, comment out this portion\n",
        "  _, ax = plt.subplots(figsize=(10, 10))\n",
        "  ax.imshow(boxing(image, result))\n",
        "  plt.title('{}) Inference time: {}'.format(i+1, format(end_time-start_time, '.2f')))\n",
        "  plt.close()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8RMd-33vOdBY"
      },
      "source": [
        "### Get inference info for test images to compare object detection model times for YOLO, SSD, and Faster-RCNN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3vFZFHWxNbut"
      },
      "source": [
        "from PIL import Image\n",
        "import os\n",
        "\n",
        "# For exporting inference times\n",
        "inf_time = []\n",
        "img_urls = []\n",
        "im_dims = []\n",
        "\n",
        "# Loops through first 5 image urls from the text file\n",
        "#for i, row in df.head(5).itertuples(index=True, name='Pandas'):\n",
        "for i, row in df.head(145).itertuples(index=True, name='Pandas'):\n",
        "\n",
        "  try:\n",
        "    image_url = df.get_value(i, \"link\")\n",
        "    image = url_to_image(image_url)\n",
        "    # Record inference time\n",
        "    start_time = time.time()\n",
        "    # Detection\n",
        "    result = tfnet.return_predict(image)\n",
        "    end_time = time.time()\n",
        "    # Draw boxes on images\n",
        "    boxing(image, result)\n",
        "    # Display progress message after each image\n",
        "    print('Detection complete in {} of 145 images'.format(i+1))\n",
        "\n",
        "    # Record inference time, image name and image dimensions to export\n",
        "    inf_time.append(end_time-start_time)\n",
        "    img_urls.append(image_url)\n",
        "    im_dims.append(image.shape)\n",
        "  \n",
        "  except:\n",
        "    print('Error: check if web address {} is valid'.format(image_url))\n",
        "    \n",
        "inf_times = pd.DataFrame(([inf_time, img_urls, im_dims]))\n",
        "inf_times = inf_times.transpose()\n",
        "inf_times.to_csv(\"aves_inference_times_yolo.csv\", index=False, header=(\"time (sec)\", \"filepath\", \"image_dims (h, w, d)\"))\n",
        "print(inf_times.head())"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}