{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/aubricot/computer_vision_with_eol_images/blob/master/object_detection_for_image_cropping/aves/aves_inspect_results.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Lv89gfSGjs3B"
      },
      "source": [
        "# Compare model outputs with known crops\n",
        "---   \n",
        "*Last Updated 7 February 2025*  \n",
        "-Now runs in Python 3 with Tensorflow 2.0-     \n",
        "\n",
        "Compare trained model predicted and post-processed square crops with known square crops from EOL user generated test data.\n",
        "\n",
        "Models [Faster-RCNN](https://tfhub.dev/tensorflow/faster_rcnn/resnet50_v1_640x640/1) and [SSD](https://tfhub.dev/tensorflow/ssd_mobilenet_v2/2) were pretrained on [MS COCO 2017](https://cocodataset.org/#explore) and used to generate crops in [aves_generate_crops_tf2.ipynb](https://github.com/aubricot/computer_vision_with_eol_images/blob/master/object_detection_for_image_cropping/aves/aves_generate_crops_tf2.ipynb).\n",
        "\n",
        "Notes:   \n",
        "* Run code blocks by pressing play button in brackets on left\n",
        "* Before you you start: change the runtime to \"GPU\" with \"High RAM\"\n",
        "* Change parameters using form fields on right (find details at corresponding lines of code by searching '#@param')\n",
        "\n",
        "References:     \n",
        "* [Official Tensorflow Object Detection API Instructions](https://tensorflow-object-detection-api-tutorial.readthedocs.io/en/latest/training.html)   \n",
        "* [Medium Blog on training using Tensorflow Object Detection API in Colab](https://medium.com/analytics-vidhya/training-an-object-detection-model-with-tensorflow-api-using-google-colab-4f9a688d5e8b)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3-5awa5YDAjy"
      },
      "source": [
        "## Installs & Imports\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VooXJOohjmLB"
      },
      "outputs": [],
      "source": [
        "#@title Choose where to save results\n",
        "# Use dropdown menu on right\n",
        "save = \"in Colab runtime (files deleted after each session)\" #@param [\"in my Google Drive\", \"in Colab runtime (files deleted after each session)\"]\n",
        "\n",
        "# Mount google drive to export image cropping coordinate file(s)\n",
        "if 'Google Drive' in save:\n",
        "    from google.colab import drive\n",
        "    drive.mount('/content/drive', force_remount=True)\n",
        "\n",
        "# Note: You can modify \"filter\" to choose detection results for any class of interest the model is trained on\n",
        "filter = \"Aves\" # @param [\"Aves\"] {\"allow-input\":true}\n",
        "\n",
        "# Type in the path to your project wd in form field on right\n",
        "basewd = \"/content/drive/MyDrive/train\" #@param [\"/content/drive/MyDrive/train\"] {allow-input: true}\n",
        "# Type in the folder that you want to contain TF2 files\n",
        "folder = \"tf2\" #@param [\"tf2\"] {allow-input: true}\n",
        "# Define current working directory using form field inputs\n",
        "cwd = basewd + '/' + folder + '/' + filter\n",
        "\n",
        "# Install dependencies\n",
        "!pip3 install --upgrade gdown\n",
        "!gdown  1-IEwduCmOWHc5uk3oKQsxeHBihS7wZtl # Download helper_funcs folder\n",
        "!tar -xzvf aves_helper_funcs.tar.gz -C .\n",
        "!pip install -r requirements.txt"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Choose saved model parameters\n",
        "import sys\n",
        "sys.path.append('/content')\n",
        "from setup import *\n",
        "\n",
        "# Set up directory structure\n",
        "setup_dirs(cwd)\n",
        "%cd $cwd\n",
        "\n",
        "# Download Aves_crops_test.tsv\n",
        "%cd $cwd\n",
        "%cd results\n",
        "!gdown 1LBfhLa-WVMJ-ffcagl22_Y8enU0Bv-TS\n",
        "%cd $cwd\n",
        "\n",
        "# Load Pre-trained model from Tensorflow Hub (both trained on MS COCO 2017)\n",
        "model = \"Faster RCNN Resnet 50\" #@param [\"SSD MobileNet v2\", \"Faster RCNN Resnet 50\"] {allow-input: true}\n",
        "detector, module_handle, mod_abbv = load_tfhub_detector(model)\n",
        "\n",
        "# Load corresponding label map for MS COCO 2017\n",
        "!gdown 1mWmTvaBWKZ2GBbRllDoxPkecgJl5jnFK # Download labelmap.json\n",
        "label_map = convert_labelmap('labelmap.json')"
      ],
      "metadata": {
        "id": "rYtYkbtd9KoM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nqADYAPDDF8a"
      },
      "outputs": [],
      "source": [
        "#@title Import libraries\n",
        "\n",
        "# For running inference on the TF-Hub module\n",
        "import tensorflow as tf\n",
        "import tensorflow_hub as hub\n",
        "\n",
        "# For downloading and displaying images\n",
        "import matplotlib.pyplot as plt\n",
        "import tempfile\n",
        "from six.moves.urllib.request import urlopen\n",
        "from six import BytesIO\n",
        "\n",
        "# For drawing onto images\n",
        "from PIL import Image\n",
        "from PIL import ImageColor\n",
        "from PIL import ImageDraw\n",
        "from PIL import ImageFont\n",
        "from PIL import ImageOps\n",
        "\n",
        "# For measuring inference time\n",
        "import time\n",
        "\n",
        "# For working with data\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "pd.set_option('display.max_colwidth', 1000)\n",
        "pd.options.display.max_columns = None\n",
        "import os\n",
        "import csv\n",
        "import urllib\n",
        "import sys\n",
        "import json\n",
        "\n",
        "# Define EOL CV custom functions\n",
        "from wrangle_data import *\n",
        "\n",
        "# Print Tensorflow version\n",
        "print('Tensorflow Version: %s' % tf.__version__)\n",
        "\n",
        "# Check available GPU devices\n",
        "print('The following GPU devices are available: %s' % tf.test.gpu_device_name())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GyeMFYrlDVGS"
      },
      "source": [
        "## Generate crops: Run inference on EOL images & save resulting coordinates for cropping\n",
        "---\n",
        "Use EOl user generated crops file to generate bounding boxes around each object with pre-trained object detection models. Results are saved to [crops_file].tsv."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sdk2mI5fDXZQ",
        "cellView": "code"
      },
      "outputs": [],
      "source": [
        "#@title Define functions\n",
        "%matplotlib inline\n",
        "\n",
        "# Set the maximum number of detections to keep per image\n",
        "max_boxes = 10 #@param {type:\"slider\", min:0, max:100, step:10}\n",
        "\n",
        "# Set the minimum confidence score for detections to keep per image\n",
        "min_score = 0.6 #@param {type:\"slider\", min:0, max:0.9, step:0.1}\n",
        "\n",
        "# Set filename for saving classification results\n",
        "def set_outpath(crops_file, cwd):\n",
        "    outpath = cwd + '/' + 'results/' + os.path.splitext(crops_file)[0] + mod_abbv + '.tsv'\n",
        "    print(\"\\nSaving results to: \\n\", outpath)\n",
        "\n",
        "    return outpath\n",
        "\n",
        "# Export object detection results\n",
        "def export_results(image_url, result, outfpath, im_h, im_w, filter=filter):\n",
        "    with open(outfpath, 'a') as out_file:\n",
        "        tsv_writer = csv.writer(out_file, delimiter='\\t')\n",
        "        img_id = os.path.splitext((os.path.basename(image_url)))[0]\n",
        "        # Write one row per detected object with bounding box coordinates\n",
        "        num_detections = min(int(result[\"num_detections\"][0]), max_boxes)\n",
        "        for i in range(0, num_detections):\n",
        "            class_name = str(label_map[result[\"detection_classes\"][0][i]])\n",
        "            filter = \"bird\"\n",
        "            if filter in class_name: # Only writes rows for filtered class\n",
        "                ymin = result[\"detection_boxes\"][0][i][0]\n",
        "                xmin = result[\"detection_boxes\"][0][i][1]\n",
        "                ymax = result[\"detection_boxes\"][0][i][2]\n",
        "                xmax = result[\"detection_boxes\"][0][i][3]\n",
        "                confidence = result[\"detection_scores\"][0][i]\n",
        "                tsv_writer.writerow([img_id, class_name, confidence,\n",
        "                          xmin, ymin, xmax, ymax, im_h, im_w, image_url])\n",
        "        print(\"\\nObject detection results for Image {} saved to: {}\".format(image_url, outfpath))\n",
        "\n",
        "    return img_id\n",
        "\n",
        "# Format cropping dimensions to EOL standards\n",
        "def format_crops_for_eol(df):\n",
        "# {\"height\":\"423\",\"width\":\"640\",\"crop_x\":123.712,\"crop_y\":53.4249,\"crop_width\":352,\"crop_height\":0}\n",
        "    df['crop_dimensions'] = np.nan\n",
        "    for i, row in df.iterrows():\n",
        "        df.loc[i, 'crop_dimensions'] = ('{{\"height\":\"{}\",\"width\":\"{}\",\"crop_x\":{},\"crop_y\":{},\"crop_width\":{},\"crop_height\":{}}}'\n",
        "        .format(df.im_height[i], df.im_width[i], df.xmin[i], df.ymin[i], df.crop_width[i], df.crop_height[i]))\n",
        "\n",
        "    # Add other dataframe elements from cols: identifier, dataobjectversionid, eolmediaurl, im_class, crop_dimensions\n",
        "    eol_crops = pd.DataFrame(df.iloc[:,np.r_[-5,-4,-6,0,-1]])\n",
        "    print(\"\\n EOL formatted cropping dimensions: \\n\", eol_crops.head())\n",
        "\n",
        "    return eol_crops\n",
        "\n",
        "print('Model loaded and functions defined! \\nGo to next steps to run inference on images.')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xiy_g1NaDqc8"
      },
      "source": [
        "### Generate predictions (crops): Run inference on EOL test images with known ground truths\n",
        "Use EOL Aves test images to get bounding boxes of detected birds. Results are saved to [crops_file].tsv."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XZVQSNQpMI0v"
      },
      "outputs": [],
      "source": [
        "#@title Enter EOL cropping test image tsv and choose inference settings\n",
        "%cd $cwd\n",
        "\n",
        "# Load in EOL image bundle\n",
        "bundle = \"Aves_crops_test.tsv\" #@param {type:\"string\"}\n",
        "bundle_path = 'results/' + bundle\n",
        "df1 = read_datafile(bundle_path, sep='\\t', header=0, disp_head=False)\n",
        "ground_truth = df1.copy()\n",
        "df = pd.DataFrame(df1['obj_url'])\n",
        "df.columns = ['url']\n",
        "print('\\n EOL test images head:\\n{}'.format(df.head()))\n",
        "\n",
        "# Test pipeline with a smaller subset than 5k images?\n",
        "run = \"test with tiny subset\" #@param [\"test with tiny subset\", \"for all images\"]\n",
        "\n",
        "# Display detection results on images?\n",
        "if 'tiny subset' in run:\n",
        "    display_results = True\n",
        "else:\n",
        "    display_results = False\n",
        "\n",
        "# Run inference on EOL test images (with known ground truths)\n",
        "crops_file = \"aves_cropcoords_tf2\" # @param [\"aves_cropcoords_tf2\"] {\"allow-input\":true}\n",
        "outfpath = set_outpath(crops_file, cwd)\n",
        "\n",
        "# Write header row of output tag file\n",
        "if not os.path.isfile(outfpath):\n",
        "    with open(outfpath, 'a') as out_file:\n",
        "              tsv_writer = csv.writer(out_file, delimiter='\\t')\n",
        "              tsv_writer.writerow([\"img_id\", \"class_name\", \"confidence\", \"xmin\", \\\n",
        "                                   \"ymin\", \"xmax\", \"ymax\", \"im_width\", \\\n",
        "                                   \"im_height\", \"url\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kJVvyl4vDxQw"
      },
      "outputs": [],
      "source": [
        "#@title Run EOL test images through trained model and save results\n",
        "print(\"Running inference on images\")\n",
        "all_predictions = []\n",
        "stop = 250\n",
        "start = 0\n",
        "display_results = False\n",
        "for i, row in enumerate(df.iloc[start:stop].iterrows()):\n",
        "    try:\n",
        "        # Run image through object detector and export result\n",
        "        image_url = df['url'][row[0]]\n",
        "        image_wboxes, result, im_h, im_w = run_detector_tf(detector, image_url, outfpath, filter, label_map, max_boxes, min_score)\n",
        "        img_id = export_results(image_url, result, outfpath, im_h, im_w)\n",
        "\n",
        "        # Optional: Display detections on images\n",
        "        if (i+1<=50) and display_results:\n",
        "            display_image(image_wboxes)\n",
        "\n",
        "        # Display progress message after each image\n",
        "        all_predictions.append(img_id)\n",
        "        print('\\033[92m {}) Inference complete for image {} of {} \\033[0m \\n'.format(i+1, i+1, stop))\n",
        "\n",
        "    except:\n",
        "        print('Check if URL from {} is valid\\n'.format(df['url'][i]))\n",
        "\n",
        "print(\"\\n\\n~~~\\n\\033[92m Inference complete!\\033[0m \\033[93m Run these steps for remaining batches A-D before proceeding.\\033[0m\\n~~~\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uSjtwcuYDzV3"
      },
      "source": [
        "## Post-process detection results\n",
        "---\n",
        "Convert detection boxes into square, centered thumbnail cropping coordinates."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6rBZMx9BD1_4"
      },
      "outputs": [],
      "source": [
        "#@title Enter path to inference result file\n",
        "%cd $cwd\n",
        "\n",
        "# If you just ran \"Generate crops\" above, you do not need to enter anything\n",
        "# If you ran \"Generate crops\" during a previous session, enter the path for ONE output file\n",
        "if 'outfpath' not in locals() or globals():\n",
        "    crops_file = \"aves_cropcoords_tf2.tsv\" # @param [\"aves_cropcoords_tf2.tsv\"] {\"allow-input\":true}\n",
        "    outfpath = set_outpath(crops_file, cwd)\n",
        "\n",
        "df = pd.read_csv(outfpath, sep='\\t', header=0, na_filter = False)\n",
        "df.columns = ['img_id', 'class_name', 'confidence', 'xmin', 'ymin', 'xmax', 'ymax', 'im_width', 'im_height', 'url']\n",
        "print(\"Bounding box dataframe, before post-processing: {} \\n{}\".format(outfpath, df.head()))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Add EOL img identifying info from breakdown file to cropping data\n",
        "def add_identifiers(superboxes, bundle_info):\n",
        "    # Get dataObjectVersionIDs, identifiers, and eolMediaURLS from indexed cols\n",
        "    ids = pd.DataFrame(bundle_info[['data_object_id', 'obj_url', 'obj_guid']])\n",
        "    ids.set_index('obj_url', inplace=True, drop=True)\n",
        "    #print(\"Bundle identifying info head: \\n\", ids.head())\n",
        "\n",
        "    # Set up superboxes df for mapping to bundle_info\n",
        "    superboxes.reset_index(inplace=True)\n",
        "    superboxes.rename(columns={'url': 'obj_url'}, inplace=True)\n",
        "    superboxes.set_index('obj_url', inplace=True, drop=True)\n",
        "\n",
        "    # Map dataObjectVersionIDs to crops_unq using eolMediaURL as the index\n",
        "    crops_w_identifiers = pd.DataFrame(superboxes.merge(ids, left_index=True, right_index=True))\n",
        "    crops_w_identifiers.reset_index(inplace=True)\n",
        "    print(\"\\n Crops with added EOL identifiers: \\n\", crops_w_identifiers.head())\n",
        "\n",
        "    return crops_w_identifiers\n",
        "\n",
        "# For images with >1 detection, make a 'super box' that containings all boxes\n",
        "def make_superboxes(crops):\n",
        "    # Get superbox coordinates that contain all detection boxes per image\n",
        "    xmin = pd.DataFrame(crops.groupby(['url'])['xmin'].min()) # smallest xmin\n",
        "    ymin = pd.DataFrame(crops.groupby(['url'])['ymin'].min()) # smallest ymin\n",
        "    xmax = pd.DataFrame(crops.groupby(['url'])['xmax'].max()) # largest xmax\n",
        "    ymax = pd.DataFrame(crops.groupby(['url'])['ymax'].max()) # largest ymax\n",
        "\n",
        "    # Workaround to get im_height, im_width and class in same format as 'super box' coords\n",
        "    # There is only one value for im_height and im_width, so taking max will return unchanged values\n",
        "    im_h = pd.DataFrame(crops.groupby(['url'])['im_height'].max())\n",
        "    im_w = pd.DataFrame(crops.groupby(['url'])['im_width'].max())\n",
        "    im_class = pd.DataFrame(crops.groupby(['url'])['class_name'].max())\n",
        "    confidence = pd.DataFrame(crops.groupby(['url'])['confidence'].max())\n",
        "\n",
        "    # Make list of superboxes\n",
        "    superbox_list = [im_h, im_w, xmin, ymin, xmax, ymax, im_class, confidence]\n",
        "\n",
        "    # Make a new dataframe with 1 superbox per image\n",
        "    superbox_df = reduce(lambda  left, right: pd.merge(left, right, on=['url'],\n",
        "                                            how='outer'), superbox_list)\n",
        "    #print(\"Cropping dataframe, 1 superbox per image: \\n\", crops_unq.head())\n",
        "\n",
        "    return superbox_df"
      ],
      "metadata": {
        "id": "C2LeFO8jQrrf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ttP8IH5_EVa1"
      },
      "outputs": [],
      "source": [
        "#@title Combine individual detection boxes into one \"superbox\" per image\n",
        "\n",
        "# For images with >1 detection, make a 'super box' that containings all boxes\n",
        "\n",
        "# Read in crop file exported from \"Combine output files A-D\" block above\n",
        "crops = df.copy()\n",
        "print(crops.head())\n",
        "\n",
        "# De-normalize cropping coordinates to pixel values\n",
        "crops = denormalize_coords(crops)\n",
        "\n",
        "# Make 1 superbox per image [coordinates: bottom left (smallest xmin, ymin) and top right (largest xmax, ymax)]\n",
        "superboxes = make_superboxes(crops)\n",
        "\n",
        "# Read in EOL image \"breakdown\" bundle dataframe from \"breakdown_download\" bundle used for cropping\n",
        "if 'bundle' not in locals() or globals():\n",
        "    bundle = \"Aves_crops_test.tsv\" # @param [\"Aves_crops_test.tsv\",\"\"] {\"allow-input\":true}\n",
        "    bundle_path = 'results/' + bundle\n",
        "bundle_info = read_datafile(bundle_path, sep='\\t', header=0, disp_head=False)\n",
        "\n",
        "# Add EOL img identifying info from breakdown file to cropping data\n",
        "crops_w_identifiers = add_identifiers(superboxes, bundle_info)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "APThvzPcEXMT"
      },
      "outputs": [],
      "source": [
        "#@title Make superbox square and within image bounds (Optional: add padding)\n",
        "\n",
        "# Pad by xx% larger crop dimension\n",
        "pad = 2.5 # @param {\"type\":\"slider\",\"min\":0,\"max\":10,\"step\":0.5}\n",
        "pad = pad/100 # Convert to percentage\n",
        "\n",
        "# Make crops square and within bounds\n",
        "df = make_square_crops(crops_w_identifiers, pad)\n",
        "\n",
        "# Export crop coordinates to display_test.tsv to visualize results in next code block and confirm crop transformations\n",
        "display_test_fpath = os.path.splitext(outfpath)[0] + '_displaytest' + '.tsv'\n",
        "print(\"\\n File for displaying square crops on images will be saved to: \\n\", display_test_fpath)\n",
        "df.to_csv(display_test_fpath, sep='\\t', index=False)\n",
        "\n",
        "# Format image and cropping dimensions for EOL standards\n",
        "eol_crops = format_crops_for_eol(df)\n",
        "\n",
        "# Write results to tsv\n",
        "eol_crops_fpath = os.path.splitext(display_test_fpath)[0].rsplit('_',2)[0] + '_20k_final' + '.tsv'\n",
        "eol_crops.to_csv(eol_crops_fpath, columns = eol_crops.iloc[:,:-1], sep='\\t', index=False)\n",
        "print(\"EOL formatted crops dataset saved to: {} \\n{}\".format(eol_crops_fpath, eol_crops.head()))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iGWwa3YGpMzS"
      },
      "outputs": [],
      "source": [
        "#@title Format EOL user crops to match display test crops\n",
        "\n",
        "# Read in EOL image \"breakdown\" bundle dataframe from \"breakdown_download\" bundle used for cropping\n",
        "if 'bundle' not in locals() or globals():\n",
        "    bundle = \"Aves_crops_test.tsv\" #@param {type:\"string\"}\n",
        "    bundle_path = 'results/' + bundle\n",
        "bundle_info = read_datafile(bundle_path, sep='\\t', header=0, disp_head=False)\n",
        "bundle_info['class_name'] = 'Aves'\n",
        "# Take and rename relevant columns\n",
        "ground_truth = pd.DataFrame(bundle_info[['obj_url', 'im_height', 'im_width', 'xmin', 'ymin', 'xmax', 'ymax', 'class_name', 'data_object_id', 'obj_guid']])\n",
        "ground_truth['crop_height'] = ground_truth['ymax'] - ground_truth['ymin']\n",
        "ground_truth['crop_width'] = ground_truth['xmax'] - ground_truth['xmin']\n",
        "\n",
        "# Export ground truth formatted crops\n",
        "ground_truth_fpath = os.path.splitext(bundle_path)[0] + '_groundtruth' + '.tsv'\n",
        "ground_truth.to_csv(ground_truth_fpath, sep='\\t', index=False)\n",
        "print(\"Ground truths saved to: \", ground_truth_fpath)\n",
        "print(ground_truth.head())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T30GOVYpEaXd"
      },
      "source": [
        "## Display ground truths versus model predictions on images and save outputs\n",
        "---\n",
        "Images will have two boxes each - one ground truth and one model prediction"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hWpSgxcpxA7b"
      },
      "outputs": [],
      "source": [
        "#@title Read in cropping file and display results on images\n",
        "from wrangle_data import *\n",
        "import cv2\n",
        "\n",
        "# Load in prediction df\n",
        "pred_fname = \"aves_cropcoords_tf2_rcnn_displaytest.tsv\" # @param [\"Aves_crops_test_groundtruth.tsv\",\"aves_cropcoords_tf2_rcnn_displaytest.tsv\"] {\"allow-input\":true}\n",
        "display_test_fpath = 'results/' + pred_fname\n",
        "df = pd.read_csv(display_test_fpath, sep=\"\\t\", header=0)\n",
        "df_pred = df.copy()\n",
        "\n",
        "# Load in ground truth df\n",
        "gt_fname = \"Aves_crops_test_groundtruth.tsv\" # @param [\"Aves_crops_test_groundtruth.tsv\",\"aves_cropcoords_tf2_rcnn_displaytest.tsv\"] {\"allow-input\":true}\n",
        "display_test_fpath = 'results/' + gt_fname\n",
        "df_gt = pd.read_csv(display_test_fpath, sep=\"\\t\", header=0)\n",
        "df_gt = df_gt.set_index('obj_url').reset_index()\n",
        "\n",
        "print(\"DF: \\n\", df.head())\n",
        "print(\"GT: \\n\", df_gt.head())\n",
        "print(\"Pred: \\n\", df_pred.head())"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Draw cropping box on image\n",
        "def draw_box_on_image(df, i, img, tag):\n",
        "    # Get box coordinates\n",
        "    xmin = df['xmin'][i].astype(int)\n",
        "    ymin = df['ymin'][i].astype(int)\n",
        "    xmax = df['xmax'][i].astype(int)\n",
        "    ymax = df['ymax'][i].astype(int)\n",
        "    boxcoords = [xmin, ymin, xmax, ymax]\n",
        "\n",
        "    # Set box/font color and size\n",
        "    maxdim = max(df['im_height'][i],df['im_width'][i])\n",
        "    fontScale = maxdim/600\n",
        "    box_col = (255, 0, 157)\n",
        "\n",
        "    # Add label to image\n",
        "    image_wbox = cv2.putText(img, tag, (xmin+7, ymax-12), cv2.FONT_HERSHEY_SIMPLEX, fontScale, box_col, 2, cv2.LINE_AA)\n",
        "\n",
        "    # Draw box label on image\n",
        "    image_wbox = cv2.rectangle(img, (xmin, ymax), (xmax, ymin), box_col, 5)\n",
        "\n",
        "    return image_wbox, boxcoords"
      ],
      "metadata": {
        "id": "LANZed8U3wlH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f0SAM4RUv6xc"
      },
      "outputs": [],
      "source": [
        "#@title Draw bounding boxes on image & save resulting images\n",
        "%matplotlib inline\n",
        "import imageio\n",
        "\n",
        "# Display results on images (only use for 5 images as a test)\n",
        "display_results = True #@param {type:\"boolean\"}\n",
        "print(\"Displaying results on images for small subset of 5 images. Uncheck display_results to run and save for all images.\")\n",
        "\n",
        "# Adjust line to right to see up to 50 images displayed at a time\n",
        "start = 0 # @param {\"type\":\"number\",\"placeholder\":\"0\"}\n",
        "if display_results:\n",
        "    stop = start + 5\n",
        "else:\n",
        "    stop = start + len(df)\n",
        "\n",
        "# Loop through images\n",
        "for i, row in df.iloc[start:stop].iterrows():\n",
        "    try:\n",
        "        # Read in image\n",
        "        url = df['obj_url'][i]\n",
        "        image = url_to_image(url)\n",
        "        # Draw bounding box on image - Ground Truth\n",
        "        image_wbox, boxcoords_gt = draw_box_on_image(df_gt, i, image, \"ground truth\")\n",
        "        # Draw bounding box on image - Prediction\n",
        "        image_wboxes, boxcoords_pred = draw_box_on_image(df_pred, i, image_wbox, \"prediction\")\n",
        "        if display_results:\n",
        "            # Plot cropping box on image\n",
        "            _, ax = plt.subplots(figsize=(10, 10))\n",
        "            ax.imshow(image_wboxes)\n",
        "\n",
        "            # Display image URL and coordinates above image\n",
        "            plt.title('{} \\n im_h: {} im_w: {} \\n Ground Truth - xmin: {}, ymin: {}, xmax: {}, ymax: {} \\n Prediction - xmin: {}, ymin: {}, xmax: {}, ymax: {}'.format(url, im_h, im_w, boxcoords_gt[0], boxcoords_gt[1], boxcoords_gt[2], boxcoords_gt[3], boxcoords_pred[0], boxcoords_pred[1], boxcoords_pred[2], boxcoords_pred[3]))\n",
        "\n",
        "        # Save Results\n",
        "        path = \"results/inspect_results/\" + str(df['data_object_id'][i]) + \"_wbox.png\"\n",
        "        imageio.imwrite(path, image_wboxes)\n",
        "        print(\"Image with boxes saved to: \", path)\n",
        "\n",
        "    except:\n",
        "        pass"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "unzipped_fpath = \"results/inspect_results\"\n",
        "zip_fpath = \"results/inspect_results.zip\"\n",
        "!zip -r $zip_fpath $unzipped_fpath"
      ],
      "metadata": {
        "id": "9Io7p1Gs5VP_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WT39cFtSNRHI"
      },
      "source": [
        "## Caculate mAP for test images\n",
        "---\n",
        "Convert detection boxes into square, centered thumbnail cropping coordinates."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ss8vyYiq6lQn"
      },
      "outputs": [],
      "source": [
        "#@title Convert cropping coordinates for EOL user generated ground truths (square crops) to mAP format\n",
        "%cd $cwd\n",
        "\n",
        "# Read in model predictions df\n",
        "predict_fname = \"aves_cropcoords_tf2_rcnn_displaytest.tsv\" # @param [\"aves_cropcoords_tf2_rcnn_displaytest.tsv\"] {\"allow-input\":true}\n",
        "predict_fpath = 'results/' + predict_fname\n",
        "df = pd.read_csv(predict_fpath, sep=\"\\t\", header=0)\n",
        "df_pred = df.copy()\n",
        "\n",
        "# Read in ground truth df\n",
        "gt_fname = \"Aves_crops_test_groundtruth.tsv\" # @param [\"Aves_crops_test_groundtruth.tsv\",\"aves_cropcoords_tf2_rcnn_displaytest.tsv\"] {\"allow-input\":true}\n",
        "gt_fpath = 'results/' + gt_fname\n",
        "df_gt = pd.read_csv(gt_fpath, sep=\"\\t\", header=0)\n",
        "# Rows in df1 that are not in df2\n",
        "df_gt = df_gt.set_index('obj_url').reindex(df_pred['obj_url']).reset_index()\n",
        "\n",
        "print(\"df\", df.head())\n",
        "print(\"gt\", df_gt.head())\n",
        "print(\"pred\", df_pred.head())\n",
        "\n",
        "df['xmin_gt'] = df_gt['xmin'].copy()\n",
        "df['ymax_gt'] = df_gt['ymax'].copy()\n",
        "df['xmax_gt'] = df_gt['xmax'].copy()\n",
        "df['ymin_gt'] = df_gt['ymin'].copy()\n",
        "print(\"Df with new cols: \", df.head())\n",
        "\n",
        "# Format bounding boxes for calculating mAP and IoU\n",
        "pred_bboxes = []\n",
        "pred_classes = []\n",
        "pred_confs = []\n",
        "gt_bboxes = []\n",
        "gt_classes = []\n",
        "# Loop through df and extract relevant info as lists\n",
        "for i, row in df.iterrows():\n",
        "    pred_bbox = [row['xmin'], row['ymin'], row['xmax'], row['ymax'], row['confidence']]\n",
        "    pred_class = 1\n",
        "    pred_conf = row['confidence']\n",
        "    gt_bbox = [row['xmin_gt'], row['ymin_gt'], row['xmax_gt'], row['ymax_gt']]\n",
        "    gt_class = 1\n",
        "\n",
        "    pred_bboxes.append(pred_bbox)\n",
        "    pred_classes.append(pred_class)\n",
        "    pred_confs.append(pred_conf)\n",
        "    gt_bboxes.append(gt_bbox)\n",
        "    gt_classes.append(gt_class)\n",
        "\n",
        "# Reformatted bounding box data\n",
        "print(\"\\n\\n~~~Reformatted bounding box data for mAP analysis~~~\\n\")\n",
        "print(\"pred_bboxes\", pred_bboxes)\n",
        "print(\"pred_classes\", pred_classes)\n",
        "print(\"pred_confs\", pred_confs)\n",
        "print(\"gt_bboxes\", gt_bboxes)\n",
        "print(\"gt_classes\", gt_classes)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "te05bKOGGh7a"
      },
      "outputs": [],
      "source": [
        "# Define functions\n",
        "from sklearn.metrics import average_precision_score\n",
        "\n",
        "# Calculate mean averag precision\n",
        "def calculate_map(gt_boxes, pred_boxes, iou_threshold=0.5):\n",
        "    aps = []\n",
        "    y_true = []\n",
        "    y_scores = []\n",
        "    ious = []\n",
        "    for i, gt_box in enumerate(gt_boxes):\n",
        "          iou = calculate_iou(gt_box, pred_boxes[i])\n",
        "          if iou > iou_threshold:\n",
        "                y_true.append(1)\n",
        "                y_scores.append(pred_boxes[i][4])  # Confidence score is at index 4\n",
        "                ious.append(iou)\n",
        "\n",
        "    if len(y_true) > 0:\n",
        "            print(\"\\n Number of true detections with iou > {} : {}: \".format(iou_threshold, len(y_true)))\n",
        "            print(\"Number of total detections: \", len(gt_boxes))\n",
        "            ap = average_precision_score(y_true, y_scores)\n",
        "            aps.append(ap)\n",
        "\n",
        "    return np.mean(aps), np.mean(ious)\n",
        "\n",
        "# Calculate intersection over union\n",
        "def calculate_iou(box1, box2):\n",
        "    # Calculate intersection area\n",
        "    print(\"box1: \", box1)\n",
        "    print(\"box2: \", box2)\n",
        "    x1 = max(box1[0], box2[0])\n",
        "    y1 = max(box1[1], box2[1])\n",
        "    x2 = min(box1[2], box2[2])\n",
        "    y2 = min(box1[3], box2[3])\n",
        "    print(\"x1: \", x1)\n",
        "    print(\"y1: \", y1)\n",
        "    print(\"x2: \", x2)\n",
        "    print(\"y2: \", y2)\n",
        "    intersection_area = (x2 - x1) * (y2 - y1)\n",
        "    if intersection_area < 0:\n",
        "        intersection_area = 0\n",
        "    print(\"intersection: \", intersection_area)\n",
        "\n",
        "    # Calculate union area\n",
        "    box1_area = abs((box1[2] - box1[0]) * (box1[3] - box1[1]))\n",
        "    box2_area = abs((box2[2] - box2[0]) * (box2[3] - box2[1]))\n",
        "    union_area = box1_area + box2_area - intersection_area\n",
        "    print(\"box1_area: \", box1_area)\n",
        "    print(\"box2_area: \", box2_area)\n",
        "    print(\"union: \", union_area)\n",
        "\n",
        "    # Calculate IoU\n",
        "    iou = intersection_area / union_area\n",
        "    print(\"iou: \", iou)\n",
        "    print(\"\\n\")\n",
        "    return iou"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jkoRPIAYIP5_"
      },
      "outputs": [],
      "source": [
        "#@title Calculate mAP\n",
        "map, mIoU = calculate_map(gt_bboxes, pred_bboxes, iou_threshold=0.5)\n",
        "print(\"\\nmAP\", map)\n",
        "print(\"\\nmIoU\", mIoU)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "machine_shape": "hm",
      "provenance": [],
      "gpuType": "A100",
      "authorship_tag": "ABX9TyNPCHXLIIVwcXRLR+aDdYTc",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}