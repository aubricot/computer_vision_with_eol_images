{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "calculate_error_mAP.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/aubricot/computer_vision_with_eol_images/blob/master/object_detection_for_image_cropping/archive/calculate_error_mAP.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k3JTznL1ocgj"
      },
      "source": [
        "# Calculate detection result error (mAP) from YOLO object detection results\n",
        "---\n",
        "Last Updated 8 April 2020   \n",
        "--*Update as of 1 June 2021--Darkflow builds are no longer being updated and only support Tensorflow 1.x builds. As a result, this notebook and others associated with darkflow in this repo are left in their state from 8 April 2020. Functions may become deprecated or lose functionality. For updated mAP and AR with Tensorflow models, refer to [Tensorflow notebooks](https://github.com/aubricot/computer_vision_with_eol_images/blob/master/object_detection_for_image_cropping/lepidoptera/lepidoptera_train_tf2_ssd_rcnn.ipynb). For object detection with YOLO v4 in it's native state and calculation of performance metrics, see [Object Detection for Image Tagging Notebooks](https://github.com/aubricot/computer_vision_with_eol_images/tree/master/object_detection_for_image_tagging)*--   \n",
        "Use exported detection result coordinates from YOLO via darkflow to calculate detection error using mean Average Precision (mAP) and Intersection over Union (IoU).\n",
        "\n",
        "Code modified from the [mAP GitHub repo](https://github.com/Cartucho/mAP#create-the-ground-truth-files)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pjGPa9NbYD1_"
      },
      "source": [
        "# Mount google drive to import/export files\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_ym-DoQfrGpZ"
      },
      "source": [
        "### Convert test image detection results (jsons) and annotation files (xmls) to text files\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IMnDtYBkoQ-M"
      },
      "source": [
        "# Install the mAP repository to calculate error from detection results\n",
        "import os\n",
        "%cd drive/My Drive/fall19_smithsonian_informatics/train\n",
        "if not os.path.exists(\"eval\"):\n",
        "  !mkdir eval\n",
        "  %cd eval\n",
        "  !git clone https://github.com/Cartucho/mAP\n",
        "  %cd ../"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4FuEdcxpiCT2"
      },
      "source": [
        "# Move yolo detection results (jsons exported from training_yolo.ipynb) to detection-results/\n",
        "%cd drive/My Drive/fall19_smithsonian_informatics/train\n",
        "!mv test_images/out/* eval/mAP/input/detection-results/\n",
        "!rm -rf test_images/out"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yBfdBGNKnd4l"
      },
      "source": [
        "# Copy image annotations (xmls formatted with ground truth bounding boxes) to ground-truth/\n",
        "%cd drive/My Drive/fall19_smithsonian_informatics/train\n",
        "!cp test_ann/* eval/mAP/input/ground-truth/"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7JuYLqfXpBsT"
      },
      "source": [
        "# Convert jsons to format needed for mAP calc\n",
        "%cd eval/mAP/scripts/extra\n",
        "!python convert_dr_darkflow_json.py"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-gM1RtGAm7Fg"
      },
      "source": [
        "# Convert xmls to format needed for mAP calc\n",
        "%cd eval/mAP/scripts/extra\n",
        "!python convert_gt_xml.py"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UKMap2ZRtC9L"
      },
      "source": [
        "# Remove sample images in input/images-optional\n",
        "# cd to mAP\n",
        "%cd ../../\n",
        "!rm -rf input/images-optional/*"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qRcR2EbErUwO"
      },
      "source": [
        "### Calculate mAP for test images\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lg3xlEK2uXNq"
      },
      "source": [
        "# Calculate mAP for detection results\n",
        "# Output will be in mAP/results\n",
        "%cd eval/mAP\n",
        "!python main.py"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}