{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": [
        "G7amcDYcQpf0",
        "VgG3-2LslczI",
        "Sz7aVQVUSecK",
        "UY7I79qftfQi",
        "feGWA2fpnZOI"
      ],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU",
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/aubricot/computer_vision_with_eol_images/blob/master/object_detection_for_image_cropping/multitaxa/multitaxa_train_tf2_rcnns.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SWrXhn1qKWm_"
      },
      "source": [
        "# Train Tensorflow Faster-RCNN models to detect snakes & lizards (Squamata), beetles (Coleoptera), frogs (Anura), and carnivores (Carnivora)  from EOL images\n",
        "---   \n",
        "*Last Updated 3 March 2023*  \n",
        "-Runs in Python 3 with Tensorflow 2.0-     \n",
        "\n",
        "Use EOL user generated cropping coordinates to train Faster-RCNN and Faster-RCNN Inception Object Detection Models implemented in Tensorflow to detect animals from EOL images. Training data consists of the user-determined best square thumbnail crop of an image, so model outputs will also be a square around objects of interest.\n",
        "\n",
        "Datasets were downloaded to Google Drive in [multitaxa_preprocessing.ipynb](https://github.com/aubricot/computer_vision_with_eol_images/blob/master/object_detection_for_image_cropping/multitaxa/multitaxa_preprocessing.ipynb).\n",
        "\n",
        "***Models were trained in Python 2 and TF 1 in April 2020: Faster RCNN ResNet 50 trained for 12 hours to 200,000 steps and Faster RCNN Inception v2 for 18 hours to 200,000 steps.*** \n",
        "\n",
        "Notes:   \n",
        "* Run code blocks by pressing play button in brackets on left\n",
        "* Before you you start: change the runtime to \"GPU\" with \"High RAM\"\n",
        "* Change parameters using form fields on right (find details at corresponding lines of code by searching '#@param')\n",
        "\n",
        "References:     \n",
        "* [Official Tensorflow Object Detection API Instructions](https://tensorflow-object-detection-api-tutorial.readthedocs.io/en/latest/training.html) \n",
        "* [Medium Blog on training using Tensorflow Object Detection API in Colab](https://medium.com/analytics-vidhya/training-an-object-detection-model-with-tensorflow-api-using-google-colab-4f9a688d5e8b)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "smQWTwI7k4Bf"
      },
      "source": [
        "## Installs & Imports\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Choose where to save results, set up directory structure & Build Tensorflow Object Detection API (if in Colab runtime, use defaults)\n",
        "import os\n",
        "\n",
        "# Choose where to save results\n",
        "save = \"in my Google Drive\" #@param [\"in my Google Drive\", \"in Colab runtime (files deleted after each session)\"]\n",
        "\n",
        "# Mount google drive to export image cropping coordinate file(s)\n",
        "if 'Google Drive' in save:\n",
        "    from google.colab import drive\n",
        "    drive.mount('/content/drive', force_remount=True)\n",
        "\n",
        "# Type in the path to your project wd in form field on right\n",
        "basewd = \"/content/drive/MyDrive/train\" #@param [\"/content/drive/MyDrive/train\"] {allow-input: true}\n",
        "\n",
        "# Type in the folder that you want to contain TF2 files\n",
        "folder = \"tf2\" #@param [\"tf2\"] {allow-input: true}\n",
        "cwd = basewd + '/' + folder\n",
        "\n",
        "# Enter taxon of interest in form field\n",
        "taxon = \"Multitaxa\" #@param [\"Multitaxa\"] {allow-input: true}\n",
        "\n",
        "# Make folders if they don't already exist\n",
        "if not os.path.exists(cwd):\n",
        "    os.makedirs(cwd)\n",
        "%cd $cwd\n",
        "if not os.path.exists(\"tf_models\"):\n",
        "    os.mkdir(\"tf_models\")\n",
        "    os.mkdir(\"results\")\n",
        "    %cd tf_models\n",
        "    # Clone the Tensorflow Model Garden\n",
        "    !git clone --depth 1 https://github.com/tensorflow/models\n",
        "# Build Object Detection API\n",
        "%cd $cwd\n",
        "!cd tf_models/models/research/ && protoc object_detection/protos/*.proto --python_out=. && cp object_detection/packages/tf2/setup.py . && python -m pip install .\n",
        "\n",
        "print(\"\\nWorking directory set to:\")\n",
        "%cd $cwd"
      ],
      "metadata": {
        "id": "7D-PUeY3-oFX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u4KnpJISUSzt"
      },
      "source": [
        "# For object detection\n",
        "import tensorflow as tf \n",
        "import tensorflow_hub as hub\n",
        "import sys\n",
        "sys.path.append(\"tf_models/models/research/\")\n",
        "from object_detection.utils import label_map_util\n",
        "from object_detection.utils import visualization_utils as vis_util\n",
        "!pip install absl-py # TF1->TF2 compatibility hacks\n",
        "!pip install lvis\n",
        "\n",
        "# For downloading and displaying images\n",
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "!pip install opencv-python-headless==4.1.2.30\n",
        "import cv2\n",
        "import tempfile\n",
        "import urllib\n",
        "from urllib.request import urlretrieve\n",
        "from six.moves.urllib.request import urlopen\n",
        "from six import BytesIO\n",
        "from collections import defaultdict\n",
        "from io import StringIO\n",
        "from IPython.display import display\n",
        "\n",
        "# For drawing onto images\n",
        "from PIL import Image\n",
        "from PIL import ImageColor\n",
        "from PIL import ImageDraw\n",
        "from PIL import ImageFont\n",
        "from PIL import ImageOps\n",
        "\n",
        "# For measuring inference time\n",
        "import time\n",
        "\n",
        "# For working with data\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import os\n",
        "import pathlib\n",
        "import csv\n",
        "import six.moves.urllib as urllib\n",
        "import tarfile\n",
        "import zipfile\n",
        "import shutil\n",
        "import glob\n",
        "\n",
        "# Print Tensorflow version\n",
        "print('\\nTensorflow Version: %s' % tf.__version__)\n",
        "\n",
        "# Check available GPU devices\n",
        "print('The following GPU devices are available: %s' % tf.config.experimental.get_device_details(tf.config.list_physical_devices('GPU')[0]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G7amcDYcQpf0"
      },
      "source": [
        "## Model preparation (only run once)\n",
        "---\n",
        "These blocks download and set-up files needed for training object detectors. After running once, you can train and re-train as many times as you'd like. Pre-trained models are downloaded from the [Tensorflow Object Detection Model Zoo](https://github.com/tensorflow/models/blob/master/research/object_detection/g3doc/tf2_detection_zoo.md)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YaLxacTBZnM1"
      },
      "source": [
        "#@title Download pre-trained Faster RCNN Resnet & Inception models from Tensorflow Object Detection Model Zoo\n",
        "# Code modified from https://github.com/RomRoc/objdet_train_tensorflow_colab/blob/master/objdet_custom_tf_colab.ipynb\n",
        "\n",
        "# Faster RCNN\n",
        "# Define parameters\n",
        "MODEL = 'faster_rcnn_resnet50_v1_640x640_coco17_tpu-8'\n",
        "MODEL_FILE = MODEL + '.tar.gz'\n",
        "DOWNLOAD_BASE = 'http://download.tensorflow.org/models/object_detection/tf2/20200711/'\n",
        "DEST_DIR = 'tf_models/train_demo/rcnn/pretrained_model'\n",
        "# Set up directory structure\n",
        "if not (os.path.exists('tf_models/train_demo')):\n",
        "    print(\"Setting up directory structure for \", MODEL)\n",
        "    !mkdir -p tf_models/train_demo/rcnn\n",
        "    %cd tf_models/train_demo/rcnn\n",
        "    !mkdir {pretrained_model,finetuned_model,trained}\n",
        "    %cd $cwd\n",
        "# Download the model\n",
        "if not (os.path.exists(MODEL_FILE)):\n",
        "    print(\"\\nDownloading model from {} to {}\".format(DOWNLOAD_BASE, DEST_DIR))\n",
        "    urlretrieve(DOWNLOAD_BASE + MODEL_FILE, MODEL_FILE)\n",
        "    tar = tarfile.open(MODEL_FILE)\n",
        "    tar.extractall()\n",
        "    tar.close()\n",
        "    os.remove(MODEL_FILE)\n",
        "    # Clean up directories from unzipping model\n",
        "    if (os.path.exists(DEST_DIR)):\n",
        "        shutil.rmtree(DEST_DIR)\n",
        "    os.rename(MODEL, DEST_DIR)\n",
        "\n",
        "# Faster RCNN Inception v2\n",
        "# Define parameters\n",
        "MODEL = 'faster_rcnn_inception_resnet_v2_640x640_coco17_tpu-8'\n",
        "MODEL_FILE = MODEL + '.tar.gz'\n",
        "DOWNLOAD_BASE = 'http://download.tensorflow.org/models/object_detection/tf2/20200711/'\n",
        "DEST_DIR = 'tf_models/train_demo/rcnn_i/pretrained_model'\n",
        "# Set up directory structure\n",
        "if not (os.path.exists('tf_models/train_demo')):\n",
        "    print(\"Setting up directory structure for \", MODEL)\n",
        "    !mkdir -p tf_models/train_demo/rcnn_i\n",
        "    %cd tf_models/train_demo/rcnn_i\n",
        "    !mkdir {pretrained_model,finetuned_model,trained}\n",
        "    %cd $cwd\n",
        "# Download the model\n",
        "if not (os.path.exists(MODEL_FILE)):\n",
        "    print(\"\\nDownloading model from {} to {}\".format(DOWNLOAD_BASE, DEST_DIR))\n",
        "    urlretrieve(DOWNLOAD_BASE + MODEL_FILE, MODEL_FILE)\n",
        "    tar = tarfile.open(MODEL_FILE)\n",
        "    tar.extractall()\n",
        "    tar.close()\n",
        "    os.remove(MODEL_FILE)\n",
        "    # Clean up directories from unzipping model\n",
        "    if (os.path.exists(DEST_DIR)):\n",
        "        shutil.rmtree(DEST_DIR)\n",
        "    os.rename(MODEL, DEST_DIR)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Convert test data to tf.record format\n",
        "# Modified from https://tensorflow-object-detection-api-tutorial.readthedocs.io/en/latest/training.html\n",
        "\n",
        "# Download multitaxa_generate_tfrecord.py\n",
        "print(\"Downloading multitaxa_generate_tfrecord.py...\\n\")\n",
        "!pip3 install --upgrade gdown\n",
        "!gdown --id 1_pRlENeAvGV-h_c-_rl2d0Y1QxMJ0TAS\n",
        "\n",
        "# Update file paths in form fields\n",
        "csv_input = \"/content/drive/MyDrive/train/tf2/pre-processing/Multitaxa_crops_test_notaug_oob_rem_fin.csv\" #@param [\"/content/drive/MyDrive/train/tf2/pre-processing/Multitaxa_crops_test_notaug_oob_rem_fin.csv\"] {allow-input: true}\n",
        "output_path = \"/content/drive/MyDrive/train/tf2/test_images/tf.record\" #@param [\"/content/drive/MyDrive/train/tf2/test_images/tf.record\"] {allow-input: true}\n",
        "test_image_dir = \"/content/drive/MyDrive/train/tf2/test_images\" #@param [\"/content/drive/MyDrive/train/tf2/test_images\"] {allow-input: true}\n",
        "\n",
        "# Generate tf.record for test images\n",
        "!python multitaxa_generate_tfrecord.py --output_path=$output_path  --csv_input=$csv_input  --image_dir=$test_image_dir "
      ],
      "metadata": {
        "id": "vzFOTEUareuz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zRr1MLxSICf_"
      },
      "source": [
        "#@title Convert train data to tf.record format\n",
        "# Modified from https://tensorflow-object-detection-api-tutorial.readthedocs.io/en/latest/training.html\n",
        "\n",
        "# Update file paths in form fields\n",
        "csv_input = \"/content/drive/MyDrive/train/tf2/pre-processing/Multitaxa_crops_train_aug_oob_rem_fin.csv\" #@param [\"/content/drive/MyDrive/train/tf2/pre-processing/Multitaxa_crops_train_aug_oob_rem_fin.csv\"] {allow-input: true}\n",
        "output_path = \"/content/drive/MyDrive/train/tf2/images/tf.record\" #@param [\"/content/drive/MyDrive/train/tf2/images/tf.record\"] {allow-input: true}\n",
        "train_image_dir = \"/content/drive/MyDrive/train/tf2/images\" #@param [\"/content/drive/MyDrive/train/tf2/images\"] {allow-input: true}\n",
        "\n",
        "# Generate tf.record for train images\n",
        "!python multitaxa_generate_tfrecord.py --output_path=$output_path  --csv_input=$csv_input  --image_dir=$train_image_dir "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s3Dc0hSqmPF4"
      },
      "source": [
        "#@title Make labelmap.pbtxt for taxa of interest\n",
        "\n",
        "%%writefile labelmap.pbtxt\n",
        "item {\n",
        "  id: 1\n",
        "  name: 'Squamata'\n",
        "}\n",
        "\n",
        "item {\n",
        "  id: 2\n",
        "  name: 'Coleoptera'\n",
        "}\n",
        "\n",
        "item {\n",
        "  id: 3\n",
        "  name: 'Anura'\n",
        "}\n",
        "\n",
        "item {\n",
        "  id: 4\n",
        "  name: 'Carnivora'\n",
        "}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "feGWA2fpnZOI"
      },
      "source": [
        "### Modify model config files for training Faster-RCNN Resnet and Faster-RCNN Inception with your dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tu_3bT7VnfIA"
      },
      "source": [
        "If you have errors with training, check the pipline_config_path and model_dir in the config files for R-FCN or Faster-RCNN model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "brm03Y4_undi"
      },
      "source": [
        "# Adjust model config file based on training/testing datasets\n",
        "# Modified from https://stackoverflow.com/a/63645324\n",
        "from google.protobuf import text_format\n",
        "from object_detection.protos import pipeline_pb2\n",
        "%cd $cwd\n",
        "\n",
        "# Adjust parameters using form fields on right\n",
        "filter = taxon # defined in first code block\n",
        "config_basepath = \"tf_models/train_demo/\" #@param [\"tf_models/train_demo/\"] {allow-input: true}\n",
        "label_map = 'labelmap.pbtxt'\n",
        "train_tfrecord_path = \"/content/drive/MyDrive/train/tf2/pre-processing/images/tf.record\" #@param [\"/content/drive/MyDrive/train/tf2/images/tf.record\"] {allow-input: true}\n",
        "test_tfrecord_path = \"/content/drive/MyDrive/train/tf2/pre-processing/test_images/tf.record\" #@param [\"/content/drive/MyDrive/train/tf2/test_images/tf.record\"] {allow-input: true}\n",
        "ft_ckpt_basepath = \"/content/drive/MyDrive/train/tf2/tf_models/train_demo/\" #@param [\"/content/drive/MyDrive/train/tf2/tf_models/train_demo/\"] {allow-input: true}\n",
        "ft_ckpt_type = \"detection\" #@param [\"detection\", \"classification\"]\n",
        "num_classes = 4 #@param [\"4\"] {type:\"raw\", allow-input: true}\n",
        "batch_size = 1 #@param [\"1\", \"4\", \"8\", \"16\", \"32\", \"64\", \"128\"] {type:\"raw\"}\n",
        "\n",
        "# Define pipeline for modifying model config files\n",
        "def read_config(model_config):\n",
        "    if 'rcnn/' in model_config:\n",
        "        model_ckpt = 'rcnn/pretrained_model/checkpoint/ckpt-0'\n",
        "    elif 'rcnn_i/' in model_config:\n",
        "        model_ckpt = 'rcnn_i/pretrained_model/checkpoint/ckpt-0'\n",
        "    config_fpath = config_basepath + model_config\n",
        "    pipeline = pipeline_pb2.TrainEvalPipelineConfig()                                                                                                                                                                                                          \n",
        "    with tf.io.gfile.GFile(config_fpath, \"r\") as f:                                                                                                                                                                                                                     \n",
        "        proto_str = f.read()                                                                                                                                                                                                                                          \n",
        "        text_format.Merge(proto_str, pipeline)\n",
        "    return pipeline, model_ckpt, config_fpath\n",
        "\n",
        "def modify_config(pipeline, model_ckpt, ft_ckpt_basepath):\n",
        "    finetune_checkpoint = ft_ckpt_basepath + model_ckpt\n",
        "    pipeline.model.faster_rcnn.num_classes = num_classes\n",
        "    pipeline.train_config.fine_tune_checkpoint = finetune_checkpoint\n",
        "    pipeline.train_config.fine_tune_checkpoint_type = ft_ckpt_type\n",
        "    pipeline.train_config.batch_size = batch_size\n",
        "    pipeline.train_config.use_bfloat16 = False # True only if training on TPU\n",
        "\n",
        "    pipeline.train_input_reader.label_map_path = label_map\n",
        "    pipeline.train_input_reader.tf_record_input_reader.input_path[0] = train_tfrecord_path\n",
        "\n",
        "    pipeline.eval_input_reader[0].label_map_path = label_map\n",
        "    pipeline.eval_input_reader[0].tf_record_input_reader.input_path[0] = test_tfrecord_path\n",
        "\n",
        "    return pipeline\n",
        "\n",
        "def write_config(pipeline, config_fpath):\n",
        "    config_outfpath = os.path.splitext(config_fpath)[0] + '_' + filter + '.config'\n",
        "    config_text = text_format.MessageToString(pipeline)                                                                                                                                                                                                        \n",
        "    with tf.io.gfile.GFile(config_outfpath, \"wb\") as f:                                                                                                                                                                                                                       \n",
        "        f.write(config_text)\n",
        "    \n",
        "    return config_outfpath\n",
        "\n",
        "def setup_pipeline(model_config, ft_ckpt_basepath):\n",
        "    print('\\n Modifying model config file for {}'.format(model_config))\n",
        "    pipeline, model_ckpt, config_fpath = read_config(model_config)\n",
        "    pipeline = modify_config(pipeline, model_ckpt, ft_ckpt_basepath)\n",
        "    config_outfpath = write_config(pipeline, config_fpath)\n",
        "    print(' Modifed model config file saved to {}'.format(config_outfpath))\n",
        "    if config_outfpath:\n",
        "        return \"Success!\"\n",
        "    else:\n",
        "        return \"Fail: try again\"\n",
        "\n",
        "# Modify model configs\n",
        "model_configs = ['rcnn/pretrained_model/pipeline.config', 'rcnn_i/pretrained_model/pipeline.config']\n",
        "[setup_pipeline(model_config, ft_ckpt_basepath) for model_config in model_configs]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "naEjBRiGu-3e"
      },
      "source": [
        "## Train\n",
        "--- "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6cUfcn0kpRX2"
      },
      "source": [
        "#@title Determine how many train and eval steps to use based on dataset size\n",
        "\n",
        "# Get the number of training examples\n",
        "try: \n",
        "    train_image_dir\n",
        "except:\n",
        "    train_image_dir = \"/content/drive/MyDrive/train/tf2/pre-processing/images\" #@param [\"/content/drive/MyDrive/train/tf2/images\"] {allow-input: true}\n",
        "examples = len(os.listdir(train_image_dir))\n",
        "print(\"Number of train examples: \\n\", examples)\n",
        "\n",
        "# Get the number of testing examples\n",
        "try: \n",
        "    test_image_dir\n",
        "except:\n",
        "    test_image_dir = \"/content/drive/MyDrive/train/tf2/pre-processing/test_images\" #@param [\"/content/drive/MyDrive/train/tf2/test_images\"] {allow-input: true}\n",
        "test_examples = len(os.listdir(test_image_dir))\n",
        "print(\"Number of test examples: \\n\", test_examples)\n",
        "\n",
        "# Get the training batch size\n",
        "try: \n",
        "    batch_size\n",
        "except: \n",
        "    batch_size = 1 #@param [\"1\", \"4\", \"8\", \"16\", \"32\", \"64\", \"128\"] {type:\"raw\"}\n",
        "print(\"Batch size: \\n\", batch_size)\n",
        "\n",
        "# Calculate number of steps to use for training and testing based on dataset size\n",
        "steps_per_epoch = examples / batch_size\n",
        "num_eval_steps = test_examples / batch_size\n",
        "print(\"Number of steps per training epoch: \\n\", int(steps_per_epoch))\n",
        "print(\"Number of evaluation steps: \\n\", int(num_eval_steps))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vaGeNKA26Qyj"
      },
      "source": [
        "#@title Set training parameters (choose if you want to use RCNN or RCNN_I in form fields on right)\n",
        "\n",
        "# Choose how many epochs to train for\n",
        "model_type = \"rcnn\" #@param [\"rcnn\", \"rcnn_i\"] {allow-input: true}\n",
        "epochs = 10 #@param {type:\"slider\", min:10, max:1000, step:100}\n",
        "num_train_steps = int(epochs * steps_per_epoch)\n",
        "num_eval_steps = int(num_eval_steps)\n",
        "# Choose paths for RCNN or RCNN_I model\n",
        "pipeline_config_fn = \"pipeline_Multitaxa.config\" #@param [\"pipeline_Multitaxa.config\"] {allow-input: true}\n",
        "pipeline_config_path = \"tf_models/train_demo/\" + model_type + \"/pretrained_model/\" + pipeline_config_fn\n",
        "model_dir = \"tf_models/train_demo/\" + model_type + \"/trained\" \n",
        "output_dir = \"tf_models/train_demo/\" + model_type + \"/finetuned_model\" \n",
        "# Save vars to environment for access with cmd line tools below\n",
        "os.environ[\"num_train_steps\"] = \"num_train_steps\"\n",
        "os.environ[\"num_eval_steps\"] = \"num_eval_steps\"\n",
        "os.environ[\"pipeline_config_path\"] = \"pipeline_config_path\"\n",
        "os.environ[\"model_dir\"] = \"model_dir\"\n",
        "os.environ[\"output_directory\"] = \"output_dir\"\n",
        "\n",
        "# Optional: Visualize training progress with Tensorboard?\n",
        "visualize_with_tensorboard = False #@param {type:\"boolean\"}\n",
        "if visualize_with_tensorboard:\n",
        "    # Load the TensorBoard notebook extension\n",
        "    %load_ext tensorboard\n",
        "    # Log training progress using TensorBoard\n",
        "    %tensorboard --logdir $model_dir"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B55tKxoL5aRM"
      },
      "source": [
        "#@title Train the model\n",
        "# Note: You can change the number of epochs in code block above, then re-run to train longer\n",
        "# Modified from https://github.com/RomRoc/objdet_train_tensorflow_colab/blob/master/objdet_custom_tf_colab.ipynb\n",
        "matplotlib.use('Agg')\n",
        "%cd $cwd\n",
        "\n",
        "!python tf_models/models/research/object_detection/model_main_tf2.py \\\n",
        "    --alsologtostderr \\\n",
        "    --num_train_steps=$num_train_steps \\\n",
        "    --num_eval_steps=$num_eval_steps \\\n",
        "    --pipeline_config_path=$pipeline_config_path \\\n",
        "    --model_dir=$model_dir "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jVuMlhoq_eqY"
      },
      "source": [
        "#@title Export trained model\n",
        "%cd $cwd\n",
        "\n",
        "# Save the model\n",
        "!python tf_models/models/research/object_detection/exporter_main_v2.py \\\n",
        "    --input_type image_tensor \\\n",
        "    --pipeline_config_path=$pipeline_config_path \\\n",
        "    --trained_checkpoint_dir=$model_dir \\\n",
        "    --output_directory=$output_dir"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "roFjqjd-tVHh"
      },
      "source": [
        "#@title Evaluate trained model to get mAP and IoU stats for COCO 2017\n",
        "matplotlib.use('Agg')\n",
        "\n",
        "!python tf_models/models/research/object_detection/model_main_tf2.py \\\n",
        "    --alsologtostderr \\\n",
        "    --model_dir=$model_dir \\\n",
        "    --pipeline_config_path=$pipeline_config_path \\\n",
        "    --checkpoint_dir=$model_dir"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}