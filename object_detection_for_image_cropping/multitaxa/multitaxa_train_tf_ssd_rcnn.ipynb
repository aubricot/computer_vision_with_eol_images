{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "multitaxa_train_tf_ssd_rcnn.ipynb",
      "provenance": [],
      "private_outputs": true,
      "collapsed_sections": [
        "G7amcDYcQpf0",
        "VgG3-2LslczI",
        "Sz7aVQVUSecK",
        "CjE-Gh5ann4E"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python2",
      "display_name": "Python 2"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/aubricot/computer_vision_with_eol_images/blob/master/object_detection_for_image_cropping/multitaxa/multitaxa_train_tf_ssd_rcnn.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SWrXhn1qKWm_",
        "colab_type": "text"
      },
      "source": [
        "# Training Tensorflow Faster-RCNN and SSD models to detect butterflies and moths (Lepidoptera) from EOL images\n",
        "---   \n",
        "*Last Updated 16 March 2020*  \n",
        "Use images and bounding box coordinates to train Faster-RCNN and SSD Object Detection Models implemented in Tensorflow to detect butterflies and moths from EOL images.\n",
        "\n",
        "Datasets exported from [lepidoptera_preprocessing.ipynb](https://github.com/aubricot/computer_vision_with_eol_images/blob/master/object_detection_for_image_cropping/lepidoptera/lepidoptera_preprocessing.ipynb) were already downloaded to Google Drive in lepidoptera_preprocessing.ipynb. \n",
        "\n",
        "Notes:   \n",
        "* For each 24 hour period on Google Colab, you have up to 12 hours of GPU access. Training the object detection model on bats took 30 hours split into 3 days.\n",
        "\n",
        "* Make sure to set the runtime to Python 2 with GPU Hardware Accelerator.  \n",
        "\n",
        "References:   \n",
        "* [Official Tensorflow Object Detection API Instructions](https://tensorflow-object-detection-api-tutorial.readthedocs.io/en/latest/training.html)   \n",
        "* [Medium Blog on training using Tensorflow Object Detection API in Colab](https://medium.com/analytics-vidhya/training-an-object-detection-model-with-tensorflow-api-using-google-colab-4f9a688d5e8b)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "smQWTwI7k4Bf",
        "colab_type": "text"
      },
      "source": [
        "## Installs (run this every time)\n",
        "---\n",
        "Install the Tensorflow Object Detection API directly to this Colab notebook."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0mAC7PfUrWX1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Mount google drive to import/export files\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "No18RpXIAgGL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Download, compile and build all ingredients for the Tensorflow Object Detection API\n",
        "# These steps take a couple of minutes and print a lot of output\n",
        "\n",
        "# Make a working directory train/ in your Google Drive and include the path here (all paths in other sections stay the same)\n",
        "import os\n",
        "%cd drive/My Drive/fall19_smithsonian_informatics/train\n",
        "if not os.path.exists(\"tf_models\"):\n",
        "  !mkdir tf_models\n",
        "%cd tf_models\n",
        "\n",
        "# Install Tensorflow Object Detection API\n",
        "import pathlib\n",
        "if not pathlib.Path(\"models\").exists():\n",
        "  !git clone https://github.com/tensorflow/models.git\n",
        "\n",
        "# Clone the COCO API repository to your Google Drive\n",
        "if not pathlib.Path(\"pycocotools\").exists():\n",
        "  !git clone https://github.com/cocodataset/cocoapi.git\n",
        "  # Move needed folders to tf_models/pycocotools and delete remaining contents of cocoapi/ to save space\n",
        "  !cd cocoapi/PythonAPI; make; cp -r pycocotools ../..\n",
        "  !rm -rf cocoapi\n",
        "\n",
        "# Install libraries\n",
        "!apt-get install -qq protobuf-compiler python-tk\n",
        "!pip install -q Cython contextlib2 pillow lxml matplotlib PyDrive\n",
        "\n",
        "# Compile object detection api using Google Protobuf\n",
        "%cd models/research\n",
        "!protoc object_detection/protos/*.proto --python_out=.\n",
        "\n",
        "# Update system path variables\n",
        "os.environ['PYTHONPATH'] = ':/drive/My Drive/fall19_smithsonian_informatics/train/tf_models/models/research/:/drive/My Drive/fall19_smithsonian_informatics/train/tf_models/models/research/slim/'\n",
        "!echo $PYTHONPATH\n",
        "\n",
        "import sys\n",
        "print(sys.path)\n",
        "sys.path.append(\"/usr/local/lib/python2.7/dist-packages/tensorflow/contrib/slim\")\n",
        "print(sys.path)\n",
        "\n",
        "# Build slim\n",
        "!python slim/setup.py build\n",
        "!python slim/setup.py install\n",
        "\n",
        "# Copy slim to specified directories to avoid errors in model_builder_test.py\n",
        "!cp -R slim/ /usr/local/lib/python2.7/dist-packages/object_detection-0.1-py2.7.egg/\n",
        "if not os.path.exists(\"object_detection/slim/nets\"):\n",
        "  !cp -R slim/nets/ object_detection/\n",
        "\n",
        "# Test build of model\n",
        "!python object_detection/builders/model_builder_test.py"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qO3sTvkrnLTp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#%cd drive/My Drive/fall19_smithsonian_informatics/train\n",
        "#!unzip tf_models/models-20200216T051538Z-001.zip"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G7amcDYcQpf0",
        "colab_type": "text"
      },
      "source": [
        "## Model preparation (only need to run these once)\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VgG3-2LslczI",
        "colab_type": "text"
      },
      "source": [
        "### Download and extract pre-trained model   "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YaLxacTBZnM1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Download pre-trained model from Tensorflow Object Detection Model Zoo\n",
        "# SSD and Faster-RCNN both included as options below\n",
        "# modified from https://github.com/RomRoc/objdet_train_tensorflow_colab/blob/master/objdet_custom_tf_colab.ipynb\n",
        "\n",
        "# cd to train/\n",
        "%cd ../../..\n",
        "\n",
        "import os\n",
        "import shutil\n",
        "import glob\n",
        "import urllib\n",
        "import tarfile\n",
        "\n",
        "# Make folders for your training files for each model\n",
        "# RCNN Model\n",
        "if not (os.path.exists('tf_models/train_demo')):\n",
        "  !mkdir tf_models/train_demo\n",
        "if not (os.path.exists('tf_models/train_demo/rcnn')):\n",
        "  !mkdir tf_models/train_demo/rcnn\n",
        "if not (os.path.exists('tf_models/train_demo/rcnn/pretrained_model')):\n",
        "  !mkdir tf_models/train_demo/rcnn/pretrained_model\n",
        "if not (os.path.exists('tf_models/train_demo/rcnn/finetuned_model')):\n",
        "  !mkdir tf_models/train_demo/rcnn/finetuned_model\n",
        "if not (os.path.exists('tf_models/train_demo/rcnn/trained')):\n",
        "  !mkdir tf_models/train_demo/rcnn/trained\n",
        "# Download the model\n",
        "MODEL = 'faster_rcnn_resnet50_coco_2018_01_28'\n",
        "MODEL_FILE = MODEL + '.tar.gz'\n",
        "DOWNLOAD_BASE = 'http://download.tensorflow.org/models/object_detection/'\n",
        "DEST_DIR = 'tf_models/train_demo/rcnn/pretrained_model'\n",
        "if not (os.path.exists(MODEL_FILE)):\n",
        "  opener = urllib.URLopener()\n",
        "  opener.retrieve(DOWNLOAD_BASE + MODEL_FILE, MODEL_FILE)\n",
        "\n",
        "tar = tarfile.open(MODEL_FILE)\n",
        "tar.extractall()\n",
        "tar.close()\n",
        "\n",
        "os.remove(MODEL_FILE)\n",
        "if (os.path.exists(DEST_DIR)):\n",
        "  shutil.rmtree(DEST_DIR)\n",
        "os.rename(MODEL, DEST_DIR)\n",
        "\n",
        "# SSD Model\n",
        "if not (os.path.exists('tf_models/train_demo/ssd')):\n",
        "  !mkdir tf_models/train_demo/ssd\n",
        "if not (os.path.exists('tf_models/train_demo/ssd/pretrained_model')):\n",
        "  !mkdir tf_models/train_demo/ssd/pretrained_model\n",
        "if not (os.path.exists('tf_models/train_demo/ssd/finetuned_model')):\n",
        "  !mkdir tf_models/train_demo/ssd/finetuned_model\n",
        "if not (os.path.exists('tf_models/train_demo/ssd/trained')):\n",
        "  !mkdir tf_models/train_demo/ssd/trained\n",
        "# Download the model\n",
        "MODEL = 'ssd_resnet50_v1_fpn_shared_box_predictor_640x640_coco14_sync_2018_07_03'\n",
        "MODEL_FILE = MODEL + '.tar.gz'\n",
        "DOWNLOAD_BASE = 'http://download.tensorflow.org/models/object_detection/'\n",
        "DEST_DIR = 'tf_models/train_demo/ssd/pretrained_model'\n",
        "if not (os.path.exists(MODEL_FILE)):\n",
        "  opener = urllib.URLopener()\n",
        "  opener.retrieve(DOWNLOAD_BASE + MODEL_FILE, MODEL_FILE)\n",
        "\n",
        "tar = tarfile.open(MODEL_FILE)\n",
        "tar.extractall()\n",
        "tar.close()\n",
        "\n",
        "os.remove(MODEL_FILE)\n",
        "if (os.path.exists(DEST_DIR)):\n",
        "  shutil.rmtree(DEST_DIR)\n",
        "os.rename(MODEL, DEST_DIR)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Sz7aVQVUSecK",
        "colab_type": "text"
      },
      "source": [
        "### Convert training data to tf.record format"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G57Xi6uSK46b",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Upload lepidoptera_generate_tfrecord.py to your Google Drive\n",
        "!gdown --id 1neN-JupseY4ug2k7MU7s6CJr888Czp-8 "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9kFe9D21WGog",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Convert crops_test to tf.record format for test data\n",
        "# Modified from https://tensorflow-object-detection-api-tutorial.readthedocs.io/en/latest/training.html\n",
        "!python lepidoptera_generate_tfrecord.py --csv_input='/content/drive/My Drive/fall19_smithsonian_informatics/train/lepidoptera_crops_test_notaug_fin.csv'  --output_path= \"/content/drive/My Drive/fall19_smithsonian_informatics/train/test_images/tf.record\"  --image_dir=\"/content/drive/My Drive/fall19_smithsonian_informatics/train/test_images\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hHcHuvpD5diH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!mv tf.record test_images/"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zRr1MLxSICf_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Convert crops_train to tf.record format for train data\n",
        "# Modified from https://tensorflow-object-detection-api-tutorial.readthedocs.io/en/latest/training.html\n",
        "!python lepidoptera_generate_tfrecord.py --csv_input='/content/drive/My Drive/fall19_smithsonian_informatics/train/lepidoptera_crops_train_aug_fin.csv'  --output_path= \"/content/drive/My Drive/fall19_smithsonian_informatics/train/images/tf.record\"  --image_dir=\"/content/drive/My Drive/fall19_smithsonian_informatics/train/images\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DScMtAYQ_Vib",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Upload label map for class Lepidoptera to your Google Drive\n",
        "!gdown --id 1QrrSKLm15UQTfAd-IDm--LQJ75f6nb3V"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kRwJ918UYdiL",
        "colab_type": "text"
      },
      "source": [
        "### Upload modified config files for Faster-RCNN and SSD models to your Google Drive\n",
        "If you have errors with training, check the pipline_config_path and model_dir in the config files for SSD or Faster-RCNN model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PGv6m4kdYgKN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%cd tf_models/models/research/object_detection/samples/configs\n",
        "# SSD ssd_resnet50_v1_fpn_shared_box_predictor_640x640_coco14_sync_2018_07_03_bats.config \n",
        "!gdown --id 192N8V3o-4z3vJRNMSgusl3vgwXH04rtX\n",
        "# Faster-RCNN faster_rcnn_resnet50_coco_2018_01_28_bats.config\n",
        "!gdown --id 18wlrqTWKLZmcvaSsNbdLGM98lFlC8CB6\n",
        "\n",
        "# cd back to train\n",
        "%cd ../../../../../.."
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "naEjBRiGu-3e",
        "colab_type": "text"
      },
      "source": [
        "## Train the model\n",
        "--- \n",
        "To switch between training Faster-RCNN and SSD models, see notes at the beginning of each code block on which lines to comment out and move to the bottom of the cell."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6cUfcn0kpRX2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# First time running this notebook: cd to train after running Model Preparation steps above\n",
        "#%cd train\n",
        "# Subsequent times running this notebook: cd to train\n",
        "%cd ../../.."
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B55tKxoL5aRM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Actual training\n",
        "# Modified from https://github.com/RomRoc/objdet_train_tensorflow_colab/blob/master/objdet_custom_tf_colab.ipynb\n",
        "# Change pipline_config_path and model_dir to the appropriate config file for SSD or Faster-RCNN model\n",
        "import matplotlib\n",
        "matplotlib.use('Agg')\n",
        "\n",
        "!python tf_models/models/research/object_detection/model_main.py \\\n",
        "    --alsologtostderr \\\n",
        "    --num_train_steps=200000 \\\n",
        "    --num_eval_steps=500 \\\n",
        "    --pipeline_config_path=tf_models/models/research/object_detection/samples/configs/ssd_resnet50_v1_fpn_shared_box_predictor_640x640_coco14_sync_2018_07_03_bats.config \\\n",
        "    --model_dir=tf_models/train_demo/ssd/trained/ \\\n",
        "    #--pipeline_config_path=tf_models/models/research/object_detection/samples/configs/faster_rcnn_resnet50_coco_2018_01_28_bats.config \\\n",
        "    #--model_dir=tf_models/train_demo/rcnn/trained/ \\"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e9jOTBgzYzMB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Export trained model\n",
        "# Modified from https://github.com/RomRoc/objdet_train_tensorflow_colab/blob/master/objdet_custom_tf_colab.ipynb\n",
        "# Change os.listdir, pipeline_config_path, output_directory and trained_checkpoint_prefix when switching between SSD and Faster-RCNN models\n",
        "%cd train\n",
        "\n",
        "lst = os.listdir('tf_models/train_demo/ssd/trained')\n",
        "#lst = os.listdir('tf_models/train_demo/rcnn/trained')\n",
        "lf = filter(lambda k: 'model.ckpt-' in k, lst)\n",
        "last_model = sorted(lf)[-1].replace('.meta', '')\n",
        "\n",
        "!python tf_models/models/research/object_detection/export_inference_graph.py \\\n",
        "    --input_type=image_tensor \\\n",
        "    --pipeline_config_path=tf_models/models/research/object_detection/samples/configs/ssd_resnet50_v1_fpn_shared_box_predictor_640x640_coco14_sync_2018_07_03_bats.config \\\n",
        "    --output_directory=tf_models/train_demo/ssd/finetuned_model \\\n",
        "    --trained_checkpoint_prefix=tf_models/train_demo/ssd/trained/$last_model \\\n",
        "    #--pipeline_config_path=tf_models/models/research/object_detection/samples/configs/faster_rcnn_resnet50_coco_2018_01_28_bats.config \\\n",
        "    #--output_directory=tf_models/train_demo/rcnn/finetuned_model \\\n",
        "    #--trained_checkpoint_prefix=tf_models/train_demo/rcnn/trained/$last_model \\"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jzgf0H5BM1I3",
        "colab_type": "text"
      },
      "source": [
        "### When finished training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "roFjqjd-tVHh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Evaluate trained model to get mAP and IoU stats\n",
        "# Change pipeline_config_path and checkpoint_dir when switching between SSD and Faster-RCNN models\n",
        "import matplotlib\n",
        "matplotlib.use('Agg')\n",
        "\n",
        "!python tf_models/models/research/object_detection/model_main.py \\\n",
        "    --alsologtostderr \\\n",
        "    --pipeline_config_path=tf_models/models/research/object_detection/samples/configs/faster_rcnn_resnet50_coco_2018_01_28_bats.config \\\n",
        "    --checkpoint_dir=tf_models/train_demo/rcnn/trained/ \\\n",
        "    #--pipeline_config_path=tf_models/models/research/object_detection/samples/configs/ssd_resnet50_v1_fpn_shared_box_predictor_640x640_coco14_sync_2018_07_03_bats.config \\\n",
        "    #--checkpoint_dir=tf_models/train_demo/ssd/trained/ \\ "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kGx_08UcmtOF",
        "colab_type": "text"
      },
      "source": [
        "## Run test images through the trained object detector\n",
        "---\n",
        "Test image detection boxes are only needed for calculating mAP (mean average precision, a performance measure to compare models) and not for cropping. The functions below will only display resulting detection boxes on test images for visualization, but does not save their coordinates to a spreadsheet. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q6h99mPKNH9L",
        "colab_type": "text"
      },
      "source": [
        "### Imports"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zlg-GTnKKRa3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# cd to train\n",
        "%cd ../../..\n",
        "#%cd train\n",
        "\n",
        "%tensorflow_version 1.0\n",
        "\n",
        "import tensorflow as tf \n",
        "tf.compat.v1.enable_eager_execution()\n",
        "\n",
        "# For importing/exporting files, working with arrays, etc\n",
        "import os\n",
        "import pathlib\n",
        "import six.moves.urllib as urllib\n",
        "import sys\n",
        "import tarfile\n",
        "import zipfile\n",
        "import numpy as np \n",
        "import csv\n",
        "import matplotlib\n",
        "import time\n",
        "import pandas as pd\n",
        "\n",
        "# For downloading the images\n",
        "import tempfile\n",
        "from six.moves.urllib.request import urlopen\n",
        "from six import BytesIO\n",
        "from collections import defaultdict\n",
        "from io import StringIO\n",
        "\n",
        "# For drawing onto and plotting the images\n",
        "import matplotlib.pyplot as plt\n",
        "from PIL import Image\n",
        "from PIL import ImageColor\n",
        "from PIL import ImageDraw\n",
        "from PIL import ImageFont\n",
        "from PIL import ImageOps\n",
        "\n",
        "import cv2\n",
        "\n",
        "from IPython.display import display\n",
        "\n",
        "sys.path.append(\"tf_models/models/research/\")\n",
        "from object_detection.utils import ops as utils_ops\n",
        "from object_detection.utils import label_map_util\n",
        "from object_detection.utils import visualization_utils as vis_util\n",
        "%matplotlib inline"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KQpr26hJOv5y",
        "colab_type": "text"
      },
      "source": [
        "### Prepare object detection functions and settings"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8n_alUkLZ1gl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Change PATH_TO_CKPT below when switching between SSD and Faster-RCNN models\n",
        "%cd train\n",
        "# SSD Model\n",
        "#PATH_TO_CKPT = 'tf_models/train_demo/ssd/finetuned_model' + '/frozen_inference_graph.pb'\n",
        "# Faster RCNN Model\n",
        "PATH_TO_CKPT = 'tf_models/train_demo/rcnn/finetuned_model' + '/frozen_inference_graph.pb'\n",
        "\n",
        "# List of the strings that is used to add correct label for each box.\n",
        "PATH_TO_LABELS = 'labelmap.pbtxt'\n",
        "NUM_CLASSES = 1\n",
        "    \n",
        "detection_graph = tf.Graph()\n",
        "with detection_graph.as_default():\n",
        "  od_graph_def = tf.compat.v1.GraphDef()\n",
        "  with tf.io.gfile.GFile(PATH_TO_CKPT, 'rb') as fid:\n",
        "    serialized_graph = fid.read()\n",
        "    od_graph_def.ParseFromString(serialized_graph)\n",
        "    tf.import_graph_def(od_graph_def, name='')\n",
        "    \n",
        "label_map = label_map_util.load_labelmap(PATH_TO_LABELS)\n",
        "categories = label_map_util.convert_label_map_to_categories(label_map, max_num_classes=NUM_CLASSES, use_display_name=True)\n",
        "category_index = label_map_util.create_category_index(categories)\n",
        "\n",
        "# For loading images into computer-readable format\n",
        "def load_image_into_numpy_array(image):\n",
        "  (im_width, im_height) = image.size\n",
        "  return np.array(image.getdata()).reshape(\n",
        "      (im_height, im_width, 3)).astype(np.uint8)\n",
        "\n",
        "# Function for loading images from urls\n",
        "def url_to_image(url):\n",
        "  resp = urllib.request.urlopen(url)\n",
        "  image = np.asarray(bytearray(resp.read()), dtype=\"uint8\")\n",
        "  image = cv2.imdecode(image, cv2.IMREAD_COLOR)\n",
        "  image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "  return image\n",
        "\n",
        "# Can change min_score_thresh and max_boxes_to_draw\n",
        "def show_inference(image_np_expanded):\n",
        "  with detection_graph.as_default():\n",
        "    with tf.Session(graph=detection_graph) as sess:\n",
        "      # Definite input and output Tensors for detection_graph\n",
        "      image_tensor = detection_graph.get_tensor_by_name('image_tensor:0')\n",
        "      # Each box represents a part of the image where a particular object was detected.\n",
        "      detection_boxes = detection_graph.get_tensor_by_name('detection_boxes:0')\n",
        "      #max_boxes_to_draw = detection_boxes.shape[0] # add this line and remove (i) and (ii) below to show multiple detection boxes\n",
        "      # Each score represent how level of confidence for each of the objects.\n",
        "      # Score is shown on the result image, together with the class label.\n",
        "      detection_scores = detection_graph.get_tensor_by_name('detection_scores:0')\n",
        "      detection_classes = detection_graph.get_tensor_by_name('detection_classes:0')\n",
        "      num_detections = detection_graph.get_tensor_by_name('num_detections:0')\n",
        "      #min_score_thresh = .7\n",
        "\n",
        "      # Actual detection\n",
        "      (boxes, scores, classes, num) = sess.run(\n",
        "          [detection_boxes, detection_scores, detection_classes, num_detections],\n",
        "          feed_dict={image_tensor: image_np_expanded})\n",
        "      \n",
        "      # Visualization of the results of a detection\n",
        "      # Modified from https://github.com/tensorflow/models/issues/4682\n",
        "      im_height, im_width, im_depth = image_np.shape\n",
        "      ymin = int((boxes[0][0][0]*im_height))\n",
        "      xmin = int((boxes[0][0][1]*im_width))\n",
        "      ymax = int((boxes[0][0][2]*im_height))\n",
        "      xmax = int((boxes[0][0][3]*im_width))\n",
        "      newImage = np.copy(image_np)\n",
        "      newImage = cv2.rectangle(newImage, (xmin, ymax), (xmax, ymin), (255, 0, 157), 3)\n",
        "      # Add labels to boxes\n",
        "      #newImage = cv2.putText(newImage, label, (xmin, ymax-5), cv2.FONT_HERSHEY_SIMPLEX, fontScale, (153, 255, 255), 5, cv2.LINE_AA)\n",
        "\n",
        "      return newImage"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CjE-Gh5ann4E",
        "colab_type": "text"
      },
      "source": [
        "### Run test images through object detector"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iSPrkTKAglMZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Update path to your test images\n",
        "PATH_TO_TEST_IMAGES_DIR = 'test_images/'\n",
        "PATH_TO_OUT_IMAGES_DIR = 'test_images/out/'\n",
        "names = os.listdir(PATH_TO_TEST_IMAGES_DIR)\n",
        "TEST_IMAGE_PATHS = [os.path.join(PATH_TO_TEST_IMAGES_DIR, name) for name in names]\n",
        "OUT_IMAGE_PATHS = [os.path.join(PATH_TO_OUT_IMAGES_DIR, name) for name in names]\n",
        "\n",
        "# Loops through first 5 image urls from the text file\n",
        "for im_num, im_path in enumerate(TEST_IMAGE_PATHS[:50], start=1):\n",
        " \n",
        "    # Load in image\n",
        "    image = Image.open(im_path)\n",
        "    image_np = load_image_into_numpy_array(image)\n",
        "    image_np_expanded = np.expand_dims(image_np, axis=0)\n",
        "    # Record inference time\n",
        "    start_time = time.time()\n",
        "    # Detection and draw boxes on image\n",
        "    show_inference(image_np_expanded)\n",
        "    end_time = time.time()\n",
        "    # Display progress message after each image\n",
        "    print('Detection complete in {} of 145 test images'.format(im_num))\n",
        "\n",
        "    # Plot and show detection boxes on images\n",
        "    # If running detection on >50 images, comment out this portion\n",
        "    _, ax = plt.subplots(figsize=(10, 10))\n",
        "    ax.imshow(show_inference(image_np_expanded))\n",
        "    plt.title('{}) Inference time: {}'.format(im_num, format(end_time-start_time, '.2f')))\n",
        "\n",
        "    # Optional: Save image with detection boxes to Google Drive\n",
        "    #img = Image.fromarray(show_inference(image_np_expanded))\n",
        "    #img.save(OUT_IMAGE_PATHS[im_num-1])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vv9c8NRXy4DM",
        "colab_type": "text"
      },
      "source": [
        "### Get inference info for test images to compare object detection model times for YOLO, SSD, and Faster-RCNN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aJcda-CNy6TY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from PIL import Image\n",
        "import os\n",
        "\n",
        "# For exporting inference times\n",
        "inf_time = []\n",
        "img_path = []\n",
        "im_dims = []\n",
        "\n",
        "# Update path to your test images\n",
        "PATH_TO_TEST_IMAGES_DIR = 'test_images/'\n",
        "names = os.listdir(PATH_TO_TEST_IMAGES_DIR)\n",
        "TEST_IMAGE_PATHS = [os.path.join(PATH_TO_TEST_IMAGES_DIR, name) for name in names]\n",
        "\n",
        "# Loops through first 5 image urls from the text file\n",
        "#for im_num, im_path in enumerate(TEST_IMAGE_PATHS[:5], start=1):\n",
        "for im_num, im_path in enumerate(TEST_IMAGE_PATHS, start=1):\n",
        " \n",
        "    # Load in image\n",
        "    image = Image.open(im_path)\n",
        "    image_np = load_image_into_numpy_array(image)\n",
        "    image_np_expanded = np.expand_dims(image_np, axis=0)\n",
        "    # Record inference time\n",
        "    start_time = time.time()\n",
        "    # Detection and draw boxes on image\n",
        "    show_inference(image_np_expanded)\n",
        "    end_time = time.time()\n",
        "    # Display progress message after each image\n",
        "    print('Detection complete in {} of 145 test images'.format(im_num))\n",
        "\n",
        "    # Record inference time, image name and image dimensions to export\n",
        "    inf_time.append(end_time-start_time)\n",
        "    img_path.append(im_path)\n",
        "    im_dims.append(image_np.shape)\n",
        "    \n",
        "inf_times = pd.DataFrame(([inf_time, img_path, im_dims]))\n",
        "inf_times = inf_times.transpose()\n",
        "#inf_times.to_csv(\"lepidoptera_inference_times_rcnn.csv\", index=False, header=(\"time (sec)\", \"filepath\", \"image_dims (h, w, d)\"))\n",
        "inf_times.to_csv(\"lepidoptera_inference_times_ssd.csv\", index=False, header=(\"time (sec)\", \"filepath\", \"image_dims (h, w, d)\"))\n",
        "print(inf_times.head())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k3HJoT3kx0a3",
        "colab_type": "text"
      },
      "source": [
        "### Run other images (from individual URLs) through object detector"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6D585u93x4N2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Test trained model on test images\n",
        "from PIL import Image\n",
        "\n",
        "# Put your urls here\n",
        "image_urls = [\"https://upload.wikimedia.org/wikipedia/commons/b/be/Batman_%28retouched%29.jpg\",\n",
        "              \"https://upload.wikimedia.org/wikipedia/commons/thumb/9/90/Bela_Lugosi_as_Dracula%2C_anonymous_photograph_from_1931%2C_Universal_Studios.jpg/690px-Bela_Lugosi_as_Dracula%2C_anonymous_photograph_from_1931%2C_Universal_Studios.jpg\"]\n",
        "\n",
        "# Loops through image_urls\n",
        "for im_num, image_url in enumerate(image_urls, start=1):\n",
        "  try:\n",
        "    # Load in image\n",
        "    image_np = url_to_image(image_url)\n",
        "    image_np_expanded = np.expand_dims(image_np, axis=0)\n",
        "    # Record inference time\n",
        "    start_time = time.time()\n",
        "    # Detection and draw boxes on image\n",
        "    show_inference(image_np_expanded)\n",
        "    end_time = time.time()\n",
        "    # Display progress message after each image\n",
        "    print('Detection complete in {} of 2 images'.format(im_num))\n",
        "\n",
        "    # Plot and show detection boxes on images\n",
        "    # If running detection on >50 images, comment out this portion\n",
        "    _, ax = plt.subplots(figsize=(10, 10))\n",
        "    ax.imshow(show_inference(image_np_expanded))\n",
        "    plt.title('{}) Inference time: {}'.format(im_num, format(end_time-start_time, '.2f')))\n",
        "\n",
        "  except:\n",
        "    print('Check if URL from {} is valid'.format(image_url))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y4xGqHxjE0mC",
        "colab_type": "text"
      },
      "source": [
        "## Run EOL image bundles through the trained object detector & save results for cropping\n",
        "---\n",
        "Display resulting detection boxes on images and save their coordinates to chiroptera_det_crops.tsv for use cropping EOL images."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NGdW08UaN1Zu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Change PATH_TO_CKPT below when switching between SSD and Faster-RCNN models\n",
        "%cd train\n",
        "# SSD Model\n",
        "#PATH_TO_CKPT = 'tf_models/train_demo/ssd/finetuned_model' + '/frozen_inference_graph.pb'\n",
        "# Faster RCNN Model\n",
        "PATH_TO_CKPT = 'tf_models/train_demo/rcnn/finetuned_model' + '/frozen_inference_graph.pb'\n",
        "\n",
        "# List of the strings that is used to add correct label for each box.\n",
        "PATH_TO_LABELS = 'labelmap.pbtxt'\n",
        "NUM_CLASSES = 1\n",
        "    \n",
        "detection_graph = tf.Graph()\n",
        "with detection_graph.as_default():\n",
        "  od_graph_def = tf.compat.v1.GraphDef()\n",
        "  with tf.io.gfile.GFile(PATH_TO_CKPT, 'rb') as fid:\n",
        "    serialized_graph = fid.read()\n",
        "    od_graph_def.ParseFromString(serialized_graph)\n",
        "    tf.import_graph_def(od_graph_def, name='')\n",
        "    \n",
        "label_map = label_map_util.load_labelmap(PATH_TO_LABELS)\n",
        "categories = label_map_util.convert_label_map_to_categories(label_map, max_num_classes=NUM_CLASSES, use_display_name=True)\n",
        "category_index = label_map_util.create_category_index(categories)\n",
        "\n",
        "# For loading images into computer-readable format\n",
        "def load_image_into_numpy_array(image):\n",
        "  (im_width, im_height) = image.size\n",
        "  return np.array(image.getdata()).reshape(\n",
        "      (im_height, im_width, 3)).astype(np.uint8)\n",
        "\n",
        "# Function for loading images from urls\n",
        "def url_to_image(url):\n",
        "  resp = urllib.request.urlopen(url)\n",
        "  image = np.asarray(bytearray(resp.read()), dtype=\"uint8\")\n",
        "  image = cv2.imdecode(image, cv2.IMREAD_COLOR)\n",
        "  image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "  return image\n",
        "\n",
        "# Can change min_score_thresh and max_boxes_to_draw\n",
        "def show_inference(image_np_expanded):\n",
        "  with detection_graph.as_default():\n",
        "    with tf.Session(graph=detection_graph) as sess:\n",
        "      # Definite input and output Tensors for detection_graph\n",
        "      image_tensor = detection_graph.get_tensor_by_name('image_tensor:0')\n",
        "      # Each box represents a part of the image where a particular object was detected.\n",
        "      detection_boxes = detection_graph.get_tensor_by_name('detection_boxes:0')\n",
        "      # Each score represents the level of confidence for each of the objects.\n",
        "      detection_scores = detection_graph.get_tensor_by_name('detection_scores:0')\n",
        "      detection_classes = detection_graph.get_tensor_by_name('detection_classes:0')\n",
        "      num_detections = detection_graph.get_tensor_by_name('num_detections:0')\n",
        "      # Optional: adjust score confidence threshold for display\n",
        "      #min_score_thresh = .7\n",
        "\n",
        "      # Actual detection\n",
        "      (boxes, scores, classes, num) = sess.run(\n",
        "          [detection_boxes, detection_scores, detection_classes, num_detections],\n",
        "          feed_dict={image_tensor: image_np_expanded})\n",
        "      \n",
        "      # Visualization of the results of a detection\n",
        "      # Modified from https://github.com/tensorflow/models/issues/4682\n",
        "      im_height, im_width, im_depth = image_np.shape\n",
        "      ymin = int((boxes[0][0][0]*im_height))\n",
        "      xmin = int((boxes[0][0][1]*im_width))\n",
        "      ymax = int((boxes[0][0][2]*im_height))\n",
        "      xmax = int((boxes[0][0][3]*im_width))\n",
        "      newImage = np.copy(image_np)\n",
        "      newImage = cv2.rectangle(newImage, (xmin, ymax), (xmax, ymin), (255, 0, 157), 3)\n",
        "      # Add labels to boxes\n",
        "      #newImage = cv2.putText(newImage, label, (xmin, ymax-5), cv2.FONT_HERSHEY_SIMPLEX, fontScale, (153, 255, 255), 5, cv2.LINE_AA)\n",
        "\n",
        "      # Export bounding boxes to drive\n",
        "      with open('/content/drive/My Drive/fall19_smithsonian_informatics/train/lepidoptera_det_crops_20000_a.tsv', 'a') as out_file:\n",
        "                  tsv_writer = csv.writer(out_file, delimiter='\\t')\n",
        "                  crop_width = xmax-xmin\n",
        "                  crop_height = ymax-ymin\n",
        "                  tsv_writer.writerow([image_url, im_height, im_width, \n",
        "                            xmin, ymin, xmax, ymax])\n",
        "      return newImage"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hvGZF-luElUe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Use URLs from EOL image URL bundles\n",
        "# Comment out to use either 1000 or 20000 image bundles\n",
        "#1000 images\n",
        "#urls = 'https://editors.eol.org/other_files/bundle_images/files/images_for_Lepidoptera_breakdown_download_000001.txt'\n",
        "#20000 images\n",
        "urls = 'https://editors.eol.org/other_files/bundle_images/files/images_for_Lepidoptera_20K_breakdown_download_000001.txt'\n",
        "\n",
        "df = pd.read_csv(urls)\n",
        "df.columns = [\"link\"]\n",
        "pd.DataFrame.head(df)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wpT10kRyF69m",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Write header row of output crops file\n",
        "with open('/content/drive/My Drive/fall19_smithsonian_informatics/train/lepidoptera_det_crops_20000_a.tsv', 'a') as out_file:\n",
        "                  tsv_writer = csv.writer(out_file, delimiter='\\t')\n",
        "                  tsv_writer.writerow([\"image_url\", \"im_height\", \"im_width\", \n",
        "                            \"xmin\", \"ymin\", \"xmax\", \"ymax\"])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DbbHfPXIE6QE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Test trained model on test images\n",
        "from PIL import Image\n",
        "\n",
        "# Set number of seconds to timeout if image url taking too long to open\n",
        "import socket\n",
        "socket.setdefaulttimeout(10)\n",
        "\n",
        "# Loops through first 5 image urls from the text file\n",
        "#for i, row in df.head(5).itertuples(index=True, name='Pandas'):\n",
        "\n",
        "# For ranges of rows or all rows, use df.iloc\n",
        "# Can be useful if running detection in batches\n",
        "for i, row in df.iloc[:5000].iterrows():\n",
        "\n",
        "  try:\n",
        "    # Load in image\n",
        "    image_url = df.get_value(i, \"link\")\n",
        "    image_np = url_to_image(image_url)\n",
        "    image_np_expanded = np.expand_dims(image_np, axis=0)\n",
        "    # Record inference time\n",
        "    start_time = time.time()\n",
        "    # Detection and draw boxes on image\n",
        "    show_inference(image_np_expanded)\n",
        "    end_time = time.time()\n",
        "    # Display progress message after each image\n",
        "    print('Detection complete in {} of 20000 test images'.format(i+1))\n",
        "\n",
        "    # Plot and show detection boxes on images\n",
        "    # If running detection on >50 images, comment out this portion\n",
        "    #_, ax = plt.subplots(figsize=(10, 10))\n",
        "    #ax.imshow(show_inference(image_np_expanded))\n",
        "    #plt.title('{}) Inference time: {}'.format(i+1, format(end_time-start_time, '.2f')))\n",
        "\n",
        "  except:\n",
        "    print('Check if URL from {} is valid'.format(image_url))"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}