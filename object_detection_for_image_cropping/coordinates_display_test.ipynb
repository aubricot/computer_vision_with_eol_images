{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "coordinates_display_test.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "Wfh8n7Utjlc_"
      ],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/aubricot/computer_vision_with_eol_images/blob/master/object_detection_for_image_cropping/coordinates_display_test.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KDF3pvUbR79-",
        "colab_type": "text"
      },
      "source": [
        "# Display box coordinates resulting from object detection or image augmentation on images\n",
        "---\n",
        "*Last Updated 15 April 2020*   \n",
        "Use this notebook to verify the coordinates resulting from either object detection or image augmentation. If results aren't as expected, data reformatting and tidying steps in [convert_bboxdims.py](https://github.com/aubricot/object_detection_for_image_cropping/blob/master/convert_bboxdims.py) or [preprocessing.ipynb](https://colab.research.google.com/github/aubricot/object_detection_for_image_cropping/blob/master/preprocessing.ipynb) can be adjusted and results re-displayed accordingly.\n",
        "\n",
        "__Coordinates from object detection__: Bounding boxes resulting from object detection using YOLO were exported from object_detection_for_image_cropping_yolo.ipynb, then converted to square dimensions and padded to be used as crop coordinates for EOL images using convert_bboxdims.py. Crop coordinates were exported to bird_crops_yolo_1000img_display_test.tsv and should be imported to your Google Drive for upload to this notebook.\n",
        "\n",
        "__Coordinates from pre-processing and augmentation__: Bounding boxes resulting from pre-processing and augmentation of EOL user-generated cropping coordinates and images were tidied and exported from preprocessing.ipynb to chiroptera_crops_train_aug_fin.tsv and chiroptera_crops_test_notaug_fin.tsv and should be imported to your Google Drive for upload to this notebook. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gB46XHAgR0rZ",
        "colab_type": "text"
      },
      "source": [
        "## Imports\n",
        "---\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ei41bcPX_Uw0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# For importing data and images\n",
        "import numpy as np \n",
        "import pandas as pd\n",
        "import urllib\n",
        "\n",
        "# For drawing on and displaying images\n",
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "%config InlineBackend.figure_format = 'svg'\n",
        "\n",
        "# For saving images\n",
        "# Un-comment out if running \"Save crop dimensions displayed on images to Google Drive\" below\n",
        "!pip install pillow\n",
        "!pip install scipy==1.1.0\n",
        "import scipy"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MMXbfv8LkPDM",
        "colab_type": "text"
      },
      "source": [
        "##Load in crop coordinates from Google Drive\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0eil6qUvOFbi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Mount Google Drive to import your file containing coordinates (object detection bounding boxes, cropping coordinates, etc.)\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JwDoLIKqANG3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Import your file containining coordinates from Google Drive\n",
        "# Note: First you need to upload the file to your Google Drive, then adjust the path accordingly\n",
        "df = pd.read_csv('drive/My Drive/fall19_smithsonian_informatics/train/results/aves_det_crops_1000img_display_test.tsv', sep='\\t', header=0)\n",
        "print(df.head())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i6CADy0ShfMy",
        "colab_type": "text"
      },
      "source": [
        "## Display crop dimensions on images\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "brfp9BGV_Ro1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# For uploading an image from url\n",
        "# Modified from https://www.pyimagesearch.com/2015/03/02/convert-url-to-image-with-python-and-opencv/\n",
        "def url_to_image(url):\n",
        "  resp = urllib.request.urlopen(url)\n",
        "  image = np.asarray(bytearray(resp.read()), dtype=\"uint8\")\n",
        "  image = cv2.imdecode(image, cv2.IMREAD_COLOR)\n",
        "  image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        " \n",
        "  return image"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NMyK85W4O5d7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Display crop dimensions on images\n",
        "# Adjust line below to see up to 50 images displayed at a time\n",
        "#for i, row in df.head(50).iterrows():\n",
        "for i, row in df.iloc[50:56].iterrows():\n",
        "  # Read in image \n",
        "  url = df['eolMediaURL'][i]\n",
        "  img = url_to_image(url)\n",
        "  # Define variables needed to draw bounding box on image\n",
        "  xmin = df['xmin'][i].astype(int)\n",
        "  ymin = df['ymin'][i].astype(int) + df['crop_height'][i].astype(int)\n",
        "  xmax = df['xmin'][i].astype(int) + df['crop_width'][i].astype(int)\n",
        "  ymax = df['ymin'][i].astype(int)\n",
        "  fontScale = max(df['im_width'][i],df['im_height'][i])/(600)\n",
        "  box_col = (255, 0, 157)\n",
        "  \n",
        "  # If using multitaxa dataset, draw color-coded boxes and class labels on images\n",
        "  if 'class' in df:\n",
        "    taxon = df['class'][i]\n",
        "    if taxon == \"Squamata\":\n",
        "      box_col = (255,199,15)\n",
        "    elif taxon == \"Coleoptera\":\n",
        "      box_col = (255,127,0)\n",
        "    elif taxon == \"Anura\":\n",
        "      box_col = (255,42,22)\n",
        "    elif taxon == \"Carnivora\":\n",
        "      box_col = (0,191,255)\n",
        "    # Draw taxon label on image\n",
        "    image_wbox = cv2.putText(img, taxon, (xmin, ymin-5), cv2.FONT_HERSHEY_SIMPLEX, fontScale, (255,255,255), 2, cv2.LINE_AA)\n",
        "  \n",
        "  # Draw box on image\n",
        "  image_wbox = cv2.rectangle(img, (xmin, ymin), (xmax, ymax), box_col, 5)\n",
        "  \n",
        "  # Plot and show cropping boxes on images\n",
        "  _, ax = plt.subplots(figsize=(10, 10))\n",
        "  ax.imshow(image_wbox)\n",
        "  # Display image URL above image to facilitate troubleshooting/fine-tuning of data reformatting and tidying steps in convert_bboxdims.py or preprocessing.ipynb\n",
        "  plt.title('{}'.format(url, xmin, ymin, xmax, ymax))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wfh8n7Utjlc_",
        "colab_type": "text"
      },
      "source": [
        "## Save crop dimensions displayed on images to Google Drive\n",
        "---\n",
        "Useful if want to share results with someone remotely. Saves images with detection boxes to Google Drive."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LeeP3DNgszPO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# For uploading an image from url\n",
        "# Modified from https://www.pyimagesearch.com/2015/03/02/convert-url-to-image-with-python-and-opencv/\n",
        "def url_to_image(url):\n",
        "  resp = urllib.request.urlopen(url)\n",
        "  image = np.asarray(bytearray(resp.read()), dtype=\"uint8\")\n",
        "  image = cv2.imdecode(image, cv2.IMREAD_COLOR)\n",
        "  image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        " \n",
        "  return image"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8IhLvxHhjnEy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# For saving images\n",
        "from scipy import misc\n",
        "\n",
        "# Path to folder for exporting images with bounding boxes\n",
        "pathbase = 'drive/My Drive/fall19_smithsonian_informatics/train/out/'\n",
        "\n",
        "# Display crop dimensions on images\n",
        "# Adjust line below to see up to 50 images displayed at a time\n",
        "#for i, row in df.head(50).iterrows():\n",
        "for i, row in df.iloc[60:63].iterrows():\n",
        "  # Make output path\n",
        "  path = pathbase + str(df.dataObjectVersionID[i]) + '.jpg'\n",
        "\n",
        "  # Read in image \n",
        "  url = df['eolMediaURL'][i]\n",
        "  img = url_to_image(url)\n",
        "\n",
        "  # Define variables needed to draw bounding box on image\n",
        "  xmin = df['xmin'][i].astype(int)\n",
        "  ymin = df['ymin'][i].astype(int) + df['crop_height'][i].astype(int)\n",
        "  xmax = df['xmin'][i].astype(int) + df['crop_width'][i].astype(int)\n",
        "  ymax = df['ymin'][i].astype(int)\n",
        "  fontScale = max(df['im_width'][i],df['im_height'][i])/(600)\n",
        "  box_col = (255, 0, 157)\n",
        "  \n",
        "  # If using multitaxa dataset, draw color-coded boxes and class labels on images\n",
        "  if 'class' in df:\n",
        "    taxon = df['class'][i]\n",
        "    if taxon == \"Squamata\":\n",
        "      box_col = (255,199,15)\n",
        "    elif taxon == \"Coleoptera\":\n",
        "      box_col = (255,127,0)\n",
        "    elif taxon == \"Anura\":\n",
        "      box_col = (255,42,22)\n",
        "    elif taxon == \"Carnivora\":\n",
        "      box_col = (0,191,255)\n",
        "    # Draw taxon label on image\n",
        "    image_wbox = cv2.putText(img, taxon, (xmin, ymin-5), cv2.FONT_HERSHEY_SIMPLEX, fontScale, (255,255,255), 2, cv2.LINE_AA)\n",
        "  \n",
        "  # Draw box on image\n",
        "  image_wbox = cv2.rectangle(img, (xmin, ymin), (xmax, ymax), box_col, 5)\n",
        "\n",
        "  # Export image to Google Drive\n",
        "  misc.imsave(path, image_wbox)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}