{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "lepidoptera_train_tf2_ssd_rcnn.ipynb",
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": [
        "Sz7aVQVUSecK",
        "UY7I79qftfQi",
        "feGWA2fpnZOI"
      ],
      "toc_visible": true,
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU",
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/aubricot/computer_vision_with_eol_images/blob/master/object_detection_for_image_cropping/lepidoptera/lepidoptera_train_tf2_ssd_rcnn.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SWrXhn1qKWm_"
      },
      "source": [
        "# Train Tensorflow Faster-RCNN and SSD models to detect butterflies & moths (Lepidoptera) from EOL images\n",
        "---   \n",
        "*Last Updated 29 May 2021*  \n",
        "-Now runs in Python 3 with Tensorflow 2.0-     \n",
        "\n",
        "Use EOL user generated cropping coordinates to train Faster-RCNN and SSD Object Detection Models implemented in Tensorflow to detect butterflies & moths from EOL images. Training data consists of the user-determined best square thumbnail crop of an image, so model outputs will also be a square around objects of interest.\n",
        "\n",
        "Datasets were downloaded to Google Drive in [lepidoptera_preprocessing.ipynb](https://github.com/aubricot/computer_vision_with_eol_images/blob/master/object_detection_for_image_cropping/lepidoptera/lepidoptera_preprocessing.ipynb).\n",
        "\n",
        "***Models were trained in Python 2 and TF 1 in Jan 2020: RCNN trained for 2 days to 200,000 steps and SSD for 2 days to 200,000 steps.*** \n",
        "\n",
        "Notes:   \n",
        "* Before you you start: change the runtime to \"GPU\" with \"High RAM\"\n",
        "* Change filepaths/taxon names where you see 'TO DO' \n",
        "* For each 24 hour period on Google Colab, you have up to 12 hours of free GPU access. \n",
        "\n",
        "References:     \n",
        "* [Official Tensorflow Object Detection API Instructions](https://tensorflow-object-detection-api-tutorial.readthedocs.io/en/latest/training.html) \n",
        "* [Medium Blog on training using Tensorflow Object Detection API in Colab](https://medium.com/analytics-vidhya/training-an-object-detection-model-with-tensorflow-api-using-google-colab-4f9a688d5e8b)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "smQWTwI7k4Bf"
      },
      "source": [
        "## Installs & Imports\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0mAC7PfUrWX1"
      },
      "source": [
        "# Mount google drive to import/export files\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u4KnpJISUSzt"
      },
      "source": [
        "# For running inference on the TF-Hub module\n",
        "import tensorflow as tf\n",
        "import tensorflow_hub as hub\n",
        "\n",
        "# For downloading and displaying images\n",
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "import tempfile\n",
        "import urllib\n",
        "from urllib.request import urlretrieve\n",
        "from six.moves.urllib.request import urlopen\n",
        "from six import BytesIO\n",
        "\n",
        "# For drawing onto images\n",
        "from PIL import Image\n",
        "from PIL import ImageColor\n",
        "from PIL import ImageDraw\n",
        "from PIL import ImageFont\n",
        "from PIL import ImageOps\n",
        "\n",
        "# For measuring the inference time\n",
        "import time\n",
        "\n",
        "# For working with data\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import os\n",
        "import csv\n",
        "\n",
        "# Print Tensorflow version\n",
        "print('Tensorflow Version: %s' % tf.__version__)\n",
        "\n",
        "# Check available GPU devices\n",
        "print('The following GPU devices are available: %s' % tf.test.gpu_device_name())\n",
        "\n",
        "# Define functions\n",
        "\n",
        "# Read in data file exported from \"Combine output files A-D\" block above\n",
        "def read_datafile(fpath, sep=\"\\t\", header=0, disp_head=True):\n",
        "    \"\"\"\n",
        "    Defaults to tab-separated data files with header in row 0\n",
        "    \"\"\"\n",
        "    try:\n",
        "        df = pd.read_csv(fpath, sep=sep, header=header)\n",
        "        if disp_head:\n",
        "          print(\"Data header: \\n\", df.head())\n",
        "    except FileNotFoundError as e:\n",
        "        raise Exception(\"File not found: Enter the path to your file in form field and re-run\").with_traceback(e.__traceback__)\n",
        "    \n",
        "    return df\n",
        "\n",
        "# To load image in and do something with it\n",
        "def load_img(path): \n",
        "  img = tf.io.read_file(path)\n",
        "  img = tf.image.decode_jpeg(img, channels=3)\n",
        "  return img\n",
        "\n",
        "# To display loaded image\n",
        "def display_image(image):\n",
        "  fig = plt.figure(figsize=(20, 15))\n",
        "  plt.grid(False)\n",
        "  plt.imshow(image)\n",
        "\n",
        "# For reading in images from URL and passing through TF models for inference\n",
        "def download_and_resize_image(url, new_width=256, new_height=256, #From URL\n",
        "                              display=False):\n",
        "  _, filename = tempfile.mkstemp(suffix=\".jpg\")\n",
        "  response = urlopen(url)\n",
        "  image_data = response.read()\n",
        "  image_data = BytesIO(image_data)\n",
        "  pil_image = Image.open(image_data)\n",
        "  im_h, im_w = pil_image.size\n",
        "  pil_image = ImageOps.fit(pil_image, (new_width, new_height), Image.ANTIALIAS)\n",
        "  pil_image_rgb = pil_image.convert(\"RGB\")\n",
        "  pil_image_rgb.save(filename, format=\"JPEG\", quality=90)\n",
        "  #print(\"Image downloaded to %s.\" % filename)\n",
        "  if display:\n",
        "    display_image(pil_image)\n",
        "  return filename, im_h, im_w"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "No18RpXIAgGL"
      },
      "source": [
        "# Download, compile and build the Tensorflow Object Detection API (takes 4-9 minutes)\n",
        "\n",
        "# TO DO: Type in the path to your working directory in form field to right\n",
        "basewd = \"/content/drive/MyDrive/train\" #@param {type:\"string\"}\n",
        "%cd $basewd\n",
        "\n",
        "# Set up directory for TF2 Model Garden\n",
        "# TO DO: Type in the folder you would like to contain TF2\n",
        "folder = \"tf2\" #@param {type:\"string\"}\n",
        "if not os.path.exists(folder):\n",
        "    os.makedirs(folder)\n",
        "    %cd $folder\n",
        "    os.makedirs(\"tf_models\")\n",
        "    %cd tf_models\n",
        "    # Clone the Tensorflow Model Garden\n",
        "    !git clone --depth 1 https://github.com/tensorflow/models/\n",
        "    %cd ../..\n",
        "\n",
        "# Build the Object Detection API\n",
        "wd = basewd + '/' + folder\n",
        "%cd $wd\n",
        "!cd tf_models/models/research/ && protoc object_detection/protos/*.proto --python_out=. && cp object_detection/packages/tf2/setup.py . && python -m pip install ."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G7amcDYcQpf0"
      },
      "source": [
        "## Model preparation (only run once)\n",
        "---\n",
        "These blocks download and set-up files needed for training object detectors. After running once, you can train and re-train as many times as you'd like."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VgG3-2LslczI"
      },
      "source": [
        "### Download and extract pre-trained models "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YaLxacTBZnM1"
      },
      "source": [
        "# Download pre-trained models from Tensorflow Object Detection Model Zoo\n",
        "# https://github.com/tensorflow/models/blob/master/research/object_detection/g3doc/tf2_detection_zoo.md\n",
        "# SSD and Faster-RCNN used as options below\n",
        "# modified from https://github.com/RomRoc/objdet_train_tensorflow_colab/blob/master/objdet_custom_tf_colab.ipynb\n",
        "\n",
        "import shutil\n",
        "import glob\n",
        "import tarfile\n",
        "\n",
        "# CD to folder where TF models are installed (tf2)\n",
        "%cd $wd\n",
        "\n",
        "# Make folders for your training files for each model\n",
        "# Faster RCNN Model\n",
        "if not (os.path.exists('tf_models/train_demo')):\n",
        "  !mkdir tf_models/train_demo\n",
        "if not (os.path.exists('tf_models/train_demo/rcnn')):\n",
        "  !mkdir tf_models/train_demo/rcnn\n",
        "if not (os.path.exists('tf_models/train_demo/rcnn/pretrained_model')):\n",
        "  !mkdir tf_models/train_demo/rcnn/pretrained_model\n",
        "if not (os.path.exists('tf_models/train_demo/rcnn/finetuned_model')):\n",
        "  !mkdir tf_models/train_demo/rcnn/finetuned_model\n",
        "if not (os.path.exists('tf_models/train_demo/rcnn/trained')):\n",
        "  !mkdir tf_models/train_demo/rcnn/trained\n",
        "# Download the model\n",
        "MODEL = 'faster_rcnn_resnet50_v1_640x640_coco17_tpu-8'\n",
        "MODEL_FILE = MODEL + '.tar.gz'\n",
        "DOWNLOAD_BASE = 'http://download.tensorflow.org/models/object_detection/tf2/20200711/'\n",
        "DEST_DIR = 'tf_models/train_demo/rcnn/pretrained_model'\n",
        "if not (os.path.exists(MODEL_FILE)):\n",
        "  urlretrieve(DOWNLOAD_BASE + MODEL_FILE, MODEL_FILE)\n",
        "\n",
        "tar = tarfile.open(MODEL_FILE)\n",
        "tar.extractall()\n",
        "tar.close()\n",
        "\n",
        "os.remove(MODEL_FILE)\n",
        "if (os.path.exists(DEST_DIR)):\n",
        "  shutil.rmtree(DEST_DIR)\n",
        "os.rename(MODEL, DEST_DIR)\n",
        "\n",
        "# SSD Model\n",
        "if not (os.path.exists('tf_models/train_demo/ssd')):\n",
        "  !mkdir tf_models/train_demo/ssd\n",
        "if not (os.path.exists('tf_models/train_demo/ssd/pretrained_model')):\n",
        "  !mkdir tf_models/train_demo/ssd/pretrained_model\n",
        "if not (os.path.exists('tf_models/train_demo/ssd/finetuned_model')):\n",
        "  !mkdir tf_models/train_demo/ssd/finetuned_model\n",
        "if not (os.path.exists('tf_models/train_demo/ssd/trained')):\n",
        "  !mkdir tf_models/train_demo/ssd/trained\n",
        "# Download the model\n",
        "MODEL = 'ssd_mobilenet_v2_320x320_coco17_tpu-8'\n",
        "MODEL_FILE = MODEL + '.tar.gz'\n",
        "DOWNLOAD_BASE = 'http://download.tensorflow.org/models/object_detection/tf2/20200711/'\n",
        "DEST_DIR = 'tf_models/train_demo/ssd/pretrained_model'\n",
        "if not (os.path.exists(MODEL_FILE)):\n",
        "  urlretrieve(DOWNLOAD_BASE + MODEL_FILE, MODEL_FILE)\n",
        "\n",
        "tar = tarfile.open(MODEL_FILE)\n",
        "tar.extractall()\n",
        "tar.close()\n",
        "\n",
        "os.remove(MODEL_FILE)\n",
        "if (os.path.exists(DEST_DIR)):\n",
        "  shutil.rmtree(DEST_DIR)\n",
        "os.rename(MODEL, DEST_DIR)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Sz7aVQVUSecK"
      },
      "source": [
        "### Convert training data to tf.record format"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ygJPRnpHTuLl"
      },
      "source": [
        "1) Download generate_tfrecord.py using code block below\n",
        "\n",
        "2) Open the Colab file explorer on the right and navigate to your current working directory\n",
        "\n",
        "3) Double click on generate_tfrecord.py to open it in the Colab text editor.\n",
        "\n",
        "4) Modify the file for your train dataset: \n",
        "*   update label names to the class(es) of interest at line 31 (Lepidoptera)\n",
        "        # TO-DO replace this with label map\n",
        "        def class_text_to_int(row_label):\n",
        "          if row_label == 'Lepidoptera':\n",
        "            return 1\n",
        "          else:\n",
        "            None\n",
        "*   update the filepath where you want your train tf.record file to save at line 85\n",
        "        # TO-DO replace path with your filepath\n",
        "        def main(_):\n",
        "            writer = tf.python_io.TFRecordWriter('/content/drive/MyDrive/[yourfilepath]/tf.record')\n",
        "\n",
        "5) Close Colab text editor and proceed with steps below to generate tf.record files for your test and train datasets"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GchfjBAQ_7-s"
      },
      "source": [
        "# Download lepidoptera_generate_tfrecord.py to your wd in Google Drive\n",
        "# Follow directions above to modify the file for your dataset\n",
        "!gdown --id 1_pRlENeAvGV-h_c-_rl2d0Y1QxMJ0TAS"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9kFe9D21WGog"
      },
      "source": [
        "# Convert crops_test to tf.record format for test data\n",
        "# Modified from https://tensorflow-object-detection-api-tutorial.readthedocs.io/en/latest/training.html\n",
        "\n",
        "# TO DO: Update file paths in form fields\n",
        "csv_input = \"/content/drive/MyDrive/train/tf2/pre-processing/Lepidoptera_crops_test_notaug_oob_rem_fin.csv\" #@param {type:\"string\"}\n",
        "output_path = \"/content/drive/MyDrive/train/tf2/test_images/tf.record\" #@param {type:\"string\"}\n",
        "test_image_dir = \"/content/drive/MyDrive/train/tf2/test_images\" #@param {type:\"string\"}\n",
        "\n",
        "!python lepidoptera_generate_tfrecord.py --csv_input=$csv_input  --output_path=$output_path  --image_dir=$test_image_dir"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vSYr0hBPg8yh"
      },
      "source": [
        "# Move tf.record for test images to test images directory\n",
        "!mv tf.record $image_dir"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zRr1MLxSICf_"
      },
      "source": [
        "# Convert crops_train to tf.record format for train data\n",
        "# Modified from https://tensorflow-object-detection-api-tutorial.readthedocs.io/en/latest/training.html\n",
        "\n",
        "# TO DO: Update file paths in form fields\n",
        "csv_input = \"/content/drive/MyDrive/train/tf2/pre-processing/Lepidoptera_crops_train_aug_oob_rem_fin.csv\" #@param {type:\"string\"}\n",
        "output_path = \"/content/drive/MyDrive/train/tf2/images/tf.record\" #@param {type:\"string\"}\n",
        "train_image_dir = \"/content/drive/MyDrive/train/tf2/images\" #@param {type:\"string\"}\n",
        "global image_dir\n",
        "\n",
        "!python lepidoptera_generate_tfrecord.py --csv_input=$csv_input  --output_path=$output_path  --image_dir=$train_image_dir"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QoFPzK-4vYse"
      },
      "source": [
        "# Move tf.record for training images to train images directory\n",
        "!mv tf.record $image_dir"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UY7I79qftfQi"
      },
      "source": [
        "### Make label map for class Lepidoptera"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s3Dc0hSqmPF4"
      },
      "source": [
        "%%writefile labelmap.pbtxt\n",
        "item {\n",
        "  id: 1\n",
        "  name: 'Lepidoptera'\n",
        "}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "feGWA2fpnZOI"
      },
      "source": [
        "### Modify model config files for training Faster-RCNN and SSD with your dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tu_3bT7VnfIA"
      },
      "source": [
        "If you have errors with training, check the pipline_config_path and model_dir in the config files for R-FCN or Faster-RCNN model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "brm03Y4_undi"
      },
      "source": [
        "# Adjust model config file based on training/testing datasets\n",
        "# Modified from https://stackoverflow.com/a/63645324\n",
        "from google.protobuf import text_format\n",
        "from object_detection.protos import pipeline_pb2\n",
        "%cd $wd\n",
        "\n",
        "# TO DO: Adjust parameters  ## add form fields here\n",
        "filter = \"Lepidoptera\" #@param {type:\"string\"}\n",
        "config_basepath = \"tf_models/train_demo/\" #@param {type:\"string\"}\n",
        "label_map = 'labelmap.pbtxt'\n",
        "train_tfrecord_path = \"/content/drive/MyDrive/train/tf2/images/tf.record\" #@param {type:\"string\"}\n",
        "test_tfrecord_path = \"/content/drive/MyDrive/train/tf2/test_images/tf.record\" #@param {type:\"string\"}\n",
        "ft_ckpt_basepath = \"/content/drive/MyDrive/train/tf2/tf_models/train_demo/\" #@param {type:\"string\"}\n",
        "ft_ckpt_type = \"detection\" #@param [\"detection\", \"classification\"]\n",
        "num_classes = 1 #@param\n",
        "batch_size = 1 #@param [\"1\", \"4\", \"8\", \"16\", \"32\", \"64\", \"128\"] {type:\"raw\"}\n",
        "\n",
        "# Define pipeline for modifying model config files\n",
        "\n",
        "def read_config(model_config):\n",
        "    if 'rcnn/' in model_config:\n",
        "        model_ckpt = 'rcnn/pretrained_model/checkpoint/ckpt-0'\n",
        "    elif 'ssd/' in model_config:\n",
        "        model_ckpt = 'ssd/pretrained_model/checkpoint/ckpt-0'\n",
        "    config_fpath = config_basepath + model_config\n",
        "    pipeline = pipeline_pb2.TrainEvalPipelineConfig()                                                                                                                                                                                                          \n",
        "    with tf.io.gfile.GFile(config_fpath, \"r\") as f:                                                                                                                                                                                                                     \n",
        "        proto_str = f.read()                                                                                                                                                                                                                                          \n",
        "        text_format.Merge(proto_str, pipeline)\n",
        "    return pipeline, model_ckpt, config_fpath\n",
        "\n",
        "def modify_config(pipeline, model_ckpt, ft_ckpt_basepath):\n",
        "    finetune_checkpoint = ft_ckpt_basepath + model_ckpt\n",
        "    pipeline.model.faster_rcnn.num_classes = num_classes\n",
        "    pipeline.train_config.fine_tune_checkpoint = finetune_checkpoint\n",
        "    pipeline.train_config.fine_tune_checkpoint_type = ft_ckpt_type\n",
        "    pipeline.train_config.batch_size = batch_size\n",
        "    pipeline.train_config.use_bfloat16 = False # True only if training on TPU\n",
        "\n",
        "    pipeline.train_input_reader.label_map_path = label_map\n",
        "    pipeline.train_input_reader.tf_record_input_reader.input_path[0] = train_tfrecord_path\n",
        "\n",
        "    pipeline.eval_input_reader[0].label_map_path = label_map\n",
        "    pipeline.eval_input_reader[0].tf_record_input_reader.input_path[0] = test_tfrecord_path\n",
        "\n",
        "    return pipeline\n",
        "\n",
        "def write_config(pipeline, config_fpath):\n",
        "    config_outfpath = os.path.splitext(config_fpath)[0] + '_' + filter + '.config'\n",
        "    config_text = text_format.MessageToString(pipeline)                                                                                                                                                                                                        \n",
        "    with tf.io.gfile.GFile(config_outfpath, \"wb\") as f:                                                                                                                                                                                                                       \n",
        "        f.write(config_text)\n",
        "    \n",
        "    return config_outfpath\n",
        "\n",
        "def setup_pipeline(model_config, ft_ckpt_basepath):\n",
        "    print('\\n Modifying model config file for {}'.format(model_config))\n",
        "    pipeline, model_ckpt, config_fpath = read_config(model_config)\n",
        "    pipeline = modify_config(pipeline, model_ckpt, ft_ckpt_basepath)\n",
        "    config_outfpath = write_config(pipeline, config_fpath)\n",
        "    print(' Modifed model config file saved to {}'.format(config_outfpath))\n",
        "    if config_outfpath:\n",
        "        return \"Success!\"\n",
        "    else:\n",
        "        return \"Fail: try again\"\n",
        "\n",
        "# Modify model configs\n",
        "model_configs = ['rcnn/pretrained_model/pipeline.config', 'ssd/pretrained_model/pipeline.config']\n",
        "[setup_pipeline(model_config, ft_ckpt_basepath) for model_config in model_configs]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "naEjBRiGu-3e"
      },
      "source": [
        "## Train\n",
        "--- "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6cUfcn0kpRX2"
      },
      "source": [
        "# Determine how many train and eval steps to use based on dataset size\n",
        "\n",
        "# TO DO: Only need to update path if you didn't just run \"Model Preparation\" block above\n",
        "try: \n",
        "    train_image_dir\n",
        "except NameError:\n",
        "    train_image_dir = \"/content/drive/MyDrive/train/tf2/images\" #@param {type:\"string\"}\n",
        "examples = len(os.listdir(train_image_dir))\n",
        "print(\"Number of train examples: \\n\", examples)\n",
        "\n",
        "# Get the number of testing examples\n",
        "# TO DO: Only need to update path if you didn't just run \"Model Preparation\" block above\n",
        "try:\n",
        "    test_image_dir\n",
        "except NameError:\n",
        "    test_image_dir = \"/content/drive/MyDrive/train/tf2/test_images\" #@param {type:\"string\"}\n",
        "test_examples = len(os.listdir(test_image_dir))\n",
        "print(\"Number of test examples: \\n\", test_examples)\n",
        "\n",
        "# Get the training batch size\n",
        "# TO DO: Only need to update value if you didn't just run \"Model Preparation\" block above\n",
        "try:\n",
        "    batch_size\n",
        "except NameError:\n",
        "    batch_size = 1 #@param [\"1\", \"4\", \"8\", \"16\", \"32\", \"64\", \"128\"] {type:\"raw\"}\n",
        "print(\"Batch size: \\n\", batch_size)\n",
        "\n",
        "# Calculate roughly how many steps to use for training and testing\n",
        "steps_per_epoch = examples / batch_size\n",
        "num_eval_steps = test_examples / batch_size\n",
        "print(\"Number of steps per training epoch: \\n\", int(steps_per_epoch))\n",
        "print(\"Number of evaluation steps: \\n\", int(num_eval_steps))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vaGeNKA26Qyj"
      },
      "source": [
        "# TO DO: Choose how many epochs to train for\n",
        "epochs = 410 #@param {type:\"slider\", min:10, max:1000, step:100}\n",
        "num_train_steps = int(epochs * steps_per_epoch)\n",
        "num_eval_steps = int(num_eval_steps)\n",
        "# TO DO: Choose paths for RCNN or SSD model\n",
        "pipeline_config_path = \"tf_models/train_demo/rcnn/pretrained_model/pipeline_Lepidoptera.config\" #@param [\"tf_models/train_demo/rcnn/pretrained_model/pipeline_Lepidoptera.config\", \"tf_models/train_demo/ssd/pretrained_model/pipeline_Lepidoptera.config\"]\n",
        "model_dir = \"tf_models/train_demo/rcnn/trained\" #@param [\"tf_models/train_demo/rcnn/trained\", \"tf_models/train_demo/ssd/trained\"]\n",
        "output_directory = \"tf_models/train_demo/rcnn/finetuned_model\" #@param [\"tf_models/train_demo/rcnn/finetuned_model\", \"tf_models/train_demo/ssd/finetuned_model\"]\n",
        "trained_checkpoint_dir = \"tf_models/train_demo/rcnn/trained\" #@param [\"tf_models/train_demo/rcnn/trained\", \"tf_models/train_demo/ssd/trained\"] {allow-input: true}\n",
        "\n",
        "# Save vars to environment for access with cmd line tools below\n",
        "os.environ[\"trained_checkpoint_dir\"] = \"trained_checkpoint_dir\"\n",
        "os.environ[\"num_train_steps\"] = \"num_train_steps\"\n",
        "os.environ[\"num_eval_steps\"] = \"num_eval_steps\"\n",
        "os.environ[\"pipeline_config_path\"] = \"pipeline_config_path\"\n",
        "os.environ[\"model_dir\"] = \"model_dir\"\n",
        "os.environ[\"output_directory\"] = \"output_directory\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EufHObsuuswu"
      },
      "source": [
        "# Optional: Visualize training progress with Tensorboard\n",
        "\n",
        "# Load the TensorBoard notebook extension\n",
        "%load_ext tensorboard\n",
        "# Log training progress using TensorBoard\n",
        "%tensorboard --logdir $model_dir"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B55tKxoL5aRM"
      },
      "source": [
        "# Actual training\n",
        "# Note: You can change the number of epochs in code block below and re-run to train longer\n",
        "# Modified from https://github.com/RomRoc/objdet_train_tensorflow_colab/blob/master/objdet_custom_tf_colab.ipynb\n",
        "matplotlib.use('Agg')\n",
        "%cd $wd\n",
        "\n",
        "!python tf_models/models/research/object_detection/model_main_tf2.py \\\n",
        "    --alsologtostderr \\\n",
        "    --num_train_steps=$num_train_steps \\\n",
        "    --num_eval_steps=$num_eval_steps \\\n",
        "    --pipeline_config_path=$pipeline_config_path \\\n",
        "    --model_dir=$model_dir "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jVuMlhoq_eqY"
      },
      "source": [
        "# Export trained model\n",
        "# Modified from https://github.com/RomRoc/objdet_train_tensorflow_colab/blob/master/objdet_custom_tf_colab.ipynb\n",
        "%cd $wd\n",
        "\n",
        "# Save the model\n",
        "!python tf_models/models/research/object_detection/exporter_main_v2.py \\\n",
        "    --input_type image_tensor \\\n",
        "    --pipeline_config_path=$pipeline_config_path \\\n",
        "    --trained_checkpoint_dir=$trained_checkpoint_dir \\\n",
        "    --output_directory=$output_directory"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "roFjqjd-tVHh"
      },
      "source": [
        "# Evaluate trained model to get mAP and IoU stats for COCO 2017\n",
        "# Change pipeline_config_path and checkpoint_dir when switching between SSD and Faster-RCNN models\n",
        "matplotlib.use('Agg')\n",
        "\n",
        "!python tf_models/models/research/object_detection/model_main_tf2.py \\\n",
        "    --alsologtostderr \\\n",
        "    --model_dir=$model_dir \\\n",
        "    --pipeline_config_path=$pipeline_config_path \\\n",
        "    --checkpoint_dir=$trained_checkpoint_dir"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}