{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.8"
    },
    "colab": {
      "name": "lepidoptera_train_yolo.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "X2fF0fSxmJZR"
      ],
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/aubricot/computer_vision_with_eol_images/blob/master/object_detection_for_image_cropping/lepidoptera/lepidoptera_train_yolo.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4Rnwb_rgmJZB",
        "colab_type": "text"
      },
      "source": [
        "# Training YOLO in Darkflow to detect moths & butterflies (Lepidoptera) from EOL images\n",
        "---\n",
        "*Last Updated 16 March 2020*   \n",
        "Use images and annotation files to train YOLO in Darkflow to detect bats from EOL images.\n",
        "\n",
        "Datasets exported from [lepidoptera_preprocessing.ipynb](https://github.com/aubricot/computer_vision_with_eol_images/blob/master/object_detection_for_image_cropping/lepidoptera/lepidoptera_preprocessing.ipynb) were converted to xml formatted annotation files before use in this notebook. Images were already downloaded to Google Drive in preprocessing.ipynb. \n",
        "\n",
        "Annotations for train and test datasets will be uploaded to your Google Drive in this notebook. \n",
        "\n",
        "Exported detection results (json files) can be used to calculate model precision for comparison with Faster-RCNN and SSD models using [calculate_error_mAP.ipynb](https://github.com/aubricot/computer_vision_with_eol_images/blob/master/object_detection_for_image_cropping/calculate_error_mAP.ipynb). \n",
        "\n",
        "Notes:   \n",
        "* For each 24 hour period on Google Colab, you have up to 12 hours of GPU access. Training the object detection model on bats took 30 hours split into 3 days.\n",
        "\n",
        "* Make sure to set the runtime to Python 2 with GPU Hardware Accelerator.   \n",
        "\n",
        "References:   \n",
        "* [Official Darkflow training instructions](https://github.com/thtrieu/darkflow)   \n",
        "* [Medium Blog on training using YOLO via Darkflow in Colab](https://medium.com/coinmonks/detecting-custom-objects-in-images-video-using-yolo-with-darkflow-1ff119fa002f)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iJz5m4BKmJZD",
        "colab_type": "text"
      },
      "source": [
        "## Installs\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yWAbU5tW1ONu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Mount google drive to import/export files\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yj3-JKOsIPtc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Change to your working directory\n",
        "%cd drive/My Drive/fall19_smithsonian_informatics/train\n",
        "\n",
        "# Install libraries\n",
        "# Make sure you are using Python 3.6\n",
        "!python --version\n",
        "!pip install tensorflow-gpu==1.15.0rc2\n",
        "!pip install cython\n",
        "!pip install opencv-python"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X2fF0fSxmJZR",
        "colab_type": "text"
      },
      "source": [
        "### Model preparation uploads to Google Drive (only need to run these once)\n",
        "For detailed instructions on training YOLO using a custom dataset, see the [Darkflow GitHub Repository](https://github.com/thtrieu/darkflow)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wKYxuyq5Ib_f",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Download train and test dataset annotation files and install darkflow\n",
        "import os\n",
        "import pathlib\n",
        "import shutil \n",
        "\n",
        "# Download Lepidoptera test annotation files to test_ann\n",
        "if not os.path.exists(\"test_ann\"):\n",
        "  !mkdir test_ann\n",
        "  %cd test_ann\n",
        "  !gdown --id 1hx1W3l6ueP-dL-Uu6DdfQkJpQXUOKoUq\n",
        "  !wget -nc -i xml_for_Lepidoptera_test.txt\n",
        "  !rm -rf xml_for_Lepidoptera_test.txt\n",
        "  %cd ../\n",
        "\n",
        "# Download darkflow (the tensorflow implementation of YOLO)\n",
        "if os.path.exists(\"darkflow-master\"):\n",
        "  %cd darkflow-master/darkflow\n",
        "  !pwd\n",
        "\n",
        "elif not os.path.exists(\"darkflow-master\"):\n",
        "    !git clone --depth 1 https://github.com/thtrieu/darkflow.git\n",
        "    # Compile darkflow\n",
        "    %cd darkflow\n",
        "    !python setup.py build_ext --inplace\n",
        "    # Rename darkflow to darkflow-master to distinguish between folder names\n",
        "    shutil.move('/content/drive/My Drive/fall19_smithsonian_informatics/train/darkflow', \n",
        "              '/content/drive/My Drive/fall19_smithsonian_informatics/train/darkflow-master')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "268I2Ev_mJZL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Test installation, you should see an output with different parameters for flow\n",
        "!python flow --h"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7SXQ5bjUzA0u",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Download other needed files for training\n",
        "\n",
        "# Download Lepidoptera training annotation files to the darkflow directory\n",
        "ann_file = 'test/training/annotations/30127271.xml'\n",
        "if not os.path.isfile(\"ann_file\"):\n",
        "  %cd test/training\n",
        "  !rm -rf annotations\n",
        "  !mkdir annotations\n",
        "  !gdown --id 1QO0JpTb_1kBHq3HttxefEpJBkXqt1KBE\n",
        "  !wget -nc -i xml_for_Lepidoptera_train.txt\n",
        "  !rm -rf xml_for_Lepidoptera_train.txt\n",
        "  %cd ../../..\n",
        "\n",
        "# Upload yolo.weights, pre-trained weights file (for YOLO v2) from Google drive \n",
        "weights_file = 'bin/yolo.weights'\n",
        "if not os.path.exists('weights_file'):\n",
        "  !gdown --id 0B1tW_VtY7oniTnBYYWdqSHNGSUU\n",
        "  !mkdir bin\n",
        "  !mv yolo.weights bin\n",
        "\n",
        "# Make new label file/overwrite existing labels.txt downloaded with darkflow\n",
        "!echo \"Lepidoptera\" > labels.txt\n",
        "\n",
        "# Download model config file edited for training darkflow to identify 1 class (yolo-1c = 1 class)\n",
        "mod_config_file = 'cfg/yolo-1c.cfg'\n",
        "if not os.path.exists('mod_config_file'):\n",
        "  %cd cfg\n",
        "  !gdown --id 1bjt5Mqvf4AZSLNARgtgmZsfHZSyFj2yx\n",
        "  %cd ../"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nwKdj73Wpnlz",
        "colab_type": "text"
      },
      "source": [
        "## Imports   \n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QSLXg6G7mJZP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%cd darkflow-master\n",
        "%tensorflow_version 1.0\n",
        "\n",
        "# For importing/exporting files, working with arrays, etc\n",
        "from google.colab import files\n",
        "import os\n",
        "import pathlib\n",
        "import imageio\n",
        "import time\n",
        "import csv\n",
        "import urllib\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "# For the actual object detection\n",
        "from darkflow.net.build import TFNet\n",
        "\n",
        "# For drawing onto and plotting the images\n",
        "import matplotlib.pyplot as plt\n",
        "import cv2\n",
        "%config InlineBackend.figure_format = 'svg'\n",
        "%matplotlib inline"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w3ouL5RM-mpX",
        "colab_type": "text"
      },
      "source": [
        "## Train the model\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QnBpq-ytrAxi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# List different parameters for flow\n",
        "!python flow --h"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pn4U3HOTgPVX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Train model (yolo-1c.cfg) using pre-trained weights from basal layers of yolo.weights, the top layer will be trained from scracth to detect Lepidoptera\n",
        "# Change the dataset and annotation directories to your paths in Google Drive\n",
        "%cd darkflow-master\n",
        "!python flow --model cfg/yolo-1c.cfg --train --trainer adam --load bin/yolo.weights --gpu 0.8 --epoch 38 --dataset \"/content/drive/My Drive/fall19_smithsonian_informatics/train/images\" --annotation \"test/training/annotations\" --savepb"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LZoKtS-xhbQm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Resume training from last checkpoint\n",
        "!python flow --load -1 --model cfg/yolo-1c.cfg --train --savepb --trainer adam --gpu 0.8 --epoch 3000 --dataset \"/content/drive/My Drive/fall19_smithsonian_informatics/train/images\" --annotation \"test/training/annotations\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UqA_lW7tbLeH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Save the last checkpoint to protobuf file\n",
        "!python flow --model cfg/yolo-1c.cfg --load -1 --savepb"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0IZw-HlWrVxn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Resume training from protobuf file\n",
        "!python flow --load -1 --pbLoad built_graph/yolo-1c.pb --metaLoad built_graph/yolo-1c.meta --train --savepb --trainer adam --gpu 0.8 --epoch 3000 --dataset \"/content/drive/My Drive/fall19_smithsonian_informatics/train/images\" --annotation \"test/training/annotations\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sLGOQiwSr-Gd",
        "colab_type": "text"
      },
      "source": [
        "### When finished training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5GhWXLLlPNrr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Export detection results for test images as json files to calculate mAP (mean average precision, a performance measure to compare models) using calculate_error_mAP.ipynb\n",
        "!python flow --pbLoad built_graph/yolo-1c.pb --gpu 0.8 --metaLoad built_graph/yolo-1c.meta --imgdir \"/content/drive/My Drive/fall19_smithsonian_informatics/train/test_images\" --json"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "1zL-PctVuqZv"
      },
      "source": [
        "## Run test images through the trained object detector & don't save results\n",
        "---\n",
        "Test image detection boxes are only needed for calculating mAP (mean average precision, a performance measure to compare models) and not for cropping. The functions below will only display resulting detection boxes on test images for visualization, but does not save their coordinates to a spreadsheet. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gy3lSNqWOjq0",
        "colab_type": "text"
      },
      "source": [
        "### Prepare object detection functions and settings"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2PXMk2Rtsnk-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# For loading images into computer-readable format\n",
        "def load_image_into_numpy_array(image):\n",
        "  (im_width, im_height) = image.size\n",
        "  return np.array(image.getdata()).reshape((im_height, im_width, 3)).astype(np.uint8)\n",
        "\n",
        "# Function for loading images from urls\n",
        "def url_to_image(url):\n",
        "  resp = urllib.request.urlopen(url)\n",
        "  image = np.asarray(bytearray(resp.read()), dtype=\"uint8\")\n",
        "  image = cv2.imdecode(image, cv2.IMREAD_COLOR)\n",
        "  image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "  return image\n",
        "\n",
        "# For drawing bounding boxes around detected objects on images\n",
        "def boxing(image, predictions):\n",
        "    newImage = np.copy(image)\n",
        "    im_height, im_width, im_depth = image.shape\n",
        "\n",
        "    # Organize results of object detection for plotting and export\n",
        "    for result in predictions:\n",
        "        xmin = result['topleft']['x']\n",
        "        ymin = result['topleft']['y']\n",
        "\n",
        "        xmax = result['bottomright']['x']\n",
        "        ymax = result['bottomright']['y']\n",
        "\n",
        "        confidence = result['confidence']\n",
        "        label = result['label'] + \" \" + str(round(confidence, 3))\n",
        "\n",
        "        # Only show boxes that are above set confidence and for the label Chiroptera\n",
        "        # Optional: change confidence and label values\n",
        "        if confidence > 0 and result['label'] == 'Lepidoptera' :\n",
        "            # Draw boxes on images\n",
        "            fontScale = min(im_width,im_height)/(600)\n",
        "            newImage = cv2.rectangle(newImage, (xmin, ymax), (xmax, ymin), (255, 0, 157), 3)\n",
        "            newImage = cv2.putText(newImage, label, (xmin, ymax-5), cv2.FONT_HERSHEY_SIMPLEX, fontScale, (153, 255, 255), 5, cv2.LINE_AA)\n",
        "    return newImage\n",
        "\n",
        "# Define parameters for \"flow\"ing the images through the model\n",
        "# Optional: adjust detection confidence threshold\n",
        "params = {\n",
        "    'model': 'cfg/yolo-1c.cfg',\n",
        "    'load': 'bin/yolo.weights',\n",
        "    'gpu': 0.8,\n",
        "    #'threshold': 0.1, \n",
        "    'pbLoad': 'built_graph/yolo-1c.pb', \n",
        "    'metaLoad': 'built_graph/yolo-1c.meta' \n",
        "}\n",
        "\n",
        "# Run the model\n",
        "tfnet = TFNet(params)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NxI1a4iRSNQU",
        "colab_type": "text"
      },
      "source": [
        "### Run test images (from file) through object detector"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": false,
        "id": "UbyA9e1omJZZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Test trained model on test images\n",
        "from PIL import Image\n",
        "\n",
        "# Update path to your test images\n",
        "PATH_TO_TEST_IMAGES_DIR = '/content/drive/My Drive/fall19_smithsonian_informatics/train/test_images'\n",
        "PATH_TO_OUT_IMAGES_DIR = '/content/drive/My Drive/fall19_smithsonian_informatics/train/test_images/out_yolo/'\n",
        "names = os.listdir(PATH_TO_TEST_IMAGES_DIR)\n",
        "TEST_IMAGE_PATHS = [os.path.join(PATH_TO_TEST_IMAGES_DIR, name) for name in names]\n",
        "OUT_IMAGE_PATHS = [os.path.join(PATH_TO_OUT_IMAGES_DIR, name) for name in names]\n",
        "\n",
        "# Loops through first 5 image urls from the text file\n",
        "for im_num, im_path in enumerate(TEST_IMAGE_PATHS[:50], start=1):\n",
        "\n",
        "    # Load in image\n",
        "    image = Image.open(im_path)\n",
        "    image_np = load_image_into_numpy_array(image)\n",
        "    # Record inference time\n",
        "    start_time = time.time()\n",
        "    # Detection\n",
        "    result = tfnet.return_predict(image_np)\n",
        "    end_time = time.time()\n",
        "    # Draw boxes on image\n",
        "    boxing(image_np, result)\n",
        "    # Display progress message after each image\n",
        "    print('Detection complete in {} of 145 test images'.format(im_num))\n",
        "\n",
        "    # Plot and show detection boxes on images\n",
        "    # If running detection on >50 images, comment out this portion\n",
        "    _, ax = plt.subplots(figsize=(10, 10))\n",
        "    ax.imshow(boxing(image_np, result))\n",
        "    plt.title('{}) Inference time: {}'.format(im_num, format(end_time-start_time, '.2f')))\n",
        "\n",
        "    # Optional: Save image with detection boxes to Google Drive\n",
        "    #img = Image.fromarray(boxing(image_np, result))\n",
        "    #img.save(OUT_IMAGE_PATHS[im_num-1])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xjDSAbX4L4kg",
        "colab_type": "text"
      },
      "source": [
        "### Get inference info for test images to compare object detection model times for YOLO, SSD, and Faster-RCNN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cfcie12ULym-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from PIL import Image\n",
        "\n",
        "# For exporting inference times\n",
        "inf_time = []\n",
        "img_path = []\n",
        "im_dims = []\n",
        "\n",
        "# Update path to your test images\n",
        "PATH_TO_TEST_IMAGES_DIR = '/content/drive/My Drive/fall19_smithsonian_informatics/train/test_images'\n",
        "names = os.listdir(PATH_TO_TEST_IMAGES_DIR)\n",
        "TEST_IMAGE_PATHS = [os.path.join(PATH_TO_TEST_IMAGES_DIR, name) for name in names]\n",
        "\n",
        "# Loops through first 5 image urls from the text file\n",
        "#for im_num, im_path in enumerate(TEST_IMAGE_PATHS[:5], start=1):\n",
        "for im_num, im_path in enumerate(TEST_IMAGE_PATHS, start=1):\n",
        "\n",
        "    # Load in image\n",
        "    image = Image.open(im_path)\n",
        "    image_np = load_image_into_numpy_array(image)\n",
        "    # Record inference time\n",
        "    start_time = time.time()\n",
        "    # Detection\n",
        "    result = tfnet.return_predict(image_np)\n",
        "    end_time = time.time()\n",
        "    # Draw boxes on image\n",
        "    boxing(image_np, result)\n",
        "    # Display progress message after each image\n",
        "    print('Detection complete in {} of 148 test images'.format(im_num))\n",
        "\n",
        "    # Record inference time, image name and image dimensions to export\n",
        "    inf_time.append(end_time-start_time)\n",
        "    img_path.append(im_path)\n",
        "    im_dims.append(image_np.shape)\n",
        "    \n",
        "inf_times = pd.DataFrame((inf_time, img_path, im_dims))\n",
        "inf_times = inf_times.transpose()\n",
        "inf_times.to_csv(\"lepidoptera_inference_times_yolo.csv\", index=False, header=(\"time (sec)\", \"filepath\", \"image_dims (h, w, d)\")\n",
        "print(inf_times.head())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ErD78FKVr0sc",
        "colab_type": "text"
      },
      "source": [
        "### Run other images (from individual URLs) through object detector"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "szb8S54dr5Qy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Test trained model on images\n",
        "from PIL import Image\n",
        "\n",
        "# Use individual URLs (use your own here)\n",
        "image_urls = [\"https://upload.wikimedia.org/wikipedia/commons/b/be/Batman_%28retouched%29.jpg\",\n",
        "              \"https://upload.wikimedia.org/wikipedia/commons/thumb/9/90/Bela_Lugosi_as_Dracula%2C_anonymous_photograph_from_1931%2C_Universal_Studios.jpg/690px-Bela_Lugosi_as_Dracula%2C_anonymous_photograph_from_1931%2C_Universal_Studios.jpg\"]\n",
        "\n",
        "# Loops through image_urls\n",
        "for im_num, image_url in enumerate(image_urls, start=1):\n",
        "  try:\n",
        "    # Load in image\n",
        "    image_np = url_to_image(image_url)\n",
        "    # Record inference time\n",
        "    start_time = time.time()\n",
        "    # Detection\n",
        "    result = tfnet.return_predict(image_np)\n",
        "    end_time = time.time()\n",
        "    # Draw boxes on image\n",
        "    boxing(image_np, result)\n",
        "    # Display progress message after each image\n",
        "    print('Detection complete in {} of 2 test images'.format(im_num))\n",
        "\n",
        "    # Plot and show detection boxes on images\n",
        "    # If running detection on >50 images, comment out this portion\n",
        "    _, ax = plt.subplots(figsize=(10, 10))\n",
        "    ax.imshow(boxing(image_np, result))\n",
        "    plt.title('{}) Inference time: {}'.format(im_num, format(end_time-start_time, '.2f')))\n",
        "\n",
        "  except:\n",
        "    print('Check if URL from {} is valid'.format(image_url))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AV08UMa0wjd0",
        "colab_type": "text"
      },
      "source": [
        "## Run EOL image bundles through the trained object detector & save results for cropping\n",
        "---\n",
        "Display resulting detection boxes on images and save their coordinates to lepidoptera_det_crops_yolo.tsv for use cropping EOL images."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a0SGWtlJxEYa",
        "colab_type": "text"
      },
      "source": [
        "### Prepare object detection functions and settings"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "0INfzqLNw-_D",
        "colab": {}
      },
      "source": [
        "# For loading images into computer-readable format\n",
        "def load_image_into_numpy_array(image):\n",
        "  (im_width, im_height) = image.size\n",
        "  return np.array(image.getdata()).reshape((im_height, im_width, 3)).astype(np.uint8)\n",
        "\n",
        "# Function for loading images from urls\n",
        "def url_to_image(url):\n",
        "  resp = urllib.request.urlopen(url)\n",
        "  image = np.asarray(bytearray(resp.read()), dtype=\"uint8\")\n",
        "  image = cv2.imdecode(image, cv2.IMREAD_COLOR)\n",
        "  image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "  return image\n",
        "\n",
        "# For drawing bounding boxes around detected objects on images\n",
        "def boxing(image, predictions):\n",
        "    newImage = np.copy(image)\n",
        "    im_height, im_width, im_depth = image.shape\n",
        "\n",
        "    # Organize results of object detection for plotting and export\n",
        "    for result in predictions:\n",
        "        xmin = result['topleft']['x']\n",
        "        ymin = result['topleft']['y']\n",
        "\n",
        "        xmax = result['bottomright']['x']\n",
        "        ymax = result['bottomright']['y']\n",
        "\n",
        "        confidence = result['confidence']\n",
        "        label = result['label'] + \" \" + str(round(confidence, 3))\n",
        "\n",
        "        # Only show boxes that are above set confidence and for the label Chiroptera\n",
        "        if confidence > 0 and result['label'] == 'Lepidoptera' :\n",
        "            # Draw boxes on images\n",
        "            fontScale = min(im_width,im_height)/(600)\n",
        "            newImage = cv2.rectangle(newImage, (xmin, ymax), (xmax, ymin), (255, 0, 157), 3)\n",
        "            newImage = cv2.putText(newImage, label, (xmin, ymax-5), cv2.FONT_HERSHEY_SIMPLEX, fontScale, (153, 255, 255), 5, cv2.LINE_AA)\n",
        "\n",
        "            # Export detection results to det_crops_yolo.tsv\n",
        "            # Change filename here if using 1000 or 20000 images dataset\n",
        "            with open('/content/drive/My Drive/fall19_smithsonian_informatics/lepidoptera_det_crops_1000.tsv', 'a') as out_file:\n",
        "                  tsv_writer = csv.writer(out_file, delimiter='\\t')\n",
        "                  tsv_writer.writerow([image_url, im_height, im_width, \n",
        "                            xmin, ymin, xmax, ymax])\n",
        "\n",
        "    return newImage\n",
        "\n",
        "# Define parameters for \"flow\"ing the images through the model\n",
        "# Optional: adjust detection confidence threshold\n",
        "params = {\n",
        "    'model': 'cfg/yolo-1c.cfg',\n",
        "    'load': 'bin/yolo.weights',\n",
        "    'gpu': 0.8,\n",
        "    #'threshold': 0.1, \n",
        "    'pbLoad': 'built_graph/yolo-1c.pb', \n",
        "    'metaLoad': 'built_graph/yolo-1c.meta' \n",
        "}\n",
        "\n",
        "# Run the model\n",
        "tfnet = TFNet(params)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aYMwPPLZvpqW",
        "colab_type": "text"
      },
      "source": [
        "### Run images (from EOL image URL bundles) through object detector"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sr6szvqZtno0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Use URLs from EOL image URL bundles\n",
        "# Comment out to use either 1000 or 20000 image bundles\n",
        "# 1000 Lepidoptera images\n",
        "urls = 'https://editors.eol.org/other_files/bundle_images/files/images_for_Lepidoptera_breakdown_download_000001.txt'\n",
        "# 20000 Lepidoptera images\n",
        "#urls = 'https://editors.eol.org/other_files/bundle_images/files/images_for_Lepidoptera_20K_breakdown_download_000001.txt'\n",
        "\n",
        "df = pd.read_csv(urls)\n",
        "df.columns = [\"link\"]\n",
        "pd.DataFrame.head(df)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KVA5olgfwZl8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Write header row of output crops file\n",
        "# For 1000 or 20000 image datasets, change filename here and in \"Prepare object detection functions and settings -> def boxing -> Export detection results\" above\n",
        "with open('/content/drive/My Drive/fall19_smithsonian_informatics/train/lepidoptera_det_crops_1000.tsv', 'a') as out_file:\n",
        "                  tsv_writer = csv.writer(out_file, delimiter='\\t')\n",
        "                  tsv_writer.writerow([\"image_url\", \"im_height\", \"im_width\", \n",
        "                            \"xmin\", \"ymin\", \"xmax\", \"ymax\"])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yyVGNtubzGlw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Set number of seconds to timeout if image url taking too long to open\n",
        "import socket\n",
        "socket.setdefaulttimeout(10)\n",
        "\n",
        "# Loops through first 5 image urls from the text file\n",
        "for i, row in df.head(5).itertuples(index=True, name='Pandas'):\n",
        "\n",
        "# For ranges of rows or all rows, use df.iloc\n",
        "# Can be useful if running detection in batches\n",
        "#for i, row in df.iloc[500:800].iterrows():\n",
        "\n",
        "  try:\n",
        "    # Record inference time\n",
        "    start_time = time.time()\n",
        "    # Load in image\n",
        "    image_url = df1.get_value(i, \"link\")\n",
        "    image = url_to_image(image_url)\n",
        "    # Detection\n",
        "    result = tfnet.return_predict(image)\n",
        "    end_time = time.time()\n",
        "    # Draw boxes on image\n",
        "    boxing(image, result)\n",
        "    # Display progress message after each image\n",
        "    print('Detection complete in {} of 1000 test images'.format(im_num))\n",
        "\n",
        "    # Plot and show detection boxes on images\n",
        "    # If running detection on >50 images, comment out this portion\n",
        "    _, ax = plt.subplots(figsize=(10, 10))\n",
        "    ax.imshow(boxing(image, result))\n",
        "    plt.title('{}) Inference time: {}'.format(i+1, format(end_time-start_time, '.2f')))\n",
        "\n",
        "  except:\n",
        "    print('Check if URL from {} is valid'.format(image_url))"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}