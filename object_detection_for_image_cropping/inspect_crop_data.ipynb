{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "inspect_crop_data.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNa+Bt+V0B5Y1fCFHTbixpF",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/aubricot/computer_vision_with_eol_images/blob/master/object_detection_for_image_cropping/inspect_crop_data.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZQJxZL3XYo9c"
      },
      "source": [
        "# Inspect EOL user-generated cropping coordinates file\n",
        "---\n",
        "*Last Updated 1 June 2021*   \n",
        "The file contains user-determined \"best\" square cropping coordinates for ~20,000 images from many taxonomic groups. Inspect what is available for building new pipelines."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7eMHtuf0ZATU"
      },
      "source": [
        "## Installs & Imports\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LN05MWg6Y-TK"
      },
      "source": [
        "# Optional: Mount google drive to import/export files\n",
        "# Note: You can also run these steps in a Colab runtime that gets cleared after each session\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yhrKmGSXZPWp"
      },
      "source": [
        "import os\n",
        "import csv\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "# So URL's don't get truncated & show all cols in display\n",
        "pd.set_option('display.max_colwidth',1000)\n",
        "pd.set_option('display.max_columns', None)\n",
        "\n",
        "# Optional: If using mounted drive, set working directory\n",
        "if os.path.isdir('/content/drive'):\n",
        "    # TO DO: Type in the path to your working directory in form field to right\n",
        "    wd = \"/content/drive/MyDrive/train/tf2\" #@param {type:\"string\"}\n",
        "    %cd $wd"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4Li3aQ9jZPt5"
      },
      "source": [
        "## Get EOL user-generated cropping file\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FRWVi1juYNpx"
      },
      "source": [
        "# Download EOL user generated cropping data\n",
        "\n",
        "# Download EOL user generated cropping file to temporary runtime location\n",
        "#!wget --user-agent=\"Mozilla\" https://editors.eol.org/other_files/EOL_v2_files/image_crops_withEOL_pk.txt.zip\n",
        "\n",
        "# Unzip cropping file to your working directory\n",
        "#!unzip /content/image_crops_withEOL_pk.txt.zip -d .\n",
        "\n",
        "# Read file into runtime\n",
        "df = pd.read_csv('image_crops_withEOL_pk.txt', sep='\\t', header=0)\n",
        "print(\"EOL user-generated cropping data: \\nNumber of available cropping coordinates: {} \\n\\n {}\".format(len(df), df.head()))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T3XaGPOAabNB"
      },
      "source": [
        "## Inspect available taxa from EOL user-generated cropping file\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JCM7NLQAcbyn"
      },
      "source": [
        "# Define functions\n",
        "\n",
        "# Tidy special characters from crops ancestry column\n",
        "def tidy_chars(df):\n",
        "    df.ancestry.replace(to_replace=['{', '}', '\\(', '\\)'], value= '', regex=True, inplace=True)\n",
        "    df.ancestry.replace(to_replace=[\"'\", '\"'], value= '', regex=True, inplace=True)\n",
        "    df.ancestry.replace('{', '', regex=True, inplace=True)\n",
        "    df.ancestry.replace(to_replace='name:', value='', regex=True, inplace=True)\n",
        "    print(\"Tidied ancestry column: \\n\", df.head())\n",
        "    \n",
        "    return df\n",
        "\n",
        "# Split ancestry column into taxonomic groups\n",
        "def split_by_ancestry(df, disp_results=False):\n",
        "    split = pd.DataFrame(df.ancestry.str.split(\",\", expand=True).stack(), columns=['a'])\n",
        "\n",
        "    # Class (but not subclass, superclass or infraclass)\n",
        "    cla = split.a[(split.a.str.contains('class', case=False)==True) & (split.a.str.contains('sub', case=False)==False)\n",
        "          & (split.a.str.contains('super', case=False)==False) & (split.a.str.contains('infra', case=False)==False)]\n",
        "    cla.replace('class:', '', regex=True, inplace=True)\n",
        "    cla = cla.str.split(\" \", expand=True)[0]\n",
        "    if disp_results:\n",
        "        print(\"\\nSplit by Class: \\n\", cla)\n",
        "\n",
        "    # Order (but not suborder, infraorder or superorder)\n",
        "    ord = split.a[(split.a.str.contains('order', case=False)==True) & (split.a.str.contains('sub', case=False)==False)\n",
        "          & (split.a.str.contains('infra', case=False)==False) & (split.a.str.contains('super', case=False)==False)]\n",
        "    ord.replace('order:', '', regex=True, inplace=True)\n",
        "    ord = ord.str.split(\" \", expand=True)[0]\n",
        "    if disp_results:\n",
        "        print(\"\\nSplit by Order: \\n\", ord)\n",
        "\n",
        "    # Family (but not superfamily or subfamily)\n",
        "    fam = split.a[(split.a.str.contains('family', case=False)==True) & (split.a.str.contains('super', case=False)==False)\n",
        "          & (split.a.str.contains('sub', case=False)==False)]\n",
        "    fam.replace('family:', '', regex=True, inplace=True)\n",
        "    fam = fam.str.split(\" \", expand=True)[0]\n",
        "    if disp_results:\n",
        "        print(\"\\nSplit by Family: \\n\", fam)\n",
        "\n",
        "    # Genus\n",
        "    gen = split.a[split.a.str.contains('genus', case=False)==True]\n",
        "    gen.replace('genus:', '', regex=True, inplace=True)\n",
        "    gen = gen.str.split(\" \", expand=True)[0]\n",
        "    if disp_results:\n",
        "        print(\"\\nSplit by Genus: \\n\", gen)\n",
        "\n",
        "    return cla, ord, fam, gen\n",
        "\n",
        "# Get frequency counts for available taxonomic groups\n",
        "def count_frequency(cla, ord, fam, gen, disp_results=False):\n",
        "    # Combine all taxa\n",
        "    all_taxa = pd.concat((cla, ord, fam, gen), axis=0, ignore_index=True)\n",
        "    #print(all_taxa.head())\n",
        "    # Count frequency for all taxa\n",
        "    all_ct = pd.DataFrame(all_taxa.value_counts()).reset_index()\n",
        "    # Sort by decreasing frequency\n",
        "    all_ct.columns = [\"taxon\", \"freq\"]\n",
        "    all_ct.sort_values(by=\"freq\", axis=0, ascending=False, inplace=True)\n",
        "\n",
        "    # Class only\n",
        "    cla_ct = pd.DataFrame(cla.value_counts()).reset_index()\n",
        "    # Sort by decreasing frequency\n",
        "    cla_ct.columns = [\"taxon\", \"freq\"]\n",
        "    cla_ct.sort_values(by=\"freq\", axis=0, ascending=False, inplace=True)\n",
        "    if disp_results:\n",
        "        print(\"\\nTop 10 most frequent Classes: \\n\", cla_ct[:10])\n",
        "  \n",
        "    # Order only\n",
        "    ord_ct = pd.DataFrame(ord.value_counts()).reset_index()\n",
        "    # Sort by decreasing frequency\n",
        "    ord_ct.columns = [\"taxon\", \"freq\"]\n",
        "    ord_ct.sort_values(by=\"freq\", axis=0, ascending=False, inplace=True)\n",
        "    if disp_results:\n",
        "        print(\"\\nTop 10 most frequent Orders: \\n\", ord_ct[:10])\n",
        "\n",
        "    # Family only\n",
        "    fam_ct = pd.DataFrame(fam.value_counts()).reset_index()\n",
        "    # Sort by decreasing frequency\n",
        "    fam_ct.columns = [\"taxon\", \"freq\"]\n",
        "    fam_ct.sort_values(by=\"freq\", axis=0, ascending=False, inplace=True)\n",
        "    if disp_results:\n",
        "        print(\"\\nTop 10 most frequent Families: \\n\", fam_ct[:10])\n",
        "\n",
        "    # Genus only\n",
        "    gen_ct = pd.DataFrame(gen.value_counts()).reset_index()\n",
        "    # Sort by decreasing frequency\n",
        "    gen_ct.columns = [\"taxon\", \"freq\"]\n",
        "    gen_ct.sort_values(by=\"freq\", axis=0, ascending=False, inplace=True)\n",
        "    if disp_results:\n",
        "        print(\"\\nTop 10 most frequent Genera: \\n\", gen_ct[:10])\n",
        "\n",
        "    return cla_ct, ord_ct, fam_ct, gen_ct"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VoAND7PNdDlV"
      },
      "source": [
        "# Make new dataframe from ancestry column, see ex entry below\n",
        "crops = df[['ancestry']].copy()\n",
        "print(\"Sample ancestry entry to be tidied & split: \\n\", crops.head(1))\n",
        "\n",
        "# Tidy special characters from ancestry column\n",
        "ancestry = tidy_chars(crops)\n",
        "\n",
        "# Split ancestry column into taxonomic groups\n",
        "cla, ord, fam, gen = split_by_ancestry(ancestry, disp_results=False)\n",
        "\n",
        "# Get frequency counts for available taxonomic groups\n",
        "cla_ct, ord_ct, fam_ct, gen_ct = count_frequency(cla, ord, fam, gen, disp_results=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IgRWlcU3ge5W"
      },
      "source": [
        "# Optional: Save frequency counts to file\n",
        "\n",
        "# Class\n",
        "outfpath = \"EOL_cropcoords_freqcounts_order.tsv\" #@param {type:\"string\"}\n",
        "cla_ct.to_csv(outfpath, sep = '\\t', index=False, header=True)\n",
        "\n",
        "# Order\n",
        "outfpath = \"EOL_cropcoords_freqcounts_order.tsv\" #@param {type:\"string\"}\n",
        "ord_ct.to_csv(outfpath, sep = '\\t', index=False, header=True)\n",
        "\n",
        "# Family\n",
        "outfpath = \"EOL_cropcoords_freqcounts_family.tsv\" #@param {type:\"string\"}\n",
        "fam_ct.to_csv(outfpath, sep = '\\t', index=False, header=True)\n",
        "\n",
        "# Genus \n",
        "outfpath = \"EOL_cropcoords_freqcounts_genus.tsv\" #@param {type:\"string\"}\n",
        "gen_ct.to_csv(outfpath, sep = '\\t', index=False, header=True)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}