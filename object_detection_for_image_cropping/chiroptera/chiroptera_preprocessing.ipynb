{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.8"
    },
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/aubricot/computer_vision_with_eol_images/blob/master/object_detection_for_image_cropping/chiroptera/chiroptera_preprocessing.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4Rnwb_rgmJZB"
      },
      "source": [
        "# Pre-processing and image augmentation for object detection model training and testing datasets\n",
        "---\n",
        "*Last Updated 21 Aug 2025*   \n",
        "\n",
        "An [EOL user generated cropping dataset](https://editors.eol.org/other_files/EOL_v2_files/image_crops_withEOL_pk.txt.zip) is pre-processed and transformed to formatting standards for use with YOLO via Darkflow and SSD and Faster-RCNN object detection models implemented in Tensorflow. All train and test images are also downloaded to Google Drive for use training and testing.\n",
        "\n",
        "Before reformatting to object detection model standards, training data is augmented using the [imgaug library](https://github.com/aleju/imgaug). Image augmentation is used to increase training data sample size and diversity to reduce overfitting when training object detection models. Both images and cropping coordinates are augmented. Augmented and original training datasets are then combined before being transformed to object detection model formatting standards.\n",
        "\n",
        "Notes:   \n",
        "* Run code blocks by pressing play button in brackets on left\n",
        "* Before you you start: change the runtime to \"GPU\" with \"High RAM\"\n",
        "* Change parameters using form fields on right (find details at corresponding lines of code by searching '#@param')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iJz5m4BKmJZD"
      },
      "source": [
        "## Installs & Imports\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Choose where to save results & set up directory structure\n",
        "import os\n",
        "\n",
        "# Use dropdown menu on right\n",
        "save = \"in Colab runtime (files deleted after each session)\" #@param [\"in my Google Drive\", \"in Colab runtime (files deleted after each session)\"]\n",
        "print(\"Saving results \", save)\n",
        "\n",
        "# Mount google drive to export image cropping coordinate file(s)\n",
        "if 'Google Drive' in save:\n",
        "    from google.colab import drive\n",
        "    drive.mount('/content/drive', force_remount=True)\n",
        "\n",
        "# Enter taxon of interest in form field\n",
        "taxon = \"Chiroptera\" #@param [\"Chiroptera\"] {allow-input: true}\n",
        "\n",
        "# Type in the path to your working directory in form field to right\n",
        "basewd = \"/content/drive/MyDrive/train/tf2\" #@param [\"/content/drive/MyDrive/train/tf2\"] {allow-input: true}\n",
        "basewd = basewd + '/' + taxon\n",
        "\n",
        "# Folder where preprocessing outputs will be saved\n",
        "folder = \"pre-processing\" # @param [\"pre-processing\",\"inspect_resul\",\"results\"] {\"allow-input\":true}\n",
        "cwd = basewd + '/' + folder\n",
        "\n",
        "# Folder where train images will be saved\n",
        "train_folder = \"images\" #@param [\"images\"] {allow-input: true}\n",
        "train_wd = cwd + '/' + train_folder\n",
        "\n",
        "# Folder where test images will be saved\n",
        "test_folder = \"test_images\" #@param [\"test_images\"] {allow-input: true}\n",
        "test_wd = cwd + '/' + test_folder\n",
        "\n",
        "# Download helper_funcs folder\n",
        "!pip3 -q install --upgrade gdown\n",
        "!gdown 1xmkrYEJKLJvei9q4zulKfqsGTgDvfvpR\n",
        "!tar -xzvf helper_funcs.tar.gz -C .\n",
        "\n",
        "# Install requirements.txt\n",
        "!pip3 -q install -r requirements.txt\n",
        "\n",
        "# Set up directory structure\n",
        "from setup import setup_dirs\n",
        "\n",
        "# Set up directory structure\n",
        "setup_dirs(cwd, train_wd, test_wd)\n",
        "print(\"\\nWorking directory set to: \\n\", cwd)\n",
        "print(\"\\nTraining images directory set to: \\n\", train_wd)\n",
        "print(\"\\nTesting images directory set to: \\n\", test_wd)"
      ],
      "metadata": {
        "id": "brbNoVuG3cAZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QSLXg6G7mJZP"
      },
      "source": [
        "#@title Install libraries\n",
        "\n",
        "# For augmenting and displaying images\n",
        "!pip install imaug\n",
        "!pip install pillow\n",
        "import imgaug as ia\n",
        "import imgaug.augmenters as iaa\n",
        "from imgaug.augmentables.bbs import BoundingBox, BoundingBoxesOnImage\n",
        "\n",
        "# For importing/exporting files, working with arrays, etc\n",
        "import pathlib\n",
        "import os\n",
        "import imageio\n",
        "import time\n",
        "import csv\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from urllib.request import urlopen\n",
        "from imageio import imread\n",
        "from PIL import Image\n",
        "\n",
        "# Set number of seconds to timeout if image url taking too long to open\n",
        "import socket\n",
        "socket.setdefaulttimeout(10)\n",
        "\n",
        "# For drawing onto and plotting the images\n",
        "import matplotlib.pyplot as plt\n",
        "import cv2\n",
        "%config InlineBackend.figure_format = 'svg'\n",
        "%matplotlib inline\n",
        "\n",
        "# So URL's don't get truncated & show all cols in display\n",
        "pd.set_option('display.max_colwidth',1000)\n",
        "pd.set_option('display.max_columns', None)\n",
        "\n",
        "# Define functions\n",
        "from wrangle_data import *"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nwKdj73Wpnlz"
      },
      "source": [
        "## Build train and test datasets from EOL user-generated cropping data\n",
        "---\n",
        "Full cropping dataset is available [here](https://editors.eol.org/other_files/EOL_v2_files/image_crops_withEOL_pk.txt.zip)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vNHjFdVr4Dfc"
      },
      "source": [
        "#@title Filter EOL cropping coordinates for taxon of interest and reformat to Pascal VOC Annotation Style\n",
        "\n",
        "# Download EOL user generated cropping file to temporary runtime location\n",
        "print(\"Downloading EOL user-generated cropping dataset...\\n\")\n",
        "!wget --user-agent=\"Mozilla\" https://editors.eol.org/other_files/EOL_v2_files/image_crops_withEOL_pk.txt.zip\n",
        "\n",
        "# Unzip cropping file to your working directory\n",
        "!unzip /content/image_crops_withEOL_pk.txt.zip -d $basewd\n",
        "\n",
        "# Change to your training directory within Google Drive\n",
        "%cd $basewd\n",
        "!mv image_crops_withEOL_pk.txt $cwd\n",
        "%cd $cwd\n",
        "\n",
        "# Read in user-generated image cropping file\n",
        "fpath = cwd + '/image_crops_withEOL_pk.txt'\n",
        "df = read_datafile(fpath, disp_head=False)\n",
        "\n",
        "# Reformat cropping dimensions\n",
        "reformatted = reformat_crops(df, disp_head=True)\n",
        "\n",
        "# Filter by taxon of interest (Chiroptera)\n",
        "filter = taxon # defined in first code block\n",
        "filtered = filter_by_taxon(reformatted, taxon, disp_head=False)\n",
        "\n",
        "# Export Chiroptera crops as tsv\n",
        "outfpath = filter + '_crops.tsv'\n",
        "filtered.to_csv(outfpath, sep='\\t', index=False)\n",
        "print(\"\\nCropping data filtered by taxon {} being saved to: \\n{}\\n\".format(filter, outfpath))\n",
        "\n",
        "# Split into train (80%) and test (20%) datasets\n",
        "train, test = split_train_test(filtered, outfpath, 0.8, disp_head=False)\n",
        "print(\"\\nCropping data split into 80% train - 20% test\\n\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1lMvu5M0oUrY"
      },
      "source": [
        "## Pre-process train dataset\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Set up cropping file export parameters\n",
        "%cd $cwd\n",
        "\n",
        "# Folder where train images will be saved (defined in first code block)\n",
        "folder = train_folder\n",
        "\n",
        "# Write header of crops_aug.tsv before looping through crops for remaining data\n",
        "outfpath = cwd + '/' + filter + '_crops_train_aug.tsv'\n",
        "print(\"\\nAugmented cropping data being saved to: \\n{}\\n\".format(outfpath))\n",
        "if not os.path.isfile(outfpath): # Prevents writing duplicate header rows\n",
        "    with open(outfpath, 'a') as out_file:\n",
        "        tsv_writer = csv.writer(out_file, delimiter='\\t')\n",
        "        tsv_writer.writerow([\"data_object_id\",\t\"obj_url\",\t\"im_height\",\t\"im_width\",\t\"xmin\",\n",
        "                                \"ymin\",\t\"xmax\",\t\"ymax\",\t\"filename\",\t\"path\",\t\"class\"])"
      ],
      "metadata": {
        "id": "DXWQjiZu7YW1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P31JjHddVSEm"
      },
      "source": [
        "#@title Augment training images & save them to Google Drive\n",
        "\n",
        "# Read in EOL user generated cropping data\n",
        "fpath = filter + \"_crops_train.tsv\"\n",
        "crops = read_datafile(fpath, disp_head=False)\n",
        "\n",
        "# Test pipeline with a smaller subset than 5k images?\n",
        "run = \"test with tiny subset\" #@param [\"test with tiny subset\", \"for all images\"]\n",
        "\n",
        "# Display detection results on images\n",
        "display_results = True #@param {type:\"boolean\"}\n",
        "\n",
        "# Download images, augment them, and save to Google Drive\n",
        "print(\"Downloading and augmenting training images\")\n",
        "start, stop = set_start_stop(run, crops)\n",
        "for i, row in enumerate(crops.iloc[start:stop].iterrows()):\n",
        "    try:\n",
        "        # Load image from url\n",
        "        url = crops[\"obj_url\"][i]\n",
        "        image = imread(url, mode='RGB')\n",
        "\n",
        "        # Augment the image and bounding box\n",
        "        image_aug, fpath_aug = augment_image_w_bboxes(image, crops, i, filter, folder, cwd, display_results)\n",
        "\n",
        "        # Save image to Google Drive\n",
        "        imageio.imwrite(fpath_aug, image_aug)\n",
        "\n",
        "        # Save unaugmented image to Google Drive\n",
        "        fpath = fpath_aug.replace(\"_aug\", \"\")\n",
        "        imageio.imwrite(fpath, image)\n",
        "\n",
        "        # Display message to track augmentation process by image\n",
        "        print('\\033[92m {}) Successfully downloaded & augmented image from {}\\033[0m'.format(format(i+1, '.0f'), url))\n",
        "\n",
        "    except:\n",
        "        print('\\033[91m {}) Error: check if web address for image from {} is valid\\033[0m'.format(format(i+1, '.0f'), url))\n",
        "\n",
        "# Remove out of bounds values\n",
        "outfpath = cwd + '/' + filter + '_crops_train_aug.tsv'\n",
        "aug_crops = read_datafile(outfpath, disp_head=False)\n",
        "crops_oobrem = remove_oob(aug_crops)\n",
        "\n",
        "# Save results for use training object detectors\n",
        "outfpath = os.path.splitext(outfpath)[0] + '_oob_rem_fin.csv'\n",
        "crops_oobrem.to_csv(outfpath, sep=',', index=False)\n",
        "print(\"\\nFinal cropping results for train data (augmented, square, centered, with out of bounds removed) being saved to: \\n{}\\n\".format(outfpath))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r7JGKXra8TTQ"
      },
      "source": [
        "## Pre-process test dataset\n",
        "---\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PBRFjkWQ2KA1"
      },
      "source": [
        "#@title Set up cropping file export parameters\n",
        "%cd $cwd\n",
        "\n",
        "# Folder where test images will be saved (defined in first code block)\n",
        "folder = test_folder\n",
        "\n",
        "# Write header of crops_test_notaug.tsv before looping through crops for other data\n",
        "fpath = cwd + \"/\" + filter + \"_crops_test.tsv\"\n",
        "outfpath = os.path.splitext(fpath)[0] + '_notaug.tsv'\n",
        "print(\"\\nCropping data being saved to: \\n{}\\n\".format(outfpath))\n",
        "if not os.path.isfile(outfpath): # Prevents writing duplicate header rows\n",
        "    with open(outfpath, 'a') as out_file:\n",
        "        tsv_writer = csv.writer(out_file, delimiter='\\t')\n",
        "        tsv_writer.writerow([\"data_object_id\",\t\"obj_url\",\t\"im_height\",\t\"im_width\",\t\"xmin\",\n",
        "                              \"ymin\",\t\"xmax\",\t\"ymax\",\t\"filename\",\t\"path\",\t\"class\"])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iDzSp9jv8Sak"
      },
      "source": [
        "#@title Save test images to Google Drive\n",
        "\n",
        "# Read in EOL user generated cropping data\n",
        "fpath = filter + \"_crops_test.tsv\"\n",
        "crops = read_datafile(fpath, disp_head=False)\n",
        "\n",
        "# Test pipeline with a smaller subset than 5k images?\n",
        "run = \"test with tiny subset\" #@param [\"test with tiny subset\", \"for all images\"]\n",
        "\n",
        "# Display detection results on images\n",
        "display_results = False #@param {type:\"boolean\"}\n",
        "\n",
        "# Loop through crop test data\n",
        "print(\"Downloading testing images\")\n",
        "start, stop = set_start_stop(run, crops)\n",
        "for i, row in crops.iloc[start:stop].iterrows():\n",
        "    try:\n",
        "        # Load image from url\n",
        "        # Use imread instead of imageio.imread to load images from url and get consistent output type and shape\n",
        "        url = crops[\"obj_url\"][i]\n",
        "        image = imread(url, mode='RGB')\n",
        "\n",
        "        # Define variables needed in exported dataset\n",
        "        fpath = get_image_info(image, crops, i, cwd, folder, filter)\n",
        "\n",
        "        # Save image to Google Drive\n",
        "        imageio.imwrite(fpath, image)\n",
        "\n",
        "        # Display message to track download process by image\n",
        "        print('\\033[92m {}) Successfully downloaded image from {}\\033[0m'.format(format(i+1, '.0f'), url))\n",
        "\n",
        "    except:\n",
        "        print('\\033[91m {}) Error: check if web address for image from {} is valid\\033[0m'.format(format(i+1, '.0f'), url))\n",
        "\n",
        "# Remove out of bounds values\n",
        "outfpath = os.path.splitext(fpath)[0] + '_notaug.tsv'\n",
        "crops = read_datafile(outfpath, disp_head=False)\n",
        "crops_oobrem = remove_oob(crops)\n",
        "\n",
        "# Save results for use training object detectors\n",
        "outfpath = os.path.splitext(outfpath)[0] + '_oob_rem_fin.csv'\n",
        "crops_oobrem.to_csv(outfpath, sep=',', index=False)\n",
        "print(\"\\nFinal cropping results for test data (square, centered, with out of bounds removed) being saved to: \\n{}\\n\".format(outfpath))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oiG0eCADiZJs"
      },
      "source": [
        "## Inspect pre-preprocessed crops on images\n",
        "---\n",
        "If needed, adjust \"iaa.Sequential\" augmentation parameters and/or \"remove_oob\" transformations above and re-visualize until desired results are acheived."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8bpzs2Koi1Vi"
      },
      "source": [
        "#@title Specify which dataset to visualize (train or test)\n",
        "%cd $cwd\n",
        "import cv2\n",
        "\n",
        "# Read in cropping file for displaying results\n",
        "dataset = \"train\" #@param [\"train\", \"test\"] {allow-input: true}\n",
        "pathbase = filter + '_crops_'\n",
        "if dataset == \"test\":\n",
        "    dataset = dataset + \"_notaug\"\n",
        "    im_path = \"test_images\"\n",
        "else:\n",
        "    dataset = dataset + \"_aug\"\n",
        "    im_path = \"images\"\n",
        "outfpath = pathbase + dataset + '_oob_rem_fin.csv'\n",
        "df = read_datafile(outfpath, sep=',', disp_head=True)\n",
        "print(\"\\nLoading cropping data from file for {} data: \\n{}\".format(dataset, df.head()))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wppitLbXjTE0"
      },
      "source": [
        "#@title Choose starting index for crops to display\n",
        "\n",
        "# Adjust line to right to see up to 50 images displayed at a time\n",
        "start = 0 #@param {type:\"slider\", min:0, max:5000, step:50}\n",
        "stop = start+50\n",
        "\n",
        "# Loop through images\n",
        "for i, row in df.iloc[start:stop].iterrows():\n",
        "    # Read in image\n",
        "    fn = df['filename'][i]\n",
        "    fpath = im_path + '/' + fn\n",
        "    img = imread(fpath, mode='RGB')\n",
        "\n",
        "    # Draw bounding box on image\n",
        "    image_wbox, box = draw_box_on_image(df, img, i)\n",
        "\n",
        "    # Plot cropping box on image\n",
        "    _, ax = plt.subplots(figsize=(10, 10))\n",
        "    ax.imshow(image_wbox)\n",
        "\n",
        "    # Display image URL and coordinates above image\n",
        "    plt.title('{} \\n xmin: {}, ymin: {}, xmax: {}, ymax: {}'.format(url, box[0], box[1], box[2], box[3]))"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}