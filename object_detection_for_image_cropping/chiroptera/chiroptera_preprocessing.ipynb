{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.8"
    },
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/aubricot/computer_vision_with_eol_images/blob/master/object_detection_for_image_cropping/chiroptera/chiroptera_preprocessing.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4Rnwb_rgmJZB"
      },
      "source": [
        "# Pre-processing and image augmentation for object detection model training and testing datasets\n",
        "---\n",
        "*Last Updated 4 Oct 2022*   \n",
        "An [EOL user generated cropping dataset](https://editors.eol.org/other_files/EOL_v2_files/image_crops_withEOL_pk.txt.zip) is pre-processed and transformed to formatting standards for use with YOLO via Darkflow and SSD and Faster-RCNN object detection models implemented in Tensorflow. All train and test images are also downloaded to Google Drive for use training and testing.\n",
        "\n",
        "Before reformatting to object detection model standards, training data is augmented using the [imgaug library](https://github.com/aleju/imgaug). Image augmentation is used to increase training data sample size and diversity to reduce overfitting when training object detection models. Both images and cropping coordinates are augmented. Augmented and original training datasets are then combined before being transformed to object detection model formatting standards.\n",
        "\n",
        "Notes:   \n",
        "* Run code blocks by pressing play button in brackets on left\n",
        "* Before you you start: change the runtime to \"GPU\" with \"High RAM\"\n",
        "* Change parameters using form fields on right (find details at corresponding lines of code by searching '#@param')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iJz5m4BKmJZD"
      },
      "source": [
        "## Installs & Imports\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yWAbU5tW1ONu"
      },
      "source": [
        "#@title Choose where to save results & set up directory structure\n",
        "# Use dropdown menu on right\n",
        "save = \"in Colab runtime (files deleted after each session)\" #@param [\"in my Google Drive\", \"in Colab runtime (files deleted after each session)\"]\n",
        "print(\"Saving results \", save)\n",
        "\n",
        "# Mount google drive to export image cropping coordinate file(s)\n",
        "if 'Google Drive' in save:\n",
        "    from google.colab import drive\n",
        "    drive.mount('/content/drive', force_remount=True)\n",
        "\n",
        "# Type in the path to your working directory in form field to right\n",
        "import os\n",
        "basewd = \"/content/drive/MyDrive/train/tf2\" #@param [\"/content/drive/MyDrive/train/tf2\"] {allow-input: true}\n",
        "if not os.path.exists(basewd):\n",
        "    os.makedirs(basewd)\n",
        "\n",
        "# Enter taxon of interest in form field\n",
        "taxon = \"Chiroptera\" #@param [\"Chiroptera\"] {allow-input: true}\n",
        "\n",
        "# Folder where pre-processing results will be saved\n",
        "preprocessing_folder = \"pre-processing\" #@param [\"pre-processing\"] {allow-input: true}\n",
        "cwd = basewd + '/' + preprocessing_folder\n",
        "print(\"\\nWorking directory set to: \\n\", cwd)\n",
        "\n",
        "# Folder where train images will be saved\n",
        "train_folder = \"images\" #@param [\"images\"] {allow-input: true}\n",
        "train_wd = cwd + '/' + train_folder\n",
        "if not os.path.exists(train_wd):\n",
        "    os.makedirs(train_wd)\n",
        "print(\"\\nTraining images directory set to: \\n\", train_wd)\n",
        "\n",
        "# Folder where test images will be saved\n",
        "test_folder = \"test_images\" #@param [\"test_images\"] {allow-input: true}\n",
        "test_wd = cwd + '/' + test_folder\n",
        "if not os.path.exists(test_wd):\n",
        "    os.makedirs(test_wd)\n",
        "print(\"\\nTesting images directory set to: \\n\", test_wd)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QSLXg6G7mJZP"
      },
      "source": [
        "# Install libraries for augmenting and displaying images\n",
        "!pip install imgaug\n",
        "!pip install pillow\n",
        "!pip install scipy==1.1.0\n",
        "\n",
        "# For importing/exporting files, working with arrays, etc\n",
        "import pathlib\n",
        "import os\n",
        "import imageio\n",
        "import time\n",
        "import csv\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from urllib.request import urlopen\n",
        "from scipy import misc\n",
        "from scipy.misc import imread\n",
        "from PIL import Image\n",
        "# Set number of seconds to timeout if image url taking too long to open\n",
        "import socket\n",
        "socket.setdefaulttimeout(10)\n",
        "\n",
        "# For augmenting the images and bounding boxes\n",
        "import imgaug as ia\n",
        "import imgaug.augmenters as iaa\n",
        "from imgaug.augmentables.bbs import BoundingBox, BoundingBoxesOnImage\n",
        "\n",
        "# For drawing onto and plotting the images\n",
        "import matplotlib.pyplot as plt\n",
        "import cv2\n",
        "%config InlineBackend.figure_format = 'svg'\n",
        "%matplotlib inline"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nwKdj73Wpnlz"
      },
      "source": [
        "## Build train and test datasets from EOL user-generated cropping data\n",
        "---\n",
        "Full cropping dataset is available [here](https://editors.eol.org/other_files/EOL_v2_files/image_crops_withEOL_pk.txt.zip)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j7ExCZeT4mqH"
      },
      "source": [
        "#@title Define functions\n",
        "\n",
        "# Suppress pandas warning about writing over a copy of data\n",
        "pd.options.mode.chained_assignment = None  # default='warn'\n",
        "\n",
        "# To read in EOL formatted data files\n",
        "def read_datafile(fpath, sep=\"\\t\", header=0, disp_head=True):\n",
        "    hdr = {\n",
        "        'User-Agent': 'Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.11 (KHTML, like Gecko) Chrome/23.0.1271.64 Safari/537.11',\n",
        "        'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8',\n",
        "        'Accept-Charset': 'ISO-8859-1,utf-8;q=0.7,*;q=0.3',\n",
        "        'Accept-Encoding': 'none',\n",
        "        'Accept-Language': 'en-US,en;q=0.8',\n",
        "        'Connection': 'keep-alive'\n",
        "        }\n",
        "    try:\n",
        "        df = pd.read_csv(fpath, sep=sep, header=header, storage_options=hdr)\n",
        "        if disp_head:\n",
        "          print(\"Data header: \\n\", df.head())\n",
        "    except FileNotFoundError as e:\n",
        "        raise Exception(\"File not found: Enter the path to your file in form field and re-run\").with_traceback(e.__traceback__)\n",
        "    \n",
        "    return df\n",
        "\n",
        "# Reformat cropping dimensions\n",
        "def reformat_crops(crops, disp_head=True):\n",
        "    # Remove/replace characters in crop_dimensions string\n",
        "    crops.crop_dimensions.replace('\"|{|}', '', regex=True, inplace=True)\n",
        "    crops.crop_dimensions.replace(':', ',', regex=True, inplace=True)\n",
        "    \n",
        "    # Split crop_dimensions into their own columns\n",
        "    cols = crops.crop_dimensions.str.split(\",\", expand=True)\n",
        "    crops[\"im_height\"] = cols[1]\n",
        "    crops[\"im_width\"] = cols[3]\n",
        "    crops[\"xmin\"] = cols[5]\n",
        "    crops[\"ymin\"] = cols[7]\n",
        "    crops[\"xmax\"] = cols[5].astype(float) + cols[9].astype(float) # add cropwidth to xmin, note crops are square so width=height\n",
        "    crops[\"ymax\"] = cols[7].astype(float) + cols[9].astype(float) # add cropheight to ymin, note crops are square so width=height\n",
        "    \n",
        "    # Remove crop_dimensions column\n",
        "    crops.drop(columns =[\"crop_dimensions\"], inplace = True) \n",
        "    if disp_head:\n",
        "        print(\"\\n~~~Reformatted EOL crops head~~~\\n\", crops.head())\n",
        "\n",
        "    return crops\n",
        "\n",
        "# Filter by taxon of interest\n",
        "filter = taxon # defined in first code block\n",
        "def filter_by_taxon(crops, filter=filter, disp_head=False):\n",
        "    taxon = crops.loc[crops.ancestry.str.contains(filter, case=False, na=False)]\n",
        "    taxon.drop(columns =[\"ancestry\"], inplace = True) \n",
        "    taxon['name'] = filter\n",
        "    taxon.reset_index(inplace=True)\n",
        "    if disp_head:\n",
        "          print(\"Showing dataset for only {}: {}\\n\".format(filter, taxon.head()))\n",
        "    print(\"\\n~~~Number of available cropping coordinates for training/testing with {}~~~: \\n{}\\n\".format(filter, len(taxon)))\n",
        "\n",
        "    return taxon\n",
        "\n",
        "# Split into train and test datasets\n",
        "def split_train_test(crops, outfpath, frac, disp_head=False):\n",
        "    # Randomly select 80% of data to use for training (set random_state seed for reproducibility)\n",
        "    idx = crops.sample(frac = 0.8, random_state=2).index\n",
        "    train = crops.iloc[idx]\n",
        "    if disp_head:\n",
        "        print(\"Training data for {} (n={} crops): \\n\".format(filter, len(train), train.head()))\n",
        "\n",
        "    # Select the remaining 20% of data for testing\n",
        "    # Uses the inverse index from above\n",
        "    test = crops.iloc[crops.index.difference(idx)]\n",
        "    if disp_head:\n",
        "        print(\"Testing data for {} (n={} crops): \\n\".format(filter, len(test), test.head()))\n",
        "\n",
        "    # Write test and train to tsvs \n",
        "    train_outfpath = os.path.splitext(outfpath)[0] + '_train' + '.tsv'\n",
        "    train.to_csv(train_outfpath, sep='\\t', header=True, index=False)\n",
        "    test_outfpath = os.path.splitext(outfpath)[0] + '_test' + '.tsv'\n",
        "    test.to_csv(test_outfpath, sep='\\t', header=True, index=False)\n",
        "    print(\"\\n Train and test datasets sucessfully split and saved to: \\n\\n{}\\n{}\"\\\n",
        "          .format(train_outfpath, test_outfpath))\n",
        "\n",
        "    return train, test"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vNHjFdVr4Dfc"
      },
      "source": [
        "#@title Filter EOL cropping coordinates for taxon of interest and reformat to Pascal VOC Annotation Style\n",
        "\n",
        "# Download EOL user generated cropping file to temporary runtime location\n",
        "print(\"Downloading EOL user-generated cropping dataset\\n\")\n",
        "!wget --user-agent=\"Mozilla\" https://editors.eol.org/other_files/EOL_v2_files/image_crops_withEOL_pk.txt.zip\n",
        "\n",
        "# Unzip cropping file to your working directory\n",
        "!unzip /content/image_crops_withEOL_pk.txt.zip -d $basewd\n",
        "\n",
        "# Change to your training directory within Google Drive\n",
        "%cd $basewd\n",
        "!mv image_crops_withEOL_pk.txt $preprocessing_folder\n",
        "%cd $cwd \n",
        "\n",
        "# Read in user-generated image cropping file\n",
        "fpath = cwd + '/image_crops_withEOL_pk.txt'\n",
        "df = read_datafile(fpath, disp_head=False)\n",
        "\n",
        "# Reformat cropping dimensions\n",
        "reformatted = reformat_crops(df, disp_head=True)\n",
        "\n",
        "# Filter by taxon of interest (Chiroptera)\n",
        "filtered = filter_by_taxon(reformatted, disp_head=False)\n",
        "\n",
        "# Export Chiroptera crops as tsv\n",
        "outfpath = filter + '_crops.tsv'\n",
        "filtered.to_csv(outfpath, sep='\\t', index=False)\n",
        "\n",
        "# Split into train (80%) and test (20%) datasets\n",
        "train, test = split_train_test(filtered, outfpath, 0.8, disp_head=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1lMvu5M0oUrY"
      },
      "source": [
        "## Pre-process train dataset\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TTW5qHqjvWSS"
      },
      "source": [
        "#@title Define functions\n",
        "%cd $cwd\n",
        "\n",
        "# So URL's don't get truncated & show all cols in display\n",
        "pd.set_option('display.max_colwidth',1000)\n",
        "pd.set_option('display.max_columns', None)\n",
        "\n",
        "# Set seed to make augmentation reproducible across runs, otherwise will be random each time\n",
        "ia.seed(1) \n",
        "\n",
        "# Folder where train images will be saved (defined in first code block)\n",
        "folder = train_folder\n",
        "\n",
        "# Define start and stop indices in EOL bundle for running inference   \n",
        "def set_start_stop(run):\n",
        "    # To test with a tiny subset, use 5 random bundle images\n",
        "    if \"tiny subset\" in run:\n",
        "        start=np.random.choice(a=1000, size=1)[0]\n",
        "        stop=start+5\n",
        "    # To run for all images\n",
        "    else:\n",
        "        start=None\n",
        "        stop=None\n",
        "    \n",
        "    return start, stop\n",
        "\n",
        "# To display an image already loaded into the runtime\n",
        "def display_image(image):\n",
        "  fig = plt.figure(figsize=(20, 15))\n",
        "  plt.grid(False)\n",
        "  plt.imshow(image)\n",
        "\n",
        "# To draw cropping coordinates on an image\n",
        "def draw_boxes(image, box, class_name):\n",
        "  image_wboxes = cv2.rectangle(image, (box[0], box[1]), (box[2], box[3]), \\\n",
        "                               (255, 0, 157), 3) # change box color and thickness\n",
        "  \n",
        "  return image_wboxes\n",
        "\n",
        "# Define image augmentation pipeline\n",
        "# modified from https://github.com/aleju/imgaug\n",
        "seq = iaa.Sequential([\n",
        "    iaa.Crop(px=(1, 16), keep_size=False), # crop by 1-16px, resize resulting image to orig dims\n",
        "    iaa.Affine(rotate=(-25, 25)), # rotate -25 to 25 degrees\n",
        "    iaa.GaussianBlur(sigma=(0, 3.0)), # blur using gaussian kernel with sigma of 0-3\n",
        "    iaa.AddToHueAndSaturation((-50, 50), per_channel=True)\n",
        "])\n",
        "\n",
        "# To augment an image\n",
        "def augment_image(image, crops, filter=filter, folder=folder):\n",
        "    pathbase = folder + '/'\n",
        "    class_name = filter\n",
        "\n",
        "    # Define image info needed for export\n",
        "    im_h, im_w = image.shape[:2]\n",
        "    xmin = crops.xmin[i].astype(int)\n",
        "    ymin = crops.ymin[i].astype(int)\n",
        "    xmax = crops.xmax[i].astype(int)\n",
        "    ymax = crops.ymax[i].astype(int)\n",
        "    box = [xmin, ymin, xmax, ymax]\n",
        "    fn = str(crops['data_object_id'][i]) + '.jpg'\n",
        "    fpath = pathbase + fn\n",
        "    \n",
        "    # Export unaugmented image info for future use training object detectors\n",
        "    with open(outfpath, 'a') as out_file:\n",
        "          tsv_writer = csv.writer(out_file, delimiter='\\t')\n",
        "          tsv_writer.writerow([crops.data_object_id[i], crops.obj_url[i], \\\n",
        "                              im_h, im_w, box[0], box[1], \\\n",
        "                              box[2], box[3], fn, fpath, class_name])\n",
        "\n",
        "    # Load original bounding box coordinates to imgaug format\n",
        "    bb  = ia.BoundingBox(x1=xmin, y1=ymin, x2=xmax, y2=ymax)        \n",
        "    bb = BoundingBoxesOnImage([bb], shape=image.shape)\n",
        "    \n",
        "    # Augment image using settings defined above in seq\n",
        "    image_aug, bb_aug = seq.augment(image=image, bounding_boxes=bb)\n",
        "\n",
        "    # Define augmentation results needed for export\n",
        "    fn_aug = str(crops['data_object_id'][i]) + '_aug' + '.jpg'\n",
        "    fpath_aug = pathbase + fn_aug\n",
        "    im_h_aug, im_w_aug = image_aug.shape[:2]\n",
        "    xmin_aug = bb_aug.bounding_boxes[0].x1.astype(int)\n",
        "    ymin_aug = bb_aug.bounding_boxes[0].y1.astype(int)\n",
        "    xmax_aug = bb_aug.bounding_boxes[0].x2.astype(int)\n",
        "    ymax_aug = bb_aug.bounding_boxes[0].y2.astype(int)\n",
        "    box_aug = [xmin_aug, ymin_aug, xmax_aug, ymax_aug]\n",
        "        \n",
        "    # Export augmentation results for future use training object detectors\n",
        "    with open(outfpath, 'a') as out_file:\n",
        "          tsv_writer = csv.writer(out_file, delimiter='\\t')\n",
        "          tsv_writer.writerow([crops.data_object_id[i], crops.obj_url[i], \\\n",
        "                              im_h_aug, im_w_aug, box_aug[0], box_aug[1], \\\n",
        "                              box_aug[2], box_aug[3], fn_aug, fpath_aug, class_name])\n",
        "\n",
        "    # Draw augmented bounding box and image\n",
        "    # Only use for up to 50 images\n",
        "    if display_results:\n",
        "        image_wboxes = draw_boxes(image_aug, box_aug, class_name)\n",
        "        display_image(image_wboxes)\n",
        "        plt.title('{}) Successfully augmented image from {}'.format(format(i+1, '.0f'), url))\n",
        "    \n",
        "    return image_aug, fpath_aug\n",
        "\n",
        "# Remove out of bounds values\n",
        "def remove_oob(crops):\n",
        "    # Set negative values to 0\n",
        "    crops.xmin[crops.xmin < 0] = 0\n",
        "    crops.ymin[crops.ymin < 0] = 0\n",
        "\n",
        "    # Remove out of bounds cropping dimensions\n",
        "    ## When crop height > image height, set crop height equal to image height\n",
        "    idx = crops.index[crops.ymax > crops.im_height]\n",
        "    crops.ymin.iloc[idx] = 0\n",
        "    crops.ymax.iloc[idx] = crops.im_height.iloc[idx]\n",
        "    ## When crop width > image width, set crop width equal to image width\n",
        "    idx = crops.index[crops.xmax > crops.im_width]\n",
        "    crops.xmin.iloc[idx] = 0\n",
        "    crops.xmax.iloc[idx] = crops.im_width.iloc[idx]\n",
        "\n",
        "    # Write relevant results to csv formatted for training and annotations needed by Tensorflow and YOLO\n",
        "    crops_oobrem = crops[['xmin', 'ymin', 'xmax', 'ymax',\n",
        "                  'filename', 'im_width', 'im_height', 'class']]\n",
        "\n",
        "    return crops_oobrem\n",
        "\n",
        "# Write header of crops_aug.tsv before looping through crops for remaining data\n",
        "outfpath = cwd + '/' + filter + '_crops_train_aug.tsv'\n",
        "if not os.path.isfile(outfpath): # Prevents writing duplicate header rows\n",
        "    with open(outfpath, 'a') as out_file:\n",
        "        tsv_writer = csv.writer(out_file, delimiter='\\t')\n",
        "        tsv_writer.writerow([\"data_object_id\",\t\"obj_url\",\t\"im_height\",\t\"im_width\",\t\"xmin\",\n",
        "                                \"ymin\",\t\"xmax\",\t\"ymax\",\t\"filename\",\t\"path\",\t\"class\"])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P31JjHddVSEm"
      },
      "source": [
        "#@title Augment training images & save them to Google Drive\n",
        "\n",
        "# Read in EOL user generated cropping data\n",
        "fpath = filter + \"_crops_train.tsv\"\n",
        "crops = read_datafile(fpath, disp_head=False)\n",
        "\n",
        "# Test pipeline with a smaller subset than 5k images?\n",
        "run = \"test with tiny subset\" #@param [\"test with tiny subset\", \"for all images\"]\n",
        "\n",
        "# Display detection results on images\n",
        "display_results = True #@param {type:\"boolean\"}\n",
        "\n",
        "# Download images, augment them, and save to Google Drive\n",
        "print(\"Downloading and augmenting training images\")\n",
        "start, stop = set_start_stop(run)\n",
        "\n",
        "for i, row in crops.iloc[start:stop].iterrows():\n",
        "    try:\n",
        "        # Load image from url\n",
        "        # Note: Use imread instead of imageio.imread to load images from url and get consistent output type and shape\n",
        "        url = crops[\"obj_url\"][i]\n",
        "        with urlopen(url) as file:\n",
        "            image = imread(file, mode='RGB')\n",
        "\n",
        "        # Augment the image and bounding box\n",
        "        image_aug, fpath_aug = augment_image(image, crops)\n",
        "\n",
        "        # Save image to Google Drive\n",
        "        imageio.imwrite(fpath_aug, image_aug)\n",
        "\n",
        "        # Save unaugmented image to Google Drive\n",
        "        fpath = fpath_aug.replace(\"_aug\", \"\")\n",
        "        imageio.imwrite(fpath, image)\n",
        "    \n",
        "        # Display message to track augmentation process by image\n",
        "        print('{}) Successfully downloaded & augmented image from {}'.format(format(i+1, '.0f'), url))\n",
        "  \n",
        "    except:\n",
        "        print('{}) Error: check if web address for image from {} is valid'.format(format(i+1, '.0f'), url))\n",
        "\n",
        "# Remove out of bounds values\n",
        "aug_crops = read_datafile(outfpath, disp_head=False)\n",
        "crops_oobrem = remove_oob(aug_crops)\n",
        "\n",
        "# Save results for use training object detectors\n",
        "outfpath = os.path.splitext(outfpath)[0] + '_oob_rem_fin.csv' \n",
        "crops_oobrem.to_csv(outfpath, sep=',', index=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r7JGKXra8TTQ"
      },
      "source": [
        "## Pre-process test dataset\n",
        "---\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PBRFjkWQ2KA1"
      },
      "source": [
        "#@title Define functions\n",
        "%cd $cwd\n",
        "\n",
        "# Folder where test images will be saved (defined in first code block)\n",
        "folder = test_folder\n",
        "\n",
        "# Get info from EOL user generated cropping file\n",
        "def get_image_info(image, crops, folder=folder, filter=filter):    \n",
        "    pathbase = folder + '/'\n",
        "    class_name = filter\n",
        "\n",
        "    # Define image info needed for export\n",
        "    im_h, im_w = image.shape[:2]\n",
        "    xmin = crops.xmin[i].astype(int)\n",
        "    ymin = crops.ymin[i].astype(int)\n",
        "    xmax = crops.xmax[i].astype(int)\n",
        "    ymax = crops.ymax[i].astype(int)\n",
        "    box = [xmin, ymin, xmax, ymax]\n",
        "    fn = str(crops['data_object_id'][i]) + '.jpg'\n",
        "    fpath = pathbase + fn\n",
        "    \n",
        "    # Export to crops_test.tsv\n",
        "    with open(outfpath, 'a') as out_file:\n",
        "            tsv_writer = csv.writer(out_file, delimiter='\\t')\n",
        "            tsv_writer.writerow([crops.data_object_id[i], crops.obj_url[i], \\\n",
        "                                 im_h, im_w, box[0], box[1], box[2], box[3], \\\n",
        "                                 fn, fpath, class_name])\n",
        "\n",
        "    return fpath\n",
        "\n",
        "# Write header of crops_test_notaug.tsv before looping through crops for other data\n",
        "fpath = cwd + \"/\" + filter + \"_crops_test.tsv\"\n",
        "outfpath = os.path.splitext(fpath)[0] + '_notaug.tsv'\n",
        "if not os.path.isfile(outfpath): # Prevents writing duplicate header rows\n",
        "    with open(outfpath, 'a') as out_file:\n",
        "        tsv_writer = csv.writer(out_file, delimiter='\\t')\n",
        "        tsv_writer.writerow([\"data_object_id\",\t\"obj_url\",\t\"im_height\",\t\"im_width\",\t\"xmin\",\n",
        "                              \"ymin\",\t\"xmax\",\t\"ymax\",\t\"filename\",\t\"path\",\t\"class\"])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iDzSp9jv8Sak"
      },
      "source": [
        "#@title Save test images to Google Drive\n",
        "\n",
        "# Read in EOL user generated cropping data\n",
        "crops = read_datafile(fpath, disp_head=False)\n",
        "\n",
        "# Test pipeline with a smaller subset than 5k images?\n",
        "run = \"test with tiny subset\" #@param [\"test with tiny subset\", \"for all images\"]\n",
        "\n",
        "# Display detection results on images\n",
        "display_results = True #@param {type:\"boolean\"}\n",
        "\n",
        "# Loop through crop test data\n",
        "print(\"Downloading testing images\")\n",
        "start, stop = set_start_stop(run)\n",
        "\n",
        "for i, row in crops.iloc[start:stop].iterrows():\n",
        "    try:\n",
        "        # Load image from url\n",
        "        # Use imread instead of imageio.imread to load images from url and get consistent output type and shape\n",
        "        url = crops[\"obj_url\"][i]\n",
        "        with urlopen(url) as file:\n",
        "            image = imread(file, mode='RGB')\n",
        "\n",
        "        # Define variables needed in exported dataset\n",
        "        fpath = get_image_info(image, crops)\n",
        "\n",
        "        # Save image to Google Drive\n",
        "        imageio.imwrite(fpath, image)\n",
        "    \n",
        "        # Display message to track download process by image\n",
        "        print('{}) Successfully downloaded image from {}'.format(format(i+1, '.0f'), url))\n",
        "  \n",
        "    except:\n",
        "        print('{}) Error: check if web address for image from {} is valid'.format(format(i+1, '.0f'), url))\n",
        "\n",
        "# Remove out of bounds values\n",
        "crops = read_datafile(outfpath, disp_head=False)\n",
        "crops_oobrem = remove_oob(crops)\n",
        "\n",
        "# Save results for use training object detectors\n",
        "outfpath = os.path.splitext(outfpath)[0] + '_oob_rem_fin.csv' \n",
        "crops_oobrem.to_csv(outfpath, sep=',', index=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oiG0eCADiZJs"
      },
      "source": [
        "## Inspect pre-preprocessed crops on images\n",
        "---\n",
        "If needed, adjust \"iaa.Sequential\" augmentation parameters and/or \"remove_oob\" transformations above and re-visualize until desired results are acheived."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8bpzs2Koi1Vi"
      },
      "source": [
        "#@title Define functions and specify which dataset to visualize (train or test)\n",
        "%cd $cwd\n",
        "import cv2\n",
        "from scipy.misc import imread\n",
        "\n",
        "# Read in cropping file for displaying results\n",
        "dataset = \"train\" #@param [\"train\", \"test\"] {allow-input: true}\n",
        "pathbase = filter + '_crops_'\n",
        "if dataset == \"test\":\n",
        "    dataset = dataset + \"_notaug\"\n",
        "    im_path = \"test_images\"\n",
        "else:\n",
        "    dataset = dataset + \"_aug\"\n",
        "    im_path = \"images\"\n",
        "outfpath = pathbase + dataset + '_oob_rem_fin.csv'\n",
        "df = read_datafile(outfpath, sep=',', disp_head=True)\n",
        "\n",
        "# Draw cropping box on image\n",
        "def draw_box_on_image(df, img):\n",
        "    # Get box coordinates\n",
        "    xmin = df['xmin'][i].astype(int)\n",
        "    ymin = df['ymin'][i].astype(int)\n",
        "    xmax = df['xmax'][i].astype(int)\n",
        "    ymax = df['ymax'][i].astype(int)\n",
        "    box = [xmin, ymin, xmax, ymax]\n",
        "\n",
        "    # Set box/font color and size\n",
        "    maxdim = max(df['im_height'][i],df['im_width'][i])\n",
        "    fontScale = maxdim/600\n",
        "    box_col = (255, 0, 157)\n",
        "  \n",
        "    # Add label to image\n",
        "    tag = df['class'][i]\n",
        "    image_wbox = cv2.putText(img, tag, (xmin+7, ymax-12), cv2.FONT_HERSHEY_SIMPLEX, fontScale, box_col, 2, cv2.LINE_AA)  \n",
        "  \n",
        "    # Draw box label on image\n",
        "    image_wbox = cv2.rectangle(img, (xmin, ymax), (xmax, ymin), box_col, 5)\n",
        "\n",
        "    return image_wbox, box"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wppitLbXjTE0"
      },
      "source": [
        "#@title Choose starting index for crops to display\n",
        "\n",
        "# Adjust line to right to see up to 50 images displayed at a time\n",
        "start = 0 #@param {type:\"slider\", min:0, max:5000, step:50}\n",
        "stop = start+50\n",
        "\n",
        "# Loop through images\n",
        "for i, row in df.iloc[start:stop].iterrows():\n",
        "    # Read in image \n",
        "    fn = df['filename'][i]\n",
        "    fpath = im_path + '/' + fn\n",
        "    img = imread(fpath, mode='RGB')\n",
        "  \n",
        "    # Draw bounding box on image\n",
        "    image_wbox, box = draw_box_on_image(df, img)\n",
        "  \n",
        "    # Plot cropping box on image\n",
        "    _, ax = plt.subplots(figsize=(10, 10))\n",
        "    ax.imshow(image_wbox)\n",
        "\n",
        "    # Display image URL and coordinates above image\n",
        "    plt.title('{} \\n xmin: {}, ymin: {}, xmax: {}, ymax: {}'.format(url, box[0], box[1], box[2], box[3]))"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}