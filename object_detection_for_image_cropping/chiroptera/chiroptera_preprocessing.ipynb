{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.8"
    },
    "colab": {
      "name": "chiroptera_preprocessing.ipynb",
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/aubricot/computer_vision_with_eol_images/blob/master/object_detection_for_image_cropping/chiroptera/chiroptera_preprocessing.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4Rnwb_rgmJZB"
      },
      "source": [
        "# Pre-processing and image augmentation for object detection model training and testing datasets\n",
        "---\n",
        "*Last Updated 25 May 2021*   \n",
        "An [EOL user generated cropping dataset](https://editors.eol.org/other_files/EOL_v2_files/image_crops_withEOL_pk.txt.zip) is pre-processed and transformed to formatting standards for use with YOLO via Darkflow and SSD and Faster-RCNN object detection models implemented in Tensorflow. All train and test images are also downloaded to Google Drive for use training and testing.\n",
        "\n",
        "Before reformatting to object detection model standards, training data is augmented using the [imgaug library](https://github.com/aleju/imgaug). Image augmentation is used to increase training data sample size and diversity to reduce overfitting when training object detection models. Both images and cropping coordinates are augmented. Augmented and original training datasets are then combined before being transformed to object detection model formatting standards."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iJz5m4BKmJZD"
      },
      "source": [
        "## Installs & Imports\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yWAbU5tW1ONu"
      },
      "source": [
        "# Mount google drive to import/export files\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QSLXg6G7mJZP"
      },
      "source": [
        "# Install libraries for augmenting and displaying images\n",
        "!pip install imgaug\n",
        "!pip install pillow\n",
        "!pip install scipy==1.1.0\n",
        "\n",
        "# For importing/exporting files, working with arrays, etc\n",
        "import pathlib\n",
        "import os\n",
        "import imageio\n",
        "import time\n",
        "import csv\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from urllib.request import urlopen\n",
        "from scipy import misc\n",
        "from scipy.misc import imread\n",
        "from PIL import Image\n",
        "# Set number of seconds to timeout if image url taking too long to open\n",
        "import socket\n",
        "socket.setdefaulttimeout(10)\n",
        "\n",
        "# For augmenting the images and bounding boxes\n",
        "import imgaug as ia\n",
        "import imgaug.augmenters as iaa\n",
        "from imgaug.augmentables.bbs import BoundingBox, BoundingBoxesOnImage\n",
        "\n",
        "# For drawing onto and plotting the images\n",
        "import matplotlib.pyplot as plt\n",
        "import cv2\n",
        "%config InlineBackend.figure_format = 'svg'\n",
        "%matplotlib inline\n",
        "\n",
        "# To read in EOL formatted data files\n",
        "def read_datafile(fpath, sep=\"\\t\", header=0, disp_head=True):\n",
        "    \"\"\"\n",
        "    Defaults to tab-separated data files with header in row 0\n",
        "    \"\"\"\n",
        "    try:\n",
        "        df = pd.read_csv(fpath, sep=sep, header=header)\n",
        "        if disp_head:\n",
        "          print(\"Data header: \\n\", df.head())\n",
        "    except FileNotFoundError as e:\n",
        "        raise Exception(\"File not found: Enter the path to your file in form field and re-run\").with_traceback(e.__traceback__)\n",
        "    \n",
        "    return df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nwKdj73Wpnlz"
      },
      "source": [
        "## Set up train and test datasets\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j7ExCZeT4mqH"
      },
      "source": [
        "# Define functions\n",
        "\n",
        "# Suppress pandas warning about writing over a copy of data\n",
        "pd.options.mode.chained_assignment = None  # default='warn'\n",
        "\n",
        "# TO DO: Type in the path to your working directory in form field to right\n",
        "wd = \"/content/drive/MyDrive/train\" #@param {type:\"string\"}\n",
        "\n",
        "# TO DO: Enter taxa to filter by in form field\n",
        "filter = \"Chiroptera\" #@param {type:\"string\"}\n",
        "\n",
        "# Reformat cropping dimensions\n",
        "def reformat_crops(crops, disp_head=True):\n",
        "    '''Split crop_dimensions into separate columns'''\n",
        "    # Remove/replace characters in crop_dimensions string\n",
        "    crops.crop_dimensions.replace('\"', '', regex=True, inplace=True)\n",
        "    crops.crop_dimensions.replace('{', '', regex=True, inplace=True)\n",
        "    crops.crop_dimensions.replace('}', '', regex=True, inplace=True)\n",
        "    crops.crop_dimensions.replace(':', ',', regex=True, inplace=True)\n",
        "    \n",
        "    # Split crop_dimensions into their own columns\n",
        "    cols = crops.crop_dimensions.str.split(\",\", expand=True)\n",
        "    crops[\"im_height\"] = cols[1]\n",
        "    crops[\"im_width\"] = cols[3]\n",
        "    crops[\"xmin\"] = cols[5]\n",
        "    crops[\"ymin\"] = cols[7]\n",
        "    crops[\"xmax\"] = cols[5].astype(float) + cols[9].astype(float) # add cropwidth to xmin, note crops are square so width=height\n",
        "    crops[\"ymax\"] = cols[7].astype(float) + cols[9].astype(float) # add cropheight to ymin, note crops are square so width=height\n",
        "    \n",
        "    # Remove crop_dimensions column\n",
        "    crops.drop(columns =[\"crop_dimensions\"], inplace = True) \n",
        "    if disp_head:\n",
        "        print(\"\\nReformatted EOL crops head: \\n\", crops.head())\n",
        "\n",
        "    return crops\n",
        "\n",
        "# Filter by taxon of interest\n",
        "def filter_by_taxon(crops, filter=filter, disp_head=False):\n",
        "    taxon = crops.loc[crops.ancestry.str.contains(filter, case=False, na=False)]\n",
        "    taxon.drop(columns =[\"ancestry\"], inplace = True) \n",
        "    taxon['name'] = filter\n",
        "    taxon.reset_index(inplace=True)\n",
        "    if disp_head:\n",
        "          print(\"Data header: \\n\", taxon.head())\n",
        "    print(\"\\n Number of available cropping coordinates for training/testing: \\n\", len(taxon))\n",
        "\n",
        "    return taxon\n",
        "\n",
        "# Split into train and test datasets\n",
        "def split_train_test(crops, frac, disp_head=False):\n",
        "    # Randomly select 80% of data to use for training\n",
        "    # Set seed with random_state=2 for reproducible results\n",
        "    idx = crops.sample(frac = 0.8, random_state=2).index\n",
        "    train = crops.iloc[idx]\n",
        "    if disp_head:\n",
        "        print(\"Training data: \\n\", train.head())\n",
        "\n",
        "    # Select the remaining 20% of data for testing\n",
        "    # Uses the inverse index from above\n",
        "    test = crops.iloc[crops.index.difference(idx)]\n",
        "    if disp_head:\n",
        "        print(\"Testing data: \\n\", test.head())\n",
        "\n",
        "    # Write test and train to tsvs \n",
        "    outfpath = 'data/' + filter + '_crops' + '_train' + '.tsv'\n",
        "    train.to_csv(outfpath, sep='\\t', header=True, index=False)\n",
        "    outfpath = 'data/' + filter + '_crops' + '_test' + '.tsv'\n",
        "    test.to_csv(outfpath, sep='\\t', header=True, index=False)\n",
        "    print(\"Train and test datasets sucessfully split and saved to file\")\n",
        "\n",
        "    return train, test"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ItlLollbCz25"
      },
      "source": [
        "# Download EOL user generated cropping data\n",
        "\n",
        "# Download EOL user generated cropping file to temporary runtime location\n",
        "!wget --user-agent=\"Mozilla\" https://editors.eol.org/other_files/EOL_v2_files/image_crops_withEOL_pk.txt.zip\n",
        "\n",
        "# Unzip cropping file to your working directory\n",
        "!unzip /content/image_crops_withEOL_pk.txt.zip -d $wd\n",
        "\n",
        "# Change to your training directory within Google Drive\n",
        "%cd $wd\n",
        "!mv image_crops_withEOL_pk.txt data/"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vNHjFdVr4Dfc"
      },
      "source": [
        "# Filter EOL cropping coordinates by taxon and reformat to Pascal VOC Annotation Style\n",
        "\n",
        "# Read in user-generated image cropping file\n",
        "fpath = 'data/' + 'image_crops_withEOL_pk.txt'\n",
        "df = read_datafile(fpath, disp_head=False)\n",
        "\n",
        "# Reformat cropping dimensions\n",
        "crops = reformat_crops(df, disp_head=True)\n",
        "\n",
        "# Filter by taxon of interest (Chiroptera)\n",
        "crops = filter_by_taxon(crops, disp_head=False)\n",
        "\n",
        "# Export as csv\n",
        "outfpath = 'data/' + filter + '_crops.tsv'\n",
        "crops.to_csv(outfpath, sep='\\t', index=False)\n",
        "\n",
        "# Split into train (80%) and test (20%) datasets\n",
        "train, test = split_train_test(crops, 0.8, disp_head=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1lMvu5M0oUrY"
      },
      "source": [
        "## Pre-process train images\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cGMDGahzm44x"
      },
      "source": [
        "#### Download images to Google Drive and augment them to increase training dataset size  \n",
        "  "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TTW5qHqjvWSS"
      },
      "source": [
        "# Define functions\n",
        "\n",
        "# So URL's don't get truncated & show all cols in display\n",
        "pd.set_option('display.max_colwidth',1000)\n",
        "pd.set_option('display.max_columns', None)\n",
        "\n",
        "# Optional: set seed to make augmentation reproducible across runs, otherwise will be random each time\n",
        "ia.seed(1) \n",
        "\n",
        "# TO DO: Type in the path to your working directory in form field to right\n",
        "wd = \"/content/drive/MyDrive/train\" #@param {type:\"string\"}\n",
        "%cd $wd\n",
        "\n",
        "# Take subset of only bats (Chiroptera)\n",
        "# TO DO: Enter taxa to filter by in form field\n",
        "filter = \"Chiroptera\" #@param {type:\"string\"}\n",
        "global filter\n",
        "\n",
        "# Define start and stop indices in EOL crops file  \n",
        "def set_start_stop():\n",
        "    # To test with a tiny subset, use first 5 bundle images\n",
        "    if test_with_tiny_subset:\n",
        "        start=0\n",
        "        stop=5\n",
        "    # To run for all images\n",
        "    else:\n",
        "        start=None\n",
        "        stop=None\n",
        "    \n",
        "    return start, stop\n",
        "\n",
        "# To display an image already loaded into the runtime\n",
        "def display_image(image):\n",
        "  fig = plt.figure(figsize=(20, 15))\n",
        "  plt.grid(False)\n",
        "  plt.imshow(image)\n",
        "\n",
        "# To draw cropping coordinates on an image\n",
        "def draw_boxes(image, box, class_name):\n",
        "  image_wboxes = cv2.rectangle(image, (box[0], box[1]), (box[2], box[3]), \\\n",
        "                               (255, 0, 157), 3) # change box color and thickness\n",
        "  \n",
        "  return image_wboxes\n",
        "\n",
        "# Define image augmentation pipeline\n",
        "# modified from https://github.com/aleju/imgaug\n",
        "seq = iaa.Sequential([\n",
        "    iaa.Crop(px=(1, 16), keep_size=False), # crop by 1-16px, resize resulting image to orig dims\n",
        "    iaa.Affine(rotate=(-25, 25)), # rotate -25 to 25 degrees\n",
        "    iaa.GaussianBlur(sigma=(0, 3.0)), # blur using gaussian kernel with sigma of 0-3\n",
        "    iaa.AddToHueAndSaturation((-50, 50), per_channel=True)\n",
        "])\n",
        "\n",
        "# To augment an image\n",
        "def augment_image(image, crops, filter=filter):\n",
        "    # TO DO: Type the name of the folder for images to the right\n",
        "    folder = \"test\" #@param {type:\"string\"}\n",
        "    pathbase = folder + '/'\n",
        "    class_name = filter\n",
        "\n",
        "    # Define image info needed for export\n",
        "    im_h, im_w = image.shape[:2]\n",
        "    xmin = crops.xmin[i].astype(int)\n",
        "    ymin = crops.ymin[i].astype(int)\n",
        "    xmax = crops.xmax[i].astype(int)\n",
        "    ymax = crops.ymax[i].astype(int)\n",
        "    box = [xmin, ymin, xmax, ymax]\n",
        "    fn = str(crops['data_object_id'][i]) + '.jpg'\n",
        "    fpath = pathbase + fn\n",
        "    \n",
        "    # Export unaugmented image info for future use training object detectors\n",
        "    with open(outfpath, 'a') as out_file:\n",
        "          tsv_writer = csv.writer(out_file, delimiter='\\t')\n",
        "          tsv_writer.writerow([crops.data_object_id[i], crops.obj_url[i], \\\n",
        "                              im_h, im_w, box[0], box[1], \\\n",
        "                              box[2], box[3], fn, fpath, class_name])\n",
        "\n",
        "    # Load original bounding box coordinates to imgaug format\n",
        "    bb  = ia.BoundingBox(x1=xmin, y1=ymin, x2=xmax, y2=ymax)        \n",
        "    bb = BoundingBoxesOnImage([bb], shape=image.shape)\n",
        "    \n",
        "    # Augment image using settings defined above in seq\n",
        "    image_aug, bb_aug = seq.augment(image=image, bounding_boxes=bb)\n",
        "\n",
        "    # Define augmentation results needed for export\n",
        "    fn_aug = str(crops['data_object_id'][i]) + '_aug' + '.jpg'\n",
        "    fpath_aug = pathbase + fn_aug\n",
        "    im_h_aug, im_w_aug = image_aug.shape[:2]\n",
        "    xmin_aug = bb_aug.bounding_boxes[0].x1.astype(int)\n",
        "    ymin_aug = bb_aug.bounding_boxes[0].y1.astype(int)\n",
        "    xmax_aug = bb_aug.bounding_boxes[0].x2.astype(int)\n",
        "    ymax_aug = bb_aug.bounding_boxes[0].y2.astype(int)\n",
        "    box_aug = [xmin_aug, ymin_aug, xmax_aug, ymax_aug]\n",
        "        \n",
        "    # Export augmentation results for future use training object detectors\n",
        "    with open(outfpath, 'a') as out_file:\n",
        "          tsv_writer = csv.writer(out_file, delimiter='\\t')\n",
        "          tsv_writer.writerow([crops.data_object_id[i], crops.obj_url[i], \\\n",
        "                              im_h_aug, im_w_aug, box_aug[0], box_aug[1], \\\n",
        "                              box_aug[2], box_aug[3], fn_aug, fpath_aug, class_name])\n",
        "\n",
        "    # Draw augmented bounding box and image\n",
        "    # Only use for up to 50 images\n",
        "    if display_results:\n",
        "        image_wboxes = draw_boxes(image_aug, box_aug, class_name)\n",
        "        display_image(image_wboxes)\n",
        "        plt.title('{}) Successfully augmented image from {}'.format(format(i+1, '.0f'), url))\n",
        "    \n",
        "    return image_aug, fn_aug, fpath_aug, box_aug\n",
        "\n",
        "# Remove out of bounds values\n",
        "def remove_oob(crops):\n",
        "    # Set negative values to 0\n",
        "    crops.xmin[crops.xmin < 0] = 0\n",
        "    crops.ymin[crops.ymin < 0] = 0\n",
        "\n",
        "    # Remove out of bounds cropping dimensions\n",
        "    ## When crop height > image height, set crop height equal to image height\n",
        "    idx = crops.index[crops.ymax > crops.im_height]\n",
        "    crops.ymin.iloc[idx] = 0\n",
        "    crops.ymax.iloc[idx] = crops.im_height.iloc[idx]\n",
        "    ## When crop width > image width, set crop width equal to image width\n",
        "    idx = crops.index[crops.xmax > crops.im_width]\n",
        "    crops.xmin.iloc[idx] = 0\n",
        "    crops.xmax.iloc[idx] = crops.im_width.iloc[idx]\n",
        "\n",
        "    # Write relevant results to csv formatted for training and annotations needed by Tensorflow and YOLO\n",
        "    crops_oobrem = crops[['xmin', 'ymin', 'xmax', 'ymax',\n",
        "                  'filename', 'im_width', 'im_height', 'class']]\n",
        "\n",
        "    return crops_oobrem\n",
        "\n",
        "# Write header of crops_aug.tsv before looping through crops for remaining data\n",
        "outfpath = 'data/' + filter + '_crops' + '_train' + '_aug' + '.tsv'\n",
        "with open(outfpath, 'a') as out_file:\n",
        "    tsv_writer = csv.writer(out_file, delimiter='\\t')\n",
        "    tsv_writer.writerow([\"data_object_id\",\t\"obj_url\",\t\"im_height\",\t\"width\",\t\"xmin\",\n",
        "                        \"ymin\",\t\"xmax\",\t\"ymax\",\t\"filename\",\t\"path\",\t\"class\"])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P31JjHddVSEm"
      },
      "source": [
        "# Augment images and bounding boxes & save to Google Drive\n",
        "\n",
        "# Read in EOL user generated cropping data\n",
        "fpath = \"data/\" + filter + \"_crops\" + \"_train\" + \".tsv\"\n",
        "crops = read_datafile(fpath, disp_head=False)\n",
        "\n",
        "# Test with a smaller subset than 5k images?\n",
        "# TO DO: If yes, check test_with_tiny_subset box\n",
        "test_with_tiny_subset = True #@param {type: \"boolean\"}\n",
        "\n",
        "# Display detection results on images?\n",
        "# TO DO: Check display_results box if \"Yes\"\n",
        "# Note: Only run for <50 images at a time\n",
        "display_results = False #@param {type:\"boolean\"}\n",
        "\n",
        "# Loop to perform image augmentation for each image in crops\n",
        "print(\"Augmenting and downloading training images\")\n",
        "start, stop = set_start_stop()\n",
        "\n",
        "for i, row in crops.iloc[start:stop].iterrows():\n",
        "    try:\n",
        "        # Load image from url\n",
        "        # Use imread instead of imageio.imread to load images from url and get consistent output type and shape\n",
        "        url = crops[\"obj_url\"][i]\n",
        "        with urlopen(url) as file:\n",
        "            image = imread(file, mode='RGB')\n",
        "\n",
        "        # Augment the image and bounding box\n",
        "        image_aug, fpath_aug = augment_image(image, crops)\n",
        "\n",
        "        # Save augmented image to Google Drive\n",
        "        imageio.imwrite(fpath_aug, image_aug)\n",
        "\n",
        "        # Save unaugmented image to Google Drive\n",
        "        fpath = fpath_aug.replace(\"_aug\", \"\")\n",
        "        imageio.imwrite(fpath, image)\n",
        "    \n",
        "        # Display message to track augmentation process by image\n",
        "        print('{}) Successfully downloaded & augmented image from {}'.format(format(i+1, '.0f'), url))\n",
        "  \n",
        "    except:\n",
        "        print('{}) Error: check if web address for image from {} is valid'.format(format(i+1, '.0f'), url))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2USBcEu3osBM"
      },
      "source": [
        "#### Remove out of bounds values from train crops and export results for use with object detection models"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6yJvWJ7_CbX1"
      },
      "source": [
        "# Read in crops_aug.tsv from above\n",
        "outfpath = 'data/' + filter + '_crops' + '_train' + '_aug' + '.tsv'\n",
        "crops = read_datafile(outfpath, disp_head=False)\n",
        "\n",
        "# Remove out of bounds values\n",
        "crops_oobrem = remove_oob(crops)\n",
        "\n",
        "# Save results for use training object detectors\n",
        "outfpath = os.path.splitext(outfpath)[0] + '_oob_rem_fin' + '.csv' \n",
        "crops_oobrem.to_csv(outfpath, sep=',', index=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r7JGKXra8TTQ"
      },
      "source": [
        "## Pre-process test images\n",
        "---\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g-0sIeHqo_b_"
      },
      "source": [
        "#### Download test images to Google Drive and write new df with updated filenames and paths "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PBRFjkWQ2KA1"
      },
      "source": [
        "# Define functions\n",
        "\n",
        "# TO DO: Type in the path to your working directory in form field to right\n",
        "wd = \"/content/drive/MyDrive/train\" #@param {type:\"string\"}\n",
        "%cd $wd\n",
        "\n",
        "# Take subset of only bats (Chiroptera)\n",
        "# TO DO: Enter taxa to filter by in form field\n",
        "filter = \"Chiroptera\" #@param {type:\"string\"}\n",
        "global filter\n",
        "\n",
        "# Suppress pandas warning about writing over a copy of data\n",
        "pd.options.mode.chained_assignment = None  # default='warn'\n",
        "\n",
        "# Define start and stop indices in EOL crops file  \n",
        "def set_start_stop():\n",
        "    # To test with a tiny subset, use first 5 bundle images\n",
        "    if test_with_tiny_subset:\n",
        "        start=0\n",
        "        stop=5\n",
        "    # To run for all images\n",
        "    else:\n",
        "        start=None\n",
        "        stop=None\n",
        "    \n",
        "    return start, stop\n",
        "\n",
        "# Get info from EOL user generated cropping file\n",
        "def get_image_info(image, crops):    \n",
        "    # TO DO: Type the name of the folder for images to the right\n",
        "    folder = \"test\" #@param {type:\"string\"}\n",
        "    pathbase = folder + '/'\n",
        "    class_name = filter\n",
        "\n",
        "    # Define image info needed for export\n",
        "    im_h, im_w = image.shape[:2]\n",
        "    xmin = crops.xmin[i].astype(int)\n",
        "    ymin = crops.ymin[i].astype(int)\n",
        "    xmax = crops.xmax[i].astype(int)\n",
        "    ymax = crops.ymax[i].astype(int)\n",
        "    box = [xmin, ymin, xmax, ymax]\n",
        "    fn = str(crops['data_object_id'][i]) + '.jpg'\n",
        "    fpath = pathbase + fn\n",
        "    \n",
        "    # Export to crops_test.tsv\n",
        "    with open(outfpath, 'a') as out_file:\n",
        "            tsv_writer = csv.writer(out_file, delimiter='\\t')\n",
        "            tsv_writer.writerow([crops.data_object_id[i], crops.obj_url[i], \\\n",
        "                                 im_h, im_w, box[0], box[1], box[2], box[3], \\\n",
        "                                 fn, fpath, class_name])\n",
        "\n",
        "    return fpath\n",
        "\n",
        "# Remove out of bounds values\n",
        "def remove_oob(crops):\n",
        "    # Set negative values to 0\n",
        "    crops.xmin[crops.xmin < 0] = 0\n",
        "    crops.ymin[crops.ymin < 0] = 0\n",
        "\n",
        "    # Remove out of bounds cropping dimensions\n",
        "    ## When crop height > image height, set crop height equal to image height\n",
        "    idx = crops.index[crops.ymax > crops.im_height]\n",
        "    crops.ymin.iloc[idx] = 0\n",
        "    crops.ymax.iloc[idx] = crops.im_height.iloc[idx]\n",
        "    ## When crop width > image width, set crop width equal to image width\n",
        "    idx = crops.index[crops.xmax > crops.im_width]\n",
        "    crops.xmin.iloc[idx] = 0\n",
        "    crops.xmax.iloc[idx] = crops.im_width.iloc[idx]\n",
        "\n",
        "    # Write relevant results to csv formatted for training and annotations needed by Tensorflow and YOLO\n",
        "    crops_oobrem = crops[['xmin', 'ymin', 'xmax', 'ymax',\n",
        "                  'filename', 'im_width', 'im_height', 'class']]\n",
        "\n",
        "    return crops_oobrem\n",
        "\n",
        "# Write header of crops_test_notaug.tsv before looping through crops for other data\n",
        "fpath = \"data/\" + filter + \"_crops\" + \"_test\" + \".tsv\"\n",
        "outfpath = os.path.splitext(fpath)[0] + '_notaug' + '.tsv'\n",
        "with open(outfpath, 'a') as out_file:\n",
        "        tsv_writer = csv.writer(out_file, delimiter='\\t')\n",
        "        tsv_writer.writerow([\"data_object_id\",\t\"obj_url\",\t\"im_height\",\t\"im_width\",\t\"xmin\",\n",
        "                              \"ymin\",\t\"xmax\",\t\"ymax\",\t\"filename\",\t\"path\",\t\"class\"])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iDzSp9jv8Sak"
      },
      "source": [
        "# Save images and bounding boxes to Google Drive\n",
        "\n",
        "# Read in EOL user generated cropping data\n",
        "crops = read_datafile(fpath, disp_head=True)\n",
        "\n",
        "# Test with a smaller subset than 5k images?\n",
        "# TO DO: If yes, check test_with_tiny_subset box\n",
        "test_with_tiny_subset = True #@param {type: \"boolean\"}\n",
        "\n",
        "# Loop through crop test data\n",
        "print(\"Downloading testing images\")\n",
        "start, stop = set_start_stop()\n",
        "\n",
        "for i, row in crops.iloc[start:stop].iterrows():\n",
        "    try:\n",
        "        # Load image from url\n",
        "        # Use imread instead of imageio.imread to load images from url and get consistent output type and shape\n",
        "        url = crops[\"obj_url\"][i]\n",
        "        with urlopen(url) as file:\n",
        "            image = imread(file, mode='RGB')\n",
        "\n",
        "        # Define variables needed in exported dataset\n",
        "        fpath = get_image_info(image, crops)\n",
        "\n",
        "        # Save image to Google Drive\n",
        "        imageio.imwrite(fpath, image)\n",
        "    \n",
        "        # Display message to track download process by image\n",
        "        print('{}) Successfully downloaded image from {}'.format(format(i+1, '.0f'), url))\n",
        "  \n",
        "    except:\n",
        "        print('{}) Error: check if web address for image from {} is valid'.format(format(i+1, '.0f'), url))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DxKEXLBlpON0"
      },
      "source": [
        "#### Remove out of bounds values from train crops and export results for use with object detection models"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NGHCbNh3jaKM"
      },
      "source": [
        "# Read in crops_aug.tsv from above\n",
        "outfpath = 'data/' + filter + '_crops' + '_test' + '_notaug' + '.tsv'\n",
        "crops = read_datafile(outfpath, disp_head=False)\n",
        "\n",
        "# Remove out of bounds values\n",
        "crops_oobrem = remove_oob(crops)\n",
        "\n",
        "# Save results for use training object detectors\n",
        "outfpath = os.path.splitext(outfpath)[0] + '_oob_rem_fin' + '.csv' \n",
        "crops_oobrem.to_csv(outfpath, sep=',', index=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oiG0eCADiZJs"
      },
      "source": [
        "## Inspect pre-preprocessed crops on images\n",
        "---\n",
        "If needed, adjust \"iaa.Sequential\" augmentation parameters and/or \"remove_oob\" transformations above and re-visualize until desired results are acheived."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8bpzs2Koi1Vi"
      },
      "source": [
        "# Define functions\n",
        "\n",
        "import cv2\n",
        "from scipy.misc import imread\n",
        "\n",
        "# TO DO: Enter path to folder containing images\n",
        "im_path = \"test\" #@param {type:\"string\"}\n",
        "\n",
        "# Read in cropping file for displaying results\n",
        "# TO DO: Choose if you want to visualize final \"train\" or \"test\" coordinates\n",
        "pathbase = 'data/' + filter + '_crops_'\n",
        "dataset = \"test\" #@param [\"train\", \"test\"] {allow-input: true}\n",
        "if dataset == \"test\":\n",
        "    dataset = dataset + \"_notaug\"\n",
        "else:\n",
        "     dataset = dataset + \"_aug\"\n",
        "outfpath = pathbase + dataset + '_oob_rem_fin' + '.csv'\n",
        "df = read_datafile(outfpath, sep=',', disp_head=True)\n",
        "\n",
        "# Draw cropping box on image\n",
        "def draw_box_on_image(df, img):\n",
        "    # Get box coordinates\n",
        "    xmin = df['xmin'][i].astype(int)\n",
        "    ymin = df['ymin'][i].astype(int)\n",
        "    xmax = df['xmax'][i].astype(int)\n",
        "    ymax = df['ymax'][i].astype(int)\n",
        "    box = [xmin, ymin, xmax, ymax]\n",
        "\n",
        "    # Set box/font color and size\n",
        "    maxdim = max(df['im_height'][i],df['im_width'][i])\n",
        "    fontScale = maxdim/600\n",
        "    box_col = (255, 0, 157)\n",
        "  \n",
        "    # Add label to image\n",
        "    tag = df['class'][i]\n",
        "    image_wbox = cv2.putText(img, tag, (xmin+7, ymax-12), cv2.FONT_HERSHEY_SIMPLEX, fontScale, box_col, 2, cv2.LINE_AA)  \n",
        "  \n",
        "    # Draw box label on image\n",
        "    image_wbox = cv2.rectangle(img, (xmin, ymax), (xmax, ymin), box_col, 5)\n",
        "\n",
        "    return image_wbox, box"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wppitLbXjTE0"
      },
      "source": [
        "# Display crop dimensions on images\n",
        "\n",
        "# TO DO: Adjust line below to see up to 50 images displayed at a time\n",
        "start = 0 #@param {type:\"slider\", min:0, max:5000, step:50}\n",
        "stop = start+50\n",
        "\n",
        "# Loop through images\n",
        "for i, row in df.iloc[start:stop].iterrows():\n",
        "    # Read in image \n",
        "    fn = df['filename'][i]\n",
        "    fpath = im_path + '/' + fn\n",
        "    img = imread(fpath, mode='RGB')\n",
        "  \n",
        "    # Draw bounding box on image\n",
        "    image_wbox, box = draw_box_on_image(df, img)\n",
        "  \n",
        "    # Plot cropping box on image\n",
        "    _, ax = plt.subplots(figsize=(10, 10))\n",
        "    ax.imshow(image_wbox)\n",
        "\n",
        "    # Display image URL and coordinatesabove image\n",
        "    # Helps with fine-tuning data transforms in post-processing steps above\n",
        "    plt.title('{} \\n xmin: {}, ymin: {}, xmax: {}, ymax: {}'.format(url, box[0], box[1], box[2], box[3]))"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}