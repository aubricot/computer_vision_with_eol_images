{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using YOLO in Darkflow to detect birds from images\n",
    "---\n",
    "*Last Updated 19 November 2019*   \n",
    "OS: Windows 10  \n",
    "GPU: NVIDIA GeForce GTX 970M  \n",
    "Requirements: Before running, need to install Visual Studio 2015 with Windows SDK, CUDA 10.0, cuDNN 7.6.0   \n",
    "Tensorflow-gpu version 2.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Start in the command prompt\n",
    "---\n",
    "Code only listed here as an example. These commands needs to be run in the command prompt window."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-5-30b2bf66b40f>, line 3)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-5-30b2bf66b40f>\"\u001b[1;36m, line \u001b[1;32m3\u001b[0m\n\u001b[1;33m    mkdir yolo_imgdetect3\u001b[0m\n\u001b[1;37m                        ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "# in your chosen working directory, make a new folder 'yolo_imgdetect/'\n",
    "mkdir yolo_imgdetect\n",
    "cd yolo_imgdetect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make sure you are using Python 3.6\n",
    "# install packages using pip\n",
    "python --version\n",
    "pip install tensorflow-gpu==1.15.0rc2\n",
    "pip install cython\n",
    "pip install opencv-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-1-b37ad199b32c>, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-1-b37ad199b32c>\"\u001b[1;36m, line \u001b[1;32m1\u001b[0m\n\u001b[1;33m    git clone https://github.com/pjreddie/darknet\u001b[0m\n\u001b[1;37m            ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "# download and compile darknet (the underlying framework of YOLO)\n",
    "git clone https://github.com/pjreddie/darknet\n",
    "cd darknet\n",
    "python setup.py build_ext --inplace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# install darkflow, the tensorflow implementation of darknet\n",
    "git clone https://github.com/thtrieu/darkflow.git\n",
    "pip install ."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download the pre-trained object detection weight files\n",
    "---   \n",
    "The models are already in darkflow/cfg, but the weights associated with these models need to be downloaded from https://pjreddie.com/media/files/yolov3.weights and https://drive.google.com/drive/folders/0B1tW_VtY7onidEwyQ2FtQVplWEU. After downloading, move them to darkflow/bin "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-1-c7798915f399>, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-1-c7798915f399>\"\u001b[1;36m, line \u001b[1;32m1\u001b[0m\n\u001b[1;33m    python setup.py build_ext --inplace\u001b[0m\n\u001b[1;37m               ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "# test installation, you should see an output with different parameters for flow\n",
    "python flow --h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# open Jupyter Notebook in the current working directory\n",
    "jupyter notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Here in Jupyter Notebook\n",
    "---   \n",
    "This is where you will run the images through the object detection model and you will be able to see the outputs as labelled images with detection classes and confidence scores within this browser window below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "from darkflow.net.build import TFNet\n",
    "import matplotlib.pyplot as plt\n",
    "import pathlib\n",
    "import time\n",
    "import numpy as np\n",
    "import csv\n",
    "import os\n",
    "\n",
    "%config InlineBackend.figure_format = 'svg'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### \"Flow\" the images through the model\n",
    "---   \n",
    "Ignore the warning messages about deprecated names, they still work at the time posting this. \n",
    "\n",
    "Your output should be a table of values like those shown below:\n",
    "\n",
    "Source | Train? | Layer description                | Output size\n",
    "------- |:--------:|:----------------------------------:| ---------------\n",
    "       |        | input                            | (?, 448, 448, 3)\n",
    " Load  |  Yep!  | scale to (-1, 1)                 | (?, 448, 448, 3)\n",
    " Load  |  Yep!  | conv 3x3p1_1    leaky            | (?, 448, 448, 16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parsing ./cfg/yolo-tiny.cfg\n",
      "Parsing cfg\\yolo-tiny.cfg\n",
      "Loading bin\\yolo-tiny.weights ...\n",
      "Successfully identified 180357512 bytes\n",
      "Finished in 0.0069811344146728516s\n",
      "Model has a VOC model name, loading VOC labels.\n",
      "\n",
      "Building net ...\n",
      "WARNING:tensorflow:From C:\\Users\\kwolcott\\Documents\\python\\image_recognition\\yolo_imgdetect\\darkflow\\net\\build.py:105: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "Source | Train? | Layer description                | Output size\n",
      "-------+--------+----------------------------------+---------------\n",
      "       |        | input                            | (?, 448, 448, 3)\n",
      " Load  |  Yep!  | scale to (-1, 1)                 | (?, 448, 448, 3)\n",
      " Load  |  Yep!  | conv 3x3p1_1    leaky            | (?, 448, 448, 16)\n",
      "WARNING:tensorflow:From C:\\Users\\kwolcott\\Documents\\python\\image_recognition\\yolo_imgdetect\\darkflow\\net\\ops\\simple.py:106: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n",
      " Load  |  Yep!  | maxp 2x2p0_2                     | (?, 224, 224, 16)\n",
      " Load  |  Yep!  | conv 3x3p1_1    leaky            | (?, 224, 224, 32)\n",
      " Load  |  Yep!  | maxp 2x2p0_2                     | (?, 112, 112, 32)\n",
      " Load  |  Yep!  | conv 3x3p1_1    leaky            | (?, 112, 112, 64)\n",
      " Load  |  Yep!  | maxp 2x2p0_2                     | (?, 56, 56, 64)\n",
      " Load  |  Yep!  | conv 3x3p1_1    leaky            | (?, 56, 56, 128)\n",
      " Load  |  Yep!  | maxp 2x2p0_2                     | (?, 28, 28, 128)\n",
      " Load  |  Yep!  | conv 3x3p1_1    leaky            | (?, 28, 28, 256)\n",
      " Load  |  Yep!  | maxp 2x2p0_2                     | (?, 14, 14, 256)\n",
      " Load  |  Yep!  | conv 3x3p1_1    leaky            | (?, 14, 14, 512)\n",
      " Load  |  Yep!  | maxp 2x2p0_2                     | (?, 7, 7, 512)\n",
      " Load  |  Yep!  | conv 3x3p1_1    leaky            | (?, 7, 7, 1024)\n",
      " Load  |  Yep!  | conv 3x3p1_1    leaky            | (?, 7, 7, 1024)\n",
      " Load  |  Yep!  | conv 3x3p1_1    leaky            | (?, 7, 7, 1024)\n",
      "WARNING:tensorflow:From c:\\users\\kwolcott\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorflow_core\\contrib\\layers\\python\\layers\\layers.py:1634: flatten (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.flatten instead.\n",
      "WARNING:tensorflow:From c:\\users\\kwolcott\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorflow_core\\python\\layers\\core.py:332: Layer.apply (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `layer.__call__` method instead.\n",
      " Load  |  Yep!  | flat                             | (?, 50176)\n",
      " Load  |  Yep!  | full 50176 x 256  linear         | (?, 256)\n",
      " Load  |  Yep!  | full 256 x 4096  leaky           | (?, 4096)\n",
      "WARNING:tensorflow:From C:\\Users\\kwolcott\\Documents\\python\\image_recognition\\yolo_imgdetect\\darkflow\\net\\ops\\simple.py:90: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      " Load  |  Yep!  | drop                             | (?, 4096)\n",
      " Load  |  Yep!  | full 4096 x 1470  linear         | (?, 1470)\n",
      "-------+--------+----------------------------------+---------------\n",
      "GPU mode with 1.0 usage\n",
      "Finished in 11.060079336166382s\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# define parameters for \"flow\"ing the images through the model\n",
    "params = {\n",
    "    'model': 'cfg\\yolo-tiny.cfg',\n",
    "    'load': 'bin\\yolo-tiny.weights',\n",
    "    'threshold': 0.3,\n",
    "    'gpu': 1.0\n",
    "}\n",
    "\n",
    "# run the model\n",
    "tfnet = TFNet(params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set the path to the sample images\n",
    "You can also delete the images from this folder and replace them with your own"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[WindowsPath('sample_img/542.10578857864.jpg'),\n",
       " WindowsPath('sample_img/542.15445377044.jpg'),\n",
       " WindowsPath('sample_img/542.4801468374.jpg'),\n",
       " WindowsPath('sample_img/542.7816025222.jpg')]"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# this is the image path 'yolo_imgdetect/sample_img'\n",
    "PATH_TO_SAMPLE_IMAGES_DIR = pathlib.Path('sample_img')\n",
    "SAMPLE_IMAGE_PATHS = sorted(list(PATH_TO_TEST_IMAGES_DIR.glob(\"*.jpg\")))\n",
    "SAMPLE_IMAGE_PATHS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define function used to draw bounding boxes\n",
    "You can adjust the parameters so that bounding boxes are only shown for certain confidence or class values.\n",
    "Here boxes are shown when confidence > 0.3 and object class is 'bird'. This function is modified from here https://gist.github.com/deep-diver/40f092ad56525189674a86b6fde6d304."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "def boxing(img, predictions):\n",
    "    newImage = np.copy(img)\n",
    "    im_height, im_width, im_depth = img.shape\n",
    "        \n",
    "    for result in predictions:\n",
    "        xmin = result['topleft']['x']\n",
    "        ymin = result['topleft']['y']\n",
    "\n",
    "        xmax = result['bottomright']['x']\n",
    "        ymax = result['bottomright']['y']\n",
    "\n",
    "        confidence = result['confidence']\n",
    "        label = result['label'] + \" \" + str(round(confidence, 3))\n",
    "\n",
    "        # only show boxes that are above .3 confidence and for the label, bird\n",
    "        if confidence > 0.3 and result['label'] == 'bird' :\n",
    "            with open('sample_img/out/sample_crops_yolo.tsv', 'a') as out_file:\n",
    "                tsv_writer = csv.writer(out_file, delimiter='\\t')\n",
    "                crop_width = xmax-xmin\n",
    "                crop_height = ymax-ymin\n",
    "                tsv_writer.writerow([os.path.splitext((os.path.basename(image_path)))[0], im_height, im_width, \n",
    "                            xmin, ymin, crop_height, crop_width])\n",
    "            fontScale = min(im_width,im_height)/(600)\n",
    "            newImage = cv2.rectangle(newImage, (xmin, ymax), (xmax, ymin), (255,0,0), 3)\n",
    "            newImage = cv2.putText(newImage, label, (xmin, ymax-5), cv2.FONT_HERSHEY_SIMPLEX, fontScale, (0, 230, 0), 7, cv2.LINE_AA)\n",
    "            \n",
    "    return newImage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run detector for all sample images\n",
    "---   \n",
    "Run the image detector for all images within 'sample_img/'. Results are plotted below and include the image with bounding box, class type, and confidence score. Inference times are printed below images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'SAMPLE_IMAGE_PATHS' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-7-7aa94c11af9f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# loop through all images in 'sample_img/'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[1;32mfor\u001b[0m \u001b[0mimage_path\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mSAMPLE_IMAGE_PATHS\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m   \u001b[0mimg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimage_path\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mIMREAD_COLOR\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m   \u001b[0mimg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcvtColor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mCOLOR_BGR2RGB\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'SAMPLE_IMAGE_PATHS' is not defined"
     ]
    }
   ],
   "source": [
    "# loop through all images in 'sample_img/'\n",
    "for image_path in SAMPLE_IMAGE_PATHS:\n",
    "  img = cv2.imread(str(image_path), cv2.IMREAD_COLOR)\n",
    "  img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "  # use YOLO for object detection  \n",
    "  # record inference time\n",
    "  start_time = time.time()\n",
    "  result = tfnet.return_predict(img)\n",
    "  end_time = time.time()\n",
    "  print(\"Inference time:\", end_time-start_time)\n",
    "\n",
    "  # plot and show detection boxes on images\n",
    "  _, ax = plt.subplots(figsize=(10, 10))\n",
    "  ax.imshow(boxing(img, result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
