{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.8"
    },
    "colab": {
      "name": "flowers_train.ipynb",
      "provenance": [],
      "private_outputs": true,
      "collapsed_sections": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/aubricot/computer_vision_with_eol_images/blob/master/classification_for_image_tagging/flowers/flowers_train.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4Rnwb_rgmJZB",
        "colab_type": "text"
      },
      "source": [
        "# Training Tensorflow MobileNetSSD v2 and Inception v3 models to classify flowers from images using PlantCLEF 2016 Images\n",
        "---\n",
        "*Last Updated 15 July 2020*   \n",
        "Train [MobileNet SSD v2](https://tfhub.dev/google/tf2-preview/mobilenet_v2/classification/4) and [Inception v3](https://tfhub.dev/google/imagenet/inception_v3/classification/4) to classify flowers from EOL images. Images are classified into flower, fruit, entire, stem, leaf, or branch using the [PlantCLEF 2016 Image dataset](https://www.imageclef.org/lifeclef/2016/plant). Because the PlantCLEF 2016 dataset used includes other categories, they will be tested, but accuracy for the flower class is the most important and other classes may be dropped depending on training results. Classifications will be used to generate image tags to improve searchability of EOLv3 images.\n",
        "\n",
        "PlantCLEF 2016 images were downloaded from [here](https://www.imageclef.org/lifeclef/2016/plant) locally to a PC. Then, 6,000 images were randomly selected and sorted into folders based on image class (flower, fruit, entire, stem, leaf, branch) using [plantclef_preprocessing.py](https://github.com/aubricot/computer_vision_with_eol_images/blob/master/classification_for_image_tagging/flowers/plantclef_preprocessing.py). Finally, images were zipped, uploaded to Google Drive, and unzipped before running this notebook (using a command like this in Colab: !unzip images.zip -d images).\n",
        "\n",
        "Initially, pre-trained MobileNet SSD v2 and Inception v3 models were fine-tuned to classify flower images. After 7 trials with sub-optimal results, custom-built models were made \"from scratch\" and trained for classification.\n",
        "\n",
        "**Best results for each model from 25 total trials:**   \n",
        "* MobileNet SSD v2 was trained for 5 hours to 150 epochs (45,000 steps).\n",
        "* Inception v3 was trained for 2 hours to 40 epochs (12,000 steps). \n",
        "* A third model was built \"from scratch\" and trained for 1 hour to 35 epochs (10,500 steps).\n",
        "\n",
        "**Notes**\n",
        "* Change filepaths or information using the form fields to the right of code blocks (also noted in code with 'TO DO')\n",
        "\n",
        "* Make sure to set the runtime to GPU Hardware Accelerator with a High Ram Runtime Shape (Runtime -> Change runtime type)\n",
        "\n",
        "**References**   \n",
        "* https://www.tensorflow.org/tutorials/customization/custom_training_walkthrough\n",
        "* https://www.tensorflow.org/tutorials/images/classification\n",
        "* https://medium.com/analytics-vidhya/create-tensorflow-image-classification-model-with-your-own-dataset-in-google-colab-63e9d7853a3e\n",
        "* https://colab.research.google.com/github/tensorflow/hub/blob/master/examples/colab/tf2_image_retraining.ipynb#scrollTo=umB5tswsfTEQ\n",
        "* https://medium.com/analytics-vidhya/how-to-do-image-classification-on-custom-dataset-using-tensorflow-52309666498e\n",
        "* https://blog.keras.io/building-powerful-image-classification-models-using-very-little-data.html"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nwKdj73Wpnlz",
        "colab_type": "text"
      },
      "source": [
        "## Imports   \n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yWAbU5tW1ONu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Mount google drive to import/export files\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QSLXg6G7mJZP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# For working with data and plotting graphs\n",
        "import itertools\n",
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# For image classification and training\n",
        "import tensorflow as tf\n",
        "import tensorflow_hub as hub\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Conv2D, Flatten, Dropout, MaxPooling2D\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "print(\"TF version:\", tf.__version__)\n",
        "print(\"Hub version:\", hub.__version__)\n",
        "print(\"GPU is\", \"available\" if tf.test.is_gpu_available() else \"NOT AVAILABLE\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ikRQ9LLbVHXQ",
        "colab_type": "text"
      },
      "source": [
        "## Train Classification Model(s)\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mvOpxBvKWCht",
        "colab_type": "text"
      },
      "source": [
        "### Training Dataset Preparation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YWylHChz4JTh",
        "colab_type": "text"
      },
      "source": [
        "#### If using pre-trained classifier\n",
        "Use dropdown menu on the right to choose which pre-trained model to use and set the image batch size for training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "77MDrSHntvWK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# TO DO: Select pre-trained model to use from Tensorflow Hub Model Zoo\n",
        "module_selection = (\"inception_v3\", 299) #@param [\"(\\\"mobilenet_v2_1.0_224\\\", 224)\", \"(\\\"inception_v3\\\", 299)\"] {type:\"raw\", allow-input: true}\n",
        "handle_base, pixels = module_selection\n",
        "\n",
        "if handle_base == \"inception_v3\":\n",
        "  MODULE_HANDLE =\"https://tfhub.dev/google/imagenet/inception_v3/classification/4\".format(handle_base)\n",
        "elif handle_base == \"mobilenet_v2_1.0_224\":\n",
        "  MODULE_HANDLE =\"https://tfhub.dev/google/tf2-preview/mobilenet_v2/classification/4\".format(handle_base) \n",
        "\n",
        "# TO DO: adjust batch size to make training faster or slower\n",
        "BATCH_SIZE = 16 #@param [\"16\", \"32\", \"64\", \"128\"]\n",
        "\n",
        "IMAGE_SIZE = (pixels, pixels)\n",
        "print(\"Using {} with input size {} and batch size {}\".format(handle_base, IMAGE_SIZE, BATCH_SIZE))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ocQ6gDasveZ5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# TO DO: Change directory to wherever images are stored\n",
        "PATH = '/content/drive/My Drive/summer20/classification/images' #@param {type:\"string\"}\n",
        "TRAINING_DATA_DIR = str(PATH)\n",
        "print(TRAINING_DATA_DIR)\n",
        "\n",
        "# TO DO: Adjust interpolation method and see how training results change\n",
        "interp = \"nearest\" #@param [\"nearest\", \"bilinear\"]\n",
        "\n",
        "# Set data generation and flow parameters\n",
        "datagen_kwargs = dict(rescale=1./255, validation_split=.20)\n",
        "dataflow_kwargs = dict(target_size=IMAGE_SIZE, batch_size=BATCH_SIZE,\n",
        "                    interpolation = interp)\n",
        "\n",
        "# Make test dataset\n",
        "test_datagen = ImageDataGenerator(**datagen_kwargs)\n",
        "test_generator = test_datagen.flow_from_directory(\n",
        "TRAINING_DATA_DIR,\n",
        "subset=\"validation\",\n",
        "shuffle=True,\n",
        "target_size=IMAGE_SIZE\n",
        ")\n",
        "\n",
        "# Make train dataset using augmentation parameters below\n",
        "train_datagen = ImageDataGenerator(\n",
        "    rotation_range=40, # randomly rotates image 0-40 degrees\n",
        "    horizontal_flip=True, # random horizontal flip\n",
        "    width_shift_range=0.2, height_shift_range=0.2, # randomly distorts height and width\n",
        "    shear_range=0.2, zoom_range=0.2, # randomly clips and zooms in on images\n",
        "    **datagen_kwargs)\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "    TRAINING_DATA_DIR, subset=\"training\", shuffle=True, **dataflow_kwargs)\n",
        "\n",
        "# Learn more about data batches\n",
        "image_batch_train, label_batch_train = next(iter(train_generator))\n",
        "print(\"Image batch shape: \", image_batch_train.shape)\n",
        "print(\"Label batch shape: \", label_batch_train.shape)\n",
        "dataset_labels = sorted(train_generator.class_indices.items(), key=lambda pair:pair[1])\n",
        "dataset_labels = np.array([key.title() for key, value in dataset_labels])\n",
        "print(dataset_labels)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LdeXMkjv4EJl",
        "colab_type": "text"
      },
      "source": [
        "#### If creating model from scratch\n",
        "* Select batch size from dropdown menu on the right  \n",
        "* Type in filepath to image directory using form field on the right"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Def61kAU4BXz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# TO DO: adjust batch size to make training faster or slower\n",
        "BATCH_SIZE = 16 #@param [\"16\", \"32\", \"64\", \"128\"]\n",
        "\n",
        "# Set input image size for model\n",
        "IMAGE_SIZE = (150, 150)\n",
        "\n",
        "# TO DO: Change directory to wherever images are stored\n",
        "PATH = '/content/drive/My Drive/summer20/classification/images' #@param {type:\"string\"}\n",
        "TRAINING_DATA_DIR = str(PATH)\n",
        "print(TRAINING_DATA_DIR)\n",
        "\n",
        "# TO DO: Adjust interpolation method and see how training results change\n",
        "interp = \"nearest\" #@param [\"nearest\", \"bilinear\"]\n",
        "\n",
        "# Set data generation and flow parameters\n",
        "datagen_kwargs = dict(rescale=1./255, validation_split=.20)\n",
        "dataflow_kwargs = dict(target_size=IMAGE_SIZE, batch_size=BATCH_SIZE,\n",
        "                    interpolation = interp)\n",
        "\n",
        "# Make test dataset\n",
        "test_datagen = ImageDataGenerator(**datagen_kwargs)\n",
        "test_generator = test_datagen.flow_from_directory(\n",
        "TRAINING_DATA_DIR,\n",
        "subset=\"validation\",\n",
        "shuffle=True,\n",
        "target_size=IMAGE_SIZE\n",
        ")\n",
        "\n",
        "# Make train dataset using augmentation parameters below\n",
        "train_datagen = ImageDataGenerator(\n",
        "    rotation_range=40, # randomly rotates image 0-40 degrees\n",
        "    horizontal_flip=True, # random horizontal flip\n",
        "    width_shift_range=0.2, height_shift_range=0.2, # randomly distorts height and width\n",
        "    shear_range=0.2, zoom_range=0.2, # randomly clips and zooms in on images\n",
        "    **datagen_kwargs)\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "    TRAINING_DATA_DIR, subset=\"training\", shuffle=True, **dataflow_kwargs)\n",
        "\n",
        "# Learn more about data batches\n",
        "image_batch_train, label_batch_train = next(iter(train_generator))\n",
        "print(\"Image batch shape: \", image_batch_train.shape)\n",
        "print(\"Label batch shape: \", label_batch_train.shape)\n",
        "dataset_labels = sorted(train_generator.class_indices.items(), key=lambda pair:pair[1])\n",
        "dataset_labels = np.array([key.title() for key, value in dataset_labels])\n",
        "print(dataset_labels)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "72N6UtPiVQNW",
        "colab_type": "text"
      },
      "source": [
        "### Model Preparation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8e8AxN-b113c",
        "colab_type": "text"
      },
      "source": [
        "#### If fine-tuning pre-trained model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g1pGKmlkVS1k",
        "colab_type": "code",
        "colab": {},
        "cellView": "both"
      },
      "source": [
        "# Build model\n",
        "print(\"Building model with\", handle_base)\n",
        "# TO DO: If model is overfitting, add/increase dropout rate\n",
        "dropout_rate = 0.2 #@param {type:\"slider\", min:0, max:0.5, step:0.1}\n",
        "\n",
        "def create_model():\n",
        "  model = tf.keras.Sequential([\n",
        "    InputLayer(input_shape=IMAGE_SIZE + (3,)),\n",
        "    hub.KerasLayer(MODULE_HANDLE, trainable=True),\n",
        "    Dropout(rate = dropout_rate), \n",
        "    Dense(train_generator.num_classes,\n",
        "                          kernel_regularizer=tf.keras.regularizers.l2(0.0001))\n",
        "  ])\n",
        "  \n",
        "  # Build model\n",
        "  model.build((None,)+IMAGE_SIZE+(3,))\n",
        "  \n",
        "  # Compile model\n",
        "  model.compile(\n",
        "    # Parameters for Adam optimizer\n",
        "    optimizer=tf.keras.optimizers.Adam(\n",
        "      learning_rate=0.001, beta_1=0.9, beta_2=0.999, epsilon=1e-07, amsgrad=False,\n",
        "      name='Adam'), \n",
        "      # Categorical cross entropy because 6 exclusive classes\n",
        "    loss=tf.keras.losses.CategoricalCrossentropy(from_logits=True, label_smoothing=0.1),\n",
        "    metrics=['accuracy'])\n",
        "  return model\n",
        "\n",
        "# Create new model instance\n",
        "model = create_model()\n",
        "\n",
        "# Steps per epoch and testing\n",
        "steps_per_epoch = train_generator.samples // train_generator.batch_size\n",
        "test_steps = test_generator.samples // test_generator.batch_size\n",
        "\n",
        "# Display model architecture\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5hh-3CQr1yGx",
        "colab_type": "text"
      },
      "source": [
        "#### Create new model from scratch"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JMpY5U9k_Tk-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Build model\n",
        "print(\"Building model from scratch\")\n",
        "# Modified from TF Image Classification Tutorial\n",
        "\n",
        "# To DO: Adjust model perforamance using below hyperparameters\n",
        "# See blog post for explanations https://www.pyimagesearch.com/2018/12/31/keras-conv2d-and-convolutional-layers/\n",
        "\n",
        "# If model is overfitting, add/increase dropout rate\n",
        "dropout_rate = 0.5 #@param {type:\"slider\", min:0, max:0.7, step:0.1}\n",
        "# Layer 1: Start with smaller number of filters and increase number if performance too low\n",
        "no_filters_lay1 = 32 #@param [\"32\", \"64\", \"128\"]\n",
        "# Layer 2: Use either the same number of layers as Layer 1, or 2x as many\n",
        "no_filters_lay2 = no_filters_lay1 #@param [\"no_filters_lay1\", \"no_filters_lay1 * 2\"] {type:\"raw\"}\n",
        "# Layer 3: Use 2x as many layers as Layer 2\n",
        "no_filters_lay3 = no_filters_lay2 * 2\n",
        "# Layer 1: If input image size >128, may need to use initial filter size of 5, 5\n",
        "filter_size_lay1 = (3, 3) #@param [\"(3, 3)\", \"(5, 5)\"]\n",
        "# Final Dense Layer: Set number of output nodes for network (same as number of classes)\n",
        "num_classes = 6 #@param {type:\"integer\"}\n",
        "# Compile model: Choose loss function. Categorical supposed to be better for multiple classes, but binary got better results one run\n",
        "loss_fun = \"categorical_crossentropy\" #@param [\"categorical_crossentropy\", \"binary_crossentropy\"]\n",
        "\n",
        "def create_model():\n",
        "  model = Sequential([\n",
        "    Conv2D(no_filters_lay1, filter_size_lay1, padding='same', activation='relu',\n",
        "        input_shape=(IMAGE_SIZE + (3,))),\n",
        "    MaxPooling2D(pool_size=(2, 2)),\n",
        "    Conv2D(no_filters_lay2, (3, 3), padding='same', activation='relu'),\n",
        "    MaxPooling2D(pool_size=(2, 2)),\n",
        "    Conv2D(no_filters_lay3, (3, 3), padding='same', activation='relu'),\n",
        "    MaxPooling2D(pool_size=(2, 2)),\n",
        "    Flatten(), # this converts our 3D feature maps to 1D feature vectors\n",
        "    Dense(64, activation='relu'),\n",
        "    Dropout(dropout_rate),\n",
        "    Dense(num_classes, activation='softmax') # softmax good for multiple class models with exclusive classes\n",
        "])\n",
        "\n",
        "  # Compile model\n",
        "  model.compile(loss=loss_fun,\n",
        "              optimizer='adam',\n",
        "              metrics=['accuracy'])\n",
        "  return model\n",
        "\n",
        "# Create model instance\n",
        "model = create_model()\n",
        "\n",
        "# Set steps per epoch and testing\n",
        "steps_per_epoch = train_generator.samples // train_generator.batch_size\n",
        "test_steps = test_generator.samples // test_generator.batch_size\n",
        "\n",
        "# Display model architecture\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A7ycnwnKkkfa",
        "colab_type": "text"
      },
      "source": [
        "### Actual Training \n",
        "---\n",
        "* For the first time training each model with specified hyper-parameters, go to **First time training**. If hyper-parameters are changed and a model is retrained, also go to **First time training**.   \n",
        "* If hyper-parameters are kept the same, and the model only needs to be trained for additional epochs, go to **Resume training from a saved checkpoint** below. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CNbToKXYlEo5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# TO DO: Adjust number of epochs to find balance between underfit and overfit for training\n",
        "num_epochs = '1' #@param {type:\"string\"}\n",
        "\n",
        "# Save each new training attempt results in new folder\n",
        "last_attempt = !ls /content/drive/'My Drive'/summer20/classification/saved_models/ | tail -n 1\n",
        "last_attempt = int(last_attempt.n)\n",
        "TRAIN_SESS_NUM = str(last_attempt + 1)\n",
        "CKPT_PATH = '/content/drive/My Drive/summer20/classification/saved_models/' + TRAIN_SESS_NUM + '/ckpt/cp-{epoch:04d}.ckpt' \n",
        "\n",
        "print(\"Last training attempt number:\", last_attempt)\n",
        "print(\"Training attempt number: {}, for {} epochs\".format(TRAIN_SESS_NUM, num_epochs))\n",
        "\n",
        "# Create a callback that saves the model's weights during training\n",
        "ckpt_callback = tf.keras.callbacks.ModelCheckpoint(filepath=CKPT_PATH,\n",
        "                                                 save_weights_only=True,\n",
        "                                                 verbose=1)\n",
        "\n",
        "# Save weights for 0th epoch\n",
        "model.save_weights(CKPT_PATH.format(epoch=0))\n",
        "\n",
        "# Train the model with the new callback\n",
        "hist = model.fit(\n",
        "    train_generator,\n",
        "    epochs=int(num_epochs), steps_per_epoch=steps_per_epoch,\n",
        "    callbacks=[ckpt_callback],\n",
        "    validation_data=test_generator,\n",
        "    validation_steps=test_steps).history\n",
        "\n",
        "# Save trained model \n",
        "saved_model_path = '/content/drive/My Drive/summer20/classification/saved_models/' + TRAIN_SESS_NUM\n",
        "tf.saved_model.save(model, saved_model_path)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Cpjn2qz-57p_",
        "colab_type": "text"
      },
      "source": [
        "### Review training results\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ionhn0UvmE-x",
        "colab_type": "text"
      },
      "source": [
        "#### Plot loss and accuracy for training session"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-kfOjJ3llGVY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Plot loss\n",
        "plt.figure()\n",
        "plt.title(\"Attempt {}:Training and Validation Loss\".format(TRAIN_SESS_NUM))\n",
        "plt.xlabel(\"Training Steps\")\n",
        "plt.ylim([0,2])\n",
        "plt.plot(hist[\"loss\"], label='Train')\n",
        "plt.plot(hist[\"val_loss\"], label='Test')\n",
        "plt.legend(loc='lower right')\n",
        "\n",
        "# Plot accuracy\n",
        "plt.figure()\n",
        "plt.title(\"Attempt {}:Training and Validation Accuracy\".format(TRAIN_SESS_NUM))\n",
        "plt.xlabel(\"Training Steps\")\n",
        "plt.ylim([0,1])\n",
        "plt.plot(hist[\"accuracy\"], label='Train')\n",
        "plt.plot(hist[\"val_accuracy\"], label='Test')\n",
        "plt.legend(loc='upper right')\n",
        "\n",
        "# Print final loss and accuracy values\n",
        "final_loss, final_accuracy = model.evaluate(test_generator, steps = test_steps)\n",
        "print('Final loss: {:.2f}'.format(final_loss))\n",
        "print('Final accuracy: {:.2f}%'.format(final_accuracy * 100))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ftZhnpyJmK-Z",
        "colab_type": "text"
      },
      "source": [
        "#### Display classification predictions for test images"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HIqlX8pYlju9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Define functions\n",
        "\n",
        "# TO DO: Do you want to display classification results for the most recently trained model?\n",
        "answer = \"No\" #@param [\"Yes\", \"No\"]\n",
        "# TO DO: If No, manually input desired training attempt number to the right\n",
        "if answer == \"Yes\":\n",
        "  # Display results from most recent training attempt\n",
        "  last_attempt = !ls /content/drive/'My Drive'/summer20/classification/saved_models/ | tail -n 1\n",
        "  TRAIN_SESS_NUM = str(last_attempt.n)\n",
        "else:\n",
        "  TRAIN_SESS_NUM = '23' #@param {type:\"string\"}\n",
        "\n",
        "# Load trained model from path\n",
        "saved_model_path = '/content/drive/My Drive/summer20/classification/saved_models/' + TRAIN_SESS_NUM\n",
        "flower_model = tf.keras.models.load_model(saved_model_path)\n",
        "\n",
        "# Generate test image batches\n",
        "test_image_batch, test_label_batch = next(iter(test_generator))\n",
        "true_label_ids = np.argmax(test_label_batch, axis=-1)\n",
        "print(\"Validation batch shape:\", test_image_batch.shape)\n",
        "\n",
        "# Run images through model for class predictions\n",
        "predictions = flower_model.predict(test_image_batch)\n",
        "predictions[0]\n",
        "np.argmax(predictions[0])\n",
        "\n",
        "# Function for plotting classification results with color-coded label if true or false prediction\n",
        "def plot_image(i, predictions_array, true_label, img):\n",
        "  predictions_array, true_label, img = predictions_array, np.argmax(true_label[i]), img[i]\n",
        "  plt.grid(False)\n",
        "  plt.xticks([])\n",
        "  plt.yticks([])\n",
        "  plt.imshow(img, cmap=plt.cm.binary)\n",
        "  # Color-code predictions if true or false\n",
        "  predicted_label = np.argmax(predictions_array)\n",
        "  if predicted_label == true_label:\n",
        "    color = 'blue'\n",
        "  else:\n",
        "    color = 'red'\n",
        "  plt.xlabel(\"{} {:2.0f}% ({})\".format(dataset_labels[predicted_label],\n",
        "                                100*np.max(predictions_array),\n",
        "                                dataset_labels[true_label]),\n",
        "                                color=color)\n",
        "\n",
        "# Function for plotting histogram with color-coded prediction probabilites for each class\n",
        "def plot_value_array(i, predictions_array, true_label):\n",
        "  predictions_array, true_label = predictions_array, np.argmax(true_label[i])\n",
        "  plt.grid(False)\n",
        "  plt.xticks(range(6))\n",
        "  plt.yticks([])\n",
        "  thisplot = plt.bar(range(6), predictions_array, color=\"#777777\")\n",
        "  plt.ylim([0, 1])\n",
        "  predicted_label = np.argmax(predictions_array)\n",
        "  thisplot[predicted_label].set_color('red')\n",
        "  thisplot[true_label].set_color('blue')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jWuEjMC7lqu3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Classify 1 image\n",
        "\n",
        "i = 0\n",
        "plt.figure(figsize=(6,3))\n",
        "plt.subplot(1,2,1)\n",
        "plot_image(i, predictions[i], test_label_batch, test_image_batch)\n",
        "plt.subplot(1,2,2)\n",
        "plot_value_array(i, predictions[i],  test_label_batch)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yRc2tjFftlPQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Classify 15 images\n",
        "\n",
        "# Plot the first X test images, their predicted labels, and the true labels.\n",
        "# Color correct predictions in blue and incorrect predictions in red.\n",
        "print(\"Attempt {}: Classification Results\".format(TRAIN_SESS_NUM))\n",
        "print('Final loss: {:.2f}'.format(final_loss))\n",
        "print('Final accuracy: {:.2f}%'.format(final_accuracy * 100))\n",
        "num_rows = 5\n",
        "num_cols = 3\n",
        "num_images = num_rows*num_cols\n",
        "plt.figure(figsize=(2*2*num_cols, 2*num_rows))\n",
        "for i in range(num_images):\n",
        "  plt.subplot(num_rows, 2*num_cols, 2*i+1)\n",
        "  plot_image(i, predictions[i], test_label_batch, test_image_batch)\n",
        "  plt.subplot(num_rows, 2*num_cols, 2*i+2)\n",
        "  plot_value_array(i, predictions[i], test_label_batch)\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}