{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNeE/Q5E3+cB3IcKShkRpOE",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/aubricot/computer_vision_with_eol_images/blob/master/classification_for_image_tagging/image_type/inspect_train_results.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_TcYNLBrWC0C"
      },
      "source": [
        "# Determine confidence threshold for Image Type Classification Models \n",
        "---\n",
        "*Last Updated 17 December 2022*   \n",
        "Choose which trained model and confidence threshold values to use for classifying EOL images as maps, phylogenies, illustrations, or herbarium sheets. Threshold values should be chosen that maximize coverage and minimize error.\n",
        "\n",
        "First, choose the 2 best models trained in [image_type_train.ipynb](https://colab.research.google.com/github/aubricot/computer_vision_with_eol_images/blob/master/classification_for_image_tagging/image_type/image_type_preprocessing.ipynb). Then, run this notebook.\n",
        "\n",
        "Run 500 images per class (map, phylogeny, illustration, herbarium sheet) through the best models chosen in image_type_train.ipynb for validation of model performance. Plot histograms of true and false predictions per class at binned confidence intervals to find the best performance by class and confidence threshold. (This is helpful because all models may not learn classes equally well).\n",
        "\n",
        "***Models were trained in Python 2 and TF 1 in October 2020: MobileNet SSD v2 was trained for 3 hours to 30 epochs with Batch Size=16, Lr=0.00001, Dropout=0.3, epsilon=1e-7, Adam optimizer. Final validation accuracy = 0.90. Inception v3 was trained for 3.5 hours to 30 epochs with Batch Size=16, Lr=0.0001, Dropout=0.2, epsilon=1, Adam optimizer. Final validation accuracy = 0.89.***\n",
        "\n",
        "Notes:   \n",
        "* Run code blocks by pressing play button in brackets on left\n",
        "* Before you you start: change the runtime to \"GPU\" with \"High RAM\"\n",
        "* Change parameters using form fields on right (find details at corresponding lines of code by searching '#@param')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZYW4W2aqdnTN"
      },
      "source": [
        "## Installs & Imports\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6k81-h_UV_ny"
      },
      "source": [
        "#@title Choose where to save results & set up directory structure\n",
        "# Use dropdown menu on right\n",
        "save = \"in Colab runtime (files deleted after each session)\" #@param [\"in my Google Drive\", \"in Colab runtime (files deleted after each session)\"]\n",
        "print(\"Saving results \", save)\n",
        "\n",
        "# Mount google drive to export file(s)\n",
        "if 'Google Drive' in save:\n",
        "    from google.colab import drive\n",
        "    drive.mount('/content/drive', force_remount=True)\n",
        "\n",
        "# Type in the path to your working directory in form field to right\n",
        "import os\n",
        "basewd = \"/content/drive/MyDrive/train/tf2\" #@param [\"/content/drive/MyDrive/train/tf2\"] {allow-input: true}\n",
        "if not os.path.exists(basewd):\n",
        "    os.makedirs(basewd)\n",
        "\n",
        "# Folder where inspect results outputs will be saved\n",
        "results_folder = \"inspect_resul\" #@param [\"inspect_resul\"] {allow-input: true}\n",
        "cwd = basewd + '/' + results_folder\n",
        "if not os.path.exists(cwd):\n",
        "    os.makedirs(cwd)\n",
        "print(\"\\nWorking directory set to: \\n\", cwd)\n",
        "\n",
        "# Enter image classes of interest in form field\n",
        "filters = ['herb', 'illus', 'map', 'null', 'phylo'] #@param [\"['herb', 'illus', 'map', 'null', 'phylo']\"] {type:\"raw\", allow-input: true}\n",
        "\n",
        "# Folder where image metadata was saved in image_type_preprocessing.ipynb\n",
        "data_folder = \"pre-processing/image_data\" #@param [\"pre-processing/image_data\"] {allow-input: true}\n",
        "data_wd = basewd + '/' + data_folder\n",
        "if not os.path.exists(data_wd):\n",
        "    !pip3 install --upgrade gdown\n",
        "    os.makedirs(data_wd)\n",
        "    print(\"\\nDownload image bundles for image type classes {}...\\n\".format(filters))\n",
        "    %cd $data_wd\n",
        "    file_ids = ['1Bkh2-TZSIKCCoKOTNr2L65BwR92Nx0vZ', '1m2sOLpUOWsw5RwzRtvj0mqH8aPloqnE_', \\\n",
        "                '1EIwPxyrawXnTPMyvO8f4nc1e3HALrTp9', '16I-_Qbh2IX_1Oz5wqlE6uzWXB2VhjE3e', \\\n",
        "                '1hQNgRLZWZu77XAxBwQIJOgRmWCCcpMos']\n",
        "    for file_id in file_ids:\n",
        "        !gdown $file_id\n",
        "print(\"\\nImage metadata directory set to: \\n\", data_wd)\n",
        "\n",
        "# Folder where saved models were stored in image_type_train.ipynb\n",
        "models_folder = \"saved_models\" #@param [\"saved_models\"] {allow-input: true}\n",
        "models_wd = basewd + '/' + models_folder\n",
        "if not os.path.exists(models_wd):\n",
        "    os.makedirs(models_wd)\n",
        "    print(\"\\nDownloading pre-trained EOL models for training attempts 11, 13...\\n\")\n",
        "    %cd $models_wd\n",
        "    file_ids = ['1Sxp742kescTGAUKlVkRR2hcoVo39y4pd', '1Fr1x5ZLXdd-DBZ7yRWx691orbtXh9lW1']\n",
        "    outfnames = ['11.zip', '13.zip']\n",
        "    for idx, file_id in enumerate(file_ids):\n",
        "        file_download_link = \"https://docs.google.com/uc?export=download&id=\" + file_id\n",
        "        outfname = outfnames[idx]\n",
        "        outfolder = outfnames[idx].split('.')[0]\n",
        "        !mkdir $outfolder\n",
        "        !gdown $file_id\n",
        "        !unzip $outfname -d .\n",
        "        outfpath = \"content/drive/MyDrive/summer20/classification/image_type/saved_models/\" + outfolder + \"/*\"\n",
        "        !mv -v $outfpath $outfolder\n",
        "        !rm -r content \n",
        "        !rm -r $outfname\n",
        "\n",
        "print(\"\\nSaved models directory set to: \\n\", models_wd)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1AGFM4fSWhbT"
      },
      "source": [
        "# For working with data\n",
        "import itertools\n",
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "# Suppress pandas setting with copy warning\n",
        "pd.options.mode.chained_assignment = None  # default='warn'\n",
        "\n",
        "# For downloading and displaying images\n",
        "import matplotlib.pyplot as plt\n",
        "from PIL import Image, ImageFile\n",
        "ImageFile.LOAD_TRUNCATED_IMAGES = True\n",
        "%matplotlib inline\n",
        "\n",
        "# For measuring inference time\n",
        "import time\n",
        "\n",
        "# For image classification and training\n",
        "import tensorflow as tf"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u2PEaR_a_0QH"
      },
      "source": [
        "## Run images through for classification and validating predictions (Run 1x for each trained model)   \n",
        "---\n",
        "Selected models from image_type_train.ipynb   \n",
        "* Run 11: Inception v3\n",
        "* Run 13: Mobilenet SSD v2"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "efIHQCtAAmYg"
      },
      "source": [
        "# Define functions\n",
        "\n",
        "# To read in EOL formatted data files\n",
        "def read_datafile(fpath, sep=\"\\t\", header=0, disp_head=True, lineterminator='\\n', encoding='latin1', dtype=None):\n",
        "    try:\n",
        "        df = pd.read_csv(fpath, sep=sep, header=header, lineterminator=lineterminator, encoding=encoding, dtype=dtype)\n",
        "        if disp_head:\n",
        "          print(\"Data header: \\n\", df.head())\n",
        "    except FileNotFoundError as e:\n",
        "        raise Exception(\"File not found: Enter the path to your file in form field and re-run\").with_traceback(e.__traceback__)\n",
        "    \n",
        "    return df\n",
        "\n",
        "# Define start and stop indices in EOL bundle for running inference   \n",
        "def set_start_stop(run, df):\n",
        "    # To test with a tiny subset, use 50 random bundle images\n",
        "    N = len(df)\n",
        "    if \"tiny subset\" in run:\n",
        "        start=np.random.choice(a=N, size=1)[0]\n",
        "        stop=start+50\n",
        "    # To run for a larger set, use 500 random images\n",
        "    else:\n",
        "        start=np.random.choice(a=N, size=1)[0]\n",
        "        stop=start+500\n",
        "    \n",
        "    return start, stop\n",
        "\n",
        "# Load saved model from directory\n",
        "def load_saved_model(models_wd, TRAIN_SESS_NUM, module_selection):\n",
        "    # Load trained model from path\n",
        "    saved_model_path = models_wd + '/' + TRAIN_SESS_NUM\n",
        "    model = tf.keras.models.load_model(saved_model_path)\n",
        "    # Get name and image size for model type\n",
        "    handle_base, pixels = module_selection\n",
        "\n",
        "    return model, pixels, handle_base\n",
        "\n",
        "# Get info about model based on training attempt number\n",
        "def get_model_info(TRAIN_SESS_NUM):\n",
        "    # Session 11\n",
        "    if int(TRAIN_SESS_NUM) == 11:\n",
        "        module_selection = (\"inception_v3\", 299)\n",
        "    # Session 13\n",
        "    elif int(TRAIN_SESS_NUM) == 13:\n",
        "        module_selection = (\"mobilenet_v2_1.0_224\", 224)\n",
        "    dataset_labels = filters \n",
        "\n",
        "    return module_selection, dataset_labels\n",
        "\n",
        "# Get test image filepaths\n",
        "def get_test_images(true_imclass):\n",
        "    impath = cwd + '/pre-processing/images/' + true_imclass\n",
        "    # If already custom-trained model, pull test images to inspect results for\n",
        "    if os.path.exists(impath):\n",
        "        demo = False # Not running in demo mode\n",
        "        fns = os.listdir(impath)\n",
        "        TEST_IMAGE_PATHS = [os.path.join(impath, fn) for fn in fns]\n",
        "        print(\"\\nUsing test images from: \\n\", impath)\n",
        "    # If running this script to test functionality, download dummy dataset from EOL image bundles\n",
        "    else:\n",
        "        demo = True # Running in demo mode using only Colab Runtime files\n",
        "        fns = os.listdir(data_wd)\n",
        "        TEST_IMAGE_PATHS = []\n",
        "        for fn in fns:\n",
        "            fpath = data_wd + '/' + fn\n",
        "            df = pd.read_csv(fpath, sep='\\n', header=None)\n",
        "            start=np.random.choice(a=len(df), size=1)[0]\n",
        "            stop=start+5\n",
        "            TEST_IMAGE_PATHS.extend(df.iloc[start:stop, 0].values.tolist())\n",
        "        print(\"\\nUsing 50 random images from each EOL image type bundle: \\n\", fns)\n",
        "\n",
        "    return TEST_IMAGE_PATHS, demo\n",
        "\n",
        "# Set filename for saving classification results\n",
        "def set_outfpath(true_imclass):\n",
        "    outfpath = cwd + '/image_type_' + TRAIN_SESS_NUM + '_' + true_imclass + '.csv'\n",
        "    print(\"\\nSaving results to: \\n\", outfpath)\n",
        "\n",
        "    return outfpath\n",
        "\n",
        "# Load in image from file\n",
        "def image_from_file(im_path):\n",
        "    imga = Image.open(im_path) # rgba (with transp)\n",
        "    colormode = imga.getbands()\n",
        "    img = imga.convert('RGB') # convert to rgb\n",
        "    image = img.resize([pixels,pixels])\n",
        "    image = np.reshape(image,[1,pixels,pixels,3])\n",
        "    image = image*1./255 # normalize colorspace\n",
        "\n",
        "    return image, colormode\n",
        "\n",
        "# Load in image from URL\n",
        "# Modified from https://colab.research.google.com/github/tensorflow/docs/blob/master/site/en/guide/saved_model.ipynb#scrollTo=JhVecdzJTsKE\n",
        "def image_from_url(url, fn):\n",
        "    file = tf.keras.utils.get_file(fn, url) # Filename doesn't matter\n",
        "    disp_img = tf.keras.preprocessing.image.load_img(file)\n",
        "    image = tf.keras.preprocessing.image.load_img(file, target_size=[pixels, pixels])\n",
        "    colormode = image.getbands()\n",
        "    image = tf.keras.preprocessing.image.img_to_array(image)\n",
        "    image = tf.keras.applications.mobilenet_v2.preprocess_input(\n",
        "        image[tf.newaxis,...])\n",
        "\n",
        "    return image, colormode\n",
        "\n",
        "# Get info from predictions to display on images\n",
        "def get_predict_info(predictions, i, stop, start):\n",
        "    # Get info from predictions\n",
        "    label_num = np.argmax(predictions[0], axis=-1)\n",
        "    conf = predictions[0][label_num]\n",
        "    im_class = dataset_labels[label_num]\n",
        "    # Display progress message after each image\n",
        "    print(\"Completed for {} of {} files\".format(i+1, format(stop-start, '.0f')))\n",
        "    \n",
        "    return label_num, conf, im_class\n",
        "\n",
        "# Make placeholder lists to fill for each class\n",
        "def make_placeholders():\n",
        "    filenames = []\n",
        "    confidences = []\n",
        "    true_imclasses = []\n",
        "    det_imclasses = []\n",
        "    colormodes = []\n",
        "\n",
        "    return filenames, confidences, true_imclasses, det_imclasses, colormodes\n",
        "    \n",
        "# Add values for each image to placeholder list\n",
        "def record_results(fn, conf, true_imclass, det_imclass, colormode):\n",
        "    filenames.append(fn)\n",
        "    confidences.append(conf)\n",
        "    true_imclasses.append(true_imclass)\n",
        "    det_imclasses.append(det_imclass)\n",
        "    colormodes.append(colormode)\n",
        "    results = [filenames, confidences, true_imclasses, det_imclasses, colormodes]\n",
        "\n",
        "    return results\n",
        "\n",
        "# Export results\n",
        "def export_results(results, outfpath):\n",
        "    results = pd.DataFrame(results)\n",
        "    results = results.transpose()\n",
        "    results.to_csv(outfpath, index=False, header=(\"filename\", \"confidence\", \n",
        "                                                     \"true_id\", \"det_id\", \"colormode\"))\n",
        "    print(\"\\nClassification predictions for image class {} being saved to : \\n{}\\n\".format(\n",
        "          true_imclass, outfpath))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0ZXo6iVvBF0G"
      },
      "source": [
        "#@title Run inference for chosen Training Session Number (11, 13) and dataset size\n",
        "%cd $cwd\n",
        "\n",
        "# Choose training attempt number to inspect results for\n",
        "TRAIN_SESS_NUM = \"13\" #@param [\"11\", \"13\"] {allow-input: true}\n",
        "\n",
        "# Test pipeline with a smaller subset than 5k images?\n",
        "run = \"test with tiny subset\" #@param [\"test with tiny subset\", \"for 500 images\"]\n",
        "print(\"Run: \", run)\n",
        "\n",
        "# Load saved model\n",
        "module_selection, dataset_labels = get_model_info(TRAIN_SESS_NUM)\n",
        "print(\"Loading saved model \", module_selection)\n",
        "model, pixels, handle_base = load_saved_model(models_wd, TRAIN_SESS_NUM, module_selection)\n",
        "\n",
        "# Run inference for each image class to compare known versus predicted image types\n",
        "true_imclasses = filters\n",
        "for true_imclass in true_imclasses:\n",
        "    print(\"Runing inference for class: {}\\n\".format(true_imclass))\n",
        "    # Set filename for saving classification results\n",
        "    outfpath = set_outfpath(true_imclass)\n",
        "    # Make placeholder lists to record values for each image\n",
        "    filenames, confidences, true_imclasses, det_imclasses, colormodes = make_placeholders()\n",
        "    # Get test images for running inference\n",
        "    df, demo = get_test_images(true_imclass)\n",
        "\n",
        "    # Run 500 random EOL bundle images through trained model\n",
        "    start, stop = set_start_stop(run, df)\n",
        "    for i, row in enumerate(df[start:stop], start=1):\n",
        "        try:\n",
        "            # Read in image from file\n",
        "            if demo:\n",
        "                url = row\n",
        "                fn = str(i) + '.jpg'\n",
        "                img, colormode = image_from_url(url, fn)\n",
        "            else:\n",
        "                img, colormode = image_from_file(row)\n",
        "        \n",
        "            # Image classification\n",
        "            start_time = time.time() # Record inference time\n",
        "            predictions = model.predict(img, batch_size=1)\n",
        "            label_num, conf, det_imclass = get_predict_info(predictions, i, stop, start)\n",
        "            end_time = time.time()\n",
        "            print(\"Inference time: {} sec\".format(format(end_time-start_time, '.2f')))\n",
        "\n",
        "            # Record results in placeholder lists to inspect results in next step\n",
        "            results = record_results(row, conf, true_imclass, det_imclass, colormode)\n",
        "\n",
        "        except:\n",
        "            pass\n",
        "\n",
        "    # Combine to df and export results\n",
        "    export_results(results, outfpath)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mnUCpn8sWVzi"
      },
      "source": [
        "#@title Combine model outputs for image type classes\n",
        "\n",
        "# Combine prediction files created in codeblock above\n",
        "base = 'image_type_' + TRAIN_SESS_NUM + '_'\n",
        "imclasses = filters\n",
        "all_filenames = [base + imclass + '.csv' for imclass in imclasses]\n",
        "all_predictions = pd.concat([pd.read_csv(f, sep=',', header=0, na_filter = False) for f in all_filenames])\n",
        "print(\"Model predictions for Training Attempt {}, {}:\".format(TRAIN_SESS_NUM, handle_base))\n",
        "print(\"Image type predictions combined for all classes. \\nNo. Images: {}\\n{}\".format(len(all_predictions), all_predictions[['filename', 'true_id', 'det_id']].head()))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bL_56etnd0Rd"
      },
      "source": [
        "## Plot prediction error and confidence for each class (Run 1x for each trained model)\n",
        "---   \n",
        "Use these histograms to find a confidence threshold value to optimize dataset coverage and accuracy"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9WWA93QDdnSb"
      },
      "source": [
        "### Plot histograms"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "code",
        "id": "gEyoDC1rL1Ub"
      },
      "source": [
        "# Define functions\n",
        "\n",
        "# Calculate prediction accuracy\n",
        "def get_accuracy(obs, all_vals):\n",
        "    # obs = observed, all_vals = observed + expected\n",
        "    if obs:\n",
        "        accuracy = format((obs/all_vals), '.2f')\n",
        "    else:\n",
        "        accuracy = 0\n",
        "    \n",
        "    return accuracy\n",
        "\n",
        "# Valide predictions by image class (and optionally, by: taxon)\n",
        "def validate_predict(df, inspect_by_taxon, taxon):\n",
        "    # If inspecting for taxon-specific images only\n",
        "    if inspect_by_taxon:\n",
        "        taxon = taxon\n",
        "        df = df.loc[df.ancestry.str.contains(taxon, case=False, na=False)]\n",
        "        print(\"Inspecting results for {}:\\n{}\".format(taxon, df.head()))\n",
        "    \n",
        "    # Validate predictions\n",
        "    # Check where true image types and model-determined classes match\n",
        "    df['det'] = (df['true_id'] == df['det_id'])\n",
        "    tru = df.loc[df.det, :] # True ID\n",
        "    fal = df.loc[~df.det, :] # False ID\n",
        "\n",
        "    return tru, fal, taxon\n",
        "\n",
        "# Plot results by image class\n",
        "def plot_predict_x_conf(tru, fal, thresh, imclasses=imclasses):\n",
        "    # Break up predictions by image class and confidence values\n",
        "    # Define variables\n",
        "    c0,c1,c2,c3,c4 = [imclasses[i] for i in range(0, len(imclasses))]\n",
        "    # Check how many true/false predictions are at each confidence value\n",
        "    # Class 0 - 'herb'\n",
        "    c0t = tru.loc[tru['true_id'] == c0, :] # True dets\n",
        "    c0f = fal.loc[fal['true_id'] == c0, :] # False dets\n",
        "    # Class 1 - 'illus'\n",
        "    c1t = tru.loc[tru['true_id'] == c1, :] \n",
        "    c1f = fal.loc[fal['true_id'] == c1, :] \n",
        "    # Class 2 - 'map'\n",
        "    c2t = tru.loc[tru['true_id'] == c2, :] \n",
        "    c2f = fal.loc[fal['true_id'] == c2, :] \n",
        "    # Class 3 - 'null'\n",
        "    c3t = tru.loc[tru['true_id'] == c3, :] \n",
        "    c3f = fal.loc[fal['true_id'] == c3, :] \n",
        "    # Class 4 - 'phylo'\n",
        "    c4t = tru.loc[tru['true_id'] == c4, :] \n",
        "    c4f = fal.loc[fal['true_id'] == c4, :] \n",
        "\n",
        "    \n",
        "    # Plot parameters to make 1 subplot per image class\n",
        "    kwargs = dict(alpha=0.5, bins=15)\n",
        "    fig, axes = plt.subplots(len(imclasses), figsize=(10, 10), constrained_layout=True)\n",
        "    fig.suptitle('Prediction Confidence by Class\\n Overall Accuracy: {}'.format(\n",
        "                  format((len(tru)/(len(tru)+len(fal))),'.2f')))\n",
        "    \n",
        "    # Make subplots\n",
        "    # Class 0 - 'herb'\n",
        "    # True predictions\n",
        "    axes[0].hist(c0t['confidence'], color='y', label='True Det', **kwargs)\n",
        "    # False predictions\n",
        "    axes[0].hist(c0f['confidence'], color='r', label='False Det', **kwargs)\n",
        "    axes[0].set_title(\"{} (n={} images)\\n Accuracy: {}\".format(imclasses[0], \n",
        "                      len(c0t+c0f), format((len(c0t)/(len(c0t)+len(c0f))),'.2f')))\n",
        "    axes[0].legend();\n",
        "\n",
        "    # Class 1 - 'illus'\n",
        "    # True predictions\n",
        "    axes[1].hist(c1t['confidence'], color='y', label='True Det', **kwargs)\n",
        "    # False predictions\n",
        "    axes[1].hist(c1f['confidence'], color='r', label='False Det', **kwargs)\n",
        "    axes[1].set_title(\"{} (n={} images)\\n Accuracy: {}\".format(imclasses[1], \n",
        "                      len(c1t+c1f), format((len(c1t)/(len(c1t)+len(c1f))),'.2f')))\n",
        "    axes[1].legend();\n",
        "\n",
        "    # Class 2 - 'herb'\n",
        "    # True predictions\n",
        "    axes[2].hist(c2t['confidence'], color='y', label='True Det', **kwargs)\n",
        "    # False predictions\n",
        "    axes[2].hist(c2f['confidence'], color='r', label='False Det', **kwargs)\n",
        "    axes[2].set_title(\"{} (n={} images)\\n Accuracy: {}\".format(imclasses[2], \n",
        "                      len(c2t+c2f), format((len(c2t)/(len(c2t)+len(c2f))),'.2f')))\n",
        "    axes[2].legend();\n",
        "\n",
        "    # Class 3 - 'null'\n",
        "    # True predictions\n",
        "    axes[3].hist(c3t['confidence'], color='y', label='True Det', **kwargs)\n",
        "    # False predictions\n",
        "    axes[3].hist(c3f['confidence'], color='r', label='False Det', **kwargs)\n",
        "    axes[3].set_title(\"{} (n={} images)\\n Accuracy: {}\".format(imclasses[3], \n",
        "                      len(c3t+c3f), format((len(c3t)/(len(c3t)+len(c3f))),'.2f')))\n",
        "    axes[3].legend();\n",
        "\n",
        "    # Class 4 - 'phylo'\n",
        "    # True predictions\n",
        "    axes[4].hist(c4t['confidence'], color='y', label='True Det', **kwargs)\n",
        "    # False predictions\n",
        "    axes[4].hist(c4f['confidence'], color='r', label='False Det', **kwargs)\n",
        "    axes[4].set_title(\"{} (n={} images)\\n Accuracy: {}\".format(imclasses[4], \n",
        "                      len(c4t+c4f), format((len(c4t)/(len(c4t)+len(c4f))),'.2f')))\n",
        "    axes[4].legend();\n",
        "\n",
        "    # Add Y-axis labels\n",
        "    for ax in fig.get_axes():\n",
        "        ax.set(ylabel='Freq (# imgs)')\n",
        "        if thresh:\n",
        "            ax.axvline(thresh, color='k', linestyle='dashed', linewidth=1)\n",
        "\n",
        "    return fig\n",
        "\n",
        "# To save the figure\n",
        "def save_figure(fig, taxon, TRAIN_SESS_NUM=TRAIN_SESS_NUM, handle_base=handle_base):\n",
        "    # Make filename\n",
        "    if taxon: # If for a specific taxon\n",
        "        if 'plant' in taxon:\n",
        "            handle_base = handle_base + '_plantae'\n",
        "        elif 'anim' in taxon:\n",
        "            handle_base = handle_base + '_animalia'\n",
        "\n",
        "    outfpath = TRAIN_SESS_NUM + '_' + handle_base + '.png'\n",
        "    fig.savefig(outfpath)\n",
        "    print(\"Histograms saved to \", outfpath)\n",
        "\n",
        "    return outfpath"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "10GhFabiCj3c"
      },
      "source": [
        "#@title Plot figures (Optional: inspect for specific taxon and/or add a confidence threshold line)\n",
        "\n",
        "# Load combined prediction results\n",
        "df = all_predictions.copy()\n",
        "\n",
        "# Optional: Inspect predictions for taxon-specific images only?\n",
        "inspect_by_taxon = False #@param {type:\"boolean\"}\n",
        "taxon = \"\" #@param {type:\"string\"}\n",
        "\n",
        "thresh = 0 #@param {type:\"number\"}\n",
        "\n",
        "# Valide predictions by image class (and optionally, by: taxon)\n",
        "tru, fal, taxon = validate_predict(df, inspect_by_taxon, taxon)\n",
        "\n",
        "# Plot result accuracy by image class (optionally, with confidence threshold line)\n",
        "fig = plot_predict_x_conf(tru, fal, thresh, imclasses)\n",
        "\n",
        "# Export histograms\n",
        "figname = save_figure(fig, taxon)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NL4Ua3TS8J3S"
      },
      "source": [
        "### Simulate resulting dataset sizes based on different confidence thresholds"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U748-euK2eKN",
        "cellView": "code"
      },
      "source": [
        "# Load combined prediction results\n",
        "df = all_predictions.copy()\n",
        "\n",
        "# Split by True or False determined image ID\n",
        "df['det'] = (df[\"true_id\"] == df[\"det_id\"])\n",
        "tru = df.loc[df.det, :] # True ID\n",
        "fal = df.loc[~df.det, :] # False ID\n",
        " \n",
        "# Confidence values to test  \n",
        "conf_vals = [1.0, 1.2, 1.4, 1.6, 1.8, 2.0, 2.2] #@param\n",
        "for conf_val in conf_vals: \n",
        "    df_c = df.loc[df[\"confidence\"] > conf_val, :]\n",
        "    true_c = tru.loc[tru[\"confidence\"] > conf_val, :]\n",
        "    fal_c = fal.loc[fal[\"confidence\"] > conf_val, :]\n",
        "    all_vals = true_c.append(fal_c)\n",
        "    print(\"\\nConfidence Value: {}\\n\".format(conf_val))\n",
        "    print(\"Accuracy for confidence > {}: {}\".format(conf_val, get_accuracy(len(true_c), len(all_vals))))\n",
        "    print(\"Predictions Retained (%): {}\".format(len(df_c)/len(df)))\n",
        "    print(\"True Predictions Retained (%): {}\".format(format((len(true_c)/len(tru)), '.2f')))\n",
        "    print(\"False Predictions Retained (%): {}\".format(format((len(fal_c)/len(fal)), '.2f')))\n",
        "    print(\"Accuracy for confidence > {}, by class:\".format(conf_val))\n",
        "    # By class\n",
        "    for imclass in imclasses:\n",
        "        true_det_c = len(true_c.loc[true_c[\"true_id\"] == imclass, :])\n",
        "        all_det_c = len(all_vals.loc[all_vals[\"true_id\"] == imclass, :])\n",
        "        accuracy = get_accuracy(true_det_c, all_det_c)\n",
        "        print(\"{}: {}\".format(imclass, accuracy))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6_wMLs4itYsU"
      },
      "source": [
        "## Inspect detections by image colorspace \n",
        "--- \n",
        "Noticed that many false dets in illustrations were from greyscale color mode ('L' in pillow). Look at true and false detections for greyscale images in each class"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-GyhC_-DtYXX"
      },
      "source": [
        "# Break up predictions by image class and colorspace\n",
        "\n",
        "# Define variables\n",
        "c0,c1,c2,c3,c4 = [imclasses[i] for i in range(0, len(imclasses))]\n",
        "# Check how many true/false predictions are at each confidence value\n",
        "# Class 0 - 'herb'\n",
        "c0t = tru.loc[tru['true_id'] == c0, :] # True dets\n",
        "c0f = fal.loc[fal['true_id'] == c0, :] # False dets\n",
        "# Class 1 - 'illus'\n",
        "c1t = tru.loc[tru['true_id'] == c1, :] \n",
        "c1f = fal.loc[fal['true_id'] == c1, :] \n",
        "# Class 2 - 'map'\n",
        "c2t = tru.loc[tru['true_id'] == c2, :] \n",
        "c2f = fal.loc[fal['true_id'] == c2, :] \n",
        "# Class 3 - 'null'\n",
        "c3t = tru.loc[tru['true_id'] == c3, :] \n",
        "c3f = fal.loc[fal['true_id'] == c3, :] \n",
        "# Class 4 - 'phylo'\n",
        "c4t = tru.loc[tru['true_id'] == c4, :] \n",
        "c4f = fal.loc[fal['true_id'] == c4, :] \n",
        "\n",
        "# Class 0 - Herbarium Sheet\n",
        "print(\"\\n{}\".format(c0))\n",
        "print(\"False detections: {}\\nTrue detections: {}\".format(len(c0f), len(c0t)))\n",
        "f_by_col = c0f.loc[c0f[\"colormode\"]==\"('L',)\", :]\n",
        "t_by_col = c0t.loc[c0t[\"colormode\"]==\"('L',)\", :]\n",
        "print(\"False for greyscale: {}\\nTrue for greyscale: {}\".format(len(f_by_col), len(t_by_col)))\n",
        "\n",
        "# Class 1 - Illustration\n",
        "print(\"\\n{}\".format(c1))\n",
        "print(\"False detections: {}\\nTrue detections: {}\".format(len(c1f), len(c1t)))\n",
        "f_by_col = c1f.loc[c1f[\"colormode\"]==\"('L',)\", :]\n",
        "t_by_col = c1t.loc[c1t[\"colormode\"]==\"('L',)\", :]\n",
        "print(\"False for greyscale: {}\\nTrue for greyscale: {}\".format(len(f_by_col), len(t_by_col)))\n",
        "\n",
        "# Class 2 = Map\n",
        "print(\"\\n{}\".format(c2))\n",
        "print(\"False detections: {}\\nTrue detections: {}\".format(len(c2f), len(c2t)))\n",
        "f_by_col = c2f.loc[c2f[\"colormode\"]==\"('L',)\", :]\n",
        "t_by_col = c2t.loc[c2t[\"colormode\"]==\"('L',)\", :]\n",
        "print(\"False for greyscale: {}\\nTrue for greyscale: {}\".format(len(f_by_col), len(t_by_col)))\n",
        "\n",
        "# Class 3 = Null\n",
        "print(\"\\n{}\".format(c3))\n",
        "print(\"False detections: {}\\nTrue detections: {}\".format(len(c3f), len(c3t)))\n",
        "f_by_col = c3f.loc[c3f[\"colormode\"]==\"('L',)\", :]\n",
        "t_by_col = c3t.loc[c3t[\"colormode\"]==\"('L',)\", :]\n",
        "print(\"False for greyscale: {}\\nTrue for greyscale: {}\".format(len(f_by_col), len(t_by_col)))\n",
        "\n",
        "# Class 4 = Phylogeny\n",
        "print(\"\\n{}\".format(c4))\n",
        "print(\"False detections: {}\\nTrue detections: {}\".format(len(c4f), len(c4t)))\n",
        "f_by_col = c4f.loc[c4f[\"colormode\"]==\"('L',)\", :]\n",
        "t_by_col = c4t.loc[c4t[\"colormode\"]==\"('L',)\", :]\n",
        "print(\"False for greyscale: {}\\nTrue for greyscale: {}\".format(len(f_by_col), len(t_by_col)))"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}