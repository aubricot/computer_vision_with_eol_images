{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPr6hq1vMiWyeULGajg2ARF",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/aubricot/computer_vision_with_eol_images/blob/master/classification_for_image_tagging/image_type/inspect_train_results.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_TcYNLBrWC0C"
      },
      "source": [
        "# Determine confidence threshold for Image Type Classification Models\n",
        "---\n",
        "*Last Updated 2 December 2024*   \n",
        "Choose which trained model and confidence threshold values to use for classifying EOL images as maps, phylogenies, illustrations, or herbarium sheets. Threshold values should be chosen that maximize coverage and minimize error.\n",
        "\n",
        "First, choose the 2 best models trained in [image_type_train.ipynb](https://colab.research.google.com/github/aubricot/computer_vision_with_eol_images/blob/master/classification_for_image_tagging/image_type/image_type_preprocessing.ipynb). Then, run this notebook.\n",
        "\n",
        "Run 500 images per class (map, phylogeny, illustration, herbarium sheet) through the best models chosen in image_type_train.ipynb for validation of model performance. Plot a confusion matrix, generate a classification report, and plot histograms of true and false predictions per class at binned confidence intervals to find the best performance by class and confidence threshold. (This is helpful because all models may not learn classes equally well).\n",
        "\n",
        "***Models were trained in Python 2 and TF 1 in October 2020: MobileNet SSD v2 (Training Session 13) was trained for 3 hours to 30 epochs with Batch Size=16, Lr=0.00001, Dropout=0.3, epsilon=1e-7, Adam optimizer. Final validation accuracy = 0.90. Inception v3 (Training Session 11) was trained for 3.5 hours to 30 epochs with Batch Size=16, Lr=0.0001, Dropout=0.2, epsilon=1, Adam optimizer. Final validation accuracy = 0.89.***\n",
        "\n",
        "Notes:   \n",
        "* Run code blocks by pressing play button in brackets on left\n",
        "* Before you you start: change the runtime to \"GPU\" with \"High RAM\"\n",
        "* Change parameters using form fields on right (find details at corresponding lines of code by searching '#@param')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZYW4W2aqdnTN"
      },
      "source": [
        "## Installs & Imports\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Choose where to save results (or keep defaults) & set up environment\n",
        "import os\n",
        "\n",
        "# Use dropdown menu on right\n",
        "save = \"in Colab runtime (files deleted after each session)\" #@param [\"in my Google Drive\", \"in Colab runtime (files deleted after each session)\"]\n",
        "print(\"Saving results \", save)\n",
        "\n",
        "# Mount google drive to export file(s)\n",
        "if 'Google Drive' in save:\n",
        "    from google.colab import drive\n",
        "    drive.mount('/content/drive', force_remount=True)\n",
        "\n",
        "# Type of classification pipeline\n",
        "classif_type = \"image_type\" #@param [\"image_type\", \"rating\"] {allow-input: true}\n",
        "\n",
        "# Type in the path to your working directory in form field to right\n",
        "basewd = \"/content/drive/MyDrive/train/tf2\" #@param [\"/content/drive/MyDrive/train/tf2\"] {allow-input: true}\n",
        "basewd = basewd + '/' + classif_type\n",
        "\n",
        "# Folder where inspect results outputs will be saved\n",
        "folder = \"inspect_resul\" # @param [\"inspect_resul\",\"results\"] {\"allow-input\":true}\n",
        "cwd = basewd + '/' + folder\n",
        "print(\"\\nWorking directory set to: \\n\", cwd)\n",
        "\n",
        "# Enter image classes of interest in form field\n",
        "filters = ['herb', 'illus', 'map', 'null', 'phylo'] # @param [\"['herb', 'illus', 'map', 'null', 'phylo']\"] {\"type\":\"raw\",\"allow-input\":true}\n",
        "\n",
        "# Download helper_funcs folder\n",
        "!pip3 -q install --upgrade gdown\n",
        "!gdown  1TfpSLwbt6i0OMdbbjcTPVFBP6vYc3CY_\n",
        "!tar -xzvf helper_funcs.tar.gz -C .\n",
        "\n",
        "# Install requirements.txt\n",
        "!pip3 -q install -r requirements.txt"
      ],
      "metadata": {
        "id": "sE0mcQMfN-5t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Choose saved model parameters (if using EOL model, defaults are already selected)\n",
        "from setup import setup_dirs, load_saved_model, get_model_info, unpack_EOL_model\n",
        "%cd /content\n",
        "\n",
        "# Use EOL pre-trained model for object detection?\n",
        "use_EOL_model = True #@param {type: \"boolean\"}\n",
        "\n",
        "# Download EOL models, if appropriate\n",
        "if (use_EOL_model==True) & (os.path.exists(\"11.zip\")==False):\n",
        "    !gdown 1Sxp742kescTGAUKlVkRR2hcoVo39y4pd\n",
        "if (use_EOL_model==True) & (os.path.exists(\"13.zip\")==False):\n",
        "    !gdown  1zpC23yiYUXZmVn7q6xhnhBTH9wTBK5Tf\n",
        "\n",
        "# If using your own trained model, change values to match your trained model\n",
        "dataset_labels = filters\n",
        "saved_models_folder = \"saved_models\" #@param [\"train/saved_models/\"] {allow-input: true}\n",
        "saved_models_dir = basewd + '/' + saved_models_folder + '/'\n",
        "print(\"\\nSaved models directory set to: \\n\", saved_models_dir)\n",
        "TRAIN_SESS_NUMS = [\"11\", \"13\"] # @param [\"[\\\"11\\\", \\\"13\\\"]\"] {\"type\":\"raw\",\"allow-input\":true}\n",
        "\n",
        "# Set up directory structure\n",
        "setup_dirs(cwd)\n",
        "%cd $basewd\n",
        "\n",
        "# Unpack EOL saved models\n",
        "for TRAIN_SESS_NUM in TRAIN_SESS_NUMS:\n",
        "    trained_model_dir = saved_models_dir + TRAIN_SESS_NUM + '/'\n",
        "    unpack_EOL_model(use_EOL_model, trained_model_dir, basewd, TRAIN_SESS_NUM, classif_type)\n",
        "\n",
        "# Folder where image metadata was saved in rating_preprocessing.ipynb\n",
        "data_folder = \"pre-processing/image_data\" #@param [\"pre-processing/image_data\"] {allow-input: true}\n",
        "data_wd = basewd + '/' + data_folder\n",
        "if not os.path.exists(data_wd):\n",
        "    os.makedirs(data_wd)\n",
        "    print(\"\\nDownload image bundles for {} classes {}...\\n\".format(classif_type, filters))\n",
        "    %cd $data_wd\n",
        "    file_ids = ['1Bkh2-TZSIKCCoKOTNr2L65BwR92Nx0vZ', '1m2sOLpUOWsw5RwzRtvj0mqH8aPloqnE_', \\\n",
        "                '1EIwPxyrawXnTPMyvO8f4nc1e3HALrTp9', '16I-_Qbh2IX_1Oz5wqlE6uzWXB2VhjE3e', \\\n",
        "                '1hQNgRLZWZu77XAxBwQIJOgRmWCCcpMos']\n",
        "    for file_id in file_ids:\n",
        "        !gdown $file_id\n",
        "print(\"\\nImage metadata directory set to: \\n\", data_wd)"
      ],
      "metadata": {
        "id": "kN4sl-xxOP6v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1AGFM4fSWhbT"
      },
      "source": [
        "#@title Import libraries\n",
        "\n",
        "# For working with data\n",
        "import itertools\n",
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "# Suppress pandas setting with copy warning\n",
        "pd.options.mode.chained_assignment = None  # default='warn'\n",
        "\n",
        "# For downloading and displaying images\n",
        "import matplotlib.pyplot as plt\n",
        "from PIL import Image, ImageFile\n",
        "ImageFile.LOAD_TRUNCATED_IMAGES = True\n",
        "%matplotlib inline\n",
        "\n",
        "# For measuring inference time\n",
        "import time\n",
        "\n",
        "# For image classification and training\n",
        "import tensorflow as tf\n",
        "print('\\n\\n\\nUsing Tensorflow Version: ', tf.__version__)\n",
        "\n",
        "# Set number of seconds to timeout if image url taking too long to open\n",
        "import socket\n",
        "socket.setdefaulttimeout(10)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u2PEaR_a_0QH"
      },
      "source": [
        "## Run images through for classification and validating predictions (Run 1x for each trained model)   \n",
        "---\n",
        "Selected models from image_type_train.ipynb   \n",
        "* Run 11: Inception v3\n",
        "* Run 13: Mobilenet SSD v2"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "efIHQCtAAmYg"
      },
      "source": [
        "# Define functions\n",
        "from wrangle_data import read_datafile, set_start_stop, image_from_url, get_predict_info\n",
        "\n",
        "# Make a dictionary of image type classes and corresponding image bundles\n",
        "demo_dict = {'herb': 'herbarium_sheets_download.txt', 'illus': ['Botanical_illustrations_download.txt', 'Zoological_illustrations_download.txt'], 'map': 'maps.txt', 'null': None, 'phylo': 'Phylogeny_images.txt'}\n",
        "\n",
        "# Set filename for saving classification results\n",
        "def get_test_images(imclass):\n",
        "    impath = cwd + '/pre-processing/images/' + imclass\n",
        "    # If already custom-trained model, pull test images to inspect results for\n",
        "    if os.path.exists(impath):\n",
        "        demo = False # Not running in demo mode\n",
        "        fns = os.listdir(impath)\n",
        "        TEST_IMAGE_PATHS = [os.path.join(impath, fn) for fn in fns]\n",
        "        print(\"\\nUsing test images from: \\n\", impath)\n",
        "    # If running this script to test functionality, download dummy dataset from EOL image bundles\n",
        "    else:\n",
        "        demo = True # Running in demo mode using only Colab Runtime files\n",
        "        TEST_IMAGE_PATHS = []\n",
        "        try:\n",
        "            if 'illus' in imclass:\n",
        "                fpath = data_wd + '/' + demo_dict[imclass][0]\n",
        "            elif 'null' in imclass:\n",
        "                print(\"\\n\\033[91m Null image class doesn't have demo image bundle available. Moving onto the next class.\\033[0m\\n\")\n",
        "                pass\n",
        "            else:\n",
        "                fpath = data_wd + '/' + demo_dict[imclass]\n",
        "            df = pd.read_table(fpath)\n",
        "            start = 1\n",
        "            stop = start + 500\n",
        "            TEST_IMAGE_PATHS = df.iloc[start:stop, 0].values.tolist()\n",
        "            print(\"\\nUsing up to 5 random images from EOL image type bundle: \\n\", fpath)\n",
        "\n",
        "        except:\n",
        "            pass\n",
        "\n",
        "    return TEST_IMAGE_PATHS, demo\n",
        "\n",
        "# Set filename for saving classification results\n",
        "def set_outfpath(imclass):\n",
        "    outfpath = cwd + '/' + classif_type + '_' + TRAIN_SESS_NUM + '_' + imclass + '.csv'\n",
        "    print(\"\\nSaving results to: \\n\", outfpath)\n",
        "\n",
        "    return outfpath\n",
        "\n",
        "# Load in image from file\n",
        "def image_from_file(im_path):\n",
        "    imga = Image.open(im_path) # rgba (with transp)\n",
        "    colormode = imga.getbands()\n",
        "    img = imga.convert('RGB') # convert to rgb\n",
        "    image = img.resize([pixels,pixels])\n",
        "    image = np.reshape(image,[1,pixels,pixels,3])\n",
        "    image = image*1./255 # normalize colorspace\n",
        "\n",
        "    return image, colormode\n",
        "\n",
        "# Make placeholder lists to fill for each class\n",
        "def make_placeholders():\n",
        "    filenames = []\n",
        "    confidences = []\n",
        "    true_imclasses = []\n",
        "    det_imclasses = []\n",
        "    colormodes = []\n",
        "\n",
        "    return filenames, confidences, true_imclasses, det_imclasses, colormodes\n",
        "\n",
        "# Add values for each image to placeholder list\n",
        "def record_results(fn, conf, true_imclass, det_imclass, colormode):\n",
        "    filenames.append(fn)\n",
        "    confidences.append(conf)\n",
        "    true_imclasses.append(true_imclass)\n",
        "    det_imclasses.append(det_imclass)\n",
        "    colormodes.append(colormode)\n",
        "    results = [filenames, confidences, true_imclasses, det_imclasses, colormodes]\n",
        "    # Display progress message after each image\n",
        "    print(\"Completed for {} of {} files\".format(len(filenames), cutoff))\n",
        "\n",
        "    return results\n",
        "\n",
        "# Export results\n",
        "def export_results(results, outfpath):\n",
        "    results = pd.DataFrame(results)\n",
        "    results = results.transpose()\n",
        "    results.to_csv(outfpath, index=False, header=(\"filename\", \"confidence\",\n",
        "                                                     \"true_id\", \"det_id\", \"colormode\"))\n",
        "    print(\"\\nClassification predictions for image class {} being saved to : \\n{}\\n\".format(\n",
        "          true_imclass, outfpath))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0ZXo6iVvBF0G"
      },
      "source": [
        "#@title Run inference for chosen Training Session Number (11, 13) and dataset size\n",
        "%cd $cwd\n",
        "\n",
        "# Choose training attempt number to inspect results for\n",
        "TRAIN_SESS_NUM = \"11\" #@param [\"11\", \"13\"] {allow-input: true}\n",
        "\n",
        "# Test pipeline with a smaller subset than 5k images?\n",
        "run = \"test with tiny subset\" #@param [\"test with tiny subset\", \"for 500 images\"]\n",
        "print(\"Run: \", run)\n",
        "\n",
        "# Load saved model\n",
        "module_selection, dataset_labels = get_model_info(TRAIN_SESS_NUM)\n",
        "print(\"Loading saved model for Train Attempt {}: {}\".format(TRAIN_SESS_NUM, module_selection))\n",
        "model, pixels, handle_base = load_saved_model(saved_models_dir, TRAIN_SESS_NUM, module_selection)\n",
        "\n",
        "# Run inference for each image class to compare known versus predicted image types\n",
        "true_imclasses = filters\n",
        "for true_imclass in true_imclasses:\n",
        "    print(\"Runing inference for class: {}\\n\".format(true_imclass))\n",
        "    # Set filename for saving classification results\n",
        "    outfpath = set_outfpath(true_imclass)\n",
        "    # Make placeholder lists to record values for each image\n",
        "    filenames, confidences, true_imclasses, det_imclasses, colormodes = make_placeholders()\n",
        "    # Get test images for running inference\n",
        "    df, demo = get_test_images(true_imclass)\n",
        "\n",
        "    # Run 500 random EOL bundle images through trained model\n",
        "    try:\n",
        "        start, stop, cutoff = set_start_stop(run, df)\n",
        "        for i, row in enumerate(df[start:stop], start=1):\n",
        "            # Read in image from file\n",
        "            if demo:\n",
        "                url = row\n",
        "                fn = str(i) + '.jpg'\n",
        "                img, _, colormode = image_from_url(url, fn, pixels)\n",
        "            else:\n",
        "                im_path = row\n",
        "                img, colormode = image_from_file(row)\n",
        "\n",
        "            # Image classification\n",
        "            start_time = time.time() # Record inference time\n",
        "            predictions = model.predict(img, batch_size=1)\n",
        "            label_num, conf, det_imclass = get_predict_info(predictions, row, i, stop, start, dataset_labels)\n",
        "            end_time = time.time()\n",
        "            print(\"Inference time: {} sec\".format(format(end_time-start_time, '.2f')))\n",
        "\n",
        "            # Record results in placeholder lists to inspect results in next step\n",
        "            results = record_results(row, conf, str(true_imclass), str(det_imclass), colormode)\n",
        "\n",
        "            # Set cutoff for # of predictions per class (workaround to get same # of predictions per class, even with many broken URLs)\n",
        "            print(\"\\033[92m Completed for {} of {} files \\033[0m\".format(len(results[0]), cutoff))\n",
        "            if len(results[0])>=cutoff:\n",
        "                break\n",
        "\n",
        "    except:\n",
        "        pass\n",
        "\n",
        "    # Combine to df and export results\n",
        "    export_results(results, outfpath)\n",
        "\n",
        "print(\"\\n\\n~~~\\n\\033[92m Inference complete!\\033[0m\\n~~~\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mnUCpn8sWVzi"
      },
      "source": [
        "#@title Combine model outputs for image type classes\n",
        "\n",
        "# Combine prediction files created in codeblock above\n",
        "base = classif_type + '_' + TRAIN_SESS_NUM + '_'\n",
        "imclasses = filters\n",
        "all_filenames = [base + imclass + '.csv' for imclass in imclasses]\n",
        "all_predictions = pd.concat([pd.read_csv(f, sep=',', header=0, na_filter = False) for f in all_filenames])\n",
        "outfpath = base + handle_base + '_all_predictions' + '.csv'\n",
        "print(\"Combining model prediction .csv's for all classes...\\n\", all_filenames, \"\\n\")\n",
        "all_predictions.to_csv(outfpath, index=False)\n",
        "print(\"Combined results saved to: \", outfpath, \"\\n\")\n",
        "print(\"No. Images: {}\\n\".format(len(all_predictions)))\n",
        "print(\"Model predictions for Training Attempt {}, {} with numeric classes:\\n{}\".format(\\\n",
        "      TRAIN_SESS_NUM, handle_base, all_predictions[['filename', 'true_id', 'det_id']].head()))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bL_56etnd0Rd"
      },
      "source": [
        "## Plot prediction error and confidence for each class (Run 1x for each trained model)\n",
        "---   \n",
        "Make a confusion matrix, classification report, and histograms. Then, use them to find a confidence threshold value for all or some classes to optimize dataset coverage and accuracy.\n",
        "\n",
        "If you already ran images through all models for predictions and want to play with plotting, specify TRAIN_SESS_NUM for your model of interest below."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Load model predictions (Optional: If you want to load in all_predictions.csv from a previous run, specify TRAIN_SESS_NUM)\n",
        "from setup import get_model_info\n",
        "\n",
        "%cd $cwd\n",
        "# Load combined prediction results from above\n",
        "run_from_file = \"no\" # @param [\"no\",\"yes\"]\n",
        "\n",
        "# Copy dataframe from above\n",
        "if run_from_file==\"no\":\n",
        "    print(\"Using runtime data from all_predictions: \", all_predictions.head())\n",
        "\n",
        "# Load all_predictions.csv from file for provided training attempt\n",
        "else:\n",
        "    # Choose training attempt number to inspect results for\n",
        "    TRAIN_SESS_NUM = \"11\" # @param [\"11\",\"13\"] {\"allow-input\":true}\n",
        "    # Get model info\n",
        "    module_selection, dataset_labels = get_model_info(TRAIN_SESS_NUM)\n",
        "    handle_base, pixels = module_selection\n",
        "    # Load in all_predictions from file\n",
        "    base = classif_type + '_' + TRAIN_SESS_NUM + '_'\n",
        "    fname = base + handle_base + '_all_predictions' + '.csv'\n",
        "    all_predictions = pd.read_csv(fname, sep=',', header=0, na_filter = False)\n",
        "    print(\"Loading prediction data from file for train attempt {}, {} with labels {} for confusion matrix and histograms: \\n{}\".format(TRAIN_SESS_NUM, handle_base, dataset_labels, all_predictions[['filename', 'true_id', 'det_id']].head()))"
      ],
      "metadata": {
        "id": "5-h2sxHscHcS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "code",
        "id": "gEyoDC1rL1Ub"
      },
      "source": [
        "# Define functions\n",
        "\n",
        "# Plot confusion matrix\n",
        "# Modified from http://scikit-learn.org/stable/auto_examples/model_selection/plot_confusion_matrix.html on 22 Oct 23\n",
        "def plot_confusion_matrix(cm, target_names, title='Confusion matrix',\n",
        "                          cmap=None, normalize=True):\n",
        "    accuracy = np.trace(cm) / np.sum(cm).astype('float')\n",
        "    misclass = 1 - accuracy\n",
        "    # Set colormap\n",
        "    if cmap is None:\n",
        "        cmap = plt.get_cmap('Blues')\n",
        "    # Build figure\n",
        "    fig = plt.figure(figsize=(8, 8))\n",
        "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
        "    plt.title(title)\n",
        "    plt.colorbar()\n",
        "    # Normalize data\n",
        "    if normalize:\n",
        "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
        "    # Add labels\n",
        "    if target_names is not None:\n",
        "        tick_marks = np.arange(len(target_names))\n",
        "        plt.xticks(tick_marks, target_names, rotation=45)\n",
        "        plt.yticks(tick_marks, target_names)\n",
        "    thresh = cm.max() / 1.5 if normalize else cm.max() / 2\n",
        "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
        "        if normalize:\n",
        "            plt.text(j, i, \"{:0.2f}\".format(cm[i, j]),\n",
        "                     horizontalalignment=\"center\",\n",
        "                     color=\"white\" if cm[i, j] > thresh else \"black\")\n",
        "        else:\n",
        "            plt.text(j, i, \"{:0.2f}\".format(cm[i, j]),\n",
        "                     horizontalalignment=\"center\",\n",
        "                     color=\"white\" if cm[i, j] > thresh else \"black\")\n",
        "    plt.tight_layout()\n",
        "    plt.ylabel('True label')\n",
        "    plt.xlabel('Predicted label\\naccuracy={:0.2f}; misclass={:0.2f}'.format(accuracy, misclass))\n",
        "    plt.show()\n",
        "\n",
        "    return fig\n",
        "\n",
        "# Calculate prediction accuracy\n",
        "def get_accuracy(obs, all_vals):\n",
        "    # obs = observed, all_vals = observed + expected\n",
        "    if obs:\n",
        "        accuracy = format((obs/all_vals), '.2f')\n",
        "    else:\n",
        "        accuracy = 0\n",
        "\n",
        "    return accuracy\n",
        "\n",
        "# Valide predictions by image class (and optionally, by: taxon)\n",
        "def validate_predict(df, inspect_by_taxon, taxon):\n",
        "    # If inspecting for taxon-specific images only\n",
        "    if inspect_by_taxon:\n",
        "        taxon = taxon\n",
        "        df = df.loc[df.ancestry.str.contains(taxon, case=False, na=False)]\n",
        "        print(\"Inspecting results for {}:\\n{}\".format(taxon, df.head()))\n",
        "\n",
        "    # Validate predictions\n",
        "    # Check where true image types and model-determined classes match\n",
        "    df['det'] = (df['true_id'] == df['det_id'])\n",
        "    tru = df.loc[df.det, :] # True ID\n",
        "    fal = df.loc[~df.det, :] # False ID\n",
        "\n",
        "    return tru, fal, taxon\n",
        "\n",
        "# Plot results by image class\n",
        "def plot_predict_x_conf(tru, fal, thresh, imclasses=imclasses):\n",
        "    # Break up predictions by image class and confidence values\n",
        "    # Define variables\n",
        "    c0,c1,c2,c3,c4 = [imclasses[i] for i in range(0, len(imclasses))]\n",
        "\n",
        "    # Check how many true/false predictions are at each confidence value\n",
        "    # Class 0 - 'herb'\n",
        "    c0t = tru.loc[tru['true_id'] == c0, :] # True dets\n",
        "    c0f = fal.loc[fal['true_id'] == c0, :] # False dets\n",
        "    # Class 1 - 'illus'\n",
        "    c1t = tru.loc[tru['true_id'] == c1, :]\n",
        "    c1f = fal.loc[fal['true_id'] == c1, :]\n",
        "    # Class 2 - 'map'\n",
        "    c2t = tru.loc[tru['true_id'] == c2, :]\n",
        "    c2f = fal.loc[fal['true_id'] == c2, :]\n",
        "    # Class 3 - 'null'\n",
        "    c3t = tru.loc[tru['true_id'] == c3, :]\n",
        "    c3f = fal.loc[fal['true_id'] == c3, :]\n",
        "    # Class 4 - 'phylo'\n",
        "    c4t = tru.loc[tru['true_id'] == c4, :]\n",
        "    c4f = fal.loc[fal['true_id'] == c4, :]\n",
        "\n",
        "\n",
        "    # Plot parameters to make 1 subplot per image class\n",
        "    kwargs = dict(alpha=0.5, bins=15)\n",
        "    fig, axes = plt.subplots(len(imclasses), figsize=(10, 10), constrained_layout=True)\n",
        "    fig.suptitle('Prediction Confidence by Class\\n Overall Accuracy: {}'.format(\n",
        "                  get_accuracy(len(tru), (len(tru)+len(fal)))))\n",
        "\n",
        "    # Make subplots\n",
        "    # Class 0 - 'herb'\n",
        "    # True predictions\n",
        "    axes[0].hist(c0t['confidence'], color='y', label='True Det', **kwargs)\n",
        "    # False predictions\n",
        "    axes[0].hist(c0f['confidence'], color='r', label='False Det', **kwargs)\n",
        "    axes[0].set_title(\"{} (n={} images)\\n Accuracy: {}\".format(imclasses[0],\n",
        "                      len(c0t+c0f), get_accuracy(len(c0t), (len(c0t)+len(c0f)))))\n",
        "    axes[0].legend();\n",
        "\n",
        "    # Class 1 - 'illus'\n",
        "    # True predictions\n",
        "    axes[1].hist(c1t['confidence'], color='y', label='True Det', **kwargs)\n",
        "    # False predictions\n",
        "    axes[1].hist(c1f['confidence'], color='r', label='False Det', **kwargs)\n",
        "    axes[1].set_title(\"{} (n={} images)\\n Accuracy: {}\".format(imclasses[1],\n",
        "                      len(c1t+c1f), get_accuracy(len(c1t), (len(c1t)+len(c1f)))))\n",
        "    axes[1].legend();\n",
        "\n",
        "    # Class 2 - 'map'\n",
        "    # True predictions\n",
        "    axes[2].hist(c2t['confidence'], color='y', label='True Det', **kwargs)\n",
        "    # False predictions\n",
        "    axes[2].hist(c2f['confidence'], color='r', label='False Det', **kwargs)\n",
        "    axes[2].set_title(\"{} (n={} images)\\n Accuracy: {}\".format(imclasses[2],\n",
        "                      len(c2t+c2f), get_accuracy(len(c2t), (len(c2t)+len(c2f)))))\n",
        "    axes[2].legend();\n",
        "\n",
        "    # Class 3 - 'null'\n",
        "    # True predictions\n",
        "    axes[3].hist(c3t['confidence'], color='y', label='True Det', **kwargs)\n",
        "    # False predictions\n",
        "    axes[3].hist(c3f['confidence'], color='r', label='False Det', **kwargs)\n",
        "    axes[3].set_title(\"{} (n={} images)\\n Accuracy: {}\".format(imclasses[3],\n",
        "                      len(c3t+c3f), get_accuracy(len(c3t), (len(c3t)+len(c3f)))))\n",
        "    axes[3].legend();\n",
        "\n",
        "    # Class 4 - 'phylo'\n",
        "    # True predictions\n",
        "    axes[4].hist(c4t['confidence'], color='y', label='True Det', **kwargs)\n",
        "    # False predictions\n",
        "    axes[4].hist(c4f['confidence'], color='r', label='False Det', **kwargs)\n",
        "    axes[4].set_title(\"{} (n={} images)\\n Accuracy: {}\".format(imclasses[4],\n",
        "                      len(c4t+c4f), get_accuracy(len(c4t), (len(c4t)+len(c4f)))))\n",
        "    axes[4].legend();\n",
        "\n",
        "    # Add Y-axis labels\n",
        "    for ax in fig.get_axes():\n",
        "        ax.set(ylabel='Freq (# imgs)')\n",
        "        if thresh:\n",
        "            ax.axvline(thresh, color='k', linestyle='dashed', linewidth=1)\n",
        "\n",
        "    return fig\n",
        "\n",
        "# To save a figure\n",
        "def save_figure(fig, figtype, filetype='.png', taxon=None, TRAIN_SESS_NUM=TRAIN_SESS_NUM, handle_base=handle_base):\n",
        "    # Make filename\n",
        "    if taxon: # If for a specific taxon\n",
        "        if 'plant' in taxon:\n",
        "            handle_base = handle_base + '_plantae'\n",
        "        elif 'anim' in taxon:\n",
        "            handle_base = handle_base + '_animalia'\n",
        "\n",
        "    outfpath = 'ratings_' + TRAIN_SESS_NUM + '_' + handle_base + '_' + figtype + filetype\n",
        "    fig.savefig(outfpath, bbox_inches=\"tight\")\n",
        "    print(\"\\nFigure(s) saved to: \", outfpath, \"\\n\")\n",
        "\n",
        "# To save a table\n",
        "def save_table(tab, tabtype, filetype='.txt', TRAIN_SESS_NUM=TRAIN_SESS_NUM, handle_base=handle_base):\n",
        "    # Make filename\n",
        "    outfpath = 'ratings_' + TRAIN_SESS_NUM + '_' + handle_base + '_' + tabtype + filetype\n",
        "    # Write table\n",
        "    f = open(outfpath,\"w+\")\n",
        "    f.writelines(tab)\n",
        "    f.close()\n",
        "    print(\"\\nTable saved to: \", outfpath, \"\\n\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Make classification report and plot confusion matrix of precision/recall for each image class\n",
        "Use the confusion matrix and classification report table to evaluate model performance and determine class predictions to keep or filter out during post-processing. Precision and recall are related to accuracy. Precision measures what the model found (how many predicted positives are actually positive), while recall measures what the model missed (sensitivity / how many actual positives did the model identify).\n",
        "\n",
        "$$precision = \\frac{true\\,positives}{true\\,positives + false\\,positives}$$\n",
        "\n",
        "$$recall = \\frac{true\\,positives}{true\\,positives + false\\,negatives}$$\n",
        "\n",
        "The classification report also includes an F1 score, which is the harmonic mean of precision and recall.\n",
        "\n",
        "$$F1 = 2* \\frac{precision*recall}{precision+recall}=\\frac{2*true\\,positives}{2*true\\,positives+false\\,positives+false\\,negatives}$$"
      ],
      "metadata": {
        "id": "mpCLEatjdPX1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Make a classification report and confusion matrix\n",
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "import seaborn as sns\n",
        "sns.set_style('darkgrid')\n",
        "\n",
        "# Make and print classification report\n",
        "df = all_predictions.replace('NaN', pd.NA).dropna(subset=['true_id', 'det_id'], ignore_index = True)\n",
        "true_id = pd.DataFrame(df[['true_id']]).to_numpy()\n",
        "det_id = pd.DataFrame(df[['det_id']]).to_numpy()\n",
        "clr = classification_report(true_id, det_id, target_names = dataset_labels)\n",
        "print(\"\\nClassification report: \\n\", clr)\n",
        "\n",
        "# Export classification report\n",
        "save_table(clr, tabtype = 'classif_rep', filetype = '.txt')\n",
        "\n",
        "# Make and plot confusion matrix\n",
        "cm = confusion_matrix(true_id, det_id)\n",
        "fig = plot_confusion_matrix(cm, dataset_labels, normalize=True)\n",
        "\n",
        "# Export confusion matrix\n",
        "save_figure(fig, figtype = 'conf_mx', filetype = '.png')"
      ],
      "metadata": {
        "id": "sQJo3x_-dTsr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Plot histograms of accuracy for each image class\n",
        "Use these plots to determine confidence thresholds or class predictions to keep or filter out during post-processing."
      ],
      "metadata": {
        "id": "H9S6z_ujddQc"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "10GhFabiCj3c"
      },
      "source": [
        "#@title Plot histograms (Optional: inspect for specific taxon and/or add a confidence threshold line)\n",
        "\n",
        "# Optional: Inspect predictions for taxon-specific images only?\n",
        "inspect_by_taxon = False #@param {type:\"boolean\"}\n",
        "taxon = \"\" #@param {type:\"string\"}\n",
        "\n",
        "# Optional: Draw threshold value to help choose optimal balance b/w maximizing useful data and minimizing error\n",
        "thresh = 1.5 #@param {type:\"number\"}\n",
        "\n",
        "# Valide predictions by image class (optionally, by taxon)\n",
        "tru, fal, taxon = validate_predict(all_predictions, inspect_by_taxon, taxon)\n",
        "\n",
        "# Plot result accuracy by image class (optionally, with confidence threshold line)\n",
        "fig = plot_predict_x_conf(tru, fal, thresh, dataset_labels)\n",
        "\n",
        "# Export histograms\n",
        "save_figure(fig, figtype = 'hist', filetype = '.png', taxon = taxon)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NL4Ua3TS8J3S"
      },
      "source": [
        "### Simulate resulting dataset sizes based on different confidence thresholds"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U748-euK2eKN",
        "cellView": "code"
      },
      "source": [
        "# Load combined prediction results\n",
        "df = all_predictions.copy()\n",
        "\n",
        "# Split by True or False determined image ID\n",
        "df['det'] = (df[\"true_id\"] == df[\"det_id\"])\n",
        "tru = df.loc[df.det, :] # True ID\n",
        "fal = df.loc[~df.det, :] # False ID\n",
        "\n",
        "# Confidence values to test\n",
        "conf_vals = [1.0, 1.2, 1.4, 1.6, 1.8, 2.0, 2.2] #@param\n",
        "for conf_val in conf_vals:\n",
        "    df_c = df.loc[df[\"confidence\"] > conf_val, :]\n",
        "    true_c = tru.loc[tru[\"confidence\"] > conf_val, :]\n",
        "    fal_c = fal.loc[fal[\"confidence\"] > conf_val, :]\n",
        "    all_vals = true_c.append(fal_c)\n",
        "    print(\"\\nConfidence Value: {}\\n\".format(conf_val))\n",
        "    print(\"Accuracy for confidence > {}: {}\".format(conf_val, get_accuracy(len(true_c), len(all_vals))))\n",
        "    print(\"Predictions Retained (%): {}\".format(len(df_c)/len(df)))\n",
        "    print(\"True Predictions Retained (%): {}\".format(format((len(true_c)/len(tru)), '.2f')))\n",
        "    print(\"False Predictions Retained (%): {}\".format(format((len(fal_c)/len(fal)), '.2f')))\n",
        "    print(\"Accuracy for confidence > {}, by class:\".format(conf_val))\n",
        "    # By class\n",
        "    for imclass in imclasses:\n",
        "        true_det_c = len(true_c.loc[true_c[\"true_id\"] == imclass, :])\n",
        "        all_det_c = len(all_vals.loc[all_vals[\"true_id\"] == imclass, :])\n",
        "        accuracy = get_accuracy(true_det_c, all_det_c)\n",
        "        print(\"{}: {}\".format(imclass, accuracy))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6_wMLs4itYsU"
      },
      "source": [
        "## Inspect detections by image colorspace\n",
        "---\n",
        "Noticed that many false dets in illustrations were from greyscale color mode ('L' in pillow). Look at true and false detections for greyscale images in each class"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-GyhC_-DtYXX"
      },
      "source": [
        "# Break up predictions by image class and colorspace\n",
        "\n",
        "# Define variables\n",
        "c0,c1,c2,c3,c4 = [imclasses[i] for i in range(0, len(imclasses))]\n",
        "# Check how many true/false predictions are at each confidence value\n",
        "# Class 0 - 'herb'\n",
        "c0t = tru.loc[tru['true_id'] == c0, :] # True dets\n",
        "c0f = fal.loc[fal['true_id'] == c0, :] # False dets\n",
        "# Class 1 - 'illus'\n",
        "c1t = tru.loc[tru['true_id'] == c1, :]\n",
        "c1f = fal.loc[fal['true_id'] == c1, :]\n",
        "# Class 2 - 'map'\n",
        "c2t = tru.loc[tru['true_id'] == c2, :]\n",
        "c2f = fal.loc[fal['true_id'] == c2, :]\n",
        "# Class 3 - 'null'\n",
        "c3t = tru.loc[tru['true_id'] == c3, :]\n",
        "c3f = fal.loc[fal['true_id'] == c3, :]\n",
        "# Class 4 - 'phylo'\n",
        "c4t = tru.loc[tru['true_id'] == c4, :]\n",
        "c4f = fal.loc[fal['true_id'] == c4, :]\n",
        "\n",
        "# Class 0 - Herbarium Sheet\n",
        "print(\"\\n{}\".format(c0))\n",
        "print(\"False detections: {}\\nTrue detections: {}\".format(len(c0f), len(c0t)))\n",
        "f_by_col = c0f.loc[c0f[\"colormode\"]==\"('L',)\", :]\n",
        "t_by_col = c0t.loc[c0t[\"colormode\"]==\"('L',)\", :]\n",
        "print(\"False for greyscale: {}\\nTrue for greyscale: {}\".format(len(f_by_col), len(t_by_col)))\n",
        "\n",
        "# Class 1 - Illustration\n",
        "print(\"\\n{}\".format(c1))\n",
        "print(\"False detections: {}\\nTrue detections: {}\".format(len(c1f), len(c1t)))\n",
        "f_by_col = c1f.loc[c1f[\"colormode\"]==\"('L',)\", :]\n",
        "t_by_col = c1t.loc[c1t[\"colormode\"]==\"('L',)\", :]\n",
        "print(\"False for greyscale: {}\\nTrue for greyscale: {}\".format(len(f_by_col), len(t_by_col)))\n",
        "\n",
        "# Class 2 = Map\n",
        "print(\"\\n{}\".format(c2))\n",
        "print(\"False detections: {}\\nTrue detections: {}\".format(len(c2f), len(c2t)))\n",
        "f_by_col = c2f.loc[c2f[\"colormode\"]==\"('L',)\", :]\n",
        "t_by_col = c2t.loc[c2t[\"colormode\"]==\"('L',)\", :]\n",
        "print(\"False for greyscale: {}\\nTrue for greyscale: {}\".format(len(f_by_col), len(t_by_col)))\n",
        "\n",
        "# Class 3 = Null\n",
        "print(\"\\n{}\".format(c3))\n",
        "print(\"False detections: {}\\nTrue detections: {}\".format(len(c3f), len(c3t)))\n",
        "f_by_col = c3f.loc[c3f[\"colormode\"]==\"('L',)\", :]\n",
        "t_by_col = c3t.loc[c3t[\"colormode\"]==\"('L',)\", :]\n",
        "print(\"False for greyscale: {}\\nTrue for greyscale: {}\".format(len(f_by_col), len(t_by_col)))\n",
        "\n",
        "# Class 4 = Phylogeny\n",
        "print(\"\\n{}\".format(c4))\n",
        "print(\"False detections: {}\\nTrue detections: {}\".format(len(c4f), len(c4t)))\n",
        "f_by_col = c4f.loc[c4f[\"colormode\"]==\"('L',)\", :]\n",
        "t_by_col = c4t.loc[c4t[\"colormode\"]==\"('L',)\", :]\n",
        "print(\"False for greyscale: {}\\nTrue for greyscale: {}\".format(len(f_by_col), len(t_by_col)))"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}