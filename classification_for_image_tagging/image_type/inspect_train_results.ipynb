{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "inspect_train_results.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNl6nSmBArjPrhPqt1e47AG",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/aubricot/computer_vision_with_eol_images/blob/master/classification_for_image_tagging/image_type/inspect_train_results.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_TcYNLBrWC0C"
      },
      "source": [
        "# Determine confidence threshold for Image Type Classification Models \n",
        "---\n",
        "*Last Updated 29 October 2021*   \n",
        "Choose which trained model and confidence threshold values to use for classifying EOL images as maps, phylogenies, illustrations, or herbarium sheets. Threshold values should be chosen that maximize coverage and minimize error.\n",
        "\n",
        "First, choose the 2 best models trained in [image_type_train.ipynb](https://colab.research.google.com/github/aubricot/computer_vision_with_eol_images/blob/master/classification_for_image_tagging/image_type/image_type_preprocessing.ipynb). Then, run this notebook.\n",
        "\n",
        "Run 500 images per class (map, phylogeny, illustration, herbarium sheet) through the best models chosen in rating_train.ipynb for validation of model performance. Plot histograms of true and false predictions per class at binned confidence intervals to find the best performance by class and confidence threshold. (This is helpful because all models may not learn classes equally well).\n",
        "\n",
        "Notes:\n",
        "\n",
        "* Change parameters using form fields on right (/where you see 'TO DO' in code)\n",
        "\n",
        "***Models were trained in Python 2 and TF 1 in October 2020: MobileNet SSD v2 was trained for 3 hours to 30 epochs with Batch Size=16, Lr=0.00001, Dropout=0.3, epsilon=1e-7, Adam optimizer. Final validation accuracy = 0.90. Inception v3 was trained for 3.5 hours to 30 epochs with Batch Size=16, Lr=0.0001, Dropout=0.2, epsilon=1, Adam optimizer. Final validation accuracy = 0.89.***"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZYW4W2aqdnTN"
      },
      "source": [
        "## Installs & Imports\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6k81-h_UV_ny"
      },
      "source": [
        "# Mount google drive to import/export files\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1AGFM4fSWhbT"
      },
      "source": [
        "# For working with data\n",
        "import itertools\n",
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "# For downloading and displaying images\n",
        "import matplotlib.pyplot as plt\n",
        "from PIL import Image, ImageFile\n",
        "ImageFile.LOAD_TRUNCATED_IMAGES = True\n",
        "%matplotlib inline\n",
        "\n",
        "# For measuring inference time\n",
        "import time\n",
        "\n",
        "# For image classification and training\n",
        "import tensorflow as tf\n",
        "\n",
        "# Define functions\n",
        "\n",
        "# To read in EOL formatted data files\n",
        "def read_datafile(fpath, sep=\"\\t\", header=0, disp_head=True, lineterminator='\\n', encoding='latin1'):\n",
        "    \"\"\"\n",
        "    Defaults to tab-separated data files with header in row 0\n",
        "    \"\"\"\n",
        "    try:\n",
        "        df = pd.read_csv(fpath, sep=sep, header=header, lineterminator=lineterminator, encoding=encoding)\n",
        "        if disp_head:\n",
        "          print(\"Data header: \\n\", df.head())\n",
        "    except FileNotFoundError as e:\n",
        "        raise Exception(\"File not found: Enter the path to your file in form field and re-run\").with_traceback(e.__traceback__)\n",
        "    \n",
        "    return df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u2PEaR_a_0QH"
      },
      "source": [
        "## Run images through for classification and validating predictions (Run 1x for each trained model)   \n",
        "---\n",
        "Selected models from rating_train.ipynb   \n",
        "* Run 11: Inception v3\n",
        "* Run 13: Mobilenet SSD v2"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "efIHQCtAAmYg"
      },
      "source": [
        "# Set parameters \n",
        "\n",
        "# TO DO: Choose training attempt number to inspect results for\n",
        "TRAIN_SESS_NUM = \"11\" #@param [\"11\", \"13\"] {allow-input: true}\n",
        "\n",
        "# Set up directory structure\n",
        "# TO DO: Type in the path to your working directory in form field to right\n",
        "wd = \"/content/drive/MyDrive/summer20/classification/image_type\" #@param {type:\"string\"}\n",
        "cwd = wd + '/inspect_resul/'\n",
        "if not os.path.isdir(cwd):\n",
        "    os.makedirs(cwd)\n",
        "%cd $cwd\n",
        "\n",
        "# Directory to saved models from image_type_train.ipynb\n",
        "saved_models_dir = wd + '/saved_models/'\n",
        "\n",
        "# Suppress pandas setting with copy warning\n",
        "pd.options.mode.chained_assignment = None  # default='warn'\n",
        "\n",
        "# Define functions\n",
        "\n",
        "# Define start and stop indices in EOL bundle for running inference   \n",
        "def set_start_stop(df):\n",
        "    # To test with a tiny subset, use 5 random bundle images\n",
        "    N = len(df)\n",
        "    if test_with_tiny_subset:\n",
        "        start=np.random.choice(a=N, size=1)[0]\n",
        "        stop=start+5\n",
        "    # To run for larger set, use 500 random images\n",
        "    else: \n",
        "        start=np.random.choice(a=N, size=1)[0]\n",
        "        stop=start+500\n",
        "    print(\"\\nRunning inference on images\")\n",
        "    \n",
        "    return start, stop\n",
        "\n",
        "# Load saved model from directory\n",
        "def load_saved_model(saved_models_dir, TRAIN_SESS_NUM, module_selection):\n",
        "    # Load trained model from path\n",
        "    saved_model_path = saved_models_dir + TRAIN_SESS_NUM\n",
        "    model = tf.keras.models.load_model(saved_model_path)\n",
        "    # Get name and image size for model type\n",
        "    handle_base, pixels = module_selection\n",
        "\n",
        "    return model, pixels, handle_base\n",
        "\n",
        "# Get info about model based on training attempt number\n",
        "def get_model_info(TRAIN_SESS_NUM):\n",
        "    # Session 11\n",
        "    if int(TRAIN_SESS_NUM) == 11:\n",
        "        module_selection = (\"inception_v3\", 299)\n",
        "    # Session 13\n",
        "    elif int(TRAIN_SESS_NUM) == 13:\n",
        "        module_selection = (\"mobilenet_v2_1.0_224\", 224)\n",
        "    dataset_labels = ['herb', 'illus', 'map', 'null', 'phylo'] \n",
        "\n",
        "    return module_selection, dataset_labels\n",
        "\n",
        "# Set filename for saving classification results\n",
        "def get_test_images(true_imclass):\n",
        "    inpath = wd + '/pre-processing/images/' + true_imclass\n",
        "    fns = os.listdir(inpath)\n",
        "    TEST_IMAGE_PATHS = [os.path.join(inpath, fn) for fn in fns]\n",
        "    print(\"\\nUsing test images from: \\n\", inpath)\n",
        "\n",
        "    return TEST_IMAGE_PATHS\n",
        "\n",
        "# Set filename for saving classification results\n",
        "def set_outpath(true_imclass):\n",
        "    outpath = wd + '/inspect_resul/image_type_' + TRAIN_SESS_NUM + '_' + true_imclass + '.csv'\n",
        "    print(\"\\nSaving results to: \\n\", outpath)\n",
        "\n",
        "    return outpath\n",
        "\n",
        "# Load in image from file\n",
        "def image_from_file(im_path):\n",
        "    imga = Image.open(im_path) # rgba (with transp)\n",
        "    colormode = imga.getbands()\n",
        "    img = imga.convert('RGB') # convert to rgb\n",
        "    image = img.resize([pixels,pixels])\n",
        "    image = np.reshape(image,[1,pixels,pixels,3])\n",
        "    image = image*1./255 # normalize colorspace\n",
        "\n",
        "    return image, colormode\n",
        "\n",
        "# Get info from predictions to display on images\n",
        "def get_predict_info(predictions, im_path, im_num, stop, start):\n",
        "    # Get info from predictions\n",
        "    label_num = np.argmax(predictions[0], axis=-1)\n",
        "    conf = predictions[0][label_num]\n",
        "    im_class = dataset_labels[label_num]\n",
        "    # Display progress message after each image\n",
        "    print(\"Completed for {}, {} of {} files\".format(im_path, im_num, format(stop-start, '.0f')))\n",
        "    \n",
        "    return label_num, conf, im_class\n",
        "\n",
        "# Record results for confidence thresholds\n",
        "# Make placeholder lists to fill for each class\n",
        "def make_placeholders():\n",
        "    filenames = []\n",
        "    confidences = []\n",
        "    true_imclasses = []\n",
        "    det_imclasses = []\n",
        "    colormodes = []\n",
        "\n",
        "    return filenames, confidences, true_imclasses, det_imclasses, colormodes\n",
        "    \n",
        "# Add values for each image to placeholder list\n",
        "def record_results(fn, conf, true_imclass, det_imclass, colormode):\n",
        "    filenames.append(fn)\n",
        "    confidences.append(conf)\n",
        "    true_imclasses.append(true_imclass)\n",
        "    det_imclasses.append(det_imclass)\n",
        "    colormodes.append(colormode)\n",
        "    results = [filenames, confidences, true_imclasses, det_imclasses, colormodes]\n",
        "\n",
        "    return results\n",
        "\n",
        "# Export results\n",
        "def export_results(results):\n",
        "    results = pd.DataFrame(results)\n",
        "    results = results.transpose()\n",
        "    results.to_csv(outpath, index=False, header=(\"filename\", \"confidence\", \n",
        "                                                     \"true_id\", \"det_id\", \"colormode\"))\n",
        "    print(\"Classification predictions for image class {}: {}\".format(\n",
        "          true_imclass, results.head()))\n",
        "    \n",
        "# Calculate prediction accuracy\n",
        "def get_accuracy(obs, all_vals):\n",
        "    # obs = observed, all_vals = observed + expected\n",
        "    if obs:\n",
        "        accuracy = format((obs/all_vals), '.2f')\n",
        "    else:\n",
        "        accuracy = 0\n",
        "    \n",
        "    return accuracy"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0ZXo6iVvBF0G",
        "cellView": "code"
      },
      "source": [
        "# Run inference\n",
        "\n",
        "# Test with tiny subset (5 images)?\n",
        "# TO DO: If yes, check test_with_tiny_subset box\n",
        "test_with_tiny_subset = True #@param {type: \"boolean\"}\n",
        "\n",
        "# Load saved model\n",
        "module_selection, dataset_labels = get_model_info(TRAIN_SESS_NUM)\n",
        "model, pixels, handle_base = load_saved_model(saved_models_dir, TRAIN_SESS_NUM, module_selection)\n",
        "\n",
        "# Get test images to run inference on\n",
        "\n",
        "# Run inference for each image class to compare known versus predicted ratings\n",
        "true_imclasses = ['herb', 'illus', 'map', 'null', 'phylo']\n",
        "for true_imclass in true_imclasses:\n",
        "\n",
        "    # Set filename for saving classification results\n",
        "    outpath = set_outpath(true_imclass)\n",
        "\n",
        "    # Make placeholder lists to record values for each image\n",
        "    filenames, confidences, true_imclasses, det_imclasses, colormodes = make_placeholders()\n",
        "\n",
        "    # Get test images for running inference\n",
        "    TEST_IMAGE_PATHS = get_test_images(true_imclass)\n",
        "\n",
        "    # Run 500 random EOL bundle images through trained model\n",
        "    start, stop = set_start_stop(TEST_IMAGE_PATHS)\n",
        "    for im_num, im_path in enumerate(TEST_IMAGE_PATHS[start:stop], start=1):\n",
        "        try:\n",
        "            # Read in image from file\n",
        "            img, colormode = image_from_file(im_path)\n",
        "        \n",
        "            # Image classification\n",
        "            start_time = time.time() # Record inference time\n",
        "            predictions = model.predict(img, batch_size=1)\n",
        "            label_num, conf, det_imclass = get_predict_info(predictions, im_path, im_num, stop, start)\n",
        "            end_time = time.time()\n",
        "            print(\"Inference time: {} sec\".format(format(end_time-start_time, '.2f')))\n",
        "\n",
        "            # Record results in placeholder lists to inspect results in next step\n",
        "            results = record_results(im_path, conf, true_imclass, det_imclass, colormode)\n",
        "\n",
        "        except:\n",
        "            pass\n",
        "\n",
        "    # Combine to df and export results\n",
        "    export_results(results)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mnUCpn8sWVzi"
      },
      "source": [
        "# Combine model outputs for image type classes\n",
        "\n",
        "# Combine prediction files created in codeblock above\n",
        "imclasses = ['herb', 'illus', 'map', 'null', 'phylo']\n",
        "base = 'image_type_' + TRAIN_SESS_NUM + '_'\n",
        "all_filenames = [base + imclass + '.csv' for imclass in imclasses]\n",
        "all_predictions = pd.concat([pd.read_csv(f, sep=',', header=0, na_filter = False) for f in all_filenames])\n",
        "print(\"Model predictions for Training Attempt {}, {}:\".format(TRAIN_SESS_NUM, handle_base))\n",
        "print(\"No. Images: {}\\n{}\".format(len(all_predictions), all_predictions[['filename', 'true_id', 'det_id']].head()))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bL_56etnd0Rd"
      },
      "source": [
        "## Plot prediction error and confidence for each class (Run 1x for each trained model)\n",
        "---   \n",
        "Use these histograms to find a confidence threshold value to optimize dataset coverage and accuracy"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9WWA93QDdnSb"
      },
      "source": [
        "### Plot histograms"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "code",
        "id": "gEyoDC1rL1Ub"
      },
      "source": [
        "# Define functions\n",
        "\n",
        "# Valide predictions by image class (and optionally, by: taxon)\n",
        "def validate_predictions(df, inspect_by_taxon):\n",
        "    # If inspecting for taxon-specific images only\n",
        "    taxon = None\n",
        "    if inspect_by_taxon:\n",
        "        # TO DO: Type in the taxon you'd like to inspect results for using form field to right\n",
        "        taxon = \"\" #@param {type:\"string\"}\n",
        "        df = df.loc[df.ancestry.str.contains(taxon, case=False, na=False)]\n",
        "        print(\"Inspecting results for {}:\\n{}\".format(taxon, df.head()))\n",
        "    \n",
        "    # Validate predictions\n",
        "    # Check where true ratings and model-determined classes match\n",
        "    df['det'] = (df['true_id'] == df['det_id'])\n",
        "    tru = df.loc[df.det, :] # True ID\n",
        "    fal = df.loc[~df.det, :] # False ID\n",
        "\n",
        "    return tru, fal, taxon\n",
        "\n",
        "# Plot results by image class\n",
        "def plot_predict_x_conf(tru, fal, thresh, imclasses=imclasses):\n",
        "    # Break up predictions by image class and confidence values\n",
        "    # Define variables\n",
        "    c0,c1,c2,c3,c4 = [imclasses[i] for i in range(0, len(imclasses))]\n",
        "    # Check how many true/false predictions are at each confidence value\n",
        "    # Class 0 - 'herb'\n",
        "    c0t = tru.loc[tru['true_id'] == c0, :] # True dets\n",
        "    c0f = fal.loc[fal['true_id'] == c0, :] # False dets\n",
        "    # Class 1 - 'illus'\n",
        "    c1t = tru.loc[tru['true_id'] == c1, :] \n",
        "    c1f = fal.loc[fal['true_id'] == c1, :] \n",
        "    # Class 2 - 'map'\n",
        "    c2t = tru.loc[tru['true_id'] == c2, :] \n",
        "    c2f = fal.loc[fal['true_id'] == c2, :] \n",
        "    # Class 3 - 'null'\n",
        "    c3t = tru.loc[tru['true_id'] == c3, :] \n",
        "    c3f = fal.loc[fal['true_id'] == c3, :] \n",
        "    # Class 4 - 'phylo'\n",
        "    c4t = tru.loc[tru['true_id'] == c4, :] \n",
        "    c4f = fal.loc[fal['true_id'] == c4, :] \n",
        "\n",
        "    \n",
        "    # Plot parameters to make 1 subplot per image class\n",
        "    kwargs = dict(alpha=0.5, bins=15)\n",
        "    fig, axes = plt.subplots(len(imclasses), figsize=(10, 10), constrained_layout=True)\n",
        "    fig.suptitle('Prediction Confidence by Class\\n Overall Accuracy: {}'.format(\n",
        "                  format((len(tru)/(len(tru)+len(fal))),'.2f')))\n",
        "    \n",
        "    # Make subplots\n",
        "    # Class 0 - 'herb'\n",
        "    # True predictions\n",
        "    axes[0].hist(c0t['confidence'], color='y', label='True Det', **kwargs)\n",
        "    # False predictions\n",
        "    axes[0].hist(c0f['confidence'], color='r', label='False Det', **kwargs)\n",
        "    axes[0].set_title(\"{} (n={} images)\\n Accuracy: {}\".format(imclasses[0], \n",
        "                      len(c0t+c0f), format((len(c0t)/(len(c0t)+len(c0f))),'.2f')))\n",
        "    axes[0].legend();\n",
        "\n",
        "    # Class 1 - 'illus'\n",
        "    # True predictions\n",
        "    axes[1].hist(c1t['confidence'], color='y', label='True Det', **kwargs)\n",
        "    # False predictions\n",
        "    axes[1].hist(c1f['confidence'], color='r', label='False Det', **kwargs)\n",
        "    axes[1].set_title(\"{} (n={} images)\\n Accuracy: {}\".format(imclasses[1], \n",
        "                      len(c1t+c1f), format((len(c1t)/(len(c1t)+len(c1f))),'.2f')))\n",
        "    axes[1].legend();\n",
        "\n",
        "    # Class 2 - 'herb'\n",
        "    # True predictions\n",
        "    axes[2].hist(c2t['confidence'], color='y', label='True Det', **kwargs)\n",
        "    # False predictions\n",
        "    axes[2].hist(c2f['confidence'], color='r', label='False Det', **kwargs)\n",
        "    axes[2].set_title(\"{} (n={} images)\\n Accuracy: {}\".format(imclasses[2], \n",
        "                      len(c2t+c2f), format((len(c2t)/(len(c2t)+len(c2f))),'.2f')))\n",
        "    axes[2].legend();\n",
        "\n",
        "    # Class 3 - 'null'\n",
        "    # True predictions\n",
        "    axes[3].hist(c3t['confidence'], color='y', label='True Det', **kwargs)\n",
        "    # False predictions\n",
        "    axes[3].hist(c3f['confidence'], color='r', label='False Det', **kwargs)\n",
        "    axes[3].set_title(\"{} (n={} images)\\n Accuracy: {}\".format(imclasses[3], \n",
        "                      len(c3t+c3f), format((len(c3t)/(len(c3t)+len(c3f))),'.2f')))\n",
        "    axes[3].legend();\n",
        "\n",
        "    # Class 4 - 'phylo'\n",
        "    # True predictions\n",
        "    axes[4].hist(c4t['confidence'], color='y', label='True Det', **kwargs)\n",
        "    # False predictions\n",
        "    axes[4].hist(c4f['confidence'], color='r', label='False Det', **kwargs)\n",
        "    axes[4].set_title(\"{} (n={} images)\\n Accuracy: {}\".format(imclasses[4], \n",
        "                      len(c4t+c4f), format((len(c4t)/(len(c4t)+len(c4f))),'.2f')))\n",
        "    axes[4].legend();\n",
        "\n",
        "    # Add Y-axis labels\n",
        "    for ax in fig.get_axes():\n",
        "        ax.set(ylabel='Freq (# imgs)')\n",
        "        if thresh:\n",
        "            ax.axvline(thresh, color='k', linestyle='dashed', linewidth=1)\n",
        "\n",
        "    return fig\n",
        "\n",
        "# To save the figure\n",
        "def save_figure(fig, taxon, TRAIN_SESS_NUM=TRAIN_SESS_NUM, handle_base=handle_base):\n",
        "    # Make filename\n",
        "    if taxon: # If for a specific taxon\n",
        "        if 'plant' in taxon:\n",
        "            handle_base = handle_base + '_plantae'\n",
        "        elif 'anim' in taxon:\n",
        "            handle_base = handle_base + '_animalia'\n",
        "\n",
        "    figname = TRAIN_SESS_NUM + '_' + handle_base + '.png'\n",
        "    fig.savefig(figname)\n",
        "    print(\"Histograms saved to \", figname)\n",
        "\n",
        "    return figname"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "10GhFabiCj3c"
      },
      "source": [
        "# Load combined prediction results\n",
        "df = all_predictions.copy()\n",
        "\n",
        "# Optional: Inspect predictions for taxon-specific images only?\n",
        "# TO DO: If \"yes,\" check box\n",
        "inspect_by_taxon = False #@param {type:\"boolean\"}\n",
        "\n",
        "# Optional: Draw threshold value to help choose optimal balance b/w maximizing useful data and minimizing error\n",
        "# TO DO: Set threshold value\n",
        "thresh = 0 #@param {type:\"number\"}\n",
        "\n",
        "# Valide predictions by image class (and optionally, by: taxon)\n",
        "tru, fal, taxon = validate_predictions(df, inspect_by_taxon)\n",
        "\n",
        "# Plot results by image class\n",
        "fig = plot_predict_x_conf(tru, fal, thresh)\n",
        "\n",
        "# Export histograms\n",
        "figname = save_figure(fig, taxon)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NL4Ua3TS8J3S"
      },
      "source": [
        "### Simulate resulting dataset sizes based on different confidence thresholds"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U748-euK2eKN",
        "cellView": "code"
      },
      "source": [
        "# Simple simulation for different confidence values\n",
        "\n",
        "# Load combined prediction results\n",
        "df = all_predictions.copy()\n",
        "\n",
        "# Split by True or False determined image ID\n",
        "df['det'] = (df[\"true_id\"] == df[\"det_id\"])\n",
        "tru = df.loc[df.det, :] # True ID\n",
        "fal = df.loc[~df.det, :] # False ID\n",
        " \n",
        "# Confidence values to test  \n",
        "# TO DO: Chose range of confidence thresholds based on histograms above\n",
        "# By confidence value\n",
        "conf_vals = [1.0, 1.2, 1.4, 1.6, 1.8, 2.0, 2.2] #@param\n",
        "for conf_val in conf_vals: \n",
        "    df_c = df.loc[df[\"confidence\"] > conf_val, :]\n",
        "    true_c = tru.loc[tru[\"confidence\"] > conf_val, :]\n",
        "    fal_c = fal.loc[fal[\"confidence\"] > conf_val, :]\n",
        "    all_vals = true_c.append(fal_c)\n",
        "    print(\"\\nConfidence Value: {}\\n\".format(conf_val))\n",
        "    print(\"Accuracy for confidence > {}: {}\".format(conf_val, get_accuracy(len(true_c), len(all_vals))))\n",
        "    print(\"Predictions Retained (%): {}\".format(len(df_c)/len(df)))\n",
        "    print(\"True Predictions Retained (%): {}\".format(format((len(true_c)/len(tru)), '.2f')))\n",
        "    print(\"False Predictions Retained (%): {}\".format(format((len(fal_c)/len(fal)), '.2f')))\n",
        "    print(\"Accuracy for confidence > {}, by class:\".format(conf_val))\n",
        "    # By class\n",
        "    for imclass in imclasses:\n",
        "        true_det_c = len(true_c.loc[true_c[\"true_id\"] == imclass, :])\n",
        "        all_det_c = len(all_vals.loc[all_vals[\"true_id\"] == imclass, :])\n",
        "        accuracy = get_accuracy(true_det_c, all_det_c)\n",
        "        print(\"{}: {}\".format(imclass, accuracy))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6_wMLs4itYsU"
      },
      "source": [
        "## Inspect detections by image colorspace \n",
        "--- \n",
        "Noticed that many false dets in illustrations were from greyscale color mode ('L' in pillow). Look at true and false detections for greyscale images in each class"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-GyhC_-DtYXX"
      },
      "source": [
        "# Break up predictions by image class and colorspace\n",
        "\n",
        "# Define variables\n",
        "c0,c1,c2,c3,c4 = [imclasses[i] for i in range(0, len(imclasses))]\n",
        "# Check how many true/false predictions are at each confidence value\n",
        "# Class 0 - 'herb'\n",
        "c0t = tru.loc[tru['true_id'] == c0, :] # True dets\n",
        "c0f = fal.loc[fal['true_id'] == c0, :] # False dets\n",
        "# Class 1 - 'illus'\n",
        "c1t = tru.loc[tru['true_id'] == c1, :] \n",
        "c1f = fal.loc[fal['true_id'] == c1, :] \n",
        "# Class 2 - 'map'\n",
        "c2t = tru.loc[tru['true_id'] == c2, :] \n",
        "c2f = fal.loc[fal['true_id'] == c2, :] \n",
        "# Class 3 - 'null'\n",
        "c3t = tru.loc[tru['true_id'] == c3, :] \n",
        "c3f = fal.loc[fal['true_id'] == c3, :] \n",
        "# Class 4 - 'phylo'\n",
        "c4t = tru.loc[tru['true_id'] == c4, :] \n",
        "c4f = fal.loc[fal['true_id'] == c4, :] \n",
        "\n",
        "# Class 0 - Herbarium Sheet\n",
        "print(\"\\n{}\".format(c0))\n",
        "print(\"False detections: {}\\nTrue detections: {}\".format(len(c0f), len(c0t)))\n",
        "f_by_col = c0f.loc[c0f[\"colormode\"]==\"('L',)\", :]\n",
        "t_by_col = c0t.loc[c0t[\"colormode\"]==\"('L',)\", :]\n",
        "print(\"False for greyscale: {}\\nTrue for greyscale: {}\".format(len(f_by_col), len(t_by_col)))\n",
        "\n",
        "# Class 1 - Illustration\n",
        "print(\"\\n{}\".format(c1))\n",
        "print(\"False detections: {}\\nTrue detections: {}\".format(len(c1f), len(c1t)))\n",
        "f_by_col = c1f.loc[c1f[\"colormode\"]==\"('L',)\", :]\n",
        "t_by_col = c1t.loc[c1t[\"colormode\"]==\"('L',)\", :]\n",
        "print(\"False for greyscale: {}\\nTrue for greyscale: {}\".format(len(f_by_col), len(t_by_col)))\n",
        "\n",
        "# Class 2 = Map\n",
        "print(\"\\n{}\".format(c2))\n",
        "print(\"False detections: {}\\nTrue detections: {}\".format(len(c2f), len(c2t)))\n",
        "f_by_col = c2f.loc[c2f[\"colormode\"]==\"('L',)\", :]\n",
        "t_by_col = c2t.loc[c2t[\"colormode\"]==\"('L',)\", :]\n",
        "print(\"False for greyscale: {}\\nTrue for greyscale: {}\".format(len(f_by_col), len(t_by_col)))\n",
        "\n",
        "# Class 3 = Null\n",
        "print(\"\\n{}\".format(c3))\n",
        "print(\"False detections: {}\\nTrue detections: {}\".format(len(c3f), len(c3t)))\n",
        "f_by_col = c3f.loc[c3f[\"colormode\"]==\"('L',)\", :]\n",
        "t_by_col = c3t.loc[c3t[\"colormode\"]==\"('L',)\", :]\n",
        "print(\"False for greyscale: {}\\nTrue for greyscale: {}\".format(len(f_by_col), len(t_by_col)))\n",
        "\n",
        "# Class 4 = Phylogeny\n",
        "print(\"\\n{}\".format(c4))\n",
        "print(\"False detections: {}\\nTrue detections: {}\".format(len(c4f), len(c4t)))\n",
        "f_by_col = c4f.loc[c4f[\"colormode\"]==\"('L',)\", :]\n",
        "t_by_col = c4t.loc[c4t[\"colormode\"]==\"('L',)\", :]\n",
        "print(\"False for greyscale: {}\\nTrue for greyscale: {}\".format(len(f_by_col), len(t_by_col)))"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}