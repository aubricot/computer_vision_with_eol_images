{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPB/+OEchWxilTSaNEz9596",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/aubricot/computer_vision_with_eol_images/blob/master/classification_for_image_tagging/image_type/image_type_preprocessing.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WGFNOrAs0pMf"
      },
      "source": [
        "# Pre-process Image Type Classifier Training Images\n",
        "---\n",
        "*Last Updated 7 Aug 2025*   \n",
        "Follow steps below to make training and testing datasets using map, phylogeny, illustration, and herbarium sheet image bundles. ~800 images per image type class are downloaded to Google Drive for use training models in [image_type_train.ipynb](https://colab.research.google.com/github/aubricot/computer_vision_with_eol_images/blob/master/classification_for_image_tagging/image_type/image_type_train.ipynb).\n",
        "\n",
        "Image bundles were made from sources containing *mostly* images from the specified class, but sometimes contain other images. One step of this notebook requires that you go to Google Drive and manually curate the downloaded images. Smaller training datasets generally require more curation for models to learn well.\n",
        "\n",
        "Notes:   \n",
        "* Run code blocks by pressing play button in brackets on left\n",
        "* Before you you start: change the runtime to \"GPU\" with \"High RAM\"\n",
        "* Change parameters using form fields on right (find details at corresponding lines of code by searching '#@param')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F53iiacTFVz7"
      },
      "source": [
        "## Installs & Imports\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Choose where to save results (or keep defaults) & set up environment\n",
        "import os\n",
        "\n",
        "# Use dropdown menu on right\n",
        "save = \"in Colab runtime (files deleted after each session)\" #@param [\"in my Google Drive\", \"in Colab runtime (files deleted after each session)\"]\n",
        "print(\"Saving results \", save)\n",
        "\n",
        "# Mount google drive to export file(s)\n",
        "if 'Google Drive' in save:\n",
        "    from google.colab import drive\n",
        "    drive.mount('/content/drive', force_remount=True)\n",
        "\n",
        "# Type of classification pipeline\n",
        "classif_type = \"image_type\" #@param [\"image_type\", \"rating\"] {allow-input: true}\n",
        "\n",
        "# Type in the path to your working directory in form field to right\n",
        "basewd = \"/content/drive/MyDrive/train/tf2\" #@param [\"/content/drive/MyDrive/train/tf2\"] {allow-input: true}\n",
        "basewd = basewd + '/' + classif_type\n",
        "\n",
        "# Folder where preprocessing outputs will be saved\n",
        "folder = \"pre-processing\" # @param [\"pre-processing\",\"inspect_resul\",\"results\"] {\"allow-input\":true}\n",
        "cwd = basewd + '/' + folder\n",
        "\n",
        "# Folder where image metadata will be saved\n",
        "data_folder = \"image_data\" #@param [\"image_data\"] {allow-input: true}\n",
        "data_wd = cwd + '/' + data_folder\n",
        "\n",
        "# Folder where train/test images will be saved\n",
        "train_folder = \"images\" #@param [\"images\"] {allow-input: true}\n",
        "train_wd = cwd + '/' + train_folder\n",
        "\n",
        "# Enter image classes of interest in form field\n",
        "filters = [\"map\", \"phylo\", \"herb\", \"illus\"] #@param [\"[\\\"map\\\", \\\"phylo, \\\"herb\\\", \\\"illus\\\"]\"] {type:\"raw\", allow-input: true}\n",
        "\n",
        "# Download helper_funcs folder\n",
        "!pip3 -q install --upgrade gdown\n",
        "!gdown 1xmkrYEJKLJvei9q4zulKfqsGTgDvfvpR\n",
        "!tar -xzvf helper_funcs.tar.gz -C .\n",
        "\n",
        "# Install requirements.txt\n",
        "!pip3 -q install -r requirements.txt\n",
        "\n",
        "# Set up directory structure\n",
        "from setup import setup_dirs\n",
        "\n",
        "# Set up directory structure\n",
        "setup_dirs(cwd, data_wd, train_wd)\n",
        "print(\"\\nWorking directory set to: \\n\", cwd)\n",
        "print(\"\\nImage metadata directory set to: \\n\", data_wd)\n",
        "print(\"\\nTraining images directory set to: \\n\", train_wd)"
      ],
      "metadata": {
        "cellView": "code",
        "id": "Xp6hQwzkgQBH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K28NLif9Mx9v"
      },
      "source": [
        "#@title Import libraries\n",
        "\n",
        "# For augmenting, displaying, and saving images\n",
        "!pip install imaug\n",
        "!pip install pillow\n",
        "\n",
        "# For downloading images\n",
        "!apt-get install aria2\n",
        "\n",
        "# For importing/exporting files, working with arrays, etc\n",
        "import pathlib\n",
        "import os\n",
        "import imageio\n",
        "import time\n",
        "import csv\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from urllib.request import urlopen\n",
        "\n",
        "# For augmenting the images\n",
        "import imgaug as ia\n",
        "import imgaug.augmenters as iaa\n",
        "\n",
        "# For drawing onto and plotting the images\n",
        "import matplotlib.pyplot as plt\n",
        "import cv2\n",
        "%config InlineBackend.figure_format = 'svg'\n",
        "%matplotlib inline\n",
        "\n",
        "# Define functions\n",
        "from wrangle_data import *\n",
        "\n",
        "# Image Type bundle urls\n",
        "# Map, Herbarium Sheet, Phylogeny\n",
        "bundles = [\"https://editors.eol.org/other_files/bundle_images/classifier/maps.txt\",\n",
        "           \"https://editors.eol.org/other_files/bundle_images/classifier/Phylogeny_images.txt\",\n",
        "           \"https://editors.eol.org/other_files/bundle_images/classifier/herbarium_sheets_download.txt\"]\n",
        "\n",
        "# Illustration\n",
        "# Pool zoology and botany into one illustration bundle\n",
        "illus_bundles = [\"https://editors.eol.org/other_files/bundle_images/classifier/Zoological_illustrations_download.txt\",\n",
        "                 \"https://editors.eol.org/other_files/bundle_images/classifier/Botanical_illustrations_download.txt\"]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LZlJ7Rjaub3O"
      },
      "source": [
        "## Download images to Google Drive from EOL, Wikimedia, and Flickr BHL image bundles\n",
        "---\n",
        "Run this step 5x (once per image bundle). For each iteration, use the dropdown menu to the right to select the image bundle to download images from."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LtX3IIpLYXEv",
        "cellView": "code"
      },
      "source": [
        "#@title Download images for each class\n",
        "\n",
        "# Test pipeline with a smaller subset than 5k images?\n",
        "run = \"test with tiny subset\" #@param [\"test with tiny subset\", \"for all images\"]\n",
        "print(\"Run: \", run)\n",
        "\n",
        "# Download images, augment them, and save to Google Drive\n",
        "print(\"\\nDownloading training images for each class\")\n",
        "\n",
        "# Download images for each class\n",
        "for i, imclass in enumerate(filters):\n",
        "\n",
        "        # Make folder for each class\n",
        "        %cd $train_wd\n",
        "        impath = train_wd + \"/\" + imclass + \"/\"\n",
        "        if not os.path.isdir(impath):\n",
        "            os.makedirs(impath)\n",
        "        print(\"Path to images:\")\n",
        "        %cd $impath\n",
        "\n",
        "        # Read in corresponding bundle\n",
        "        # For map, herbarium sheet, phylogeny\n",
        "        if imclass != 'illus':\n",
        "            bundle = bundles[i]\n",
        "            !wget --user-agent=\"Mozilla\" $bundle\n",
        "            fn = os.path.basename(bundle)\n",
        "            df = pd.read_table(fn)\n",
        "\n",
        "        # For illustration\n",
        "        else:\n",
        "            il_fns = []\n",
        "            for illus_bundle in illus_bundles:\n",
        "                !wget --user-agent=\"Mozilla\" $illus_bundle\n",
        "                il_fn = os.path.basename(illus_bundle)\n",
        "                il_fns.append(il_fn)\n",
        "\n",
        "            df = pd.concat([pd.read_table(il_fn) for il_fn in il_fns], ignore_index=True)\n",
        "            fn = 'illustrations_download.txt'\n",
        "\n",
        "        # Take tiny subset or all images from bundle\n",
        "        start, stop = set_start_stop(run, df)\n",
        "        df = df.iloc[start:stop]\n",
        "        df.to_csv(fn, sep='\\n', header=False, index=False)\n",
        "\n",
        "        # Download images\n",
        "        !aria2c -x 16 -s 1 -i $fn\n",
        "\n",
        "        # Check how many images downloaded\n",
        "        print(\"Number of images downloaded to Google Drive for class {}:\".format(imclass))\n",
        "        !ls . | wc -l\n",
        "\n",
        "        # Move image metadata text file(s) to image_data/bundles\n",
        "        %cd $cwd\n",
        "        impath = impath + \"*.txt\"\n",
        "        !mv $impath image_data/"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Crpl2CtzuWTI"
      },
      "source": [
        "## Build \"null\" image class from EOL images\n",
        "---   \n",
        "Having a negative control will help train the classifier on what images do not belong in any of the above classes"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LuBO0i472WHV"
      },
      "source": [
        "# Download null.zip images folder leftover from flower_fruit classifier model\n",
        "%cd $train_wd\n",
        "!pip3 install --upgrade gdown\n",
        "!gdown 1-8-5EVq21jMUSvuEJynOBryKSJojOH49\n",
        "\n",
        "# Unzip images\n",
        "print(\"Unzipping botanical null images...\")\n",
        "!unzip null.zip\n",
        "\n",
        "# Move unzipped null image folder content to images/null\n",
        "# Google Drive Zipped folders have preserved directory structure\n",
        "if not os.path.isdir('null'):\n",
        "      os.makedirs('null')\n",
        "# Only move 5 images if running in demo mode\n",
        "if \"tiny subset\" in run:\n",
        "    !shuf -n 6 -e content/drive/'My Drive'/summer20/classification/image_type/images/null/* | xargs -i mv {} null\n",
        "# Run for all images\n",
        "else:\n",
        "    !mv content/drive/'My Drive'/summer20/classification/image_type/images/null/* null\n",
        "\n",
        "# Check how many images in 'null/'\n",
        "print(\"Number of images in 'null' class:\")\n",
        "%cd null\n",
        "!ls . | wc -l\n",
        "\n",
        "# Delete not needed files/folders\n",
        "%cd ../\n",
        "!rm -r content\n",
        "!rm -r null.zip"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r4fdwzVnuwPQ"
      },
      "source": [
        "## Go to Google Drive and visually inspect images in each folder\n",
        "---   \n",
        "Delete images based on chosen exclusion criteria to get consistent classes with representative images."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7FyeJcEu5gkH"
      },
      "source": [
        "#@title Standardize number of images per class\n",
        "%cd $cwd\n",
        "\n",
        "# Inspect the number of images in each folder\n",
        "print(\"Number of map images:\")\n",
        "maps = !ls images/map | wc -l\n",
        "print(maps)\n",
        "print(\"Number of herbarium sheet images:\")\n",
        "herb = !ls images/herb | wc -l\n",
        "print(herb)\n",
        "print(\"Number of phylogeny images:\")\n",
        "phylo = !ls images/phylo | wc -l\n",
        "print(phylo)\n",
        "print(\"Number of illustration images:\")\n",
        "illus = !ls images/illus | wc -l\n",
        "print(illus)\n",
        "print(\"Number of null images:\")\n",
        "null = !ls images/null | wc -l\n",
        "print(null)\n",
        "\n",
        "# Check which folder has the smallest number of images\n",
        "folders = [maps, herb, phylo, illus, null]\n",
        "foldernames = [\"maps\", \"herb\", \"phylo\", \"illus\", \"null\"]\n",
        "num_imgs = [int(x.list[0]) for x in folders]\n",
        "min_imgs = (min(num_imgs))\n",
        "idx = num_imgs.index(min(num_imgs))\n",
        "keepfolder = foldernames[idx]\n",
        "print(\"\\033[93mThe minimum number of images is {} in the folder {}\\033[0m\".format(min_imgs, foldernames[idx]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yK9MMPoYI_Lj"
      },
      "source": [
        "#@title Augment phylogeny images to increase dataset size and diversity\n",
        "# Phylogeny has half the images of other folders. Use image augmentation to increase the number and diversity of phylogeny images, then make remaining image classes even.\n",
        "\n",
        "# Test pipeline with a smaller subset than 5k images?\n",
        "run = \"test with tiny subset\" #@param [\"test with tiny subset\", \"for all images\"]\n",
        "print(\"Run: \", run)\n",
        "\n",
        "# Download images, augment them, and save to Google Drive\n",
        "print(\"\\nAugmenting images for phylogeny\")\n",
        "filenames = os.listdir(\"images/phylo\")\n",
        "start, stop = set_start_stop(run, filenames)\n",
        "\n",
        "# Loop through phylogeny images\n",
        "for i, fn in enumerate(filenames[start:stop], start=1):\n",
        "    # Read in image\n",
        "    impath = \"images/phylo/\" + fn\n",
        "    image = imageio.imread(impath, pilmode='RGB')\n",
        "\n",
        "    # Augment image using settings defined above in seq\n",
        "    ##image_aug = seq.augment(image=image)\n",
        "    image_aug = augment_image(image)\n",
        "\n",
        "    # Define augmentation results needed in exported dataset\n",
        "    fn_aug = os.path.splitext(impath)[0] + '_aug.jpg'\n",
        "\n",
        "    # Export augmented images to Google Drive\n",
        "    imageio.imwrite(fn_aug, image_aug)\n",
        "\n",
        "    # Display original and augmented image\n",
        "    if 'tiny subset' in run:\n",
        "        display_image(image)\n",
        "        display_image(image_aug)\n",
        "\n",
        "    # Display message to track augmentation process by image\n",
        "    print('\\033[92m{}) Successfully augmented image from {}\\033[0m'.format(i, fn))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Randomly delete all but N images to normalize number of images per folder\n",
        "# Only run for 5 images if running in demo mode\n",
        "if \"tiny subset\" in run:\n",
        "    print(\"\\033[92mDeleting all but 5 images from all folders...\\033[0m\")\n",
        "    !find \"images/illus\" -type f -print0 | sort -zR | tail -zn +6 | xargs -0 -r rm -v\n",
        "    !find \"images/phylo\" -type f -print0 | sort -zR | tail -zn +6 | xargs -0 -r rm -v\n",
        "    !find \"images/null\" -type f -print0 | sort -zR | tail -zn +6 | xargs -0 -r rm -v\n",
        "    !find \"images/map\" -type f -print0 | sort -zR | tail -zn +6 | xargs -0 -r rm -v\n",
        "    !find \"images/herb\" -type f -print0 | sort -zR | tail -zn +6 | xargs -0 -r rm -v\n",
        "# Run for all images - up to 3k per training class\n",
        "else:\n",
        "    print(\"\\033[92mDeleting all but 5 images from all folders...\\033[0m\")\n",
        "    !find \"images/illus\" -type f -print0 | sort -zR | tail -zn +3001 | xargs -0 -r rm -v\n",
        "    !find \"images/phylo\" -type f -print0 | sort -zR | tail -zn +3001 | xargs -0 -r rm -v\n",
        "    !find \"images/null\" -type f -print0 | sort -zR | tail -zn +3001 | xargs -0 -r rm -v\n",
        "    !find \"images/map\" -type f -print0 | sort -zR | tail -zn +3001 | xargs -0 -r rm -v\n",
        "    !find \"images/herb\" -type f -print0 | sort -zR | tail -zn +3001 | xargs -0 -r rm -v"
      ],
      "metadata": {
        "id": "mzmizWnPo_SC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Inspect the final number of images for each class\n",
        "import orjson\n",
        "\n",
        "# Inspect the number of images in each folder\n",
        "print(\"Number of map images:\")\n",
        "maps = !ls images/map | wc -l\n",
        "print(maps)\n",
        "print(\"Number of herbarium sheet images:\")\n",
        "herb = !ls images/herb | wc -l\n",
        "print(herb)\n",
        "print(\"Number of phylogeny images:\")\n",
        "phylo = !ls images/phylo | wc -l\n",
        "print(phylo)\n",
        "print(\"Number of illustration images:\")\n",
        "illus = !ls images/illus | wc -l\n",
        "print(illus)\n",
        "print(\"Number of null images:\")\n",
        "null = !ls images/null | wc -l\n",
        "print(null)\n",
        "\n",
        "# Make dictionary of folders and number of images they contain\n",
        "folders = [maps, herb, phylo, illus, null]\n",
        "foldernames = [\"maps\", \"herb\", \"phylo\", \"illus\", \"null\"]\n",
        "num_imgs = [int(x.list[0]) for x in folders]\n",
        "num_train = dict(zip(foldernames, num_imgs))\n",
        "print(num_train)\n",
        "\n",
        "# Save number of images per training class to a json file\n",
        "outfpath = \"image_data/num_imgs_per_class.json\"\n",
        "print(\"\\nSaving data on number of images per training class to: \", outfpath)\n",
        "with open(outfpath, \"wb\") as f:\n",
        "        f.write(orjson.dumps(num_train, option= orjson.OPT_INDENT_2))"
      ],
      "metadata": {
        "id": "rEJ8TAqvqskr"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}