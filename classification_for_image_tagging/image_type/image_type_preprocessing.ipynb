{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "image_type_preprocessing.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "Crpl2CtzuWTI",
        "xXbfCxBNILb5"
      ],
      "authorship_tag": "ABX9TyPATysl+D/hXVwvMrGpFmEW",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/aubricot/computer_vision_with_eol_images/blob/master/classification_for_image_tagging/image_type/image_type_preprocessing.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WGFNOrAs0pMf"
      },
      "source": [
        "# Pre-process Image Type Classifier Training Images\n",
        "---\n",
        "*Last Updated 28 Oct 2021*   \n",
        "Follow steps below to make training and testing datasets using map, phylogeny, illustration, and herbarium sheet image bundles. ~800 images per image type class are downloaded to Google Drive for use training models in [image_type_train.ipynb](https://colab.research.google.com/github/aubricot/computer_vision_with_eol_images/blob/master/classification_for_image_tagging/image_type/image_type_train.ipynb). \n",
        "\n",
        "Image bundles were made from sources containing *mostly* images from the specified class, but sometimes contain other images. One step of this notebook requires that you go to Google Drive and manually curate the downloaded images. Smaller training datasets generally require more curation for models to learn well.\n",
        "\n",
        "Notes:\n",
        "* Change filepaths or information using the form fields to the right of code blocks (also noted in code with 'TO DO')\n",
        "* One step of this notebook requires that you go to Google Drive and manually curate the downloaded images."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F53iiacTFVz7"
      },
      "source": [
        "## Installs & Imports\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MeNoVQDN0I1q"
      },
      "source": [
        "# Mount google drive to import/export files\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K28NLif9Mx9v"
      },
      "source": [
        "# Install libraries for augmenting, displaying, and saving images\n",
        "!pip install imgaug\n",
        "!pip install pillow\n",
        "\n",
        "# For downloading images\n",
        "!apt-get install aria2\n",
        "\n",
        "# For importing/exporting files, working with arrays, etc\n",
        "import pathlib\n",
        "import os\n",
        "import imageio\n",
        "import time\n",
        "import csv\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from urllib.request import urlopen\n",
        "from scipy import misc\n",
        "\n",
        "# For augmenting the images and bounding boxes\n",
        "import imgaug as ia\n",
        "import imgaug.augmenters as iaa\n",
        "from imgaug.augmentables.bbs import BoundingBox, BoundingBoxesOnImage\n",
        "\n",
        "# For drawing onto and plotting the images\n",
        "import matplotlib.pyplot as plt\n",
        "import cv2\n",
        "%config InlineBackend.figure_format = 'svg'\n",
        "%matplotlib inline\n",
        "\n",
        "# Define functions\n",
        "\n",
        "# To read in EOL formatted data files\n",
        "def read_datafile(fpath, sep=\"\\t\", header=0, disp_head=True, lineterminator='\\n', encoding='latin1'):\n",
        "    \"\"\"\n",
        "    Defaults to tab-separated data files with header in row 0\n",
        "    \"\"\"\n",
        "    try:\n",
        "        df = pd.read_csv(fpath, sep=sep, header=header, lineterminator=lineterminator, encoding=encoding)\n",
        "        if disp_head:\n",
        "          print(\"Data header: \\n\", df.head())\n",
        "    except FileNotFoundError as e:\n",
        "        raise Exception(\"File not found: Enter the path to your file in form field and re-run\").with_traceback(e.__traceback__)\n",
        "    \n",
        "    return df\n",
        "\n",
        "# To display an image already loaded into the runtime\n",
        "def display_image(image):\n",
        "  fig = plt.figure(figsize=(20, 15))\n",
        "  plt.grid(False)\n",
        "  plt.imshow(image)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LZlJ7Rjaub3O"
      },
      "source": [
        "## Download images to Google Drive from EOL, Wikimedia, and Flickr BHL image bundles\n",
        "---\n",
        "Run this step 5x (once per image bundle). For each iteration, use the dropdown menu to the right to select the image bundle to download images from."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7WNWuVOFU53G"
      },
      "source": [
        "# Set up directory structure\n",
        "# TO DO: Type in the path to your working directory in form field to right\n",
        "wd = \"/content/drive/MyDrive/train\" #@param {type:\"string\"}\n",
        "cwd = wd + '/pre-processing/images/'\n",
        "image_data = wd + '/pre-processing/image_data/'\n",
        "if not os.path.isdir(cwd):\n",
        "    os.makedirs(cwd)\n",
        "    os.makedirs(image_data)\n",
        "%cd $cwd\n",
        "\n",
        "# Image Type classes\n",
        "imclasses = [\"map\", \"herb\", \"phylo\", \"illus\"]\n",
        "\n",
        "# Image Type bundles\n",
        "# Map, Herbarium Sheet, Phylogeny\n",
        "bundles = [\"https://editors.eol.org/other_files/bundle_images/classifier/maps.txt\", \n",
        "           \"https://editors.eol.org/other_files/bundle_images/classifier/Phylogeny_images.txt\", \n",
        "           \"https://editors.eol.org/other_files/bundle_images/classifier/herbarium_sheets_download.txt\"]\n",
        "\n",
        "# Illustration\n",
        "# Combine zoology and botany into one illustration bundle\n",
        "illus_bundles = [\"https://editors.eol.org/other_files/bundle_images/classifier/Zoological_illustrations_download.txt\", \n",
        "                 \"https://editors.eol.org/other_files/bundle_images/classifier/Botanical_illustrations_download.txt\"]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LtX3IIpLYXEv"
      },
      "source": [
        "# Optional: Test downloads with a small subset first?\n",
        "# TO DO: If yes, check test_with_tiny_subset box\n",
        "test_with_tiny_subset = True #@param {type: \"boolean\"}\n",
        "\n",
        "# Test downloads with tiny subset\n",
        "if test_with_tiny_subset:\n",
        "    filenames_tiny = []\n",
        "    # Download images for each class\n",
        "    for i, imclass in enumerate(imclasses):\n",
        "        # Make folder for each class\n",
        "        %cd $cwd\n",
        "        impath = cwd + imclass + \"/\"\n",
        "        if not os.path.isdir(impath):\n",
        "            os.makedirs(impath)\n",
        "        print(\"Path to images:\")\n",
        "        %cd $impath\n",
        "\n",
        "        # Read in corresponding bundle \n",
        "        # For map, herbarium sheet, phylogeny\n",
        "        if imclass != 'illus':\n",
        "            bundle = bundles[i]\n",
        "            fn = os.path.basename(bundle)\n",
        "            df = pd.read_table(bundle, sep='\\n', header=None)\n",
        "        # For illustration\n",
        "        else:\n",
        "            fn = 'illustrations_download.txt'\n",
        "            df = pd.concat([pd.read_table(f, sep='\\n', header=None, \n",
        "                                na_filter = False) for f in illus_bundles], \n",
        "                                ignore_index=True)\n",
        "        # Save tiny subset file\n",
        "        df = df.head()\n",
        "        fn_tiny = impath + os.path.splitext(fn)[0] + '_tinysubset.txt'\n",
        "        df.to_csv(fn_tiny, sep='\\n', header=False)\n",
        "\n",
        "        # Download images\n",
        "        !aria2c -x 16 -s 1 -i $fn_tiny\n",
        "\n",
        "        # Check how many images downloaded\n",
        "        print(\"Number of images downloaded to Google Drive for class {}:\".format(imclass))\n",
        "        !ls . | wc -l\n",
        "\n",
        "        # Move text file to image_data/bundles\n",
        "        %cd ../..\n",
        "        !mv $fn_tiny image_data"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ocIw1WmV44Mr",
        "cellView": "code"
      },
      "source": [
        "# Run for all images\n",
        "\n",
        "# Download images for each class\n",
        "for i, imclass in enumerate(imclasses):\n",
        "        # Make folder for each class\n",
        "        %cd $cwd\n",
        "        impath = cwd + imclass + \"/\"\n",
        "        if not os.path.isdir(impath):\n",
        "            os.makedirs(impath)\n",
        "        print(\"Path to images:\")\n",
        "        %cd $impath\n",
        "\n",
        "        # Read in corresponding bundle \n",
        "        # For map, herbarium sheet, phylogeny\n",
        "        if imclass != 'illus':\n",
        "            bundle = bundles[i]\n",
        "            !wget --user-agent=\"Mozilla\" $bundle\n",
        "            fn = os.path.basename(bundle)  \n",
        "        # For illustration\n",
        "        else:\n",
        "            \n",
        "            df = pd.concat([pd.read_table(f, sep='\\n', header=None, \n",
        "                                na_filter = False) for f in illus_bundles], \n",
        "                                ignore_index=True)\n",
        "            fn = 'illustrations_download.txt'\n",
        "            df.to_csv(fn, sep='\\n', header=False, index=False)\n",
        "\n",
        "        # Download images\n",
        "        !aria2c -x 16 -s 1 -i $fn\n",
        "\n",
        "        # Check how many images downloaded\n",
        "        print(\"Number of images downloaded to Google Drive for class {}:\".format(imclass))\n",
        "        !ls . | wc -l\n",
        "\n",
        "        # Move text file to image_data/bundles\n",
        "        fpath = impath + fn\n",
        "        %cd ../..\n",
        "        !mv $fpath image_data"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Crpl2CtzuWTI"
      },
      "source": [
        "## Build \"null\" image class from EOL images\n",
        "---   \n",
        "Having a negative control will help train the classifier on what images do not belong in any of the above classes"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LuBO0i472WHV"
      },
      "source": [
        "# Download null.zip images folder leftover from flower_fruit classifier model\n",
        "!gdown --id 1-8-5EVq21jMUSvuEJynOBryKSJojOH49\n",
        "\n",
        "# Unzip images\n",
        "print(\"Unzipping botanical null images\")\n",
        "!unzip null.zip\n",
        "\n",
        "# Google Drive Zipped folders have preserved directory structure\n",
        "# Hacky workaround to move images to null folder\n",
        "if not os.path.isdir('null'):\n",
        "      os.makedirs('null')\n",
        "!mv content/drive/'My Drive'/summer20/classification/image_type/images/null/* images/null\n",
        "\n",
        "# Check how many images in 'null/'\n",
        "print(\"Number of images in 'null' class:\")\n",
        "!ls . | wc -l\n",
        "\n",
        "# Delete not needed files/folders\n",
        "!rm -r content\n",
        "!rm -r null.zip"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r4fdwzVnuwPQ"
      },
      "source": [
        "## Go to Google Drive and visually inspect images in each folder\n",
        "---   \n",
        "Delete images based on chosen exclusion criteria to get consistent classes with representative images."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZfUGCY-nVW7R"
      },
      "source": [
        "## Standardize number of images per class\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7FyeJcEu5gkH"
      },
      "source": [
        "# Inspect the number of images in each folder\n",
        "print(\"Number of map images:\")\n",
        "maps = !ls images/map | wc -l\n",
        "print(maps)\n",
        "print(\"Number of herbarium sheet images:\")\n",
        "herb = !ls images/herb | wc -l\n",
        "print(herb)\n",
        "print(\"Number of phylogeny images:\")\n",
        "phylo = !ls images/phylo | wc -l\n",
        "print(phylo)\n",
        "print(\"Number of illustration images:\")\n",
        "illus = !ls images/illus | wc -l\n",
        "print(illus)\n",
        "print(\"Number of null images:\")\n",
        "null = !ls images/null | wc -l\n",
        "print(null)\n",
        "\n",
        "# Check which folder has the smallest number of images\n",
        "folders = [maps, herb, phylo, illus, null]\n",
        "foldernames = [\"maps\", \"herb\", \"phylo\", \"illus\", \"null\"]\n",
        "num_imgs = [int(x.list[0]) for x in folders]\n",
        "min_imgs = (min(num_imgs))\n",
        "idx = num_imgs.index(min(num_imgs))\n",
        "keepfolder = foldernames[idx]\n",
        "print(\"The minimum number of images is {} in the folder {}\".format(min_imgs, foldernames[idx]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xXbfCxBNILb5"
      },
      "source": [
        "#### Augment phylogenies to increase dataset size and diversity\n",
        "Phylogeny has half the images of other folders. Use image augmentation to increase the number and diversity of phylogeny images, then make remaining image classes even."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ykfc-DwKIOdv"
      },
      "source": [
        "# Define image augmentation pipeline\n",
        "# modified from https://github.com/aleju/imgaug\n",
        "seq = iaa.Sequential([\n",
        "    iaa.Crop(px=(1, 16), keep_size=False), # crop by 1-16px, resize resulting image to orig dims\n",
        "    iaa.Affine(rotate=(-25, 25)), # rotate -25 to 25 degrees\n",
        "    iaa.GaussianBlur(sigma=(0, 3.0)), # blur using gaussian kernel with sigma of 0-3\n",
        "    iaa.AddToHueAndSaturation((-50, 50), per_channel=True)\n",
        "])\n",
        "\n",
        "# Optional: set seed to make augmentations reproducible across runs, otherwise will be random each time\n",
        "ia.seed(1) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yK9MMPoYI_Lj"
      },
      "source": [
        "# Optional: Test downloads with a small subset first?\n",
        "# TO DO: If yes, check test_with_tiny_subset box\n",
        "test_with_tiny_subset = True #@param {type: \"boolean\"}\n",
        "\n",
        "# Augment phylogeny images to increase dataset size and diversity\n",
        "filenames = os.listdir(\"images/phylo\")\n",
        "if test_with_tiny_subset:\n",
        "    filenames = filenames[:6]\n",
        "    display_results = True\n",
        "# Loop through phylogeny images \n",
        "for i, fn in enumerate(filenames, start=1):\n",
        "    # Read in image\n",
        "    impath = \"images/phylo/\" + fn\n",
        "    image = imageio.imread(impath, pilmode='RGB')\n",
        "    \n",
        "    # Augment image using settings defined above in seq\n",
        "    image_aug = seq.augment(image=image)\n",
        "    \n",
        "    # Define augmentation results needed in exported dataset\n",
        "    fn_aug = os.path.splitext(impath)[0] + '_aug.jpg'\n",
        "\n",
        "    # Export augmented images to Google Drive\n",
        "    imageio.imwrite(fn_aug, image_aug)\n",
        "    \n",
        "    # Display original and augmented image\n",
        "    if display_results:\n",
        "        display_image(image)\n",
        "        display_image(image_aug)    \n",
        "\n",
        "    # Display message to track augmentation process by image\n",
        "    print('{}) Successfully augmented image from {}'.format(i, fn))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wzPmo0wmmTeX"
      },
      "source": [
        "#### Delete excess images from classes so that folders have roughly the same number of images"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2ges1Dpcj62i"
      },
      "source": [
        "# Randomly delete all but 3000 images from whichever folders have too many images\n",
        "!find \"images/illus\" -type f -print0 | sort -zR | tail -zn +3001 | xargs -0 rm\n",
        "!find \"images/phylogeny\" -type f -print0 | sort -zR | tail -zn +3001 | xargs -0 rm"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}