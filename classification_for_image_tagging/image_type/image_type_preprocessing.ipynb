{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPkp4f7NO72Bo31wf++jKFO",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/aubricot/computer_vision_with_eol_images/blob/master/classification_for_image_tagging/image_type/image_type_preprocessing.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WGFNOrAs0pMf"
      },
      "source": [
        "# Pre-process Image Type Classifier Training Images\n",
        "---\n",
        "*Last Updated 17 December 2022*   \n",
        "Follow steps below to make training and testing datasets using map, phylogeny, illustration, and herbarium sheet image bundles. ~800 images per image type class are downloaded to Google Drive for use training models in [image_type_train.ipynb](https://colab.research.google.com/github/aubricot/computer_vision_with_eol_images/blob/master/classification_for_image_tagging/image_type/image_type_train.ipynb). \n",
        "\n",
        "Image bundles were made from sources containing *mostly* images from the specified class, but sometimes contain other images. One step of this notebook requires that you go to Google Drive and manually curate the downloaded images. Smaller training datasets generally require more curation for models to learn well.\n",
        "\n",
        "Notes:   \n",
        "* Run code blocks by pressing play button in brackets on left\n",
        "* Before you you start: change the runtime to \"GPU\" with \"High RAM\"\n",
        "* Change parameters using form fields on right (find details at corresponding lines of code by searching '#@param')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F53iiacTFVz7"
      },
      "source": [
        "## Installs & Imports\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MeNoVQDN0I1q"
      },
      "source": [
        "#@title Choose where to save results & set up directory structure\n",
        "# Use dropdown menu on right\n",
        "save = \"in Colab runtime (files deleted after each session)\" #@param [\"in my Google Drive\", \"in Colab runtime (files deleted after each session)\"]\n",
        "print(\"Saving results \", save)\n",
        "\n",
        "# Mount google drive to export image cropping coordinate file(s)\n",
        "if 'Google Drive' in save:\n",
        "    from google.colab import drive\n",
        "    drive.mount('/content/drive', force_remount=True)\n",
        "\n",
        "# Type in the path to your working directory in form field to right\n",
        "import os\n",
        "basewd = \"/content/drive/MyDrive/train/tf2\" #@param [\"/content/drive/MyDrive/train/tf2\"] {allow-input: true}\n",
        "if not os.path.exists(basewd):\n",
        "    os.makedirs(basewd)\n",
        "\n",
        "# Enter taxon of interest in form field\n",
        "imclasses = [\"map\", \"phylo\", \"herb\", \"illus\"] #@param [\"[\\\"map\\\", \\\"phylo, \\\"herb\\\", \\\"illus\\\"]\"] {type:\"raw\", allow-input: true}\n",
        "\n",
        "# Folder where pre-processing results will be saved\n",
        "preprocessing_folder = \"pre-processing\" #@param [\"pre-processing\"] {allow-input: true}\n",
        "cwd = basewd + '/' + preprocessing_folder\n",
        "print(\"\\nWorking directory set to: \\n\", cwd)\n",
        "\n",
        "# Folder where image metadata will be saved\n",
        "data_folder = \"image_data\" #@param [\"image_data\"] {allow-input: true}\n",
        "data_wd = cwd + '/' + data_folder\n",
        "if not os.path.exists(data_wd):\n",
        "    os.makedirs(data_wd)\n",
        "print(\"\\nImage metadata directory set to: \\n\", data_wd)\n",
        "\n",
        "# Folder where train/test images will be saved\n",
        "train_folder = \"images\" #@param [\"images\"] {allow-input: true}\n",
        "train_wd = cwd + '/' + train_folder\n",
        "if not os.path.exists(train_wd):\n",
        "    os.makedirs(train_wd)\n",
        "print(\"\\nTraining images directory set to: \\n\", train_wd)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K28NLif9Mx9v"
      },
      "source": [
        "#@title Install libraries\n",
        "\n",
        "# For augmenting, displaying, and saving images\n",
        "!pip install imgaug\n",
        "!pip install pillow\n",
        "\n",
        "# For downloading images\n",
        "!apt-get install aria2\n",
        "\n",
        "# For importing/exporting files, working with arrays, etc\n",
        "import pathlib\n",
        "import os\n",
        "import imageio\n",
        "import time\n",
        "import csv\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from urllib.request import urlopen\n",
        "\n",
        "# For augmenting the images and bounding boxes\n",
        "import imgaug as ia\n",
        "import imgaug.augmenters as iaa\n",
        "from imgaug.augmentables.bbs import BoundingBox, BoundingBoxesOnImage\n",
        "\n",
        "# For drawing onto and plotting the images\n",
        "import matplotlib.pyplot as plt\n",
        "import cv2\n",
        "%config InlineBackend.figure_format = 'svg'\n",
        "%matplotlib inline"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LZlJ7Rjaub3O"
      },
      "source": [
        "## Download images to Google Drive from EOL, Wikimedia, and Flickr BHL image bundles\n",
        "---\n",
        "Run this step 5x (once per image bundle). For each iteration, use the dropdown menu to the right to select the image bundle to download images from."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7WNWuVOFU53G"
      },
      "source": [
        "#@title Define functions\n",
        "\n",
        "# Image Type bundle urls\n",
        "# Map, Herbarium Sheet, Phylogeny\n",
        "bundles = [\"https://editors.eol.org/other_files/bundle_images/classifier/maps.txt\", \n",
        "           \"https://editors.eol.org/other_files/bundle_images/classifier/Phylogeny_images.txt\", \n",
        "           \"https://editors.eol.org/other_files/bundle_images/classifier/herbarium_sheets_download.txt\"]\n",
        "\n",
        "# Illustration\n",
        "# Pool zoology and botany into one illustration bundle\n",
        "illus_bundles = [\"https://editors.eol.org/other_files/bundle_images/classifier/Zoological_illustrations_download.txt\", \n",
        "                 \"https://editors.eol.org/other_files/bundle_images/classifier/Botanical_illustrations_download.txt\"]\n",
        "\n",
        "# Define functions\n",
        "\n",
        "# To read in EOL formatted data files\n",
        "def read_datafile(fpath, sep=\"\\t\", header=0, disp_head=True):\n",
        "    try:\n",
        "        df = pd.read_csv(fpath, sep=sep, header=header)\n",
        "        if disp_head:\n",
        "          print(\"Data header: \\n\", df.head())\n",
        "    except FileNotFoundError as e:\n",
        "        raise Exception(\"File not found: Enter the path to your file in form field and re-run\").with_traceback(e.__traceback__)\n",
        "    \n",
        "    return df\n",
        "\n",
        "# To display an image already loaded into the runtime\n",
        "def display_image(image):\n",
        "    fig = plt.figure(figsize=(20, 15))\n",
        "    plt.grid(False)\n",
        "    plt.imshow(image)\n",
        "\n",
        "# Define start and stop indices in EOL bundle for running inference   \n",
        "def set_start_stop(run, df):\n",
        "    # To test with a tiny subset, use 50 random bundle images\n",
        "    N = len(df)\n",
        "    if \"tiny subset\" in run:\n",
        "        start=np.random.choice(a=N, size=1)[0]\n",
        "        stop=start+50\n",
        "    # To run for a larger set, use 500 random images\n",
        "    else:\n",
        "        start=np.random.choice(a=N, size=1)[0]\n",
        "        stop=start+500\n",
        "    \n",
        "    return start, stop"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LtX3IIpLYXEv",
        "cellView": "code"
      },
      "source": [
        "#@title Download images for each class\n",
        "\n",
        "# Test pipeline with a smaller subset than 5k images?\n",
        "run = \"test with tiny subset\" #@param [\"test with tiny subset\", \"for all images\"]\n",
        "print(\"Run: \", run)\n",
        "\n",
        "# Download images, augment them, and save to Google Drive\n",
        "print(\"\\nDownloading training images for each class\")\n",
        "\n",
        "# Download images for each class\n",
        "for i, imclass in enumerate(imclasses):\n",
        "    \n",
        "        # Make folder for each class\n",
        "        %cd $train_wd\n",
        "        impath = train_wd + \"/\" + imclass + \"/\"\n",
        "        if not os.path.isdir(impath):\n",
        "            os.makedirs(impath)\n",
        "        print(\"Path to images:\")\n",
        "        %cd $impath\n",
        "\n",
        "        # Read in corresponding bundle \n",
        "        # For map, herbarium sheet, phylogeny\n",
        "        if imclass != 'illus':\n",
        "            bundle = bundles[i]\n",
        "            !wget --user-agent=\"Mozilla\" $bundle\n",
        "            fn = os.path.basename(bundle)\n",
        "            df = pd.read_csv(fn, sep='\\n', header=None)\n",
        "\n",
        "        # For illustration\n",
        "        else:\n",
        "            il_fns = []\n",
        "            for illus_bundle in illus_bundles:\n",
        "                !wget --user-agent=\"Mozilla\" $illus_bundle\n",
        "                il_fn = os.path.basename(illus_bundle)\n",
        "                il_fns.append(il_fn)\n",
        "\n",
        "            df = pd.concat([pd.read_csv(il_fn, sep='\\n', header=None) for il_fn in il_fns], ignore_index=True)\n",
        "            fn = 'illustrations_download.txt'\n",
        "        \n",
        "        # Take tiny subset or all images from bundle\n",
        "        start, stop = set_start_stop(run, df)\n",
        "        df = df.iloc[start:stop]\n",
        "        df.to_csv(fn, sep='\\n', header=False, index=False)\n",
        "\n",
        "        # Download images\n",
        "        !aria2c -x 16 -s 1 -i $fn\n",
        "\n",
        "        # Check how many images downloaded\n",
        "        print(\"Number of images downloaded to Google Drive for class {}:\".format(imclass))\n",
        "        !ls . | wc -l\n",
        "\n",
        "        # Move image metadata text file(s) to image_data/bundles\n",
        "        %cd $cwd\n",
        "        impath = impath + \"*.txt\"\n",
        "        !mv $impath image_data/"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Crpl2CtzuWTI"
      },
      "source": [
        "## Build \"null\" image class from EOL images\n",
        "---   \n",
        "Having a negative control will help train the classifier on what images do not belong in any of the above classes"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LuBO0i472WHV"
      },
      "source": [
        "# Download null.zip images folder leftover from flower_fruit classifier model\n",
        "%cd $train_wd\n",
        "!gdown 1-8-5EVq21jMUSvuEJynOBryKSJojOH49\n",
        "\n",
        "# Unzip images\n",
        "print(\"Unzipping botanical null images\")\n",
        "!unzip null.zip\n",
        "\n",
        "# Move unzipped null image folder content to images/null\n",
        "# Google Drive Zipped folders have preserved directory structure\n",
        "if not os.path.isdir('null'):\n",
        "      os.makedirs('null')\n",
        "!mv content/drive/'My Drive'/summer20/classification/image_type/images/null/* null\n",
        "\n",
        "# Check how many images in 'null/'\n",
        "print(\"Number of images in 'null' class:\")\n",
        "%cd null\n",
        "!ls . | wc -l\n",
        "\n",
        "# Delete not needed files/folders\n",
        "!rm -r content\n",
        "!rm -r null.zip"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r4fdwzVnuwPQ"
      },
      "source": [
        "## Go to Google Drive and visually inspect images in each folder\n",
        "---   \n",
        "Delete images based on chosen exclusion criteria to get consistent classes with representative images."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZfUGCY-nVW7R"
      },
      "source": [
        "## Standardize number of images per class\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7FyeJcEu5gkH"
      },
      "source": [
        "%cd $cwd\n",
        "\n",
        "# Inspect the number of images in each folder\n",
        "print(\"Number of map images:\")\n",
        "maps = !ls images/map | wc -l\n",
        "print(maps)\n",
        "print(\"Number of herbarium sheet images:\")\n",
        "herb = !ls images/herb | wc -l\n",
        "print(herb)\n",
        "print(\"Number of phylogeny images:\")\n",
        "phylo = !ls images/phylo | wc -l\n",
        "print(phylo)\n",
        "print(\"Number of illustration images:\")\n",
        "illus = !ls images/illus | wc -l\n",
        "print(illus)\n",
        "print(\"Number of null images:\")\n",
        "null = !ls images/null | wc -l\n",
        "print(null)\n",
        "\n",
        "# Check which folder has the smallest number of images\n",
        "folders = [maps, herb, phylo, illus, null]\n",
        "foldernames = [\"maps\", \"herb\", \"phylo\", \"illus\", \"null\"]\n",
        "num_imgs = [int(x.list[0]) for x in folders]\n",
        "min_imgs = (min(num_imgs))\n",
        "idx = num_imgs.index(min(num_imgs))\n",
        "keepfolder = foldernames[idx]\n",
        "print(\"The minimum number of images is {} in the folder {}\".format(min_imgs, foldernames[idx]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xXbfCxBNILb5"
      },
      "source": [
        "#### Augment phylogenies to increase dataset size and diversity\n",
        "Phylogeny has half the images of other folders. Use image augmentation to increase the number and diversity of phylogeny images, then make remaining image classes even."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ykfc-DwKIOdv"
      },
      "source": [
        "#@title Define image augmentation pipeline\n",
        "# modified from https://github.com/aleju/imgaug\n",
        "seq = iaa.Sequential([\n",
        "    iaa.Crop(px=(1, 16), keep_size=False), # crop by 1-16px, resize resulting image to orig dims\n",
        "    iaa.Affine(rotate=(-25, 25)), # rotate -25 to 25 degrees\n",
        "    iaa.GaussianBlur(sigma=(0, 3.0)), # blur using gaussian kernel with sigma of 0-3\n",
        "    iaa.AddToHueAndSaturation((-50, 50), per_channel=True)\n",
        "])\n",
        "\n",
        "# Optional: set seed to make augmentations reproducible across runs, otherwise will be random each time\n",
        "ia.seed(1) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yK9MMPoYI_Lj"
      },
      "source": [
        "#@title Augment phylogeny images to increase dataset size and diversity\n",
        "\n",
        "# Test pipeline with a smaller subset than 5k images?\n",
        "run = \"test with tiny subset\" #@param [\"test with tiny subset\", \"for all images\"]\n",
        "print(\"Run: \", run)\n",
        "\n",
        "# Download images, augment them, and save to Google Drive\n",
        "print(\"\\nAugmenting images for phylogeny\")\n",
        "filenames = os.listdir(\"images/phylo\")\n",
        "start, stop = set_start_stop(run, filenames)\n",
        "\n",
        "# Loop through phylogeny images \n",
        "for i, fn in enumerate(filenames[start:stop], start=1):\n",
        "    # Read in image\n",
        "    impath = \"images/phylo/\" + fn\n",
        "    image = imageio.imread(impath, pilmode='RGB')\n",
        "    \n",
        "    # Augment image using settings defined above in seq\n",
        "    image_aug = seq.augment(image=image)\n",
        "    \n",
        "    # Define augmentation results needed in exported dataset\n",
        "    fn_aug = os.path.splitext(impath)[0] + '_aug.jpg'\n",
        "\n",
        "    # Export augmented images to Google Drive\n",
        "    imageio.imwrite(fn_aug, image_aug)\n",
        "    \n",
        "    # Display original and augmented image\n",
        "    if 'tiny subset' in run:\n",
        "        display_image(image)\n",
        "        display_image(image_aug)    \n",
        "\n",
        "    # Display message to track augmentation process by image\n",
        "    print('{}) Successfully augmented image from {}'.format(i, fn))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wzPmo0wmmTeX"
      },
      "source": [
        "#### Delete excess images from classes so that folders have roughly the same number of images"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2ges1Dpcj62i"
      },
      "source": [
        "# Randomly delete all but 3000 images from whichever folders have too many images\n",
        "!find \"images/illus\" -type f -print0 | sort -zR | tail -zn +3001 | xargs -0 rm\n",
        "!find \"images/phylogeny\" -type f -print0 | sort -zR | tail -zn +3001 | xargs -0 rm"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}