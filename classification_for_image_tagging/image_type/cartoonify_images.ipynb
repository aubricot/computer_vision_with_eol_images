{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/aubricot/computer_vision_with_eol_images/blob/master/classification_for_image_tagging/image_type/cartoonify_images.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YuyVuOl95iA3"
      },
      "source": [
        "# Determine if images are a cartoon or photograph\n",
        "---\n",
        "*Last Updated 17 December 2022*   \n",
        "Classification accuracy for illustrated images and phylogenies was low for the trained model. This notebook uses an alternate approach that leverages image processing to identify images as photographic or non-photographic. First, cartoonify image, then compare change in color values. If change above a certain threshold, then image is likely photographic. If change below a certain threshold, image is likely non-photographic.\n",
        "  \n",
        "***Using 500 images from all image type classes, the best predictor of \"not cartoon\" was found to be Manhattan norm per pixel > 2.***"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aOEIcN9khD5r"
      },
      "source": [
        "## Installs & Imports\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RLomsEYpp4Dj"
      },
      "source": [
        "#@title Choose where to save results & set up directory structure\n",
        "# Use dropdown menu on right\n",
        "save = \"in Colab runtime (files deleted after each session)\" #@param [\"in my Google Drive\", \"in Colab runtime (files deleted after each session)\"]\n",
        "print(\"Saving results \", save)\n",
        "\n",
        "# Mount google drive to export file(s)\n",
        "if 'Google Drive' in save:\n",
        "    from google.colab import drive\n",
        "    drive.mount('/content/drive', force_remount=True)\n",
        "\n",
        "# Type in the path to your working directory in form field to right\n",
        "import os\n",
        "basewd = \"/content/drive/MyDrive/train/tf2\" #@param [\"/content/drive/MyDrive/train/tf2\"] {allow-input: true}\n",
        "if not os.path.exists(basewd):\n",
        "    os.makedirs(basewd)\n",
        "\n",
        "# Folder where inspect results outputs will be saved\n",
        "results_folder = \"inspect_resul\" #@param [\"inspect_resul\"] {allow-input: true}\n",
        "cwd = basewd + '/' + results_folder\n",
        "if not os.path.exists(cwd):\n",
        "    os.makedirs(cwd)\n",
        "print(\"\\nWorking directory set to: \\n\", cwd)\n",
        "\n",
        "# Enter image classes of interest in form field\n",
        "filters = ['herb', 'illus', 'map', 'null', 'phylo'] #@param [\"['herb', 'illus', 'map', 'null', 'phylo']\"] {type:\"raw\", allow-input: true}\n",
        "\n",
        "# Folder where image metadata was saved in image_type_preprocessing.ipynb\n",
        "data_folder = \"pre-processing/image_data\" #@param [\"pre-processing/image_data\"] {allow-input: true}\n",
        "data_wd = basewd + '/' + data_folder\n",
        "if not os.path.exists(data_wd):\n",
        "    !pip3 install --upgrade gdown\n",
        "    os.makedirs(data_wd)\n",
        "    print(\"\\nDownload image bundles for image type classes {}...\\n\".format(filters))\n",
        "    %cd $data_wd\n",
        "    file_ids = ['1Bkh2-TZSIKCCoKOTNr2L65BwR92Nx0vZ', '1m2sOLpUOWsw5RwzRtvj0mqH8aPloqnE_', \\\n",
        "                '1EIwPxyrawXnTPMyvO8f4nc1e3HALrTp9', '16I-_Qbh2IX_1Oz5wqlE6uzWXB2VhjE3e', \\\n",
        "                '1hQNgRLZWZu77XAxBwQIJOgRmWCCcpMos']\n",
        "    for file_id in file_ids:\n",
        "        !gdown $file_id\n",
        "print(\"\\nImage metadata directory set to: \\n\", data_wd)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fns = os.listdir(data_wd)\n",
        "imclasses = filters\n",
        "demo_dict = dict(zip(imclasses, fns))\n",
        "\n",
        "demo_dict = {'herb': 'herbarium_sheets_download.txt', 'illus': ['Botanical_illustrations_download.txt', 'Zoological_illustrations_download.txt'], 'map': 'maps.txt', 'null': None, 'phylo': 'Phylogeny_images.txt'}\n",
        "print(demo_dict)\n",
        "print(demo_dict[filters[0]])"
      ],
      "metadata": {
        "id": "O7FgFXBSq208"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "543EFNyF8P2e"
      },
      "source": [
        "# For importing data and images\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from numpy import sum\n",
        "import os\n",
        "import scipy\n",
        "from scipy.linalg import norm\n",
        "from scipy import average\n",
        "\n",
        "# For working with images\n",
        "from PIL import Image\n",
        "import imageio\n",
        "import six.moves.urllib as urllib\n",
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "%config InlineBackend.figure_format = 'svg'\n",
        "\n",
        "# Define functions\n",
        "\n",
        "# Define start and stop indices in EOL bundle for running inference   \n",
        "def set_start_stop(run, df):\n",
        "    # To test with a tiny subset, use 50 random bundle images\n",
        "    N = len(df)\n",
        "    if \"tiny subset\" in run:\n",
        "        start=np.random.choice(a=N, size=1)[0]\n",
        "        stop=start+50\n",
        "    # To run for a larger set, use 500 random images\n",
        "    else:\n",
        "        start=np.random.choice(a=N, size=1)[0]\n",
        "        stop=start+500\n",
        "    \n",
        "    return start, stop\n",
        "\n",
        "# Make a dictionary of image type classes and corresponding image bundles\n",
        "demo_dict = {'herb': 'herbarium_sheets_download.txt', 'illus': ['Botanical_illustrations_download.txt', 'Zoological_illustrations_download.txt'], 'map': 'maps.txt', 'null': None, 'phylo': 'Phylogeny_images.txt'}\n",
        "\n",
        "# Set filename for saving classification results\n",
        "def get_test_images(imclass):\n",
        "    impath = cwd + '/pre-processing/images/' + imclass\n",
        "    # If already custom-trained model, pull test images to inspect results for\n",
        "    if os.path.exists(impath):\n",
        "        demo = False # Not running in demo mode\n",
        "        fns = os.listdir(impath)\n",
        "        TEST_IMAGE_PATHS = [os.path.join(impath, fn) for fn in fns]\n",
        "        print(\"\\nUsing test images from: \\n\", impath)\n",
        "    # If running this script to test functionality, download dummy dataset from EOL image bundles\n",
        "    else:\n",
        "        demo = True # Running in demo mode using only Colab Runtime files\n",
        "        TEST_IMAGE_PATHS = []\n",
        "        try:\n",
        "            fpath = data_wd + '/' + demo_dict[imclass]\n",
        "            df = pd.read_csv(fpath, sep='\\n', header=None)\n",
        "            start=np.random.choice(a=len(df), size=1)[0]\n",
        "            stop=start+5\n",
        "            TEST_IMAGE_PATHS = df.iloc[start:stop, 0].values.tolist()\n",
        "            print(\"\\nUsing 5 random images from EOL image type bundle: \\n\", fpath)\n",
        "        \n",
        "        except:\n",
        "            pass\n",
        "\n",
        "    return TEST_IMAGE_PATHS, demo\n",
        "\n",
        "# For uploading an image from url\n",
        "# Modified from https://www.pyimagesearch.com/2015/03/02/convert-url-to-image-with-python-and-opencv/\n",
        "def url_to_image(url):\n",
        "    resp = urllib.request.urlopen(url)\n",
        "    image = np.asarray(bytearray(resp.read()), dtype=\"uint8\")\n",
        "    image = cv2.imdecode(image, cv2.IMREAD_COLOR)\n",
        "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "    im_h, im_w = image.shape[:2]\n",
        " \n",
        "    return image\n",
        "\n",
        "# Set filename for saving classification results\n",
        "def set_outfpath(imclass):\n",
        "    outfpath = cwd + '/' + imclass + '_cartoonifcation_values.csv'\n",
        "    print(\"\\nSaving results to: \\n\", outfpath)\n",
        "\n",
        "    return outfpath\n",
        "\n",
        "# To cartoonize an image\n",
        "def cartoonize(image):\n",
        "    # Add edges\n",
        "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY) \n",
        "    gray = cv2.medianBlur(gray, 5) \n",
        "    edges = cv2.adaptiveThreshold(gray, 255, cv2.ADAPTIVE_THRESH_MEAN_C,  \n",
        "                                         cv2.THRESH_BINARY, 9, 9)  \n",
        "    edges = cv2.cvtColor(edges, cv2.COLOR_GRAY2RGB)\n",
        "    # Bilateral filter \n",
        "    color = cv2.bilateralFilter(img, 9, 250, 250) \n",
        "    img2 = cv2.bitwise_and(color, edges)\n",
        "\n",
        "    return img2\n",
        "\n",
        "# Calculate differences between original and cartoonized image\n",
        "def calc_img_diffs(img, img2):\n",
        "    # Convert both images from RGB to HSV\n",
        "    HSV_img = cv2.cvtColor(img, cv2.COLOR_RGB2HSV)\n",
        "    HSV_img2 = cv2.cvtColor(img2, cv2.COLOR_RGB2HSV)\n",
        "    # Fnd the difference for H of HSV values of the images\n",
        "    diff = HSV_img[:,:,0]-HSV_img2[:,:,0]\n",
        "    mnorm = sum(abs(diff))  # Manhattan norm\n",
        "    mnorm_pp = mnorm/HSV_img.size # per pixel\n",
        "    znorm = norm(diff.ravel(), 0)  # Zero norm\n",
        "    znorm_pp = znorm*1.0/HSV_img2.size # per pixel\n",
        "\n",
        "    return mnorm, mnorm_pp, znorm, znorm_pp\n",
        "\n",
        "# To display an image already loaded into the runtime\n",
        "def display_images(image, image2, mnorm, mnorm_pp, znorm, znorm_pp):\n",
        "    fig, (a,b) = plt.subplots(2, figsize=(5, 5), constrained_layout=True)\n",
        "    fig.suptitle(\"Original vs Cartoonized, pairwise differences\\nManhattan norm: {} / per pixel: {}\\\n",
        "                  \\nZero norm: {} / per pixel: {}\".format(mnorm, mnorm_pp, znorm, znorm_pp))\n",
        "    a.imshow(image) ;\n",
        "    b.imshow(image2)\n",
        "\n",
        "# Make placeholder lists to fill for each class\n",
        "def make_placeholders():\n",
        "    filenames = []\n",
        "    mnorms = []\n",
        "    mnorms_pp = []\n",
        "    znorms = []\n",
        "    znorms_pp = []\n",
        "\n",
        "    return filenames, mnorms, mnorms_pp, znorms, znorms_pp\n",
        "    \n",
        "# Add values for each image to placeholder list\n",
        "def record_results(fn, mnorm, mnorm_pp, znorm, znorm_pp):\n",
        "    filenames.append(fn)\n",
        "    mnorms.append(mnorm)\n",
        "    mnorms_pp.append(mnorm_pp)\n",
        "    znorms.append(znorm)\n",
        "    znorms_pp.append(znorm_pp)\n",
        "    results = [filenames, mnorms, mnorms_pp, znorms, znorms_pp]\n",
        "\n",
        "    return results\n",
        "\n",
        "# Export results\n",
        "def export_results(results):\n",
        "    results = pd.DataFrame(results)\n",
        "    results = results.transpose()\n",
        "    results.to_csv(outfpath, index=False, header=(\"filename\", \"mnorm\", \"mnorm_pp\", \n",
        "                                                 \"znorm\", \"znorm_pp\"))\n",
        "    \n",
        "# To save the figure\n",
        "def save_figure(fig, imclass):\n",
        "    figname = cwd + '/' + imclass + '_cartoonization_hists.png'\n",
        "    fig.savefig(figname)\n",
        "    print(\"Histograms saved to \", figname)\n",
        "\n",
        "    return figname"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ieUdvK06hG_U"
      },
      "source": [
        "## Cartoonization - Cartoonize images, then compare how different they are to the original and determine if they are likely a cartoon or photograph\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xe3YUp515fV3",
        "cellView": "code"
      },
      "source": [
        "#@title Cartoonify images\n",
        "\n",
        "# Test pipeline with a smaller subset than 5k images?\n",
        "run = \"test with tiny subset\" #@param [\"test with tiny subset\", \"for 500 images\"]\n",
        "print(\"Run: \", run)\n",
        "\n",
        "# For each image class, measure difference betweeen cartoonified and original\n",
        "imclasses = filters\n",
        "for imclass in imclasses:\n",
        "    # Set filename for saving classification results\n",
        "    outfpath = set_outfpath(imclass)\n",
        "    # Make placeholder lists to record values for each image\n",
        "    filenames, mnorms, mnorms_pp, znorms, znorms_pp = make_placeholders()\n",
        "    # Get test images for cartoonizing\n",
        "    df, demo = get_test_images(imclass)\n",
        "\n",
        "    # Cartoonify images\n",
        "    try:\n",
        "        start, stop = set_start_stop(run, df)\n",
        "        for i, row in enumerate(df[start:stop], start=1):\n",
        "            # Read in image from url or file\n",
        "            if demo:\n",
        "                url = row\n",
        "                img = url_to_image(url)\n",
        "            else:\n",
        "                im_path = row\n",
        "                img = cv2.imread(im_path)\n",
        "        \n",
        "            # Cartoonization\n",
        "            img2 = cartoonize(img) \n",
        "\n",
        "            # Calculate differences between original and cartoonized image\n",
        "            mnorm, mnorm_pp, znorm, znorm_pp = calc_img_diffs(img, img2)\n",
        "\n",
        "            # Display cartoonized image when testing with tiny subset\n",
        "            if \"tiny subset\" in run:\n",
        "                display_images(img, img2, mnorm, mnorm_pp, znorm, znorm_pp)\n",
        "\n",
        "            # Record results in placeholder lists to inspect results in next step\n",
        "            results = record_results(row, mnorm, mnorm_pp, znorm, znorm_pp)\n",
        "    except:\n",
        "        pass\n",
        "\n",
        "    # Combine to df and export results\n",
        "    export_results(results)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rtWAgRdlhKBg"
      },
      "source": [
        "### Inspect cartoonizaton results\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X2vcKgUu0QvX"
      },
      "source": [
        "#@title Combine model outputs for image type classes\n",
        "\n",
        "# Get cartoonization files for each image type class\n",
        "imclasses = filters\n",
        "all_filenames = [cwd + '/' + imclass + '_cartoonifcation_values.csv' for imclass in imclasses]\n",
        "imclass_dict = dict(zip(all_filenames, imclasses))\n",
        "\n",
        "# Loop through cartoonization files and display histograms\n",
        "for fn in all_filenames:\n",
        "    print(\"\\nInspecting cartoonization values for: \", fn)\n",
        "    imclass = imclass_dict[fn]\n",
        "    df = pd.read_csv(fn, header=0)\n",
        "    mnorms = df['mnorm']\n",
        "    mnorms_pp = df['mnorm_pp']\n",
        "    znorms = df['znorm']\n",
        "    znorms_pp = df['znorm_pp']\n",
        "\n",
        "    # Plot parameters\n",
        "    kwargs = dict(alpha=0.5, bins=15)\n",
        "    fig, (a, b, c, d) = plt.subplots(4, figsize=(10, 10), sharey=True, constrained_layout=True)\n",
        "    fig.suptitle('{}: Image differences after cartoonization (n={} imgs)'.format(imclass, len(df)))\n",
        "\n",
        "    # Manhattan norm values\n",
        "    bins, counts = np.histogram(mnorms)\n",
        "    a.hist(mnorms, color='y', label='True Det', **kwargs)\n",
        "    a.set_title(\"{}: Manhattan norm\".format(imclass));\n",
        "\n",
        "    # Zero norm values\n",
        "    bins, counts = np.histogram(znorms)\n",
        "    c.hist(znorms, color='y', label='True Det', **kwargs)\n",
        "    c.set_title(\"{}: Zero norm\".format(imclass));\n",
        "\n",
        "    # Manhattan norm values per pixel\n",
        "    bins, counts = np.histogram(mnorms_pp)\n",
        "    b.hist(mnorms_pp, color='y', label='True Det', **kwargs)\n",
        "    b.set_title(\"{}: Manhattan norm per pixel\".format(imclass));\n",
        "\n",
        "    # Zero norm values per pixel\n",
        "    bins, counts = np.histogram(znorms_pp)\n",
        "    d.hist(znorms_pp, color='y', label='True Det', **kwargs)\n",
        "    d.set_title(\"{}: Zero norm per pixel\".format(imclass));\n",
        "\n",
        "    # Export histograms\n",
        "    figname = save_figure(fig, imclass)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}