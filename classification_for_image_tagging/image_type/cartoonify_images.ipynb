{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMBOOJzO3cU18Uo4eUGxqrj",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/aubricot/computer_vision_with_eol_images/blob/master/classification_for_image_tagging/image_type/cartoonify_images.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WGFNOrAs0pMf"
      },
      "source": [
        "# Determine if images are a cartoon or photograph\n",
        "---\n",
        "*Last Updated 7 September 2025*   \n",
        "Classification accuracy for illustrated images and phylogenies was low for the trained model. This notebook uses an alternate approach that leverages image processing to identify images as photographic or non-photographic. First, cartoonify image, then compare change in color values. If change above a certain threshold, then image is likely photographic. If change below a certain threshold, image is likely non-photographic.\n",
        "  \n",
        "***Using 500 images from all image type classes, the best predictor of \"not cartoon\" was found to be Manhattan norm per pixel > 2.***"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F53iiacTFVz7"
      },
      "source": [
        "## Installs & Imports\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Choose where to save results (or keep defaults) & set up environment\n",
        "import os\n",
        "\n",
        "# Use dropdown menu on right\n",
        "save = \"in Colab runtime (files deleted after each session)\" #@param [\"in my Google Drive\", \"in Colab runtime (files deleted after each session)\"]\n",
        "print(\"Saving results \", save)\n",
        "\n",
        "# Mount google drive to export file(s)\n",
        "if 'Google Drive' in save:\n",
        "    from google.colab import drive\n",
        "    drive.mount('/content/drive', force_remount=True)\n",
        "\n",
        "# Type of classification pipeline\n",
        "classif_type = \"image_type\" #@param [\"image_type\", \"rating\"] {allow-input: true}\n",
        "\n",
        "# Type in the path to your working directory in form field to right\n",
        "basewd = \"/content/drive/MyDrive/train/tf2\" #@param [\"/content/drive/MyDrive/train/tf2\"] {allow-input: true}\n",
        "basewd = basewd + '/' + classif_type\n",
        "\n",
        "# Folder where preprocessing outputs will be saved\n",
        "folder = \"pre-processing\" # @param [\"pre-processing\",\"inspect_resul\",\"results\"] {\"allow-input\":true}\n",
        "cwd = basewd + '/' + folder\n",
        "\n",
        "# Folder where image metadata will be saved\n",
        "data_folder = \"image_data\" #@param [\"image_data\"] {allow-input: true}\n",
        "data_wd = cwd + '/' + data_folder\n",
        "\n",
        "# Folder where train/test images will be saved\n",
        "train_folder = \"images\" #@param [\"images\"] {allow-input: true}\n",
        "train_wd = cwd + '/' + train_folder\n",
        "\n",
        "# Enter image classes of interest in form field\n",
        "filters = [\"map\", \"phylo\", \"herb\", \"illus\"] #@param [\"[\\\"map\\\", \\\"phylo, \\\"herb\\\", \\\"illus\\\"]\"] {type:\"raw\", allow-input: true}\n",
        "\n",
        "# Download helper_funcs folder\n",
        "!pip3 -q install --upgrade gdown\n",
        "!gdown 1xmkrYEJKLJvei9q4zulKfqsGTgDvfvpR\n",
        "!tar -xzvf helper_funcs.tar.gz -C .\n",
        "\n",
        "# Install requirements.txt\n",
        "!pip3 -q install -r requirements.txt\n",
        "\n",
        "# Set up directory structure\n",
        "from setup import setup_dirs\n",
        "\n",
        "# Set up directory structure\n",
        "setup_dirs(cwd, data_wd, train_wd)\n",
        "print(\"\\nWorking directory set to: \\n\", cwd)\n",
        "print(\"\\nImage metadata directory set to: \\n\", data_wd)\n",
        "print(\"\\nTraining images directory set to: \\n\", train_wd)"
      ],
      "metadata": {
        "cellView": "code",
        "id": "Xp6hQwzkgQBH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K28NLif9Mx9v"
      },
      "source": [
        "#@title Import libraries\n",
        "\n",
        "# For augmenting, displaying, and saving images\n",
        "!pip install imaug\n",
        "!pip install pillow\n",
        "\n",
        "# For downloading images\n",
        "!apt-get install aria2\n",
        "\n",
        "# For importing/exporting files, working with arrays, etc\n",
        "import pathlib\n",
        "import os\n",
        "import imageio\n",
        "import time\n",
        "import csv\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from urllib.request import urlopen\n",
        "import mimetypes\n",
        "import requests\n",
        "from concurrent.futures import ThreadPoolExecutor\n",
        "from tqdm import tqdm\n",
        "\n",
        "# For augmenting the images\n",
        "import imgaug as ia\n",
        "import imgaug.augmenters as iaa\n",
        "\n",
        "# For drawing onto and plotting the images\n",
        "import matplotlib.pyplot as plt\n",
        "import cv2\n",
        "import scipy\n",
        "from scipy.linalg import norm\n",
        "%config InlineBackend.figure_format = 'svg'\n",
        "%matplotlib inline\n",
        "\n",
        "# Define functions\n",
        "from wrangle_data import *\n",
        "\n",
        "# Image Type bundle urls\n",
        "# Map, Herbarium Sheet, Phylogeny\n",
        "bundles = [\"https://editors.eol.org/other_files/bundle_images/classifier/maps.txt\",\n",
        "           \"https://editors.eol.org/other_files/bundle_images/classifier/Phylogeny_images.txt\",\n",
        "           \"https://editors.eol.org/other_files/bundle_images/classifier/herbarium_sheets_download.txt\"]\n",
        "\n",
        "# Illustration\n",
        "# Pool zoology and botany into one illustration bundle\n",
        "illus_bundles = [\"https://editors.eol.org/other_files/bundle_images/classifier/Zoological_illustrations_download.txt\",\n",
        "                 \"https://editors.eol.org/other_files/bundle_images/classifier/Botanical_illustrations_download.txt\"]\n",
        "\n",
        "\n",
        "\n",
        "# Set filename for saving classification results\n",
        "def set_outfpath(imclass):\n",
        "    outfpath = cwd + '/' + imclass + '_cartoonification_values.csv'\n",
        "    print(\"\\nSaving results to: \\n\", outfpath)\n",
        "\n",
        "    return outfpath\n",
        "\n",
        "# Export results\n",
        "def export_results(results):\n",
        "    results = pd.DataFrame(results)\n",
        "    results = results.transpose()\n",
        "    results.to_csv(outfpath, index=False, header=(\"filename\", \"mnorm\", \"mnorm_pp\",\n",
        "                                                 \"znorm\", \"znorm_pp\"))\n",
        "\n",
        "# To save the figure\n",
        "def save_figure(fig, imclass):\n",
        "    figname = cwd + '/' + imclass + '_cartoonization_hists.png'\n",
        "    fig.savefig(figname)\n",
        "    print(\"Histograms saved to \", figname)\n",
        "\n",
        "    return figname"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LZlJ7Rjaub3O"
      },
      "source": [
        "## Download images to Google Drive from EOL, Wikimedia, and Flickr BHL image bundles\n",
        "---\n",
        "Run this step 5x (once per image bundle). For each iteration, use the dropdown menu to the right to select the image bundle to download images from."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Download images for each class\n",
        "\n",
        "# Test pipeline with a smaller subset than 5k images?\n",
        "run = \"test with tiny subset\" #@param [\"test with tiny subset\", \"for all images\"]\n",
        "print(\"Run: \", run)\n",
        "\n",
        "# Download images, augment them, and save to Google Drive\n",
        "print(\"\\nDownloading training images for each class\")\n",
        "\n",
        "# Download images for each class\n",
        "for i, imclass in enumerate(filters):\n",
        "\n",
        "        # Make folder for each class\n",
        "        %cd $train_wd\n",
        "        impath = train_wd + \"/\" + imclass + \"/\"\n",
        "        if not os.path.isdir(impath):\n",
        "            os.makedirs(impath)\n",
        "        print(\"Path to images:\")\n",
        "        %cd $impath\n",
        "\n",
        "        # Read in corresponding bundle\n",
        "        # For map, herbarium sheet, phylogeny\n",
        "        if imclass != 'illus':\n",
        "            bundle = bundles[i]\n",
        "            !wget --user-agent=\"Mozilla\" $bundle\n",
        "            print(\"Downloaded \", bundle)\n",
        "            fn = os.path.basename(bundle)\n",
        "            df = pd.read_table(fn)\n",
        "            print(imclass, df.head())\n",
        "\n",
        "        # For illustration\n",
        "        else:\n",
        "            il_fns = []\n",
        "            for illus_bundle in illus_bundles:\n",
        "                !wget --user-agent=\"Mozilla\" $illus_bundle\n",
        "                il_fn = os.path.basename(illus_bundle)\n",
        "                il_fns.append(il_fn)\n",
        "\n",
        "            df = pd.concat([pd.read_table(il_fn, header=None, names=['url']) for il_fn in il_fns], ignore_index=True)\n",
        "            fn = 'illustrations_download.txt'\n",
        "            print(imclass, df.head())\n",
        "\n",
        "        # Take tiny subset or all images from bundle\n",
        "        start, stop = set_start_stop(run, df)\n",
        "        df = df.iloc[start:stop]\n",
        "        df.to_csv(fn, index=False, header=False, lineterminator='\\n')\n",
        "        urls = df.iloc[:,0].dropna().astype(str).tolist()\n",
        "\n",
        "        # Download images\n",
        "        # Clean URLs list\n",
        "        urls = [u.strip() for u in urls if u.strip() and u.startswith(\"http\")]\n",
        "        print(urls)\n",
        "        download_images_parallel(urls, impath)\n",
        "\n",
        "        # Check how many images downloaded\n",
        "        print(\"Number of images downloaded to Google Drive for class {}:\".format(imclass))\n",
        "        !ls . | wc -l\n",
        "\n",
        "        # Move image metadata text file(s) to image_data/bundles\n",
        "        %cd $cwd\n",
        "        impath = impath + \"*.txt\"\n",
        "        !mv $impath image_data/"
      ],
      "metadata": {
        "id": "d-Qi8mprLnz1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Crpl2CtzuWTI"
      },
      "source": [
        "## Build \"null\" image class from EOL images\n",
        "---   \n",
        "Having a negative control will help train the classifier on what images do not belong in any of the above classes"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LuBO0i472WHV"
      },
      "source": [
        "# Download null.zip images folder leftover from flower_fruit classifier model\n",
        "%cd $train_wd\n",
        "!pip3 install --upgrade gdown\n",
        "!gdown 1-8-5EVq21jMUSvuEJynOBryKSJojOH49\n",
        "\n",
        "# Unzip images\n",
        "print(\"Unzipping botanical null images...\")\n",
        "!unzip null.zip\n",
        "\n",
        "# Move unzipped null image folder content to images/null\n",
        "# Google Drive Zipped folders have preserved directory structure\n",
        "if not os.path.isdir('null'):\n",
        "      os.makedirs('null')\n",
        "# Only move 5 images if running in demo mode\n",
        "if \"tiny subset\" in run:\n",
        "    !shuf -n 6 -e content/drive/'My Drive'/summer20/classification/image_type/images/null/* | xargs -i mv {} null\n",
        "# Run for all images\n",
        "else:\n",
        "    !mv content/drive/'My Drive'/summer20/classification/image_type/images/null/* null\n",
        "\n",
        "# Check how many images in 'null/'\n",
        "print(\"Number of images in 'null' class:\")\n",
        "%cd null\n",
        "!ls . | wc -l\n",
        "\n",
        "# Delete not needed files/folders\n",
        "%cd ../\n",
        "!rm -r content\n",
        "!rm -r null.zip\n",
        "\n",
        "# Add 'null' to imclasses list\n",
        "filters.append('null')\n",
        "print(\"Image classes to filter results by: \", filters)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r4fdwzVnuwPQ"
      },
      "source": [
        "## Cartoonify images\n",
        "---   \n",
        "Cartoonize images, then compare how different they are to the original and determine if they are likely a cartoon or photograph."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Cartoonify images\n",
        "\n",
        "# Test pipeline with a smaller subset than 5k images?\n",
        "run = \"test with tiny subset\" #@param [\"test with tiny subset\", \"for 500 images\"]\n",
        "print(\"Run: \", run)\n",
        "\n",
        "# For each image class, measure difference betweeen cartoonified and original\n",
        "imclasses = filters\n",
        "for imclass in imclasses:\n",
        "    # Set filename for saving classification results\n",
        "    outfpath = set_outfpath(imclass)\n",
        "    # Make placeholder lists to record values for each image\n",
        "    filenames, mnorms, mnorms_pp, znorms, znorms_pp = make_placeholders()\n",
        "    # Get test images for cartoonizing\n",
        "    df = get_test_images(imclass, cwd)\n",
        "\n",
        "    # Cartoonify images\n",
        "    try:\n",
        "        start, stop = set_start_stop(run, df)\n",
        "        for i, row in enumerate(df[start:stop], start=1):\n",
        "            # Read in image from url or file\n",
        "            im_path = row\n",
        "            img = cv2.imread(im_path)\n",
        "\n",
        "            # Cartoonization\n",
        "            img2 = cartoonize(img)\n",
        "\n",
        "            # Calculate differences between original and cartoonized image\n",
        "            mnorm, mnorm_pp, znorm, znorm_pp = calc_img_diffs(img, img2)\n",
        "\n",
        "            # Display cartoonized image when testing with tiny subset\n",
        "            if \"tiny subset\" in run:\n",
        "                display_images(img, img2, mnorm, mnorm_pp, znorm, znorm_pp)\n",
        "\n",
        "            # Record results in placeholder lists to inspect results in next step\n",
        "            results = record_results(row, mnorm, mnorm_pp, znorm, znorm_pp, filenames, mnorms, mnorms_pp, znorms, znorms_pp)\n",
        "    except:\n",
        "        pass\n",
        "\n",
        "    # Combine to df and export results\n",
        "    export_results(results)"
      ],
      "metadata": {
        "id": "HqJZ3lOU6oCk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Combine model outputs for image type classes\n",
        "%cd $cwd\n",
        "\n",
        "# Get cartoonization files for each image type class\n",
        "imclasses = filters\n",
        "all_filenames = [imclass + '_cartoonification_values.csv' for imclass in imclasses]\n",
        "imclass_dict = dict(zip(all_filenames, imclasses))\n",
        "# Set threshold for cartoon or not\n",
        "thresh = 2 #@param {type:\"number\"}\n",
        "\n",
        "# Loop through cartoonization files and display histograms\n",
        "for fn in all_filenames:\n",
        "    print(\"\\nInspecting cartoonization values for: \", fn)\n",
        "    imclass = imclass_dict[fn]\n",
        "    df = pd.read_csv(fn, header=0)\n",
        "    mnorms = df['mnorm']\n",
        "    mnorms_pp = df['mnorm_pp']\n",
        "    znorms = df['znorm']\n",
        "    znorms_pp = df['znorm_pp']\n",
        "\n",
        "    # Plot parameters\n",
        "    kwargs = dict(alpha=0.5, bins=15)\n",
        "    fig, (a, b, c, d) = plt.subplots(4, figsize=(10, 10), sharey=True, constrained_layout=True)\n",
        "    fig.suptitle('{}: Image differences after cartoonization (n={} imgs)'.format(imclass, len(df)))\n",
        "\n",
        "    # Manhattan norm values\n",
        "    bins, counts = np.histogram(mnorms)\n",
        "    a.hist(mnorms, color='y', label='True Det', **kwargs)\n",
        "    a.set_title(\"{}: Manhattan norm\".format(imclass));\n",
        "\n",
        "    # Zero norm values\n",
        "    bins, counts = np.histogram(znorms)\n",
        "    c.hist(znorms, color='y', label='True Det', **kwargs)\n",
        "    c.set_title(\"{}: Zero norm\".format(imclass));\n",
        "\n",
        "    # Manhattan norm values per pixel\n",
        "    bins, counts = np.histogram(mnorms_pp)\n",
        "    b.hist(mnorms_pp, color='y', label='True Det', **kwargs)\n",
        "    b.set_title(\"{}: Manhattan norm per pixel\".format(imclass));\n",
        "\n",
        "    # Zero norm values per pixel\n",
        "    bins, counts = np.histogram(znorms_pp)\n",
        "    d.hist(znorms_pp, color='y', label='True Det', **kwargs)\n",
        "    d.set_title(\"{}: Zero norm per pixel\".format(imclass));\n",
        "\n",
        "    # Add Y-axis labels\n",
        "    for ax in fig.get_axes():\n",
        "        ax.set(ylabel='Freq (# imgs)')\n",
        "        if thresh:\n",
        "            ax.axvline(thresh, color='k', linestyle='dashed', linewidth=1)\n",
        "\n",
        "    # Export histograms\n",
        "    figname = save_figure(fig, imclass)"
      ],
      "metadata": {
        "id": "eBBglOa-Dma5"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}