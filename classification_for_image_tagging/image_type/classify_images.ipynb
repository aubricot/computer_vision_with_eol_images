{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "classify_images.ipynb",
      "provenance": [],
      "private_outputs": true,
      "collapsed_sections": [
        "eEWlhuLnV-lh",
        "W2tO7HH-uLXY",
        "u2PEaR_a_0QH"
      ],
      "machine_shape": "hm",
      "authorship_tag": "ABX9TyOs8nHAno6UZq4BgVbi0QaM",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/aubricot/computer_vision_with_eol_images/blob/master/classification_for_image_tagging/image_type/classify_images.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_TcYNLBrWC0C"
      },
      "source": [
        "# Run images through image type classification pipeline\n",
        "---\n",
        "*Last Updated 30 October 2020*  \n",
        "Classify images as map, phylogeny, illustration, herbarium sheet, or none.\n",
        "\n",
        "1) Use \"cartoonization\" approach to add photographic or non-photographic tags to images. (Low accuracy for illustrations, so this method adds coverage for downstream predictions with low confidence values).\n",
        "\n",
        "2) Run images through trained MobileNet SSD v2 model to add tags to images for image types (map, phylogeny, ilustration, herbarium sheet, non) for predictions with confidence > 1.6. (Confidence value chosen in [inspect_train_results.ipynb](https://colab.research.google.com/github/aubricot/computer_vision_with_eol_images/blob/master/classification_for_image_tagging/image_type/inspect_train_results.ipynb)).\n",
        "\n",
        "3) Display tagging results on images to verify behavior is as expected."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZYW4W2aqdnTN"
      },
      "source": [
        "### Imports\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6k81-h_UV_ny"
      },
      "source": [
        "# Mount google drive to import/export files\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1AGFM4fSWhbT"
      },
      "source": [
        "# For working with data and plotting graphs\n",
        "import itertools\n",
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from scipy.linalg import norm\n",
        "from scipy import sum, average\n",
        "%matplotlib inline\n",
        "%config InlineBackend.figure_format = 'svg'\n",
        "\n",
        "# For image classification and training\n",
        "import tensorflow as tf\n",
        "\n",
        "# For working with images\n",
        "!pip install pillow\n",
        "!pip install scipy==1.1.0\n",
        "import cv2\n",
        "import scipy\n",
        "from scipy import misc"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eEWlhuLnV-lh"
      },
      "source": [
        "### 1) Cartoonization and Classification\n",
        "----"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b0u9Dd5OmWAO"
      },
      "source": [
        "#### Define functions & variables\n",
        "---\n",
        "To run classification on batches of 5k images at a time, change tag file and start/end rows (a/b) using form fields to right. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y7LrA9zfAlq3"
      },
      "source": [
        "# For images to read in from bundle\n",
        "\n",
        "# Load in image from URL\n",
        "# Modified from https://colab.research.google.com/github/tensorflow/docs/blob/master/site/en/guide/saved_model.ipynb#scrollTo=JhVecdzJTsKE\n",
        "def image_from_url(url, fn):\n",
        "  file = tf.keras.utils.get_file(fn, url) # Filename doesn't matter\n",
        "  disp_img = tf.keras.preprocessing.image.load_img(file)\n",
        "  img = tf.keras.preprocessing.image.load_img(file, target_size=[224, 224])\n",
        "  x = tf.keras.preprocessing.image.img_to_array(img)\n",
        "  x = tf.keras.applications.mobilenet_v2.preprocess_input(\n",
        "    x[tf.newaxis,...])\n",
        "  return x, disp_img\n",
        "\n",
        "# Read in EOL image bundle dataframe\n",
        "# TO DO: Type in image bundle address using form field to right\n",
        "bundle = \"https://editors.eol.org/other_files/bundle_images/files/images_for_Angiosperms_20K_breakdown_000031.txt\" #@param [\"https://editors.eol.org/other_files/bundle_images/files/images_for_Angiosperms_20K_breakdown_000031.txt\", \"https://editors.eol.org/other_files/bundle_images/files/images_for_Anura_20K_breakdown_000001.txt\", \"https://editors.eol.org/other_files/bundle_images/files/images_for_Chiroptera_breakdown_000001.txt\"]\n",
        "df = pd.read_csv(bundle, sep='\\t', header=0)\n",
        "print(df.head())\n",
        "\n",
        "# For exporting tagging results\n",
        "import csv\n",
        "\n",
        "# Write header row of output crops file\n",
        "# TO DO: Change file name for each bundle/run abcd if doing 4 batches using dropdown form to right\n",
        "tags_file = \"tags_imtype_20k_a\" #@param [\"tags_imtype_20k_a\", \"tags_imtype_20k_b\", \"tags_imtype_20k_c\", \"tags_imtype_20k_d\"]\n",
        "tags_fpath = \"/content/drive/My Drive/summer20/classification/image_type/results/\" + tags_file + \".tsv\"\n",
        "\n",
        "# TO DO: Set start and end rows to run inference for from EOL image bundle using form field to right\n",
        "# If running in 4 batches of 5000 images, use values in dropdown menu\n",
        "a = 0 #@param [\"0\", \"5000\", \"10000\", \"15000\"] {type:\"raw\"}\n",
        "b = 5000 #@param [\"5000\", \"10000\", \"15000\", \"20000\"] {type:\"raw\"}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W2tO7HH-uLXY"
      },
      "source": [
        "#### A) Cartoonize images to classify as photographic or non-photographic\n",
        "---  \n",
        "Cartoonify image, then compare change in color values. If change above a certain threshold, then image is likely a photograph. If change below a certain threshold, image is likely a cartoon (non-photograph).   \n",
        "Note: All 5k image batches can be run through this section first and then through the classification section below, or they can be run through in order (ie. batch a can be cartoonized and then classified, or batches a-d can all be cartoonized and then classified)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_05_nxEYupOY"
      },
      "source": [
        "from PIL import Image\n",
        "import time\n",
        "\n",
        "# Write header row of tagging files\n",
        "with open(tags_fpath, 'a') as out_file:\n",
        "      tsv_writer = csv.writer(out_file, delimiter='\\t')\n",
        "      tsv_writer.writerow([\"eolMediaURL\", \"identifier\", \\\n",
        "                          \"dataObjectVersionID\", \"ancestry\", \\\n",
        "                          \"mnorm_pp\"])\n",
        "\n",
        "# Loop through EOL image bundle to classify images and generate tags\n",
        "for i, row in df.iloc[a:b].iterrows():\n",
        "  try:\n",
        "    # Get url from image bundle\n",
        "    start = time.time()\n",
        "    url = df['eolMediaURL'][i]\n",
        "    # Read in image from url\n",
        "    fn = str(i) + '.jpg'\n",
        "    img, disp_img = image_from_url(url, fn)\n",
        "    # Display image\n",
        "    #_, ax = plt.subplots(figsize=(10, 10))\n",
        "    #plt.title(\"Original\")\n",
        "    #ax.imshow(disp_img)\n",
        "    # Make edges\n",
        "    cv_img = np.array(disp_img) \n",
        "    gray = cv2.cvtColor(cv_img, cv2.COLOR_BGR2GRAY)\n",
        "    gray = cv2.medianBlur(gray, 5) \n",
        "    edges = cv2.adaptiveThreshold(gray, 255, cv2.ADAPTIVE_THRESH_MEAN_C,  \n",
        "                                         cv2.THRESH_BINARY, 9, 9)  \n",
        "    edges = cv2.cvtColor(edges, cv2.COLOR_GRAY2RGB)\n",
        "    # Cartoonization - bilateral filter and edges \n",
        "    color = cv2.bilateralFilter(cv_img, 9, 250, 250) \n",
        "    img2 = cv2.bitwise_and(color, edges) \n",
        "\n",
        "    # Calculate difference in original and cartoonized image\n",
        "    # Convert both images from RGB to HSV\n",
        "    HSV_img = cv2.cvtColor(cv_img, cv2.COLOR_RGB2HSV)\n",
        "    HSV_img2 = cv2.cvtColor(img2, cv2.COLOR_RGB2HSV)\n",
        "    # Fnd the difference for H of HSV values of the images\n",
        "    diff = HSV_img[:,:,0]-HSV_img2[:,:,0]\n",
        "    mnorm = sum(abs(diff))  # Manhattan norm\n",
        "    mnorm_pp = mnorm/HSV_img.size # per pixel\n",
        "    end = time.time()\n",
        "    \n",
        "    # Display cartoonized image\n",
        "    #_, ax = plt.subplots(figsize=(10, 10))\n",
        "    #plt.title(\"Cartoonized \\n Manhattan norm: {} / per pixel {} \\\n",
        "    #\".format(mnorm, mnorm_pp))\n",
        "    #ax.imshow(img2)\n",
        "\n",
        "    # Export tagging results to tsv\n",
        "    # Define variables for export\n",
        "    identifier = df['identifier'][i]\n",
        "    dataObjectVersionID = df['dataObjectVersionID'][i]\n",
        "    if 'ancestry' in df.columns:\n",
        "      ancestry = df['ancestry'][i]\n",
        "    else:\n",
        "      ancestry = \"NA\"\n",
        "    with open(tags_fpath, 'a') as out_file:\n",
        "      tsv_writer = csv.writer(out_file, delimiter='\\t')\n",
        "      tsv_writer.writerow([url, identifier, dataObjectVersionID, ancestry, \\\n",
        "                               mnorm_pp])\n",
        "    print(\"Completed for {}, {} of {} files in {} seconds\".format(url, i, format(b-a, '.0f'), format(end-start, '.2f')))\n",
        "\n",
        "  except:\n",
        "    print('Check if URL from {} is valid'.format(url))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u2PEaR_a_0QH"
      },
      "source": [
        "#### B) Run images through model(s) for image type classification\n",
        "---   \n",
        "Use model selected in inspect_train_results.ipynb (MobileNet SSD v2) to classify images as map, phylogeny, herbarium sheet, illustration, or none."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0ZXo6iVvBF0G"
      },
      "source": [
        "# Load trained model from path\n",
        "TRAIN_SESS_NUM = \"13\"\n",
        "saved_model_path = '/content/drive/My Drive/summer20/classification/image_type/saved_models/' + TRAIN_SESS_NUM\n",
        "imtype_model = tf.keras.models.load_model(saved_model_path)\n",
        "label_names = ['herbarium sheet', 'illustration', 'map', 'null', 'phylogeny']\n",
        "module_selection = (\"mobilenet_v2_1.0_224\", 224)\n",
        "handle_base, pixels = module_selection\n",
        "IMAGE_SIZE = (pixels, pixels)\n",
        "\n",
        "# Set number of seconds to timeout if image url taking too long to open\n",
        "import socket\n",
        "socket.setdefaulttimeout(10)\n",
        "import time\n",
        "from PIL import Image\n",
        "\n",
        "# For exporting results\n",
        "confs = []\n",
        "imclasses = []\n",
        "\n",
        "# Loop through EOL image bundle to classify images and generate tags\n",
        "for i, row in df.iloc[a:b].iterrows():\n",
        "  try:\n",
        "    # Get url from image bundle\n",
        "    url = df['eolMediaURL'][i]\n",
        "    # Read in image from url\n",
        "    fn = str(i) + '.jpg'\n",
        "    img, disp_img = image_from_url(url, fn)\n",
        "    #ax.imshow(disp_img)\n",
        "    # Record inference time\n",
        "    start_time = time.time()\n",
        "    # Detection and draw boxes on image\n",
        "    # For flowers/fruits (reproductive structures)\n",
        "    predictions = imtype_model.predict(img, batch_size=1)\n",
        "    label_num = np.argmax(predictions)\n",
        "    conf = predictions[0][label_num]\n",
        "    confs.append(conf)\n",
        "    imclass = label_names[label_num]\n",
        "    imclasses.append(imclass)\n",
        "    end_time = time.time()\n",
        "    # Display progress message after each image\n",
        "    print('Inference complete for Row {} of {} images in {} sec'.format(i, (b-a), \\\n",
        "                                            format(end_time-start_time, '.2f')))\n",
        "\n",
        "    # Optional: Show classification results for images\n",
        "    # Only use to view predictions on <50 images at a time\n",
        "    #_, ax = plt.subplots(figsize=(10, 10))\n",
        "    #ax.imshow(disp_img)\n",
        "    #plt.axis('off')\n",
        "    #plt.title(\"{}) Prediction: {}, Confidence: {}%, \\\n",
        "    #\\n Inference Time: {}\".format(i, imclass, conf, \\\n",
        "    #format(end_time-start_time, '.2f')))\n",
        "\n",
        "  except:\n",
        "    print('Check if URL from {} is valid'.format(url))\n",
        "\n",
        "# Export tagging results to tsv\n",
        "# Define variables for export\n",
        "classif = pd.DataFrame(([imclasses,confs]))\n",
        "classif = classif.transpose()\n",
        "classif.columns = [\"imclass\", \"conf\"]\n",
        "df = pd.read_csv(tags_fpath, sep='\\t')\n",
        "comb = pd.concat([df, classif], axis=1, ignore_index=True)\n",
        "comb.columns = [\"eolMediaURL\", \"identifier\", \"dataObjectVersionID\", \\\n",
        "                  \"ancestry\", \"mnorm_pp\", \"imclass\", \"conf\"]\n",
        "comb.to_csv(tags_fpath, sep='\\t', index=False)\n",
        "new_tags_fpath = os.path.splitext(tags_fpath)[0]+'_2.tsv'\n",
        "comb.to_csv(new_tags_fpath, sep='\\t', index=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2GrMVL_CTZit"
      },
      "source": [
        "### 2) Post-process classification predictions using Manhattan norm and confidence threshold values\n",
        "---\n",
        "Manhattan norm per pixel threshold (=<2) was determined in cartoonify_images.ipynb. MobileNet SSD v2 confidence threshold (>1.6) was chosen in inspect_train_results.ipynb."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GrAcuOHO62g1"
      },
      "source": [
        "df = pd.read_csv('/content/drive/My Drive/summer20/classification/image_type/results/angiosp_20k_a.tsv', sep='\\t', header=0, na_filter = False)\n",
        "df = df[:145]\n",
        "base = '/content/drive/My Drive/summer20/classification/image_type/results/angiosp_20k_a'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SdgO3bk8mdKJ"
      },
      "source": [
        "# TO DO: Are images botanical? Answer in form field to right\n",
        "bot = \"no\" #@param [\"yes\", \"no\"]\n",
        "\n",
        "# TO DO: Input and adjust cartoonization and classification confidence thresholds\n",
        "# Thresholds for tagging as photographic or not and for image types\n",
        "## Cartoonization threshold value \n",
        "### Strict, almost all photos below will be non-photographic\n",
        "mnorm_thresh = 2 #@param\n",
        "## Classification confidence threshold \n",
        "### Less strict, optimizes true id and coverage\n",
        "conf_thresh = 1.6 #@param \n",
        "\n",
        "# Thresholds for refining results\n",
        "## Cartoonization threshold value for herbarium sheet predictions \n",
        "### Lower mnorm than regular photographs, higher than non-photographs\n",
        "mnorm_herb = 20 #@param\n",
        "## Cartoonization threshold value to refine conflicting classifications\n",
        "### Ex: non photo class and photo image type\n",
        "### Less strict than mnorm_thresh \n",
        "mnorm_np = 15 #@param\n",
        "\n",
        "# Combine exported model predictions and confidence values from above to one dataframe\n",
        "fpath =  os.path.splitext(tags_fpath)[0]\n",
        "base = fpath.rsplit('_',1)[0] + '_'\n",
        "exts = ['a.tsv', 'b.tsv', 'c.tsv', 'd.tsv']\n",
        "all_filenames = [base + e for e in exts]\n",
        "df = pd.concat([pd.read_csv(f, sep='\\t', header=0, na_filter = False) for f in all_filenames], ignore_index=True)\n",
        "df[['mnorm_pp', 'conf']] = df[['mnorm_pp', 'conf']].apply(pd.to_numeric)\n",
        "\n",
        "# Filter predictions using determined confidence value thresholds\n",
        "# Make column for \"reproductive structures present?\" tag\n",
        "df['tag_cartoon'] = np.nan\n",
        "df['tag_imtype'] = np.nan\n",
        "df['problematic'] = np.nan\n",
        "# Adjust final tag based on Model 7 and 11 predictions and confidence values\n",
        "for i, row in df.iterrows():\n",
        "  # Filter by cartoonization threshold\n",
        "  if df['mnorm_pp'][i]<=mnorm_thresh: \n",
        "    df['tag_cartoon'][i] = 'non-photo'\n",
        "  else: \n",
        "    df['tag_cartoon'][i] = 'photo'\n",
        "# Filter by classification confidence threshold\n",
        "for i, row in df.iterrows():\n",
        "  if df['conf'][i]>conf_thresh: \n",
        "    df['tag_imtype'][i] = df['imclass'][i]  \n",
        "  else: \n",
        "    df['tag_imtype'][i] = 'null' \n",
        "# Illustrations were a difficult class to identify\n",
        "for i, row in df.iterrows():\n",
        "  if df['imclass'][i]=='illustration': \n",
        "    df['problematic'][i] = 'maybe' \n",
        "# Refine conflicting cartoonization and classification tags \n",
        "for i, row in df.iterrows():\n",
        "  # Rows/images that cartoonization tags as non-photographic\n",
        "  if 'non-photo' in df['tag_cartoon'][i]:\n",
        "    # Conflicting rows (where classification tags photographic classes)\n",
        "    pcs = ['herb', 'null'] \n",
        "    if df['tag_imtype'][i] in pcs:\n",
        "      df['tag_imtype'][i] = 'null'\n",
        "  # Rows/images that cartoonization tags as photographic\n",
        "  else:\n",
        "    # Conflicting rows (where classification tags non-photographic classes)\n",
        "    npcs = ['phylogeny', 'map', 'illustration']\n",
        "    # If prediction is non-photo class and mnorm below less strict threshold\n",
        "    if df['imclass'][i] in npcs:\n",
        "      if (df['mnorm_pp'][i]<=mnorm_np) and (df['conf'][i]>0.05): \n",
        "        df['tag_cartoon'][i] = 'non-photo'\n",
        "        df['tag_imtype'][i] = df['imclass'][i]\n",
        "        df['problematic'][i] = 'maybe' \n",
        "      else:\n",
        "        df['tag_imtype'][i] = 'null'\n",
        "# Refine herbarium sheet classifications \n",
        "for i, row in df.iterrows():\n",
        "  if 'herbarium sheet' in df['imclass'][i]:\n",
        "    # Remove false classifications for zoological image bundles\n",
        "    if bot == 'no':\n",
        "      df['tag_imtype'][i] = 'null'\n",
        "    # Reduce false classifications for botanical images using cartoonization mnorms\n",
        "    elif (bot == 'yes') and ('Poaceae' in df['ancestry'][i]):\n",
        "      df['problematic'][i] = 'maybe'\n",
        "    else:\n",
        "      if (df['mnorm_pp'][i]<mnorm_herb) and (df['conf'][i]>0.05):\n",
        "        df['tag_imtype'][i] = 'herbarium sheet'\n",
        "      else:\n",
        "        df['tag_imtype'][i] = 'null'\n",
        "\n",
        "# Write results to tsv\n",
        "outfpath = base + 'finaltags.tsv'\n",
        "df.to_csv(outfpath, sep='\\t', index=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tDnCXzDGVa6t"
      },
      "source": [
        "### 3) Display final classification results on images\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TxurlbjZJd9q"
      },
      "source": [
        "# Set number of seconds to timeout if image url taking too long to open\n",
        "import socket\n",
        "socket.setdefaulttimeout(10)\n",
        "\n",
        "# TO DO: Update file path to finaltags.tsv file\n",
        "path = \"/content/drive/My Drive/summer20/classification/image_type/results/\"\n",
        "f = \"tags_imtype_20k_finaltags.tsv\" #@param\n",
        "fpath = path + f\n",
        "df = pd.read_csv(fpath, sep='\\t', header=0, na_filter = False)\n",
        "\n",
        "# Function to load in image from URL\n",
        "# Modified from https://colab.research.google.com/github/tensorflow/docs/blob/master/site/en/guide/saved_model.ipynb#scrollTo=JhVecdzJTsKE\n",
        "def image_from_url(url, fn):\n",
        "  file = tf.keras.utils.get_file(fn, url) # Filename doesn't matter\n",
        "  disp_img = tf.keras.preprocessing.image.load_img(file)\n",
        "  img = tf.keras.preprocessing.image.load_img(file, target_size=[224, 224])\n",
        "  x = tf.keras.preprocessing.image.img_to_array(img)\n",
        "  x = tf.keras.applications.mobilenet_v2.preprocess_input(\n",
        "    x[tf.newaxis,...])\n",
        "  return x, disp_img\n",
        "\n",
        "# TO DO: Set start and end rows to run inference for from EOL image bundle using form field to right\n",
        "# If running in 4 batches of 5000 images, use values in dropdown menu\n",
        "start =  0#@param {type:\"raw\"}\n",
        "end = 50 #@param {type:\"raw\"}\n",
        "\n",
        "# Loop through EOL image bundle to classify images and generate tags\n",
        "for i, row in df.iloc[start:end].iterrows():\n",
        "  try:\n",
        "    # Get url from image bundle\n",
        "    url = df['eolMediaURL'][i]\n",
        "    # Read in image from url\n",
        "    fn = str(i) + '.jpg'\n",
        "    img, disp_img = image_from_url(url, fn)\n",
        "    # Record inference time\n",
        "    tag1 = df['tag_cartoon'][i]\n",
        "    tag2 = df['tag_imtype'][i]\n",
        "    # Display progress message after each image is loaded\n",
        "    print('Successfully loaded {} of {} images'.format(i+1, (end-start)))\n",
        "\n",
        "    # Show classification results for images\n",
        "    # Only use to view predictions on <50 images at a time\n",
        "    _, ax = plt.subplots(figsize=(10, 10))\n",
        "    ax.imshow(disp_img)\n",
        "    plt.axis('off')\n",
        "    plt.title(\"{}) Photo or not: {}, Image type: {} \".format(i+1, tag1, tag2))\n",
        "\n",
        "  except:\n",
        "    print('Check if URL from {} is valid'.format(url))"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}