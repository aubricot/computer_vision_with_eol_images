{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "rating_preprocessing.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "F53iiacTFVz7",
        "LZlJ7Rjaub3O",
        "sUzJS0BsYh0f",
        "bOJEcY_BYYjl",
        "uELne7tJrEDZ",
        "QG12l9JVnpmU"
      ],
      "authorship_tag": "ABX9TyM/On6fsrldXOFYimydeyq/",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/aubricot/computer_vision_with_eol_images/blob/master/classification_for_image_tagging/rating/rating_preprocessing.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WGFNOrAs0pMf"
      },
      "source": [
        "# Pre-process Image Rating Classifier Training Images\n",
        "---\n",
        "*Last Updated 26 Dec 2020*   \n",
        "Follow steps below to download images from EOL generated user image ratings file (image_ratings.txt) to Google Drive into their appropriate folders for use training image rating classification models.     \n",
        "\n",
        "**Notes**\n",
        "* Change filepaths or information using the form fields to the right of code blocks (also noted in code with 'TO DO')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F53iiacTFVz7"
      },
      "source": [
        "### Connect to Google Drive\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MeNoVQDN0I1q"
      },
      "source": [
        "# Mount google drive to import/export files\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lxIUuGkDa__r"
      },
      "source": [
        "# Imports and Installs\n",
        "import os\n",
        "import pandas as pd\n",
        "!apt-get install aria2"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LZlJ7Rjaub3O"
      },
      "source": [
        "### 1) Inspect EOL User Generated Image Ratings File\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s67Ly5pmL6LD"
      },
      "source": [
        "# Read in EOL user generated rating file\n",
        "df = pd.read_csv(\"/content/drive/My Drive/summer20/classification/rating/image_data/bundles/image_ratings.txt\", sep=\"\\t\", lineterminator='\\n', encoding='latin1', header=0)\n",
        "print(\"Total number of EOL user generated image ratings: {}\".format(len(df)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UvXPZGsnXoCr"
      },
      "source": [
        "# Inspect Data\n",
        "\n",
        "# Optional = Un-comment out if want to view individual URLs, increase output length so full URL visible\n",
        "#pd.set_option('display.max_colwidth', 1000) # Print full urls for inspection\n",
        "\n",
        "# See column names\n",
        "print(\"Column Names:\")\n",
        "for col in df.columns: \n",
        "    print(col) \n",
        "\n",
        "# Split dataset by image ratings\n",
        "# Rating = 1 (rounded to nearest whole number)\n",
        "one = df.loc[round(df[\"overall_rating\"])==1]\n",
        "one = one[[\"obj_with_overall_rating\", \"obj_url\", \"overall_rating\", \"ancestry\"]].copy()\n",
        "one[\"obj_url\"].to_csv(\"/content/drive/My Drive/summer20/classification/rating/image_data/one_download.txt\", sep=\"\\n\", index=False, header=False)\n",
        "print(len(one))\n",
        "print(\"Rating = 1:\\n {}\".format(one.head()))\n",
        "\n",
        "# Rating = 2 (rounded to nearest whole number)\n",
        "two = df.loc[round(df[\"overall_rating\"])==2]\n",
        "two = two[[\"obj_with_overall_rating\", \"obj_url\", \"overall_rating\", \"ancestry\"]].copy()\n",
        "two[\"obj_url\"].to_csv(\"/content/drive/My Drive/summer20/classification/rating/image_data/two_download.txt\", sep=\"\\n\", index=False, header=False)\n",
        "print(len(two))\n",
        "print(\"Rating = 2:\\n {}\".format(two.head()))\n",
        "\n",
        "# Rating = 3 (rounded to nearest whole number)\n",
        "three = df.loc[round(df[\"overall_rating\"])==3]\n",
        "three = three[[\"obj_with_overall_rating\", \"obj_url\", \"overall_rating\", \"ancestry\"]].copy()\n",
        "three[\"obj_url\"].to_csv(\"/content/drive/My Drive/summer20/classification/rating/image_data/three_download.txt\", sep=\"\\n\", index=False, header=False)\n",
        "print(len(three))\n",
        "print(\"Rating = 3:\\n {}\".format(three.head()))\n",
        "\n",
        "# Rating = 4 (rounded to nearest whole number)\n",
        "four = df.loc[round(df[\"overall_rating\"])==4]\n",
        "four = four[[\"obj_with_overall_rating\", \"obj_url\", \"overall_rating\", \"ancestry\"]].copy()\n",
        "four[\"obj_url\"].to_csv(\"/content/drive/My Drive/summer20/classification/rating/image_data/four_download.txt\", sep=\"\\n\", index=False, header=False)\n",
        "print(len(four))\n",
        "print(\"Rating = 4:\\n {}\".format(four.head()))\n",
        "\n",
        "# Rating = 5 (rounded to nearest whole number)\n",
        "five = df.loc[round(df[\"overall_rating\"])==5]\n",
        "five = five[[\"obj_with_overall_rating\", \"obj_url\", \"overall_rating\", \"ancestry\"]].copy()\n",
        "five[\"obj_url\"].to_csv(\"/content/drive/My Drive/summer20/classification/rating/image_data/five_download.txt\", sep=\"\\n\", index=False, header=False)\n",
        "print(len(five))\n",
        "print(\"Rating = 5:\\n {}\".format(five.head()))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sUzJS0BsYh0f"
      },
      "source": [
        "### 2) Build 7k image bundles for rating classes 1-5\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pt7zEGcKZF97"
      },
      "source": [
        "# Make 7k image bundles for rating classes 1-4 \n",
        "# Rating class 5 only has 1200 images, so it is built differently in next code block\n",
        "\n",
        "%cd drive/My Drive/summer20/classification/rating/images\n",
        "import os\n",
        "import pandas as pd\n",
        "\n",
        "# Future image directories for training classifier\n",
        "folders = ['1', '2', '3', '4']\n",
        "nums = ['one', 'two', 'three', 'four']\n",
        "all_filenames = [folder + '/' + num + '_download.txt' for folder, num in zip(folders, nums)] # Image rating filenames\n",
        "filenames_7k = [folder + '/' + num + '_download_7k.txt' for folder, num in zip(folders, nums)] # Future 7K image bundle filenames\n",
        "print(all_filenames)\n",
        "\n",
        "# Randomly pick 7,000 images from each rating class and write to csv\n",
        "for num, f in enumerate(all_filenames):\n",
        "  df = pd.read_table(f, sep='\\n')\n",
        "  bundle = df.sample(7000)\n",
        "  fn = str(filenames_7k[num])\n",
        "  print(fn)\n",
        "  print(bundle.head())\n",
        "  #bundle.to_csv(fn, sep='\\n')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rsoet2PW6G-5"
      },
      "source": [
        "# Make 7k bundle for Rating = 5 dataset\n",
        "# Different because only 1200 images total\n",
        "\n",
        "%cd drive/My Drive/summer20/classification/rating/images\n",
        "import os\n",
        "import pandas as pd\n",
        "\n",
        "# Add images to Rating = 5 dataset from EOL User Exemplar File\n",
        "# Read in Exemplar File\n",
        "df = pd.read_csv(\"5/images_selected_as_exemplar.txt\", sep=\"\\t\", lineterminator='\\n', encoding='latin1', header=0)\n",
        "# Include all duplicates from exemplar file (these ones may be better or more controversial, see email from jen 28 oct 2020)\n",
        "idx = df.index[df.duplicated(['object_url'])].tolist()\n",
        "dups = df.loc[idx]\n",
        "dups = pd.DataFrame(dups[\"object_url\"])\n",
        "# Add 4k random images from exemplar file\n",
        "unq = df.drop(idx, errors='ignore')\n",
        "unq = unq.sample(4000)\n",
        "unq = pd.DataFrame(unq[\"object_url\"])\n",
        "# Read in Rating = 5 images\n",
        "df1 = pd.read_table('5/five_download.txt', sep='\\n')\n",
        "df1.columns = unq.columns\n",
        "# Make 7k bundle from Exemplar duplicates & random images, and Rating = 5 images\n",
        "new5 = pd.concat([df1,unq,dups], ignore_index=True)\n",
        "print(new5)\n",
        "print(len(new5))\n",
        "#new5.to_csv('5/five_download_7k.txt', sep='\\n', index=False, header=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bOJEcY_BYYjl"
      },
      "source": [
        "### 3) Download images to Google Drive\n",
        "---\n",
        "Run all steps once per rating class 1-5. Where you see 'TO DO' (3 places), change number to match rating class each time you run "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yZIZpuuwOhaD"
      },
      "source": [
        "# Download images (this will take a few hours)\r\n",
        "%cd drive/My Drive/summer20/classification/rating/images\r\n",
        "%cd 1 #TO DO: Change number for each rating class\r\n",
        "!aria2c -x 16 -s 1 -i \"one_download_7k.txt\" #TO DO: Change number for each rating class"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H1FEL48SOxdP"
      },
      "source": [
        "# Check how many images downloaded\r\n",
        "print(\"Number of images downloaded to Google Drive: \")\r\n",
        "!ls . | wc -l"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7y1GZ-IRKVnz"
      },
      "source": [
        "# Move text file to image_data/bundles\n",
        "%cd ../..\n",
        "!mv images/1/*.txt image_data/bundles/ # TO DO: Change folder number for each rating class"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uELne7tJrEDZ"
      },
      "source": [
        "### 4) Delete all downloaded non-image files\n",
        "---\n",
        "Run all steps once per rating class 1-5. Where you see 'TO DO' (1 place), change number to match rating class each time you run"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bTPAxR5V-wTm"
      },
      "source": [
        "from os import listdir\n",
        "from PIL import Image\n",
        "Image.MAX_IMAGE_PIXELS = 95000000 # To suppress errors from Pillow about decompression bombs\n",
        "import io\n",
        "\n",
        "#TO DO: Change each time you run to match image class\n",
        "%cd /content/drive/My Drive/summer20/classification/rating/images/4\n",
        "\n",
        "for path in listdir('./'):\n",
        "  with open(path, 'rb') as f:\n",
        "    try:\n",
        "      img = Image.open(io.BytesIO(f.read()))\n",
        "      img.verify() # verify that it is an image\n",
        "    except (IOError, SyntaxError) as e:\n",
        "      print('Bad file:', filename)\n",
        "      if '(' in filename: # rm doesn't work for files with parenthesis in name, need to manually remove\n",
        "        print(\"Manually remove from Google Drive: {}\".format(filename)) \n",
        "      else:\n",
        "        !rm $filename "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QG12l9JVnpmU"
      },
      "source": [
        "### 5) Aggregate classes into good (4 & 5) and bad (1 & 2) because models not learning classes 1-5 with any hyperparameter combinations\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5Ag4nN14noK2"
      },
      "source": [
        "# Move text file to image_data/bundles\n",
        "%cd drive/My Drive/summer20/classification/rating/images\n",
        "# Make aggregated training images folder\n",
        "#!mkdir agg\n",
        "\n",
        "# Make aggregated 'bad' images folder (combined classes 1 and 2)\n",
        "#!mkdir agg/bad\n",
        "#!cp 1/* agg/bad/\n",
        "#!cp 2/* agg/bad/\n",
        "print(\"Number of images in new aggregated 'bad' folder: \")\n",
        "!ls agg/bad | wc -l\n",
        "\n",
        "# Make aggregated 'good' images folder (combined classes 4 and 5)\n",
        "#!mkdir agg/good\n",
        "#!cp 4/* agg/good/\n",
        "#!cp 5/* agg/good/\n",
        "print(\"Number of images in new aggregated 'good' folder: \")\n",
        "!ls agg/good | wc -l"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}