{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "machine_shape": "hm",
      "toc_visible": true,
      "authorship_tag": "ABX9TyO9R0776ubAf3cacFhn/e9U",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/aubricot/computer_vision_with_eol_images/blob/master/classification_for_image_tagging/rating/classify_images.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_TcYNLBrWC0C"
      },
      "source": [
        "# Run images through image rating classification pipeline\n",
        "---\n",
        "*Last Updated 2 December 2024*  \n",
        "-Runs in Python 3 with Tensorflow 2.0-   \n",
        "\n",
        "Use trained image classification model to add tags for image quality rating (bad, good) to EOL images.\n",
        "\n",
        "Models were trained in [rating_train.ipynb](https://colab.research.google.com/github/aubricot/computer_vision_with_eol_images/blob/master/classification_for_image_tagging/rating/rating_train.ipynb). Confidence threshold for the best trained model was selected in [inspect_train_results.ipynb](https://colab.research.google.com/github/aubricot/computer_vision_with_eol_images/blob/master/classification_for_image_tagging/rating/inspect_train_results.ipynb).\n",
        "\n",
        "We observed controversy among users assigning ratings to \"good\" images, and consensus for assigning ratings to \"bad\" images (Users were more conflicted on what they like than what they don't like). Model behavior matched this observation. In post-processing, keep only \"bad\" image quality predictions (model accuracy was high for this class) when confidence > 1.5. \"Good\" image quality predications are discarded (model accuracy was low for this class).\n",
        "\n",
        "Finally, display tagging results on images to verify behavior is as expected.\n",
        "\n",
        "***Models were trained in Python 2 and TF 1 in December 2020: MobileNet SSD v2 (Run 18, trained on 'good' and 'bad' classes) was trained for 12 hours to 10 epochs with Batch Size=16, Lr=0.001, Dropout=0.2.***\n",
        "\n",
        "Notes:     \n",
        "* Run code blocks by pressing play button in brackets on left\n",
        "* Before you you start: change the runtime to \"GPU\" with \"High RAM\"\n",
        "* Change parameters using form fields on right (find details at corresponding lines of code by searching '#@param')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZYW4W2aqdnTN"
      },
      "source": [
        "## Installs & Imports\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6k81-h_UV_ny"
      },
      "source": [
        "#@title Choose where to save results and set up environment\n",
        "import os\n",
        "\n",
        "# Use dropdown menu on right\n",
        "save = \"in Colab runtime (files deleted after each session)\" #@param [\"in my Google Drive\", \"in Colab runtime (files deleted after each session)\"]\n",
        "print(\"Saving results \", save)\n",
        "\n",
        "# Mount google drive to export image tagging file(s)\n",
        "if 'Google Drive' in save:\n",
        "    from google.colab import drive\n",
        "    drive.mount('/content/drive', force_remount=True)\n",
        "\n",
        "# Type of classification pipeline\n",
        "classif_type = \"rating\" #@param [\"image_type\", \"rating\"] {allow-input: true}\n",
        "\n",
        "# Type in the path to your project wd in form field on right\n",
        "basewd = \"/content/drive/MyDrive/train\" #@param [\"/content/drive/MyDrive/train\"] {allow-input: true}\n",
        "basewd = basewd + '/' + classif_type\n",
        "\n",
        "# Type in the folder that you want to contain TF2 files\n",
        "folder = \"results\" #@param [\"darknet\"] {allow-input: true}\n",
        "cwd = basewd + '/' + folder\n",
        "print(\"\\nWorking directory set to: \\n\", cwd)\n",
        "\n",
        "# Download helper_funcs folder\n",
        "!pip3 -q install --upgrade gdown\n",
        "!gdown  1TfpSLwbt6i0OMdbbjcTPVFBP6vYc3CY_\n",
        "!tar -xzvf helper_funcs.tar.gz -C .\n",
        "\n",
        "# Install requirements.txt\n",
        "!pip3 -q install -r requirements.txt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Choose saved model parameters (if using EOL model, defaults are already selected)\n",
        "from setup import setup_dirs, load_saved_model, get_model_info, unpack_EOL_model\n",
        "\n",
        "# Use EOL pre-trained model for object detection?\n",
        "use_EOL_model = True #@param {type: \"boolean\"}\n",
        "\n",
        "# Download EOL model if appropriate\n",
        "if (use_EOL_model==True) & (os.path.exists(\"18.zip\")==False):\n",
        "    !gdown 1L-WqfuoQtPgqJzU8tDKjgsZC98M-68w9\n",
        "\n",
        "# If using your own trained model, change values to match your trained model\n",
        "module_selection = (\"mobilenet_v2_1.0_224\", 224) #@param [\"(\\\"mobilenet_v2_1.0_224\\\", 224)\", \"(\\\"inception_v3\\\", 299)\"] {type:\"raw\", allow-input: true}\n",
        "dataset_labels = [\"bad\", \"good\"] #@param [\"[\\\"bad\\\", \\\"good\\\"]\"] {type:\"raw\", allow-input: true}\n",
        "saved_models_folder = \"saved_models\" #@param [\"train/saved_models/\"] {allow-input: true}\n",
        "saved_models_dir = basewd + '/' + saved_models_folder + '/'\n",
        "TRAIN_SESS_NUM = \"18\" #@param [\"18\"] {allow-input: true}\n",
        "\n",
        "# Set up directory structure\n",
        "setup_dirs(cwd)\n",
        "%cd $basewd\n",
        "\n",
        "# Unpack EOL saved model\n",
        "trained_model_dir = saved_models_dir + TRAIN_SESS_NUM + '/'\n",
        "unpack_EOL_model(use_EOL_model, trained_model_dir, basewd, TRAIN_SESS_NUM, classif_type)\n",
        "\n",
        "# Load saved model\n",
        "module_selection, dataset_labels = get_model_info(TRAIN_SESS_NUM)\n",
        "model, pixels, handle_base = load_saved_model(saved_models_dir, TRAIN_SESS_NUM, module_selection)"
      ],
      "metadata": {
        "cellView": "code",
        "id": "_ny7uvWN0B20"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1AGFM4fSWhbT"
      },
      "source": [
        "#@title Import libraries\n",
        "\n",
        "# For downloading and displaying images\n",
        "from PIL import Image\n",
        "import cv2\n",
        "import imageio\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "%config InlineBackend.figure_format = 'svg'\n",
        "\n",
        "# For working with data\n",
        "import numpy as np\n",
        "from numpy import sum\n",
        "import pandas as pd\n",
        "from os import path\n",
        "import csv\n",
        "import itertools\n",
        "from scipy.linalg import norm\n",
        "# So URL's don't get truncated in display\n",
        "pd.set_option('display.max_colwidth',1000)\n",
        "pd.options.display.max_columns = None\n",
        "\n",
        "# For measuring inference time\n",
        "import time\n",
        "\n",
        "# For image classification\n",
        "import tensorflow as tf\n",
        "print('\\nTensorflow Version: %s' % tf.__version__)\n",
        "\n",
        "# Set number of seconds to timeout if image url taking too long to open\n",
        "import socket\n",
        "socket.setdefaulttimeout(10)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eEWlhuLnV-lh"
      },
      "source": [
        "## Generate tags: Run inference on EOL images & save results for tagging - Run 4X for batches A-D\n",
        "---\n",
        "Use 20K EOL image bundle to classify image quality rating as bad or good. Results are saved to [tags_file].tsv. Run this section 4 times (to make batches A-D) of 5K images each to incrementally save in case of Colab timeouts."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b0u9Dd5OmWAO"
      },
      "source": [
        "### Prepare classification functions and settings"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Define functions\n",
        "from wrangle_data import read_datafile, set_start_stop, image_from_url, get_predict_info\n",
        "\n",
        "# Set filename for saving classification results\n",
        "def set_outpath(tags_file):\n",
        "    outpath = cwd + '/' + tags_file + '.tsv'\n",
        "    print(\"\\nSaving results to: \\n\", outpath)\n",
        "\n",
        "    return outpath\n",
        "\n",
        "# Export results\n",
        "def export_results(df, url, det_imclass, conf):\n",
        "    # Define variables for export\n",
        "    if 'ancestry' in df.columns:\n",
        "        ancestry = df['ancestry'][i]\n",
        "    else:\n",
        "        ancestry = \"NA\"\n",
        "    identifier = df['identifier'][i]\n",
        "    dataObjectVersionID = df['dataObjectVersionID'][i]\n",
        "    # Write row with results for each image\n",
        "    results = [url, identifier, dataObjectVersionID, ancestry,\n",
        "               det_imclass, conf]\n",
        "    with open(outfpath, 'a') as out_file:\n",
        "        tsv_writer = csv.writer(out_file, delimiter='\\t')\n",
        "        tsv_writer.writerow(results)"
      ],
      "metadata": {
        "id": "nbFSjm5qWjp3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O60NDALk_8LW"
      },
      "source": [
        "#@title Enter EOL image bundle and choose inference settings. Change **tags_file** for each batch A-D\n",
        "%cd $cwd\n",
        "\n",
        "# Load in EOL image bundle\n",
        "bundle = \"https://editors.eol.org/other_files/bundle_images/files/images_for_Squamata_20K_breakdown_000001.txt\" #@param [\"https://editors.eol.org/other_files/bundle_images/files/images_for_Squamata_20K_breakdown_000001.txt\", \"https://editors.eol.org/other_files/bundle_images/files/images_for_Coleoptera_20K_breakdown_000001.txt\", \"https://editors.eol.org/other_files/bundle_images/files/images_for_Anura_20K_breakdown_000001.txt\", \"https://editors.eol.org/other_files/bundle_images/files/images_for_Carnivora_20K_breakdown_000001.txt\"] {allow-input: true}\n",
        "df = read_datafile(bundle, sep='\\t', header=0, disp_head=False)\n",
        "\n",
        "# Test pipeline with a smaller subset than 5k images?\n",
        "run = \"test with tiny subset\" #@param [\"test with tiny subset\", \"for 500 images\"]\n",
        "print(\"Run: \", run)\n",
        "\n",
        "# Take 5k subset of bundle for running inference\n",
        "# Change filename for each batch\n",
        "tags_file = \"rating_tags_tf2_b\" #@param [\"rating_tags_tf2_a\", \"rating_tags_tf2_b\", \"rating_tags_tf2_c\", \"rating_tags_tf2_d\"] {allow-input: true}\n",
        "outfpath = set_outpath(tags_file)\n",
        "\n",
        "# Write header row of tagging file\n",
        "print(\"\\nClassification predictions for tags_file {} being saved to : \\n{}\\n\".format(tags_file, outfpath))\n",
        "if not os.path.isfile(outfpath):\n",
        "    with open(outfpath, 'a') as out_file:\n",
        "              tsv_writer = csv.writer(out_file, delimiter='\\t')\n",
        "              tsv_writer.writerow([\"eolMediaURL\", \"identifier\", \\\n",
        "                                   \"dataObjectVersionID\", \"ancestry\", \\\n",
        "                                   \"imclass\", \"confidence\"])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_05_nxEYupOY"
      },
      "source": [
        "#@title Run inference\n",
        "\n",
        "# Run EOL bundle images through trained model\n",
        "all_predictions = []\n",
        "start, stop, cutoff = set_start_stop(run, df)\n",
        "for i, row in enumerate(df.iloc[start:stop].iterrows()):\n",
        "    try:\n",
        "        # Read in image from url\n",
        "        url = df['eolMediaURL'][i]\n",
        "        fn = str(i) + '.jpg'\n",
        "        img, disp_img, _ = image_from_url(url, fn, pixels)\n",
        "\n",
        "        # Image classification\n",
        "        start_time = time.time() # Record inference time\n",
        "        predictions = model.predict(img, batch_size=1)\n",
        "        label_num = np.argmax(predictions[0], axis=-1)\n",
        "        label_num, conf, det_imclass = get_predict_info(predictions, url, i, stop, start, dataset_labels)\n",
        "        end_time = time.time()\n",
        "        print(\"Inference time: {} sec\".format(format(end_time-start_time, '.2f')))\n",
        "\n",
        "        # Export results for each image to tags_file (saves incrementally in case of timeouts)\n",
        "        export_results(df, url, det_imclass, conf)\n",
        "\n",
        "        # Set cutoff for # of predictions per class (workaround to get same # of predictions per class, even with many broken URLs)\n",
        "        all_predictions.append(det_imclass)\n",
        "        print(\"\\033[92m Completed for {} of {} files \\033[0m\".format(len(all_predictions), cutoff))\n",
        "        if len(all_predictions)>=cutoff:\n",
        "              break\n",
        "\n",
        "    except:\n",
        "        print('Check if URL from {} is valid'.format(url))\n",
        "\n",
        "print(\"\\n\\n~~~\\n\\033[92m Inference complete!\\033[0m \\033[93m Run these steps for remaining batches A-D before proceeding.\\033[0m\\n~~~\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2GrMVL_CTZit"
      },
      "source": [
        "## Post-process classification results\n",
        "---\n",
        "MobileNet SSD v2 confidence threshold (>1.5) for all 'bad' predictions was chosen in inspect_train_results.ipynb to minimize false detections and maximize dataset coverage. All 'good' predictions and any 'bad' predictions below the confidence threshold are discarded."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CpyJZTh4mJ_e"
      },
      "source": [
        "#@title Use chosen confidence threshold (or EOL default)\n",
        "\n",
        "# Adjust confidence threshold parameter\n",
        "conf_thresh = 1.5 #@param [\"1.5\"] {type:\"raw\", allow-input: true}\n",
        "\n",
        "# Combine tagging files for batches A-D\n",
        "fpath =  os.path.splitext(tags_file)[0] # Get name of one tag file\n",
        "base = cwd + '/' + fpath.rsplit('_',1)[0] + '_' # Remove lettered suffix to get basename\n",
        "exts = ['a.tsv', 'b.tsv', 'c.tsv', 'd.tsv']\n",
        "all_filenames = [base + e for e in exts] # List all tag filenames\n",
        "df = pd.concat([pd.read_csv(f, sep='\\t', header=0, na_filter = False) for f in all_filenames], ignore_index=True)\n",
        "df[['confidence']] = df[['confidence']].apply(pd.to_numeric)\n",
        "\n",
        "# Summarize combined results\n",
        "print(\"Model predictions for Training Attempt {}, {}:\".format(TRAIN_SESS_NUM, handle_base))\n",
        "print(\"No. Images: {}\\n{}\".format(len(df), df[['eolMediaURL', 'imclass', 'confidence']].head()))\n",
        "\n",
        "# Discard all predictions for 'good' or below confidence threshold\n",
        "# (Final tag to keep -> predictions for 'bad' with confidence > 1.5)\n",
        "idx_tokeep = df.index[(df.imclass == 'bad') & (df.confidence > conf_thresh)]\n",
        "idx_todiscard = df.index.difference(idx_tokeep)\n",
        "df.loc[idx_todiscard, 'imclass'] = 'NA'\n",
        "\n",
        "# Write results to tsv\n",
        "print(\"\\nFinal tagging dataset after filtering predictions: \\n\", df[['eolMediaURL', 'imclass', 'confidence']].head())\n",
        "outfpath = base + 'final.tsv'\n",
        "print(\"\\nSaving results to: \\n\", outfpath)\n",
        "df.to_csv(outfpath, sep='\\t', index=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tDnCXzDGVa6t"
      },
      "source": [
        "## Display classification results on images\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TxurlbjZJd9q"
      },
      "source": [
        "#@title Adjust start index and display up to 50 images with their tags\n",
        "from wrangle_data import plot_image_results\n",
        "\n",
        "# Adjust start index using slider\n",
        "start = 0 #@param {type:\"slider\", min:0, max:5000, step:50}\n",
        "stop = min((start+50), len(df))\n",
        "\n",
        "# Loop through EOL image bundle to classify images and generate tags\n",
        "for i, row in df.iloc[start:stop].iterrows():\n",
        "    try:\n",
        "        # Read in image from url\n",
        "        url = df['eolMediaURL'][i]\n",
        "        fn = str(i) + '.jpg'\n",
        "        img, disp_img, _ = image_from_url(url, fn, pixels)\n",
        "\n",
        "        # Get quality rating tag\n",
        "        tag = df['imclass'][i]\n",
        "\n",
        "        # Display progress message after each image is loaded\n",
        "        print('Successfully loaded {} of {} images'.format(i+1, (stop-start)))\n",
        "\n",
        "        # Show classification results for images\n",
        "        # Only use to view predictions on <50 images at a time\n",
        "        plot_image_results(i, disp_img, tag)\n",
        "\n",
        "    except:\n",
        "        print('Check if URL from {} is valid'.format(url))"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}