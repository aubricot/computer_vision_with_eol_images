{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "machine_shape": "hm",
      "authorship_tag": "ABX9TyM3sPY7ZPga1mBPdyI5O14j",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/aubricot/computer_vision_with_eol_images/blob/master/classification_for_image_tagging/rating/classify_images.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_TcYNLBrWC0C"
      },
      "source": [
        "# Run images through image rating classification pipeline\n",
        "---\n",
        "*Last Updated 13 September 2025*  \n",
        "-Runs in Python 3 with Tensorflow 2.0-   \n",
        "\n",
        "Use trained image classification model to add tags for image quality rating (bad, good) to EOL images.\n",
        "\n",
        "Models were trained in [rating_train.ipynb](https://colab.research.google.com/github/aubricot/computer_vision_with_eol_images/blob/master/classification_for_image_tagging/rating/rating_train.ipynb). Confidence threshold for the best trained model was selected in [inspect_train_results.ipynb](https://colab.research.google.com/github/aubricot/computer_vision_with_eol_images/blob/master/classification_for_image_tagging/rating/inspect_train_results.ipynb).\n",
        "\n",
        "We observed controversy among users assigning ratings to \"good\" images, and consensus for assigning ratings to \"bad\" images (Users were more conflicted on what they like than what they don't like). Model behavior matched this observation. In post-processing, keep only \"bad\" image quality predictions (model accuracy was high for this class) when confidence > 1.5. \"Good\" image quality predications are discarded (model accuracy was low for this class).\n",
        "\n",
        "Finally, display tagging results on images to verify behavior is as expected.\n",
        "\n",
        "***Models were trained in Python 2 and TF 1 in December 2020: MobileNet SSD v2 (Run 18, trained on 'good' and 'bad' classes) was trained for 12 hours to 10 epochs with Batch Size=16, Lr=0.001, Dropout=0.2.***\n",
        "\n",
        "Notes:     \n",
        "* Run code blocks by pressing play button in brackets on left\n",
        "* Before you you start: change the runtime to \"GPU\" with \"High RAM\"\n",
        "* Change parameters using form fields on right (find details at corresponding lines of code by searching '#@param')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZYW4W2aqdnTN"
      },
      "source": [
        "## Installs & Imports\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6k81-h_UV_ny"
      },
      "source": [
        "#@title Choose where to save results and set up environment\n",
        "import os\n",
        "\n",
        "# Use dropdown menu on right\n",
        "save = \"in Colab runtime (files deleted after each session)\" #@param [\"in my Google Drive\", \"in Colab runtime (files deleted after each session)\"]\n",
        "print(\"Saving results \", save)\n",
        "\n",
        "# Mount google drive to export image tagging file(s)\n",
        "if 'Google Drive' in save:\n",
        "    from google.colab import drive\n",
        "    drive.mount('/content/drive', force_remount=True)\n",
        "\n",
        "# Type of classification pipeline\n",
        "classif_type = \"rating\" #@param [\"image_type\", \"rating\"] {allow-input: true}\n",
        "\n",
        "# Type in the path to your project wd in form field on right\n",
        "basewd = \"/content/drive/MyDrive/train\" #@param [\"/content/drive/MyDrive/train\"] {allow-input: true}\n",
        "basewd = basewd + '/' + classif_type\n",
        "\n",
        "# Type in the folder that you want to contain TF2 files\n",
        "folder = \"results\" #@param [\"darknet\"] {allow-input: true}\n",
        "cwd = basewd + '/' + folder\n",
        "print(f\"\\033[92m\\nWorking directory set to: \\n{cwd}\\n\\033[0m\")\n",
        "\n",
        "# Download helper_funcs folder\n",
        "!pip3 -q install --upgrade gdown\n",
        "!gdown  1TfpSLwbt6i0OMdbbjcTPVFBP6vYc3CY_\n",
        "!tar -xzvf helper_funcs.tar.gz -C .\n",
        "\n",
        "# Install requirements.txt\n",
        "#!pip3 -q install -r requirements.txt\n",
        "\n",
        "# Install compatible versions of numpy and tensorflow (Note: auto-restarts the runtime during first install. Need to run first two blocks twice to us new versions)\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "\n",
        "if tf.__version__ != '2.17.0' or not np.__version__.startswith('1.26'):\n",
        "    print(\"\\033[93m\\n\\n\\nThe first time you run this block, it will trigger an auto-restart of the Colab runtime to use newly installed versions. Re-run, then proceed with the remaining notebook steps to generate tags.\\033[0m\\n\\n\\n\")\n",
        "    !pip install --force-reinstall tensorflow==2.17.0 numpy==1.26.4 --no-cache-dir\n",
        "    # Force restarts the runtime cleanly\n",
        "    os.kill(os.getpid(), 9)\n",
        "else:\n",
        "    print(\"\\033[92mSuccessfully installed and restarted to use compatible versions of tensorflow and numpy for generating image tags.\\033[0m\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Choose saved model parameters (if using EOL model, defaults are already selected)\n",
        "from setup import *\n",
        "\n",
        "# Use EOL pre-trained model for object detection?\n",
        "use_EOL_model = True #@param {type: \"boolean\"}\n",
        "\n",
        "# Download EOL model if appropriate\n",
        "if (use_EOL_model==True) & (os.path.exists(\"18.zip\")==False):\n",
        "    !gdown 1L-WqfuoQtPgqJzU8tDKjgsZC98M-68w9\n",
        "\n",
        "# If using your own trained model, change values to match your trained model\n",
        "module_selection = (\"mobilenet_v2_1.0_224\", 224) #@param [\"(\\\"mobilenet_v2_1.0_224\\\", 224)\", \"(\\\"inception_v3\\\", 299)\"] {type:\"raw\", allow-input: true}\n",
        "dataset_labels = [\"bad\", \"good\"] #@param [\"[\\\"bad\\\", \\\"good\\\"]\"] {type:\"raw\", allow-input: true}\n",
        "saved_models_folder = \"saved_models\" #@param [\"train/saved_models/\"] {allow-input: true}\n",
        "saved_models_dir = basewd + '/' + saved_models_folder + '/'\n",
        "TRAIN_SESS_NUM = \"18\" #@param [\"18\"] {allow-input: true}\n",
        "\n",
        "# Set up directory structure\n",
        "setup_dirs(cwd)\n",
        "%cd $basewd\n",
        "\n",
        "# Unpack EOL saved model\n",
        "trained_model_dir = saved_models_dir + TRAIN_SESS_NUM + '/'\n",
        "unpack_EOL_model(use_EOL_model, trained_model_dir, basewd, TRAIN_SESS_NUM, classif_type)\n",
        "\n",
        "# Load saved model\n",
        "module_selection, dataset_labels = get_model_info(TRAIN_SESS_NUM)\n",
        "model, pixels, handle_base = load_saved_model(saved_models_dir, TRAIN_SESS_NUM, module_selection)"
      ],
      "metadata": {
        "cellView": "code",
        "id": "_ny7uvWN0B20"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1AGFM4fSWhbT"
      },
      "source": [
        "#@title Import libraries\n",
        "\n",
        "# For downloading and displaying images\n",
        "from PIL import Image\n",
        "import cv2\n",
        "import imageio\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "%config InlineBackend.figure_format = 'svg'\n",
        "\n",
        "# For working with data\n",
        "import numpy as np\n",
        "from numpy import sum\n",
        "import pandas as pd\n",
        "from os import path\n",
        "import csv\n",
        "import itertools\n",
        "from scipy.linalg import norm\n",
        "# So URL's don't get truncated in display\n",
        "pd.set_option('display.max_colwidth',1000)\n",
        "pd.options.display.max_columns = None\n",
        "\n",
        "# For measuring inference time\n",
        "import time\n",
        "\n",
        "# For image classification\n",
        "import tensorflow as tf\n",
        "print('\\nTensorflow Version: %s' % tf.__version__)\n",
        "\n",
        "# Set number of seconds to timeout if image url taking too long to open\n",
        "import socket\n",
        "socket.setdefaulttimeout(10)\n",
        "\n",
        "# Import wrangle data helper funcs\n",
        "from wrangle_data import *\n",
        "\n",
        "# Define functions\n",
        "# Set filename for saving classification results\n",
        "def set_outpath(tags_file):\n",
        "    outpath = cwd + '/' + tags_file + '.tsv'\n",
        "    print(\"\\nSaving results to: \\n\", outpath)\n",
        "\n",
        "    return outpath\n",
        "\n",
        "# Export results\n",
        "def export_results(df, url, det_imclass, conf, i):\n",
        "    # Define variables for export\n",
        "    if 'ancestry' in df.columns:\n",
        "        ancestry = df['ancestry'][i]\n",
        "    else:\n",
        "        ancestry = \"NA\"\n",
        "    identifier = df['identifier'][i]\n",
        "    dataObjectVersionID = df['dataObjectVersionID'][i]\n",
        "    # Write row with results for each image\n",
        "    results = [url, identifier, dataObjectVersionID, ancestry,\n",
        "               det_imclass, conf]\n",
        "    with open(outfpath, 'a') as out_file:\n",
        "        tsv_writer = csv.writer(out_file, delimiter='\\t')\n",
        "        tsv_writer.writerow(results)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eEWlhuLnV-lh"
      },
      "source": [
        "## Generate tags: Run inference on EOL images & save results for tagging - Run 4X for batches A-D\n",
        "---\n",
        "Use 20K EOL image bundle to classify image quality rating as bad or good. Results are saved to [tags_file].tsv. Run this section 4 times (to make batches A-D) of 5K images each to incrementally save in case of Colab timeouts."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b0u9Dd5OmWAO"
      },
      "source": [
        "### Prepare classification functions and settings"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O60NDALk_8LW"
      },
      "source": [
        "#@title Enter EOL image bundle and choose inference settings. Change **tags_file** for each batch A-D\n",
        "%cd $cwd\n",
        "\n",
        "# Load in EOL image bundle\n",
        "bundle = \"https://editors.eol.org/other_files/bundle_images/files/images_for_Squamata_20K_breakdown_000001.txt\" #@param [\"https://editors.eol.org/other_files/bundle_images/files/images_for_Squamata_20K_breakdown_000001.txt\", \"https://editors.eol.org/other_files/bundle_images/files/images_for_Coleoptera_20K_breakdown_000001.txt\", \"https://editors.eol.org/other_files/bundle_images/files/images_for_Anura_20K_breakdown_000001.txt\", \"https://editors.eol.org/other_files/bundle_images/files/images_for_Carnivora_20K_breakdown_000001.txt\"] {allow-input: true}\n",
        "df = read_datafile(bundle, sep='\\t', header=0, disp_head=False)\n",
        "\n",
        "# Test pipeline with a smaller subset than 5k images?\n",
        "run = \"test with tiny subset\" #@param [\"test with tiny subset\", \"for 500 images\"]\n",
        "print(\"Run: \", run)\n",
        "\n",
        "# Take 5k subset of bundle for running inference\n",
        "# Change filename for each batch\n",
        "tags_file = \"rating_tags_tf2_d\" #@param [\"rating_tags_tf2_a\", \"rating_tags_tf2_b\", \"rating_tags_tf2_c\", \"rating_tags_tf2_d\"] {allow-input: true}\n",
        "outfpath = set_outpath(tags_file)\n",
        "\n",
        "# Write header row of tagging file\n",
        "print(\"\\nClassification predictions for tags_file {} being saved to : \\n{}\\n\".format(tags_file, outfpath))\n",
        "if not os.path.isfile(outfpath):\n",
        "    with open(outfpath, 'a') as out_file:\n",
        "              tsv_writer = csv.writer(out_file, delimiter='\\t')\n",
        "              tsv_writer.writerow([\"eolMediaURL\", \"identifier\", \\\n",
        "                                   \"dataObjectVersionID\", \"ancestry\", \\\n",
        "                                   \"imclass\", \"confidence\"])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Run inference\n",
        "\n",
        "# Define start and stop indices for EOL bundle images\n",
        "start, stop, cutoff = set_start_stop(run, df)\n",
        "\n",
        "# Run EOL bundle images through trained model\n",
        "print(f\"Running inference for images {start} : {stop} of EOL bundle: {bundle}\\n\")\n",
        "run_inference(\n",
        "    model=model,\n",
        "    df=df,\n",
        "    pixels=pixels,\n",
        "    dataset_labels=dataset_labels,\n",
        "    start=start,\n",
        "    stop=stop,\n",
        "    cutoff=cutoff,\n",
        "    outfpath=outfpath,\n",
        "    image_from_url=image_from_url,\n",
        "    get_predict_info=get_predict_info,\n",
        "    export_results=export_results)"
      ],
      "metadata": {
        "id": "d-gWNRfBlwSx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2GrMVL_CTZit"
      },
      "source": [
        "## Post-process classification results\n",
        "---\n",
        "MobileNet SSD v2 confidence threshold (>1.5) for all 'bad' predictions was chosen in inspect_train_results.ipynb to minimize false detections and maximize dataset coverage. All 'good' predictions and any 'bad' predictions below the confidence threshold are discarded."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CpyJZTh4mJ_e"
      },
      "source": [
        "#@title Use chosen confidence threshold (or EOL default)\n",
        "\n",
        "# Adjust confidence threshold parameter\n",
        "conf_thresh = 1.5 #@param [\"1.5\"] {type:\"raw\", allow-input: true}\n",
        "\n",
        "# Combine tagging files for batches A-D\n",
        "fpath =  os.path.splitext(tags_file)[0] # Get name of one tag file\n",
        "base = cwd + '/' + fpath.rsplit('_',1)[0] + '_' # Remove lettered suffix to get basename\n",
        "exts = ['a.tsv', 'b.tsv', 'c.tsv', 'd.tsv']\n",
        "all_filenames = [base + e for e in exts] # List all tag filenames\n",
        "df = pd.concat([pd.read_csv(f, sep='\\t', header=0, na_filter = False) for f in all_filenames], ignore_index=True)\n",
        "df[['confidence']] = df[['confidence']].apply(pd.to_numeric)\n",
        "\n",
        "# Summarize combined results\n",
        "print(\"Model predictions for Training Attempt {}, {}:\".format(TRAIN_SESS_NUM, handle_base))\n",
        "print(\"No. Images: {}\\n{}\".format(len(df), df[['eolMediaURL', 'imclass', 'confidence']].head()))\n",
        "\n",
        "# Discard all predictions for 'good' or below confidence threshold\n",
        "# (Final tag to keep -> predictions for 'bad' with confidence > 1.5)\n",
        "idx_tokeep = df.index[(df.imclass == 'bad') & (df.confidence > conf_thresh)]\n",
        "idx_todiscard = df.index.difference(idx_tokeep)\n",
        "df.loc[idx_todiscard, 'imclass'] = 'NA'\n",
        "\n",
        "# Write results to tsv\n",
        "print(\"\\nFinal tagging dataset after filtering predictions: \\n\", df[['eolMediaURL', 'imclass', 'confidence']].head())\n",
        "outfpath = base + 'final.tsv'\n",
        "print(\"\\nSaving results to: \\n\", outfpath)\n",
        "df.to_csv(outfpath, sep='\\t', index=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tDnCXzDGVa6t"
      },
      "source": [
        "## Display classification results on images\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TxurlbjZJd9q"
      },
      "source": [
        "#@title Adjust start index and display up to 50 images with their tags\n",
        "\n",
        "# Adjust start index using slider\n",
        "start = 0 #@param {type:\"slider\", min:0, max:5000, step:50}\n",
        "stop = min((start+50), len(df))\n",
        "\n",
        "# Loop through EOL image bundle to classify images and generate tags\n",
        "for i, row in df.iloc[start:stop].iterrows():\n",
        "    try:\n",
        "        # Read in image from url\n",
        "        url = df['eolMediaURL'][i]\n",
        "        fn = str(i) + '.jpg'\n",
        "        img, disp_img, _ = image_from_url(url, fn, pixels)\n",
        "\n",
        "        # Get quality rating tag\n",
        "        tag = df['imclass'][i]\n",
        "\n",
        "        # Display progress message after each image is loaded\n",
        "        print('Successfully loaded {} of {} images'.format(i+1, (stop-start)))\n",
        "\n",
        "        # Show classification results for images\n",
        "        # Only use to view predictions on <50 images at a time\n",
        "        plot_image_results(i, disp_img, tag)\n",
        "\n",
        "    except:\n",
        "        print('Check if URL from {} is valid'.format(url))"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}