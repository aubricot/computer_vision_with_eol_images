{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "machine_shape": "hm",
      "authorship_tag": "ABX9TyOoOqNSBpfI/DLST0DaxEG4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/aubricot/computer_vision_with_eol_images/blob/master/classification_for_image_tagging/rating/classify_images.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_TcYNLBrWC0C"
      },
      "source": [
        "# Run images through image rating classification pipeline\n",
        "---\n",
        "*Last Updated 12 December 2022*  \n",
        "-Runs in Python 3 with Tensorflow 2.0-   \n",
        "\n",
        "Use trained image classification model to add tags for image quality rating (bad, good) to EOL images.\n",
        "\n",
        "Models were trained in [rating_train.ipynb](https://colab.research.google.com/github/aubricot/computer_vision_with_eol_images/blob/master/classification_for_image_tagging/rating/rating_train.ipynb). Confidence threshold for the best trained model was selected in [inspect_train_results.ipynb](https://colab.research.google.com/github/aubricot/computer_vision_with_eol_images/blob/master/classification_for_image_tagging/rating/inspect_train_results.ipynb). \n",
        "\n",
        "We observed controversy among users assigning ratings to \"good\" images, and consensus for assigning ratings to \"bad\" images (Users were more conflicted on what they like than what they don't like). Model behavior matched this observation. In post-processing, keep only \"bad\" image quality predictions (model accuracy was high for this class) when confidence > 1.5. \"Good\" image quality predications are discarded (model accuracy was low for this class). \n",
        "\n",
        "Finally, display tagging results on images to verify behavior is as expected.\n",
        "\n",
        "***Models were trained in Python 2 and TF 1 in December 2020: MobileNet SSD v2 (Run 18, trained on 'good' and 'bad' classes) was trained for 12 hours to 10 epochs with Batch Size=16, Lr=0.001, Dropout=0.2.***\n",
        "\n",
        "Notes:     \n",
        "* Run code blocks by pressing play button in brackets on left\n",
        "* Before you you start: change the runtime to \"GPU\" with \"High RAM\"\n",
        "* Change parameters using form fields on right (find details at corresponding lines of code by searching '#@param')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZYW4W2aqdnTN"
      },
      "source": [
        "## Installs & Imports\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6k81-h_UV_ny"
      },
      "source": [
        "#@title Choose where to save results\n",
        "import os\n",
        "\n",
        "# Use dropdown menu on right\n",
        "save = \"in Colab runtime (files deleted after each session)\" #@param [\"in my Google Drive\", \"in Colab runtime (files deleted after each session)\"]\n",
        "\n",
        "# Mount google drive to export image tagging file(s)\n",
        "if 'Google Drive' in save:\n",
        "    from google.colab import drive\n",
        "    drive.mount('/content/drive', force_remount=True)\n",
        "\n",
        "# Type in the path to your project wd in form field on right\n",
        "basewd = \"/content/drive/MyDrive/train\" #@param [\"/content/drive/MyDrive/train\"] {allow-input: true}\n",
        "\n",
        "# Make folder for image tags within base wd\n",
        "cwd = basewd + '/results/'\n",
        "if not os.path.exists(cwd):\n",
        "    os.makedirs(cwd)\n",
        "\n",
        "print(\"Saving results {} to {}\".format(save, cwd))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1AGFM4fSWhbT"
      },
      "source": [
        "#@title Import libraries\n",
        "\n",
        "# For downloading and displaying images\n",
        "from PIL import Image\n",
        "import cv2\n",
        "import imageio\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "%config InlineBackend.figure_format = 'svg'\n",
        "\n",
        "# For working with data\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from os import path\n",
        "import csv\n",
        "import itertools\n",
        "from scipy.linalg import norm\n",
        "from scipy import sum, average\n",
        "# So URL's don't get truncated in display\n",
        "pd.set_option('display.max_colwidth',1000)\n",
        "pd.options.display.max_columns = None\n",
        "\n",
        "# For measuring inference time\n",
        "import time\n",
        "\n",
        "# For image classification\n",
        "import tensorflow as tf\n",
        "print('\\nTensorflow Version: %s' % tf.__version__)\n",
        "\n",
        "# Set number of seconds to timeout if image url taking too long to open\n",
        "import socket\n",
        "socket.setdefaulttimeout(10)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y7LrA9zfAlq3"
      },
      "source": [
        "#@title Choose saved model parameters (if using EOL model, defaults are already selected)\n",
        "\n",
        "# Use EOL pre-trained model for object detection?\n",
        "use_EOL_model = True #@param {type: \"boolean\"}\n",
        "\n",
        "# Get info about trained classification model\n",
        "def get_model_info(use_EOL_model):\n",
        "    # Use EOL pre-trained model\n",
        "    if use_EOL_model:\n",
        "        # Model metadata\n",
        "        module_selection =('mobilenet_v2_1.0_224', 224)\n",
        "        dataset_labels = [\"bad\",\"good\"]\n",
        "        TRAIN_SESS_NUM = '18'\n",
        "        saved_models_dir = basewd + '/saved_models/'\n",
        "        # If running for the first time, download model\n",
        "        if not os.path.exists(saved_models_dir):\n",
        "            # Make folder for trained model\n",
        "            os.makedirs(saved_models_dir)\n",
        "            %cd $saved_models_dir\n",
        "            os.makedirs(TRAIN_SESS_NUM)\n",
        "            # Download saved model files for Run 18 - MobileNet SSD v2\n",
        "            !pip3 install --upgrade gdown\n",
        "            !gdown --id 1L-WqfuoQtPgqJzU8tDKjgsZC98M-68w9 # 18.zip 404 Mb\n",
        "            !unzip 18.zip -d .\n",
        "            !mv -v content/drive/MyDrive/summer20/classification/rating/saved_models/18/* 18\n",
        "            !rm -r content\n",
        "            !rm -r 18.zip\n",
        "            %cd ../\n",
        "            print(\"\\nSuccessfully downloaded pre-trained EOL model to: \\n\", (saved_models_dir + TRAIN_SESS_NUM))\n",
        "    \n",
        "    # Use your own trained model\n",
        "    elif not use_EOL_model:\n",
        "        # Change values to match your trained model\n",
        "        module_selection = (\"mobilenet_v2_1.0_224\", 224) #@param [\"(\\\"mobilenet_v2_1.0_224\\\", 224)\", \"(\\\"inception_v3\\\", 299)\"] {type:\"raw\", allow-input: true}\n",
        "        dataset_labels = [\"bad\", \"good\"] #@param [\"[\\\"bad\\\", \\\"good\\\"]\"] {type:\"raw\", allow-input: true}\n",
        "        saved_models_dir = \"train/saved_models/\" #@param [\"train/saved_models/\"] {allow-input: true}\n",
        "        TRAIN_SESS_NUM = \"18\" #@param [\"18\"] {allow-input: true}\n",
        "\n",
        "    return module_selection, dataset_labels, saved_models_dir, TRAIN_SESS_NUM\n",
        "\n",
        "# Load saved model\n",
        "module_selection, dataset_labels, saved_models_dir, TRAIN_SESS_NUM = get_model_info(use_EOL_model)\n",
        "model, pixels, handle_base = load_saved_model(saved_models_dir, TRAIN_SESS_NUM, module_selection)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eEWlhuLnV-lh"
      },
      "source": [
        "## Generate tags: Run inference on EOL images & save results for tagging - Run 4X for batches A-D\n",
        "---\n",
        "Use 20K EOL image bundle to classify image quality rating as bad or good. Results are saved to [tags_file].tsv. Run this section 4 times (to make batches A-D) of 5K images each to incrementally save in case of Colab timeouts."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b0u9Dd5OmWAO"
      },
      "source": [
        "### Prepare classification functions and settings"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Define functions\n",
        "\n",
        "# To read in EOL formatted data files\n",
        "def read_datafile(fpath, sep=\"\\t\", header=0, disp_head=True):\n",
        "    try:\n",
        "        df = pd.read_csv(fpath, sep=sep, header=header, storage_options=hdr)\n",
        "        if disp_head:\n",
        "          print(\"Data header: \\n\", df.head())\n",
        "    except FileNotFoundError as e:\n",
        "        raise Exception(\"File not found: Enter the path to your file in form field and re-run\").with_traceback(e.__traceback__)\n",
        "    \n",
        "    return df\n",
        "\n",
        "# Define start and stop indices in EOL bundle for running inference   \n",
        "def set_start_stop(df):\n",
        "    # To test with a tiny subset, use 5 random bundle images\n",
        "    if \"tiny subset\" in run:\n",
        "        start=np.random.choice(a=len(df), size=1)[0]\n",
        "        stop=start+5\n",
        "    # To run inference on 4 batches of 5k images each\n",
        "    elif \"_a.\" in outfpath: # batch a is from 0-5000\n",
        "        start=0\n",
        "        stop=5000\n",
        "    elif \"_b.\" in outfpath: # batch b is from 5000-1000\n",
        "        start=5000\n",
        "        stop=10000\n",
        "    elif \"_c.\" in outfpath: # batch c is from 10000-15000\n",
        "        start=10000\n",
        "        stop=15000\n",
        "    elif \"_d.\" in outfpath: # batch d is from 15000-20000\n",
        "        start=15000\n",
        "        stop=20000\n",
        "\n",
        "    return start, stop\n",
        "\n",
        "# Load in image from URL\n",
        "# Modified from https://colab.research.google.com/github/tensorflow/docs/blob/master/site/en/guide/saved_model.ipynb#scrollTo=JhVecdzJTsKE\n",
        "def image_from_url(url, fn):\n",
        "    # Formatted for classification\n",
        "    f = tf.keras.utils.get_file(fn, url) # Filename doesn't matter\n",
        "    disp_img = tf.keras.preprocessing.image.load_img(f) # For display\n",
        "    img_cv = np.array(disp_img) # For working with cv2 lib\n",
        "    image = tf.keras.preprocessing.image.load_img(f, target_size=[pixels, pixels])\n",
        "    image = tf.keras.preprocessing.image.img_to_array(image)\n",
        "    image = tf.keras.applications.mobilenet_v2.preprocess_input(\n",
        "        image[tf.newaxis,...])\n",
        "    \n",
        "    return image, disp_img\n",
        "\n",
        "# Load saved model from directory\n",
        "def load_saved_model(saved_models_dir, TRAIN_SESS_NUM, module_selection):\n",
        "    # Load trained model from path\n",
        "    saved_model_path = saved_models_dir + TRAIN_SESS_NUM\n",
        "    model = tf.keras.models.load_model(saved_model_path)\n",
        "    # Get name and image size for model type\n",
        "    handle_base, pixels = module_selection\n",
        "\n",
        "    return model, pixels, handle_base\n",
        "\n",
        "# Get info from predictions to display on images\n",
        "def get_predict_info(predictions, url, i, stop, start):\n",
        "    # Get info from predictions\n",
        "    label_num = np.argmax(predictions[0], axis=-1)\n",
        "    conf = predictions[0][label_num]\n",
        "    im_class = dataset_labels[label_num]\n",
        "    # Display progress message after each image\n",
        "    print(\"Completed for {}, {} of {} files\".format(url, i+1, format(stop-start, '.0f')))\n",
        "    \n",
        "    return label_num, conf, im_class\n",
        "\n",
        "# Set filename for saving classification results\n",
        "def set_outpath(tags_file):\n",
        "    outpath = basewd + '/results/' + tags_file + '.tsv'\n",
        "    print(\"\\nSaving results to: \\n\", outpath)\n",
        "\n",
        "    return outpath\n",
        "\n",
        "# Export results\n",
        "def export_results(df, url, det_imclass, conf):\n",
        "    # Define variables for export\n",
        "    if 'ancestry' in df.columns:\n",
        "        ancestry = df['ancestry'][i]\n",
        "    else:\n",
        "        ancestry = \"NA\"\n",
        "    identifier = df['identifier'][i]\n",
        "    dataObjectVersionID = df['dataObjectVersionID'][i] \n",
        "    # Write row with results for each image\n",
        "    results = [url, identifier, dataObjectVersionID, ancestry,  \n",
        "               det_imclass, conf]\n",
        "    with open(outfpath, 'a') as out_file:\n",
        "        tsv_writer = csv.writer(out_file, delimiter='\\t')\n",
        "        tsv_writer.writerow(results)"
      ],
      "metadata": {
        "id": "nbFSjm5qWjp3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O60NDALk_8LW"
      },
      "source": [
        "#@title Enter EOL image bundle and choose inference settings. Change **tags_file** for each batch A-D\n",
        "%cd $cwd\n",
        "\n",
        "# Load in EOL image bundle\n",
        "bundle = \"https://editors.eol.org/other_files/bundle_images/files/images_for_Squamata_20K_breakdown_000001.txt\" #@param [\"https://editors.eol.org/other_files/bundle_images/files/images_for_Squamata_20K_breakdown_000001.txt\", \"https://editors.eol.org/other_files/bundle_images/files/images_for_Coleoptera_20K_breakdown_000001.txt\", \"https://editors.eol.org/other_files/bundle_images/files/images_for_Anura_20K_breakdown_000001.txt\", \"https://editors.eol.org/other_files/bundle_images/files/images_for_Carnivora_20K_breakdown_000001.txt\"] {allow-input: true}\n",
        "df = read_datafile(bundle, sep='\\t', header=0, disp_head=False)\n",
        "\n",
        "# Test pipeline with a smaller subset than 5k images?\n",
        "run = \"test with tiny subset\" #@param [\"test with tiny subset\", \"for all images\"]\n",
        "\n",
        "# Take 5k subset of bundle for running inference\n",
        "# Change filename for each batch\n",
        "tags_file = \"rating_tags_tf2_c\" #@param [\"rating_tags_tf2_a\", \"rating_tags_tf2_b\", \"rating_tags_tf2_c\", \"rating_tags_tf2_d\"] {allow-input: true}\n",
        "outfpath = set_outpath(tags_file)\n",
        "\n",
        "# Write header row of tagging file\n",
        "if not os.path.isfile(outfpath): \n",
        "    with open(outfpath, 'a') as out_file:\n",
        "              tsv_writer = csv.writer(out_file, delimiter='\\t')\n",
        "              tsv_writer.writerow([\"eolMediaURL\", \"identifier\", \\\n",
        "                                   \"dataObjectVersionID\", \"ancestry\", \\\n",
        "                                   \"imclass\", \"confidence\"])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Add tags to images"
      ],
      "metadata": {
        "id": "7GyW09OL1dgf"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_05_nxEYupOY"
      },
      "source": [
        "#@title Run inference \n",
        "start, stop = set_start_stop(df)\n",
        "for i, row in enumerate(df.iloc[start:stop].iterrows()):\n",
        "    try:       \n",
        "        # Read in image from url\n",
        "        url = df['eolMediaURL'][i]\n",
        "        fn = str(i) + '.jpg'\n",
        "        img, disp_img = image_from_url(url, fn)\n",
        "\n",
        "        # Image classification\n",
        "        start_time = time.time() # Record inference time\n",
        "        predictions = model.predict(img, batch_size=1)\n",
        "        label_num, conf, det_imclass = get_predict_info(predictions, url, i, stop, start)\n",
        "        end_time = time.time()\n",
        "        print(\"Inference time: {} sec\".format(format(end_time-start_time, '.2f')))\n",
        "\n",
        "        # Export tagging results to \n",
        "        export_results(df, url, det_imclass, conf)\n",
        "\n",
        "    except:\n",
        "        print('Check if URL from {} is valid'.format(url))\n",
        "\n",
        "print(\"\\n\\n~~~\\nInference complete! Run these steps for remaining batches A-D before proceeding.\\n~~~\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2GrMVL_CTZit"
      },
      "source": [
        "## Post-process classification results\n",
        "---\n",
        "MobileNet SSD v2 confidence threshold (>1.5) for all 'bad' predictions was chosen in inspect_train_results.ipynb to minimize false detections and maximize dataset coverage. All 'good' predictions and any 'bad' predictions below the confidence threshold are discarded."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CpyJZTh4mJ_e"
      },
      "source": [
        "#@title Use chosen confidence threshold (or EOL default)\n",
        "\n",
        "# Adjust confidence threshold parameter\n",
        "conf_thresh = 1.5 #@param [\"1.5\"] {type:\"raw\", allow-input: true}\n",
        "\n",
        "# Combine tagging files for batches A-D\n",
        "fpath =  os.path.splitext(tags_file)[0] # Get name of one tag file\n",
        "base = cwd + fpath.rsplit('_',1)[0] + '_' # Remove lettered suffix to get basename\n",
        "exts = ['a.tsv', 'b.tsv', 'c.tsv', 'd.tsv']\n",
        "all_filenames = [base + e for e in exts] # List all tag filenames\n",
        "df = pd.concat([pd.read_csv(f, sep='\\t', header=0, na_filter = False) for f in all_filenames], ignore_index=True)\n",
        "df[['confidence']] = df[['confidence']].apply(pd.to_numeric)\n",
        "\n",
        "# Summarize combined results\n",
        "print(\"Model predictions for Training Attempt {}, {}:\".format(TRAIN_SESS_NUM, handle_base))\n",
        "print(\"No. Images: {}\\n{}\".format(len(df), df[['eolMediaURL', 'imclass', 'confidence']].head()))\n",
        "\n",
        "# Discard all predictions for 'good' or below confidence threshold\n",
        "# (Final tag to keep -> predictions for 'bad' with confidence > 1.5) \n",
        "idx_tokeep = df.index[(df.imclass == 'bad') & (df.confidence > conf_thresh)]\n",
        "idx_todiscard = df.index.difference(idx_tokeep)\n",
        "df.loc[idx_todiscard, 'imclass'] = 'NA'\n",
        "\n",
        "# Write results to tsv\n",
        "print(\"\\nFinal tagging dataset after filtering predictions: \\n\", df[['eolMediaURL', 'imclass', 'confidence']].head())\n",
        "outfpath = base + 'final.tsv'\n",
        "print(\"\\nSaving results to: \\n\", outfpath)\n",
        "df.to_csv(outfpath, sep='\\t', index=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tDnCXzDGVa6t"
      },
      "source": [
        "## Display classification results on images\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TxurlbjZJd9q"
      },
      "source": [
        "#@title Adjust start index and display up to 50 images with their tags\n",
        "\n",
        "# Adjust start index using slider\n",
        "start = 0 #@param {type:\"slider\", min:0, max:5000, step:50}\n",
        "stop = min((start+50), len(df))\n",
        "\n",
        "# Loop through EOL image bundle to classify images and generate tags\n",
        "for i, row in df.iloc[start:stop].iterrows():\n",
        "    try:\n",
        "        # Read in image from url\n",
        "        url = df['eolMediaURL'][i]\n",
        "        fn = str(i) + '.jpg'\n",
        "        img, disp_img = image_from_url(url, fn)\n",
        "    \n",
        "        # Get quality rating tag\n",
        "        tag = df['imclass'][i]\n",
        "    \n",
        "        # Display progress message after each image is loaded\n",
        "        print('Successfully loaded {} of {} images'.format(i+1, (stop-start)))\n",
        "\n",
        "        # Show classification results for images\n",
        "        # Only use to view predictions on <50 images at a time\n",
        "        _, ax = plt.subplots(figsize=(10, 10))\n",
        "        ax.imshow(disp_img)\n",
        "        plt.axis('off')\n",
        "        plt.title(\"{}) Image quality rating: {} \".format(i+1, tag))\n",
        "\n",
        "    except:\n",
        "        print('Check if URL from {} is valid'.format(url))"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}