{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "classify_images.ipynb",
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "authorship_tag": "ABX9TyP7VwC8yOP9FzgYgFPnPF99",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/aubricot/computer_vision_with_eol_images/blob/master/classification_for_image_tagging/rating/classify_images.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_TcYNLBrWC0C"
      },
      "source": [
        "# Run images through image rating classification pipeline\n",
        "--- \n",
        "Classify images as \"bad\" or \"good\" quality.  \n",
        "*Last Updated 26 January 2021* \n",
        "\n",
        "1) Run images through trained MobileNet SSD v2 model (Attempt 18) to add tags to images for image rating (bad, good) for predictions with confidence > 1.5. (Confidence value chosen in [inspect_train_results.ipynb](https://colab.research.google.com/github/aubricot/computer_vision_with_eol_images/blob/master/classification_for_image_tagging/rating/inspect_train_results.ipynb)).\n",
        "\n",
        "2) Discard \"good\" predications (model accuracy was low for these) and keep only \"bad\" predications (model accuracy was high for these) above the chosen confidence threshold (1.5).*\n",
        "\n",
        "3) Display tagging results on images to verify behavior is as expected.\n",
        "\n",
        "**Notes**:     \n",
        "**We observed controversy among users assigning ratings to \"good\" images, and general consensus for assigning ratings to \"bad\" images. Model behavior matches this observation.*\n",
        "\n",
        "Change filepaths or information using the form fields to the right of code blocks (also noted in code with 'TO DO')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZYW4W2aqdnTN"
      },
      "source": [
        "### Imports\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6k81-h_UV_ny"
      },
      "source": [
        "# Mount google drive to import/export files\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1AGFM4fSWhbT"
      },
      "source": [
        "# For working with data and plotting graphs\n",
        "import itertools\n",
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from scipy.linalg import norm\n",
        "from scipy import sum, average\n",
        "%matplotlib inline\n",
        "%config InlineBackend.figure_format = 'svg'\n",
        "\n",
        "# For image classification and training\n",
        "import tensorflow as tf\n",
        "\n",
        "# For working with images\n",
        "!pip install pillow\n",
        "!pip install scipy==1.1.0\n",
        "import cv2\n",
        "import scipy\n",
        "from scipy import misc"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eEWlhuLnV-lh"
      },
      "source": [
        "### 1) Classification\n",
        "----"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b0u9Dd5OmWAO"
      },
      "source": [
        "#### Define functions & variables\n",
        "---\n",
        "To run classification on batches of 5k images at a time, change tag output file name (abcd for 4 batches from 20k bundle + taxon name) and start/end rows (a/b) using form fields to right. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y7LrA9zfAlq3"
      },
      "source": [
        "# For images to read in from bundle\n",
        "\n",
        "# Load in image from URL\n",
        "# Modified from https://colab.research.google.com/github/tensorflow/docs/blob/master/site/en/guide/saved_model.ipynb#scrollTo=JhVecdzJTsKE\n",
        "def image_from_url(url, fn):\n",
        "  file = tf.keras.utils.get_file(fn, url) # Filename doesn't matter\n",
        "  disp_img = tf.keras.preprocessing.image.load_img(file)\n",
        "  img = tf.keras.preprocessing.image.load_img(file, target_size=[224, 224])\n",
        "  x = tf.keras.preprocessing.image.img_to_array(img)\n",
        "  x = tf.keras.applications.mobilenet_v2.preprocess_input(\n",
        "    x[tf.newaxis,...])\n",
        "  return x, disp_img\n",
        "\n",
        "# Read in EOL image bundle dataframe\n",
        "# TO DO: Type in image bundle address using form field to right\n",
        "bundle = \"https://editors.eol.org/other_files/bundle_images/files/images_for_Chiroptera_breakdown_000001.txt\" #@param [\"https://editors.eol.org/other_files/bundle_images/files/images_for_Angiosperms_20K_breakdown_000031.txt\", \"https://editors.eol.org/other_files/bundle_images/files/images_for_Anura_20K_breakdown_000001.txt\", \"https://editors.eol.org/other_files/bundle_images/files/images_for_Chiroptera_breakdown_000001.txt\", \"https://editors.eol.org/other_files/bundle_images/files/images_for_Squamata_breakdown_000001.txt\"] {allow-input: true}\n",
        "df = pd.read_csv(bundle, sep='\\t', header=0)\n",
        "print(df.head())\n",
        "\n",
        "# For exporting tagging results\n",
        "import csv\n",
        "\n",
        "# Write header row of output tagging file\n",
        "# TO DO: Change file name for each bundle/run abcd if doing 4 batches using dropdown form to right\n",
        "tags_file = \"tags_rating_20k_d\" #@param [\"tags_rating_20k_a\", \"tags_rating_20k_b\", \"tags_rating_20k_c\", \"tags_rating_20k_d\"] {allow-input: true}\n",
        "tags_fpath = \"/content/drive/My Drive/summer20/classification/rating/results/\" + tags_file + \".tsv\"\n",
        "\n",
        "# Run in 4 batches of 5k images each (batch a is from 0-5000, b from 5000 to 10000, etc)\n",
        "if \"a\" in tags_file:\n",
        "  a=0\n",
        "  b=5000\n",
        "elif \"b\" in tags_file:\n",
        "  a=5000\n",
        "  b=10000\n",
        "elif \"c\" in tags_file:\n",
        "  a=10000\n",
        "  b=15000\n",
        "elif \"d\" in tags_file:\n",
        "  a=15000\n",
        "  b=20000"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W2tO7HH-uLXY"
      },
      "source": [
        "#### Run images through model for image rating classification\n",
        "---  \n",
        "Use model selected in inspect_train_results.ipynb (MobileNet SSD v2, Train attempt 18) to classify image quality as good or bad."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0ZXo6iVvBF0G"
      },
      "source": [
        "from PIL import Image\n",
        "import time\n",
        "\n",
        "# Write header row of tagging files\n",
        "with open(tags_fpath, 'a') as out_file:\n",
        "      tsv_writer = csv.writer(out_file, delimiter='\\t')\n",
        "      tsv_writer.writerow([\"eolMediaURL\", \"identifier\", \\\n",
        "                          \"dataObjectVersionID\", \"ancestry\", \\\n",
        "                          \"tag_rating\", \"confidence\"])\n",
        "\n",
        "# Load trained model from path\n",
        "TRAIN_SESS_NUM = \"18\"\n",
        "saved_model_path = '/content/drive/My Drive/summer20/classification/rating/saved_models/' + TRAIN_SESS_NUM\n",
        "model = tf.keras.models.load_model(saved_model_path)\n",
        "label_names = ['bad', 'good']\n",
        "module_selection = (\"mobilenet_v2_1.0_224\", 224)\n",
        "handle_base, pixels = module_selection\n",
        "IMAGE_SIZE = (pixels, pixels)\n",
        "\n",
        "# Set number of seconds to timeout if image url taking too long to open\n",
        "import socket\n",
        "socket.setdefaulttimeout(10)\n",
        "import time\n",
        "from PIL import Image\n",
        "\n",
        "# Loop through EOL image bundle to classify images and generate tags\n",
        "for i, row in df.iloc[a:b].iterrows():\n",
        "  try:\n",
        "    # Get url from image bundle\n",
        "    url = df['eolMediaURL'][i]\n",
        "    # Read in image from url\n",
        "    fn = str(i) + '.jpg'\n",
        "    img, disp_img = image_from_url(url, fn)\n",
        "    #ax.imshow(disp_img)\n",
        "    # Record inference time\n",
        "    start_time = time.time()\n",
        "    # Detection and draw boxes on image\n",
        "    # For flowers/fruits (reproductive structures)\n",
        "    predictions = model.predict(img, batch_size=1)\n",
        "    label_num = np.argmax(predictions)\n",
        "    conf = predictions[0][label_num]\n",
        "    imclass = label_names[label_num]\n",
        "    end_time = time.time()\n",
        "    # Display progress message after each image\n",
        "    print('Inference complete for Row {} of {} images in {} sec'.format(i, (b-a), \\\n",
        "                                            format(end_time-start_time, '.2f')))\n",
        "\n",
        "    # Export tagging results to tsv\n",
        "    # Define variables for export\n",
        "    identifier = df['identifier'][i]\n",
        "    dataObjectVersionID = df['dataObjectVersionID'][i]\n",
        "    if 'ancestry' in df.columns:\n",
        "      ancestry = df['ancestry'][i]\n",
        "    else:\n",
        "      ancestry = \"NA\"\n",
        "    with open(tags_fpath, 'a') as out_file:\n",
        "      tsv_writer = csv.writer(out_file, delimiter='\\t')\n",
        "      tsv_writer.writerow([url, identifier, dataObjectVersionID, ancestry, \\\n",
        "                               imclass, conf])\n",
        "  except:\n",
        "    print('Check if URL from {} is valid'.format(url))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2GrMVL_CTZit"
      },
      "source": [
        "### 2) Post-process classification predictions using confidence threshold values\n",
        "---\n",
        "MobileNet SSD v2 confidence threshold (>1.5) for all 'bad' predictions was chosen in inspect_train_results.ipynb to minimize false detections."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SdgO3bk8mdKJ"
      },
      "source": [
        "# TO DO: Input and adjust classification confidence thresholds\n",
        "conf_thresh = 1.5 #@param \n",
        "\n",
        "# Combine exported model predictions and confidence values from above to one dataframe\n",
        "fpath =  os.path.splitext(tags_fpath)[0]\n",
        "base = fpath.rsplit('_',1)[0] + '_'\n",
        "exts = ['a.tsv', 'b.tsv', 'c.tsv', 'd.tsv']\n",
        "all_filenames = [base + e for e in exts]\n",
        "df = pd.concat([pd.read_csv(f, sep='\\t', header=0, na_filter = False) for f in all_filenames], ignore_index=True)\n",
        "df[['confidence']] = df[['confidence']].apply(pd.to_numeric)\n",
        "\n",
        "# Adjust final tag so that all 'bad' predications > 1.5 confidence value = 'bad'\n",
        "for i, row in df.iterrows():\n",
        "  if (df['tag_rating'][i] == 'bad') and (df['confidence'][i]>conf_thresh): \n",
        "    df['tag_rating'][i] = df['tag_rating'][i]  \n",
        "  else: \n",
        "    df['tag_rating'][i] = 'NA' \n",
        "\n",
        "# Write results to tsv\n",
        "print(df.head())\n",
        "outfpath = base + 'finaltags.tsv'\n",
        "df.to_csv(outfpath, sep='\\t', index=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tDnCXzDGVa6t"
      },
      "source": [
        "### 3) Display final classification results on images\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TxurlbjZJd9q"
      },
      "source": [
        "# Set number of seconds to timeout if image url taking too long to open\n",
        "import socket\n",
        "socket.setdefaulttimeout(10)\n",
        "\n",
        "# TO DO: Update file path to finaltags.tsv file\n",
        "path = \"/content/drive/My Drive/summer20/classification/rating/results/\"\n",
        "f = \"tags_rating_20k_finaltags.tsv\" #@param\n",
        "fpath = path + f\n",
        "df = pd.read_csv(fpath, sep='\\t', header=0, na_filter = False)\n",
        "\n",
        "# Function to load in image from URL\n",
        "# Modified from https://colab.research.google.com/github/tensorflow/docs/blob/master/site/en/guide/saved_model.ipynb#scrollTo=JhVecdzJTsKE\n",
        "def image_from_url(url, fn):\n",
        "  file = tf.keras.utils.get_file(fn, url) # Filename doesn't matter\n",
        "  disp_img = tf.keras.preprocessing.image.load_img(file)\n",
        "  img = tf.keras.preprocessing.image.load_img(file, target_size=[224, 224])\n",
        "  x = tf.keras.preprocessing.image.img_to_array(img)\n",
        "  x = tf.keras.applications.mobilenet_v2.preprocess_input(\n",
        "    x[tf.newaxis,...])\n",
        "  return x, disp_img\n",
        "\n",
        "# TO DO: Set start and end rows to run inference for from EOL image bundle using form field to right\n",
        "start =  0#@param {type:\"raw\"}\n",
        "end = 50 #@param {type:\"raw\"}\n",
        "\n",
        "# Loop through EOL image bundle to classify images and generate tags\n",
        "for i, row in df.iloc[start:end].iterrows():\n",
        "  try:\n",
        "    # Get url from image bundle\n",
        "    url = df['eolMediaURL'][i]\n",
        "    # Read in image from url\n",
        "    fn = str(i) + '.jpg'\n",
        "    img, disp_img = image_from_url(url, fn)\n",
        "    # Record inference time\n",
        "    tag = df['tag_rating'][i]\n",
        "    # Display progress message after each image is loaded\n",
        "    print('Successfully loaded {} of {} images'.format(i+1, (end-start)))\n",
        "\n",
        "    # Show classification results for images\n",
        "    # Only use to view predictions on <50 images at a time\n",
        "    _, ax = plt.subplots(figsize=(10, 10))\n",
        "    ax.imshow(disp_img)\n",
        "    plt.axis('off')\n",
        "    plt.title(\"{}) Image quality rating: {} \".format(i+1, tag))\n",
        "\n",
        "  except:\n",
        "    print('Check if URL from {} is valid'.format(url))"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}