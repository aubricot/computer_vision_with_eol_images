{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "classify_images.ipynb",
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "authorship_tag": "ABX9TyM9F1bwslYS1RkUbrbY25H6",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/aubricot/computer_vision_with_eol_images/blob/master/classification_for_image_tagging/rating/classify_images.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_TcYNLBrWC0C"
      },
      "source": [
        "# Run images through image rating classification pipeline\n",
        "--- \n",
        "Classify images as \"bad\" or \"good\" quality.  \n",
        "*Last Updated 27 October 2021* \n",
        "\n",
        "Use trained image classification model (Run 18, MobileNet SSD v2) to add tags for image rating (bad, good) to EOL images for predictions above the chosen confidence threshold. (Confidence value and model selected in [inspect_train_results.ipynb](https://colab.research.google.com/github/aubricot/computer_vision_with_eol_images/blob/master/classification_for_image_tagging/rating/inspect_train_results.ipynb)).\n",
        "\n",
        "In post-processing, keep only \"bad\" image quality predications (model accuracy was high for this class) when confidence > 1.5. \"Good\" image quality predications are discarded (model accuracy was low for this class). Then, display tagging results on images to verify behavior is as expected.\n",
        "\n",
        "***Models were trained in Python 2 and TF 1 in December 2020: MobileNet SSD v2 (Run 18, trained on 'good' and 'bad' classes) was trained for 12 hours to 10 epochs with Batch Size=16, Lr=0.001, Dropout=0.2.***\n",
        "\n",
        "Notes:     \n",
        "* Change parameters using form fields on right (/where you see 'TO DO' in code)\n",
        "* To test the notebook, all code can be run without connecting to your Google Drive. Results will be saved to the Colab runtime and cleared at the end of your session.\n",
        "* We observed controversy among users assigning ratings to \"good\" images, and consensus for assigning ratings to \"bad\" images (Users were more conflicted on what they like than what they don't like). Model behavior matched this observation.*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZYW4W2aqdnTN"
      },
      "source": [
        "## Installs & Imports\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6k81-h_UV_ny"
      },
      "source": [
        "# (Optional): Mount google drive to import/export files\n",
        "# Note: Only run this cell if want to save results\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1AGFM4fSWhbT"
      },
      "source": [
        "# For downloading and displaying images\n",
        "!pip install pillow\n",
        "!pip install scipy==1.1.0\n",
        "from PIL import Image\n",
        "import cv2\n",
        "import scipy\n",
        "from scipy import misc\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "%config InlineBackend.figure_format = 'svg'\n",
        "\n",
        "# For working with data\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import os\n",
        "from os import path\n",
        "import csv\n",
        "import itertools\n",
        "from scipy.linalg import norm\n",
        "from scipy import sum, average\n",
        "# So URL's don't get truncated in display\n",
        "pd.set_option('display.max_colwidth',1000)\n",
        "pd.options.display.max_columns = None\n",
        "\n",
        "# For measuring inference time\n",
        "import time\n",
        "\n",
        "# For image classification\n",
        "import tensorflow as tf\n",
        "print('\\nTensorflow Version: %s' % tf.__version__)\n",
        "\n",
        "# Set number of seconds to timeout if image url taking too long to open\n",
        "import socket\n",
        "socket.setdefaulttimeout(10)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eEWlhuLnV-lh"
      },
      "source": [
        "## Generate tags for images\n",
        "---\n",
        "Run EOL 20k image bundles through pre-trained image classification models and save results in 4 batches (A-D). "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b0u9Dd5OmWAO"
      },
      "source": [
        "### Prepare classification functions and settings"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PFVJYJuLIjkZ"
      },
      "source": [
        "# Set working directory\n",
        "# TO DO: Type in the path to your working directory in form field to right\n",
        "wd = \"/content/drive/MyDrive/train/\" #@param {type:\"string\"}\n",
        "\n",
        "# Make folder for image tags within base wd\n",
        "cwd = wd + 'results/'\n",
        "if not os.path.exists(cwd):\n",
        "    os.makedirs(cwd)\n",
        "\n",
        "# Define functions\n",
        "\n",
        "# To read in EOL formatted data files\n",
        "def read_datafile(fpath, sep=\"\\t\", header=0, disp_head=True, lineterminator='\\n', encoding='latin1'):\n",
        "    \"\"\"\n",
        "    Defaults to tab-separated data files with header in row 0\n",
        "    \"\"\"\n",
        "    try:\n",
        "        df = pd.read_csv(fpath, sep=sep, header=header, lineterminator=lineterminator, encoding=encoding)\n",
        "        if disp_head:\n",
        "          print(\"Data header: \\n\", df.head())\n",
        "    except FileNotFoundError as e:\n",
        "        raise Exception(\"File not found: Enter the path to your file in form field and re-run\").with_traceback(e.__traceback__)\n",
        "    \n",
        "    return df\n",
        "\n",
        "# Define start and stop indices in EOL bundle for running inference   \n",
        "def set_start_stop():\n",
        "    # To test with a tiny subset, use 5 random bundle images\n",
        "    if test_with_tiny_subset:\n",
        "        start=np.random.choice(a=1000, size=1)[0]\n",
        "        stop=start+5\n",
        "    # To run inference on 4 batches of 5k images each\n",
        "    elif \"_a.\" in outfpath: # batch a is from 0-5000\n",
        "        start=0\n",
        "        stop=5000\n",
        "    elif \"_b.\" in outfpath: # batch b is from 5000-1000\n",
        "        start=5000\n",
        "        stop=10000\n",
        "    elif \"_c.\" in outfpath: # batch c is from 10000-15000\n",
        "        start=10000\n",
        "        stop=15000\n",
        "    elif \"_d.\" in outfpath: # batch d is from 15000-20000\n",
        "        start=15000\n",
        "        stop=20000\n",
        "    print(\"Running inference on images\")\n",
        "\n",
        "    return start, stop\n",
        "\n",
        "# Load in image from URL\n",
        "# Modified from https://colab.research.google.com/github/tensorflow/docs/blob/master/site/en/guide/saved_model.ipynb#scrollTo=JhVecdzJTsKE\n",
        "def image_from_url(url, fn):\n",
        "    file = tf.keras.utils.get_file(fn, url) # Filename doesn't matter\n",
        "    disp_img = tf.keras.preprocessing.image.load_img(file)\n",
        "    image = tf.keras.preprocessing.image.load_img(file, target_size=[pixels, pixels])\n",
        "    image = tf.keras.preprocessing.image.img_to_array(image)\n",
        "    image = tf.keras.applications.mobilenet_v2.preprocess_input(\n",
        "        image[tf.newaxis,...])\n",
        "\n",
        "    return image, disp_img\n",
        "\n",
        "# Get info about trained classification model\n",
        "def get_model_info(use_EOL_model):\n",
        "    # Use EOL pre-trained model\n",
        "    if use_EOL_model:\n",
        "        # Model metadata\n",
        "        module_selection =('mobilenet_v2_1.0_224', 224)\n",
        "        dataset_labels = ['bad', 'good']\n",
        "        TRAIN_SESS_NUM = '18'\n",
        "        saved_models_dir = 'saved_models/'\n",
        "        # If running for the first time, download model\n",
        "        if not os.path.exists('saved_models/'):\n",
        "            # Make folder for trained model\n",
        "            os.makedirs(saved_models_dir)\n",
        "            %cd $saved_models_dir\n",
        "            os.makedirs(TRAIN_SESS_NUM)\n",
        "            # Download saved model files for Run 18 - MobileNet SSD v2\n",
        "            !gdown --id 1L-WqfuoQtPgqJzU8tDKjgsZC98M-68w9 # 18.zip 404 Mb\n",
        "            !unzip 18.zip -d .\n",
        "            !mv -v content/drive/MyDrive/summer20/classification/rating/saved_models/18/* 18\n",
        "            !rm -r content\n",
        "            !rm -r 18.zip\n",
        "            %cd ../\n",
        "            print(\"Successfully downloaded pre-trained EOL model to \", (saved_models_dir + '/' + TRAIN_SESS_NUM))\n",
        "    \n",
        "    # Use your own trained model\n",
        "    elif not use_EOL_model:\n",
        "        # TO DO: Change values to match your trained model\n",
        "        module_selection = (\"inception_v3\", 299) #@param [\"(\\\"mobilenet_v2_1.0_224\\\", 224)\", \"(\\\"inception_v3\\\", 299)\"] {type:\"raw\", allow-input: true}\n",
        "        dataset_labels = ['bad', 'good'] #@param\n",
        "        saved_models_dir = \"train/saved_models/\" #@param {type:\"string\"}\n",
        "        TRAIN_SESS_NUM = \"18\" #@param\n",
        "\n",
        "    return module_selection, dataset_labels, saved_models_dir, TRAIN_SESS_NUM\n",
        "\n",
        "# Load saved model from directory\n",
        "def load_saved_model(saved_models_dir, TRAIN_SESS_NUM, module_selection):\n",
        "    # Load trained model from path\n",
        "    saved_model_path = saved_models_dir + TRAIN_SESS_NUM\n",
        "    model = tf.keras.models.load_model(saved_model_path)\n",
        "    # Get name and image size for model type\n",
        "    handle_base, pixels = module_selection\n",
        "\n",
        "    return model, pixels, handle_base\n",
        "\n",
        "# Get info from predictions to display on images\n",
        "def get_predict_info(predictions, url, i, stop, start):\n",
        "    # Get info from predictions\n",
        "    label_num = np.argmax(predictions[0], axis=-1)\n",
        "    conf = predictions[0][label_num]\n",
        "    im_class = dataset_labels[label_num]\n",
        "    # Display progress message after each image\n",
        "    print(\"Completed for {}, {} of {} files\".format(url, i+1, format(stop-start, '.0f')))\n",
        "    \n",
        "    return label_num, conf, im_class\n",
        "\n",
        "# Set filename for saving classification results\n",
        "def set_outpath(tags_file):\n",
        "    outpath = wd + 'results/' + tags_file + '.tsv'\n",
        "    print(\"Saving results to: \\n\", outpath)\n",
        "\n",
        "    return outpath\n",
        "\n",
        "# Export results\n",
        "def export_results(df, url, det_imclass, conf):\n",
        "    # Define variables for export\n",
        "    if 'ancestry' in df.columns:\n",
        "        ancestry = df['ancestry'][i]\n",
        "    else:\n",
        "        ancestry = \"NA\"\n",
        "    identifier = df['identifier'][i]\n",
        "    dataObjectVersionID = df['dataObjectVersionID'][i] \n",
        "    # Write row with results for each image\n",
        "    results = [url, identifier, dataObjectVersionID, ancestry, det_imclass, conf]\n",
        "    with open(outpath, 'a') as out_file:\n",
        "        tsv_writer = csv.writer(out_file, delimiter='\\t')\n",
        "        tsv_writer.writerow(results)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GJlYW8FPYEt8"
      },
      "source": [
        "# Set current working directory\n",
        "%cd $cwd\n",
        "\n",
        "# Read in EOL image bundle dataframe\n",
        "# TO DO: Choose image bundle address using form field to right\n",
        "bundle = \"https://editors.eol.org/other_files/bundle_images/files/images_for_Squamata_20K_breakdown_000001.txt\" #@param [\"https://editors.eol.org/other_files/bundle_images/files/images_for_Squamata_20K_breakdown_000001.txt\", \"https://editors.eol.org/other_files/bundle_images/files/images_for_Coleoptera_20K_breakdown_000001.txt\", \"https://editors.eol.org/other_files/bundle_images/files/images_for_Anura_20K_breakdown_000001.txt\", \"https://editors.eol.org/other_files/bundle_images/files/images_for_Carnivora_20K_breakdown_000001.txt\"] {allow-input: true}\n",
        "df = read_datafile(bundle, sep='\\t', header=0, disp_head=False)\n",
        "\n",
        "# Use EOL pre-trained model for object detection?\n",
        "# TO DO: Check use_EOL_model if \"Yes\"\n",
        "use_EOL_model = True #@param {type: \"boolean\"}\n",
        "\n",
        "# Load saved model\n",
        "module_selection, dataset_labels, saved_models_dir, TRAIN_SESS_NUM = get_model_info(use_EOL_model)\n",
        "model, pixels, handle_base = load_saved_model(saved_models_dir, TRAIN_SESS_NUM, module_selection)\n",
        "\n",
        "# Set filepath for output tagging file\n",
        "# TO DO: Change file name for each bundle/run\n",
        "tags_file = \"rating_tags_tf2_d\" #@param [\"rating_tags_tf2_a\", \"rating_tags_tf2_b\", \"rating_tags_tf2_c\", \"rating_tags_tf2_d\"] {allow-input: true}\n",
        "outpath = set_outpath(tags_file)\n",
        "\n",
        "# Write header row of tagging file\n",
        "if not os.path.isfile(outpath): \n",
        "    with open(outpath, 'a') as out_file:\n",
        "              tsv_writer = csv.writer(out_file, delimiter='\\t')\n",
        "              tsv_writer.writerow([\"eolMediaURL\", \"identifier\", \n",
        "                                   \"dataObjectVersionID\", \"ancestry\", \\\n",
        "                                   \"tag_rating\", \"confidence\"])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W2tO7HH-uLXY"
      },
      "source": [
        "### Run images through model for image rating classification "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0ZXo6iVvBF0G"
      },
      "source": [
        "# Run inference\n",
        "\n",
        "# Test with tiny subset (5 images)?\n",
        "# TO DO: If yes, check test_with_tiny_subset box\n",
        "test_with_tiny_subset = True #@param {type: \"boolean\"}\n",
        "\n",
        "# Run EOL bundle images through classifier to add rating tags\n",
        "start, stop = set_start_stop()\n",
        "for i, row in enumerate(df.iloc[start:stop].iterrows()):\n",
        "    try:\n",
        "        # Read in image from url\n",
        "        url = df['eolMediaURL'][i]\n",
        "        fn = str(i) + '.jpg'\n",
        "        img, disp_img = image_from_url(url, fn)\n",
        "\n",
        "        # Image classification\n",
        "        start_time = time.time() # Record inference time\n",
        "        predictions = model.predict(img, batch_size=1)\n",
        "        label_num, conf, det_imclass = get_predict_info(predictions, url, i, stop, start)\n",
        "        end_time = time.time()\n",
        "        print(\"Inference time: {} sec\".format(format(end_time-start_time, '.2f')))\n",
        "\n",
        "        # Export tagging results to tsv\n",
        "        export_results(df, url, det_imclass, conf)\n",
        "\n",
        "    except:\n",
        "        print('Check if URL from {} is valid'.format(url))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2GrMVL_CTZit"
      },
      "source": [
        "## Post-process classification results\n",
        "---\n",
        "MobileNet SSD v2 confidence threshold (>1.5) for all 'bad' predictions was chosen in inspect_train_results.ipynb to minimize false detections and maximize dataset coverage. All 'good' predictions and any 'bad' predictions below the confidence threshold are discarded."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SdgO3bk8mdKJ",
        "cellView": "code"
      },
      "source": [
        "# TO DO: Input and adjust classification confidence thresholds\n",
        "conf_thresh = 1.5 #@param \n",
        "\n",
        "# Combine 4 batches of classification tags\n",
        "fpath =  os.path.splitext(tags_file)[0] # Get name of one tag file\n",
        "base = cwd + fpath.rsplit('_',1)[0] + '_' # Remove lettered suffix to get basename\n",
        "exts = ['a.tsv', 'b.tsv', 'c.tsv', 'd.tsv']\n",
        "all_filenames = [base + e for e in exts] # List all tag filenames\n",
        "df = pd.concat([pd.read_csv(f, sep='\\t', header=0, na_filter = False) for f in all_filenames], ignore_index=True)\n",
        "df[['confidence']] = df[['confidence']].apply(pd.to_numeric)\n",
        "\n",
        "# Summarize combined results\n",
        "print(\"Model predictions for Training Attempt {}, {}:\".format(TRAIN_SESS_NUM, handle_base))\n",
        "print(\"No. Images: {}\\n{}\".format(len(df), df[['eolMediaURL', 'tag_rating', 'confidence']].head()))\n",
        "\n",
        "# Discard all predictions for 'good' or below confidence threshold\n",
        "# (Final tag to keep -> predictions for 'bad' with confidence > 1.5) \n",
        "idx_tokeep = df.index[(df.tag_rating == 'bad') & (df.confidence > conf_thresh)]\n",
        "idx_todiscard = df.index.difference(idx_tokeep)\n",
        "df.loc[idx_todiscard, 'tag_rating'] = 'NA'\n",
        "\n",
        "# Write results to tsv\n",
        "print(\"\\nNew concatenated dataframe with all 4 batches: \\n\", df[['eolMediaURL', 'tag_rating', 'confidence']].head())\n",
        "outpath = base + 'finaltags.tsv'\n",
        "df.to_csv(outpath, sep='\\t', index=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tDnCXzDGVa6t"
      },
      "source": [
        "## Display classification results on images\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TxurlbjZJd9q",
        "cellView": "code"
      },
      "source": [
        "# Set number of seconds to timeout if image url taking too long to open\n",
        "import socket\n",
        "socket.setdefaulttimeout(10)\n",
        "\n",
        "# TO DO: Adjust start index and display 50 image with tags\n",
        "start = 0 #@param {type:\"slider\", min:0, max:5000, step:50}\n",
        "stop = start+50\n",
        "\n",
        "# Loop through EOL image bundle to classify images and generate tags\n",
        "for i, row in df.iloc[start:stop].iterrows():\n",
        "    try:\n",
        "        # Read in image from url\n",
        "        url = df['eolMediaURL'][i]\n",
        "        fn = str(i) + '.jpg'\n",
        "        img, disp_img = image_from_url(url, fn)\n",
        "    \n",
        "        # Get quality rating tag\n",
        "        tag = df['tag_rating'][i]\n",
        "    \n",
        "        # Display progress message after each image is loaded\n",
        "        print('Successfully loaded {} of {} images'.format(i+1, (stop-start)))\n",
        "\n",
        "        # Show classification results for images\n",
        "        # Only use to view predictions on <50 images at a time\n",
        "        _, ax = plt.subplots(figsize=(10, 10))\n",
        "        ax.imshow(disp_img)\n",
        "        plt.axis('off')\n",
        "        plt.title(\"{}) Image quality rating: {} \".format(i+1, tag))\n",
        "\n",
        "    except:\n",
        "        print('Check if URL from {} is valid'.format(url))"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}