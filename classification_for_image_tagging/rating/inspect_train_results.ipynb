{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "inspect_train_results.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyO6oLyWNGz85pjg6Rwf2fsT",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/aubricot/computer_vision_with_eol_images/blob/master/classification_for_image_tagging/rating/inspect_train_results.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_TcYNLBrWC0C"
      },
      "source": [
        "# Determine confidence threshold for Image Rating Classification Models \n",
        "---\n",
        "*Last Updated 29 December 2020*   \n",
        "Choose which trained model and confidence threshold values to use for classifying EOL image ratings. Threshold values should be chosen that maximize coverage and minimize error.\n",
        "\n",
        "First, choose the best models trained in [rating_train.ipynb](https://colab.research.google.com/github/aubricot/computer_vision_with_eol_images/blob/master/classification_for_image_tagging/rating/rating_train.ipynb). Then, run this notebook. \n",
        "\n",
        "1) Save model predictions and confidence values for 50 images per class (Image rating 1-5) for best models chosen in rating_train.ipynb (Run 20: Inception v3 - trained on 'good' and 'bad' classes; Run 18: Mobilenet SSD v2 - trained on 'good' and 'bad' classes; Run 06: Inception v3 - trained on numerical rating classes 1-5).   \n",
        "2) Load saved model prediction and confidence files from 1.   \n",
        "3) Visualize confidence values for true and false predictions per class to determine thresholds for use with image type classifiers (with option to inspect by taxon)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZYW4W2aqdnTN"
      },
      "source": [
        "### Imports\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6k81-h_UV_ny"
      },
      "source": [
        "# Mount google drive to import/export files\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1AGFM4fSWhbT"
      },
      "source": [
        "# For working with data and plotting graphs\n",
        "import itertools\n",
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "# For image classification and training\n",
        "import tensorflow as tf\n",
        "%cd drive/My Drive/summer20/classification/rating/"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u2PEaR_a_0QH"
      },
      "source": [
        "### 1) Save model predictions and confidence values for 50 images per class  (rating 1-5) for best training run\n",
        "---   \n",
        "True and false predictions by confidence value will be used to compare model performance per class. Get values for models from best training runs in rating_train.ipynb. Change values where you see 'TO DO'.   "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KfFgkKi3nILR"
      },
      "source": [
        "#### Run 1x: Build dataset of image ratings for images not previously seen by models \r\n",
        "(Image ratings found in EOL user generated rating and exemplar files not included in 7k training/testing datasets)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VpIZ_UE6RCo-"
      },
      "source": [
        "# Make sure in rating/\r\n",
        "#%cd ../\r\n",
        "%cd rating\r\n",
        "\r\n",
        "# Get list of images used for 7k training/testing datasets\r\n",
        "nums = ['one', 'two', 'three', 'four', 'five']\r\n",
        "all_fns = ['image_data/bundles/' + num + '_download_7k.txt' for num in nums] # Image rating filenames\r\n",
        "print(all_fns)\r\n",
        "\r\n",
        "# For classes 1-4\r\n",
        "# List all ratings used to build 7k training/testing datasets\r\n",
        "used_imgs = []\r\n",
        "for fn in all_fns[:4]:\r\n",
        "    df = pd.read_csv(fn, index_col=0, header=None, sep='\\t')\r\n",
        "    df1 = df.iloc[::2].reset_index() # hacky step to delete every other row, bc they contain old index/rownums\r\n",
        "    df1.columns = ['link']\r\n",
        "    used_imgs.append(df1)\r\n",
        "# For class 5 \r\n",
        "# bundle was made differently (from EOL ratings & exemplars) so formatting is not same as 1-4\r\n",
        "df = pd.read_csv(all_fns[4], index_col=None, header=1, sep='\\t') \r\n",
        "\r\n",
        "# Combine ratings for classes 1-5\r\n",
        "df.columns = ['link']\r\n",
        "used_imgs.append(df)\r\n",
        "used = pd.concat(used_imgs, axis=0, ignore_index=True)\r\n",
        "print('Total image ratings used in training/testing: ', len(used), used.head())\r\n",
        "\r\n",
        "# Remove ratings used for training/testing from total EOL rating dataset\r\n",
        "df = pd.read_csv(\"/content/drive/My Drive/summer20/classification/rating/image_data/bundles/image_ratings.txt\", sep=\"\\t\", lineterminator='\\n', encoding='latin1', header=0)\r\n",
        "print(\"Total image ratings available:\", len(df))\r\n",
        "cond = df['obj_url'].isin(used['link'])\r\n",
        "df.drop(df[cond].index, inplace = True)\r\n",
        "unused = df.copy()\r\n",
        "unused.to_csv('image_data/bundles/unused_image_ratings_foreval.txt', sep=\"\\t\", index=False, header=True)\r\n",
        "print(\"Total un-used image ratings available:\", len(unused))\r\n",
        "\r\n",
        "# Remove ratings used for training/testing from total EOL exemplar dataset (used to supplment rating 5)\r\n",
        "df = pd.read_csv(\"/content/drive/My Drive/summer20/classification/rating/image_data/bundles/images_selected_as_exemplar.txt\", sep=\"\\t\", lineterminator='\\n', encoding='latin1', header=0)\r\n",
        "print(\"Total image exemplars available:\", len(df))\r\n",
        "cond = df['object_url'].isin(used['link'])\r\n",
        "df.drop(df[cond].index, inplace = True)\r\n",
        "unused = df.copy()\r\n",
        "unused.to_csv('image_data/bundles/unused_image_exemplars_foreval.txt', sep=\"\\t\", index=False, header=True)\r\n",
        "print(\"Total un-used image exemplars available:\", len(unused))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MC_uxbhWyHag"
      },
      "source": [
        "#### Run 1x for each of 3 models: Run images through models for classification   \r\n",
        "Selected models from rating_train.ipynb   \r\n",
        "* Run 20: Inception v3 (trained on 'good' and 'bad' classes)\r\n",
        "* Run 18: Mobilenet SSD v2 (trained on 'good' and 'bad' classes)\r\n",
        "* Run 06: Inception v3 (trained on numerical rating classes 1-5)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "efIHQCtAAmYg"
      },
      "source": [
        "%cd inspect_resul\n",
        "# Define functions\n",
        "\n",
        "# TO DO: Do you want to display classification results for the most recently trained model?\n",
        "answer = \"No\" #@param [\"Yes\", \"No\"]\n",
        "# TO DO: If No, manually input desired training attempt number to the right\n",
        "if answer == \"Yes\":\n",
        "  # Display results from most recent training attempt\n",
        "  last_attempt = !ls /content/drive/'My Drive'/summer20/classification/rating/saved_models/ | tail -n 1\n",
        "  TRAIN_SESS_NUM = str(last_attempt.n)\n",
        "else:\n",
        "  TRAIN_SESS_NUM = \"06\" #@param [\"20\", \"18\", \"06\"]\n",
        "\n",
        "# Load trained model from path\n",
        "saved_model_path = '/content/drive/My Drive/summer20/classification/rating/saved_models/' + TRAIN_SESS_NUM\n",
        "rating_model = tf.keras.models.load_model(saved_model_path)\n",
        "\n",
        "# Model type for different train sessions\n",
        "# Session 18\n",
        "if int(TRAIN_SESS_NUM) == 18:\n",
        "  module_selection =(\"mobilenet_v2_1.0_224\", 224)\n",
        "# Sessions 20 and 6\n",
        "else:\n",
        "  module_selection = (\"inception_v3\", 299) \n",
        "handle_base, pixels = module_selection\n",
        "IMAGE_SIZE = (pixels, pixels)\n",
        "\n",
        "# Function for plotting classification results with color-coded label if true or false prediction\n",
        "if int(TRAIN_SESS_NUM) > 7:\n",
        "  label_names = ['bad', 'good']\n",
        "else:\n",
        "  label_names = ['1', '2', '3', '4', '5']\n",
        "\n",
        "# Load in image from URL\n",
        "# Modified from https://colab.research.google.com/github/tensorflow/docs/blob/master/site/en/guide/saved_model.ipynb#scrollTo=JhVecdzJTsKE\n",
        "def image_from_url(url, fn):\n",
        "  file = tf.keras.utils.get_file(fn, url) # Filename doesn't matter\n",
        "  disp_img = tf.keras.preprocessing.image.load_img(file)\n",
        "  img = tf.keras.preprocessing.image.load_img(file, target_size=[pixels, pixels])\n",
        "  x = tf.keras.preprocessing.image.img_to_array(img)\n",
        "  x = tf.keras.applications.mobilenet_v2.preprocess_input(\n",
        "    x[tf.newaxis,...])\n",
        "  return x, disp_img"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mvKIy83ZnOGd"
      },
      "source": [
        "#### Run 1x per model per class: Perform inference to test model performance on unseen dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pZzZIIwNjCrV"
      },
      "source": [
        "# TO DO: Choose different image classes (1-5) to test model performance on never before seen images (not used in trianing or testing)\r\n",
        "num = 3 #@param {type:\"slider\", min:1, max:5, step:1}\r\n",
        "if num < 5:\r\n",
        "  df1 = pd.read_csv(\"/content/drive/My Drive/summer20/classification/rating/image_data/bundles/unused_image_ratings_foreval.txt\", sep=\"\\t\", lineterminator='\\n', encoding='latin1', header=0)\r\n",
        "  df1.head()\r\n",
        "  df = df1.loc[round(df1[\"overall_rating\"])==num]\r\n",
        "  df = df[[\"obj_with_overall_rating\", \"obj_url\", \"overall_rating\", \"ancestry\"]].copy()\r\n",
        "else:\r\n",
        "  df = pd.read_csv(\"/content/drive/My Drive/summer20/classification/rating/image_data/bundles/unused_image_exemplars_foreval.txt\", sep=\"\\t\", lineterminator='\\n', encoding='latin1', header=0)\r\n",
        "  df.head()\r\n",
        "  df = df[[\"target_id\", \"object_url\", \"ancestry\"]].copy()\r\n",
        "  df.rename(columns={\"object_url\": \"obj_url\"}, inplace=True)\r\n",
        "  df[\"overall_rating\"] = 5\r\n",
        "# Randomly sample 500 images/ratings\r\n",
        "df = df.sample(500)\r\n",
        "df.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NS95n46BnbJ5"
      },
      "source": [
        "# Run inference\r\n",
        "from PIL import Image, ImageFile\r\n",
        "ImageFile.LOAD_TRUNCATED_IMAGES = True\r\n",
        "import time\r\n",
        "\r\n",
        "# TO DO: Choose the image class to run for (Run 1x per class per model)\r\n",
        "base = '/content/drive/My Drive/summer20/classification/'\r\n",
        "classifier = \"rating/\" #@param [\"flower_fruit/\", \"image_type/\", \"rating/\"]\r\n",
        "true_imclass = str(num)\r\n",
        "outpath = base + classifier + 'inspect_resul/ratings_' + TRAIN_SESS_NUM + '_' + true_imclass + '.csv'\r\n",
        "print(outpath)\r\n",
        "\r\n",
        "# For inspecting results based on ancestry and confidence threshold\r\n",
        "filen = []\r\n",
        "confi = []\r\n",
        "true_id = []\r\n",
        "det_id = []\r\n",
        "ancest = []\r\n",
        "\r\n",
        "# Loops through first 5 image urls from the text file\r\n",
        "start = 0 #@param {type:\"number\"}\r\n",
        "end =  50 #@param {type:\"number\"}\r\n",
        "for i, row in df.iloc[start:end].iterrows():\r\n",
        "  try:\r\n",
        "    # Get url from image bundle\r\n",
        "    t1 = time.time()\r\n",
        "    url = df['obj_url'][i]\r\n",
        "    # Read in image from url\r\n",
        "    fn = str(i) + '.jpg'\r\n",
        "    img, disp_img = image_from_url(url, fn)\r\n",
        "    ancestry = df['ancestry'][i]\r\n",
        "    # Record inference time\r\n",
        "    start_time = time.time()\r\n",
        "    # Detection and draw boxes on image\r\n",
        "    predictions = rating_model.predict(img, batch_size=1)\r\n",
        "    label_num = np.argmax(predictions)\r\n",
        "    conf = predictions[0][label_num]\r\n",
        "    imclass = label_names[label_num]\r\n",
        "    t2 = time.time()\r\n",
        "    # Display progress message after each image\r\n",
        "    print(\"Completed for {}, {} of {} files in {} seconds\".format(url, i, format(end-start, '.0f'), format(t2-t1, '.2f')))\r\n",
        "\r\n",
        "    # Record confidence, true id, determined id to export and choose confidence thresholds\r\n",
        "    filen.append(fn)\r\n",
        "    confi.append(conf)\r\n",
        "    true_id.append(true_imclass)\r\n",
        "    det_id.append(str(imclass))\r\n",
        "    ancest.append(ancestry)\r\n",
        "  \r\n",
        "  except:\r\n",
        "    pass\r\n",
        "\r\n",
        "# Combine to df and export results\r\n",
        "rating_conf = pd.DataFrame(([filen, confi, true_id, det_id, ancest]))\r\n",
        "rating_conf = rating_conf.transpose()\r\n",
        "rating_conf.to_csv(outpath, index=False, header=(\"filename\", \"confidence\", \"true_id\", \"det_id\", \"ancestry\"))\r\n",
        "print(rating_conf.head())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F2jfuHDydqUe"
      },
      "source": [
        "### 2) Load saved model prediction and confidence files from 1\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mnUCpn8sWVzi"
      },
      "source": [
        "%cd /content/drive/My Drive/summer20/classification/rating/inspect_resul/\n",
        "\n",
        "# Combine confidence threshold values for classes 1-3 for all models\n",
        "num = \"06\" #@param [\"20\", \"18\", \"06\"]\n",
        "base = 'ratings_' + num + '_'\n",
        "exts = [\"1.csv\", \"2.csv\", \"3.csv\", \"4.csv\", \"5.csv\"]\n",
        "\n",
        "# Combine all files in the list\n",
        "all_filenames = [base + e for e in exts]\n",
        "mod = pd.concat([pd.read_csv(f, sep=',', header=0, na_filter = False) for f in all_filenames])\n",
        "print(\"Model Results:\")\n",
        "print(\"No. Images:\", len(mod))\n",
        "print(mod.head())\n",
        "\n",
        "# Aggregate \"true_id\" classes into good and bad\n",
        "if int(num) > 7:\n",
        "  mod.true_id[mod.true_id==(1 or 2)] = 'bad'\n",
        "  mod.true_id[mod.true_id==(4 or 5)] = 'good'\n",
        "else:\n",
        "  pass"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bL_56etnd0Rd"
      },
      "source": [
        "### 3) Look at prediction error and confidence for each class\n",
        "---   "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "10GhFabiCj3c"
      },
      "source": [
        "# Trained model used in 2 above\n",
        "df = mod.copy()\n",
        "\n",
        "# Optional: Run inference for taxon-specific images only\n",
        "# TO DO: Type in the taxon you'd like to inspect results for using form field to right\n",
        "taxon = \"\" #@param {type:\"string\"}\n",
        "df = df.loc[df.ancestry.str.contains(taxon, case=False, na=False)]\n",
        "print(df.head())\n",
        "\n",
        "# Optional: Show threshold value to help choose optimal balance b/w maximizing useful data and minimizing error\n",
        "thresh=0 #@param\n",
        "\n",
        "# Split by True or False determined image ID\n",
        "df['det'] = (df[\"true_id\"] == df[\"det_id\"])\n",
        "tru = df.loc[df.det, :] # True ID\n",
        "fal = df.loc[~df.det, :] # False ID\n",
        "\n",
        "# and by Image class\n",
        "if int(num) > 7:\n",
        "  # Bad\n",
        "  badt = tru.loc[tru[\"true_id\"] == \"bad\", :] # and True ID\n",
        "  badt_conf = badt['confidence']\n",
        "  badf = fal.loc[fal[\"true_id\"] == \"bad\", :]# and False ID\n",
        "  badf_conf = badf['confidence']\n",
        "\n",
        "  # Good\n",
        "  goodt = tru.loc[tru[\"true_id\"] == \"good\", :] # and True ID\n",
        "  goodt_conf = goodt['confidence']\n",
        "  goodf = fal.loc[fal[\"true_id\"] == \"good\", :]# and False ID\n",
        "  goodf_conf = goodf['confidence']\n",
        "else:\n",
        "  # Bad\n",
        "  badt = tru.loc[tru[\"true_id\"] == any([1,2]), :] # and True ID\n",
        "  badt_conf = badt['confidence']\n",
        "  badf = fal.loc[fal[\"true_id\"] == any([1,2]), :]# and False ID\n",
        "  badf_conf = badf['confidence']\n",
        "\n",
        "  # Good\n",
        "  goodt = tru.loc[tru[\"true_id\"] == any([4,5]), :] # and True ID\n",
        "  goodt_conf = goodt['confidence']\n",
        "  goodf = fal.loc[fal[\"true_id\"] == any([4,5]), :]# and False ID\n",
        "  goodf_conf = goodf['confidence']\n",
        "\n",
        "## Plot parameters\n",
        "kwargs = dict(alpha=0.5, bins=15)\n",
        "fig, (ax1, ax2) = plt.subplots(2, figsize=(10, 10), constrained_layout=True)\n",
        "fig.suptitle('Prediction Confidence by Class\\n Accuracy: {}'.format(format((len(tru)/(len(tru)+len(fal))),'.2f')))\n",
        "\n",
        "# Bad\n",
        "ax1.hist(badt_conf, color='y', label='True Det', **kwargs)\n",
        "ax1.hist(badf_conf, color='r', label='False Det', **kwargs)\n",
        "ax1.set_title(\"Bad - Classes 1&2 (n=50 images)\\n Accuracy: {}\".format(format((len(badt)/(len(badt)+len(badf))),'.2f')))\n",
        "ax1.legend();\n",
        "\n",
        "# Good\n",
        "ax2.hist(goodt_conf, color='y', label='True Det', **kwargs)\n",
        "ax2.hist(goodf_conf, color='r', label='False Det', **kwargs)\n",
        "ax2.set_title(\"Good - Classes 4&5 (n=50 images)\\n Accuracy: {}\".format(format((len(goodt)/(len(goodt)+len(goodf))),'.2f')))\n",
        "ax2.legend();\n",
        "\n",
        "# Y-axis label\n",
        "for ax in fig.get_axes():\n",
        "    ax.set(ylabel='Freq (# imgs)')\n",
        "    if thresh:\n",
        "      ax.axvline(thresh, color='k', linestyle='dashed', linewidth=1)\n",
        "\n",
        "# TO DO: Choose model name for exporting graphs\n",
        "if int(num) == 18:\n",
        "  model = 'mobilenetv2_18'\n",
        "elif int(num) == 20:\n",
        "  model = 'inceptionv3_20'\n",
        "elif int(num) < 7:\n",
        "  model = 'inceptionv3_06'\n",
        "if taxon:\n",
        "  if 'plant' in taxon:\n",
        "    figname = model + '_plantae' + '.png'\n",
        "  elif 'anim' in taxon:\n",
        "    figname = model + '_animalia' + '.png'\n",
        "else:\n",
        "  figname = model + '.png'\n",
        "print(figname)\n",
        "#fig.savefig(figname)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}