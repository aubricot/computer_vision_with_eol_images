{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMJd9aDTJU5TuEkHeNA2yF7",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/aubricot/computer_vision_with_eol_images/blob/master/classification_for_image_tagging/rating/inspect_train_results.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_TcYNLBrWC0C"
      },
      "source": [
        "# Determine confidence threshold for Image Rating Classification Models \n",
        "---\n",
        "*Last Updated 17 December 2022*   \n",
        "Choose which trained model and confidence threshold values to use for classifying EOL image ratings. Threshold values should be chosen that maximize coverage and minimize error.\n",
        "\n",
        "First, choose the best models trained in [rating_train.ipynb](https://colab.research.google.com/github/aubricot/computer_vision_with_eol_images/blob/master/classification_for_image_tagging/rating/rating_train.ipynb). Then, run this notebook. \n",
        "\n",
        "Run 500 images per class (Image ratings 1-5) through the best models chosen in rating_train.ipynb for validation of model performance. Plot histograms of true and false predictions per class at binned confidence intervals to find the best performance by class and confidence threshold. (This is helpful because all models may not learn classes equally well).\n",
        "\n",
        "***Models were trained in Python 2 and TF 1 in December 2020: MobileNet SSD v2 (Run 18, trained on 'good' and 'bad' classes) was trained for 12 hours to 10 epochs with Batch Size=16, Lr=0.001, Dropout=0.2. Inception v3 was trained for 12 hours to 10 epochs with Batch Size=32 Lr=0.001, Dropout=0 (Run 20, trained on 'good' and 'bad' classes). Inception v3 was trained for 4 hours to 15 epochs with Batch Size=64, Lr=0.1, Dropout=0 (Run 6, trained on numerical rating classes 1-5).***\n",
        "\n",
        "Notes:   \n",
        "* Run code blocks by pressing play button in brackets on left\n",
        "* Before you you start: change the runtime to \"GPU\" with \"High RAM\"\n",
        "* Change parameters using form fields on right (find details at corresponding lines of code by searching '#@param')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZYW4W2aqdnTN"
      },
      "source": [
        "## Installs & Imports\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Choose where to save results & set up directory structure\n",
        "# Use dropdown menu on right\n",
        "save = \"in Colab runtime (files deleted after each session)\" #@param [\"in my Google Drive\", \"in Colab runtime (files deleted after each session)\"]\n",
        "print(\"Saving results \", save)\n",
        "\n",
        "# Mount google drive to export file(s)\n",
        "if 'Google Drive' in save:\n",
        "    from google.colab import drive\n",
        "    drive.mount('/content/drive', force_remount=True)\n",
        "\n",
        "# Type in the path to your working directory in form field to right\n",
        "import os\n",
        "basewd = \"/content/drive/MyDrive/train/tf2\" #@param [\"/content/drive/MyDrive/train/tf2\"] {allow-input: true}\n",
        "if not os.path.exists(basewd):\n",
        "    os.makedirs(basewd)\n",
        "\n",
        "# Folder where inspect results outputs will be saved\n",
        "results_folder = \"inspect_resul\" #@param [\"inspect_resul\"] {allow-input: true}\n",
        "cwd = basewd + '/' + results_folder\n",
        "if not os.path.exists(cwd):\n",
        "    os.makedirs(cwd)\n",
        "print(\"\\nWorking directory set to: \\n\", cwd)\n",
        "\n",
        "# Enter image classes of interest in form field\n",
        "filters = [\"1\", \"2\", \"3\", \"4\", \"5\"] #@param [\"[\\\"1\\\", \\\"2\\\", \\\"3\\\", \\\"4\\\", \\\"5\\\"]\"] {type:\"raw\", allow-input: true}\n",
        "\n",
        "# Folder where image metadata was saved in rating_preprocessing.ipynb\n",
        "data_folder = \"pre-processing/image_data\" #@param [\"pre-processing/image_data\"] {allow-input: true}\n",
        "data_wd = basewd + '/' + data_folder\n",
        "if not os.path.exists(data_wd):\n",
        "    !pip3 install --upgrade gdown\n",
        "    os.makedirs(data_wd)\n",
        "    print(\"\\nDownload image bundles for rating classes 1-5...\\n\")\n",
        "    %cd $data_wd\n",
        "    file_ids = ['1XbINEyYbCkVlnsOlniobpvBPnYfBt5lT', '1ovMMh6U4biqmYzLt3bguonQa9GMfA901', \\\n",
        "                '1-OYbexPMJlPKTLCmj_zHW9LCQ1wjywqU', '1-OY_Bxoi7OeKM8VrrQHyqPt46TrhQ6kx', \\\n",
        "                '1-NJVPsKEuPCHFdcl-mDXsYOWZNDIqOdi', '1-KNgpvgBvf8mjeIFuHGxd7UIWMH-ssmB', \\\n",
        "                '1CVWiGCGGdPoWa4jsqZz6H_0zb_KKa2Qq']\n",
        "    for file_id in file_ids:\n",
        "        !gdown $file_id\n",
        "print(\"\\nImage metadata directory set to: \\n\", data_wd)\n",
        "\n",
        "# Folder where saved models were stored in rating_train.ipynb\n",
        "models_folder = \"saved_models\" #@param [\"saved_models\"] {allow-input: true}\n",
        "models_wd = basewd + '/' + models_folder\n",
        "if not os.path.exists(models_wd):\n",
        "    os.makedirs(models_wd)\n",
        "    print(\"\\nDownloading pre-trained EOL models for training attempts 06, 18, 20...\\n\")\n",
        "    %cd $models_wd\n",
        "    file_ids = ['1v-Qq2699o7SV4DH3s0Gr3_m1uPzeh3bA', '1L-WqfuoQtPgqJzU8tDKjgsZC98M-68w9', '1-7gwnHoqTseAuBxsafow9bkRiGeuy7yB']\n",
        "    outfnames = ['06.zip', '18.zip', '20.zip']\n",
        "    for idx, file_id in enumerate(file_ids):\n",
        "        file_download_link = \"https://docs.google.com/uc?export=download&id=\" + file_id\n",
        "        outfname = outfnames[idx]\n",
        "        outfolder = outfnames[idx].split('.')[0]\n",
        "        !mkdir $outfolder\n",
        "        !gdown $file_id\n",
        "        !unzip $outfname -d .\n",
        "        outfpath = 'content/drive/MyDrive/summer20/classification/rating/saved_models/' + outfolder + '/*'\n",
        "        !mv -v $outfpath $outfolder\n",
        "        !rm -r content #is this safe if connected to google drive?\n",
        "        !rm -r $outfname\n",
        "\n",
        "print(\"\\nSaved models directory set to: \\n\", models_wd)"
      ],
      "metadata": {
        "id": "8qL-_sO6hjGe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1AGFM4fSWhbT"
      },
      "source": [
        "# For working with data\n",
        "import itertools\n",
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "# Suppress pandas setting with copy warning\n",
        "pd.options.mode.chained_assignment = None  # default='warn'\n",
        "\n",
        "# For downloading and displaying images\n",
        "import matplotlib.pyplot as plt\n",
        "from PIL import Image, ImageFile\n",
        "ImageFile.LOAD_TRUNCATED_IMAGES = True\n",
        "%matplotlib inline\n",
        "\n",
        "# For measuring inference time\n",
        "import time\n",
        "\n",
        "# For image classification and training\n",
        "import tensorflow as tf\n",
        "\n",
        "# Define functions\n",
        "\n",
        "# To read in EOL formatted data files\n",
        "def read_datafile(fpath, sep=\"\\t\", header=0, disp_head=True, lineterminator='\\n', encoding='latin1', dtype=None):\n",
        "    try:\n",
        "        df = pd.read_csv(fpath, sep=sep, header=header, lineterminator=lineterminator, encoding=encoding, dtype=dtype)\n",
        "        if disp_head:\n",
        "          print(\"Data header: \\n\", df.head())\n",
        "    except FileNotFoundError as e:\n",
        "        raise Exception(\"File not found: Enter the path to your file in form field and re-run\").with_traceback(e.__traceback__)\n",
        "    \n",
        "    return df\n",
        "\n",
        "# List filenames of all images used for training/testing models\n",
        "def list_train_images(imclasses):\n",
        "    # Get image class bundle filenames\n",
        "    all_filenames = [imclass + '_download_7k.txt' for imclass in imclasses] \n",
        "    print('Image class bundles used for training/testing models: \\n', all_filenames)\n",
        "    # Make combined list all image ratings from bundles\n",
        "    used_images = []\n",
        "    for fn in all_filenames: \n",
        "        df = pd.read_csv(fn, index_col=None, header=1, sep='\\n')\n",
        "        df.columns = ['link']\n",
        "        used_images.append(df)\n",
        "    used_images = pd.concat(used_images, axis=0, ignore_index=True)\n",
        "    print('\\nNo. image ratings used for training/testing: {}'.format(len(used_images),\n",
        "                                                                   used_images.head()))\n",
        "\n",
        "    return used_images\n",
        "\n",
        "# Remove all images used for training/testing from EOL bundle\n",
        "def remove_used_images(df, used_images, dataset):\n",
        "    print(\"\\nTotal image ratings available for {}: {}\".format(dataset, len(df)))\n",
        "    if 'object_url' in df:\n",
        "        df.rename(columns={'object_url':'obj_url'}, inplace=True)\n",
        "    condition = df['obj_url'].isin(used_images['link'])\n",
        "    df.drop(df[condition].index, inplace = True)\n",
        "    unused_images = df.copy()\n",
        "    print(\"\\nTotal un-used image ratings available for {}: {}\".format(dataset, len(unused_images)))\n",
        "\n",
        "    return unused_images\n",
        "\n",
        "# Make master unused image dataset for ratings and exemplars\n",
        "def make_master_unused_df(ratings, exemplars):\n",
        "    # Reformat image ratings to match exemplars\n",
        "    df1 = unused_ratings[[\"obj_with_overall_rating\", \"obj_url\", \"overall_rating\", \"ancestry\"]].copy()\n",
        "    df1.rename(columns={\"obj_with_overall_rating\": \"obj_id\"}, inplace=True)\n",
        "    # Reformat image exemplars to match ratings\n",
        "    df2 = unused_exemplars[[\"target_id\", \"obj_url\", \"ancestry\"]].copy()\n",
        "    df2.rename(columns={\"object_url\":\"obj_url\", \"target_id\": \"obj_id\"}, inplace=True)\n",
        "    df2[\"overall_rating\"] = 5\n",
        "    # Merge ratings and exemplars\n",
        "    unused_images = pd.concat([df1, df2])\n",
        "    print(\"\\nMaster un-used image ratings for validation (ratings + exemplars): {}\".format(len(unused_images)))\n",
        "\n",
        "    return unused_images"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KfFgkKi3nILR"
      },
      "source": [
        "## Build validation dataset (Only run once)\n",
        "---\n",
        "Build dataset of image ratings for images not previously seen by models.  \n",
        "Removes image ratings found in EOL user generated rating and exemplar files that were used in 7k training/testing datasets "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VpIZ_UE6RCo-"
      },
      "source": [
        "# Find images with ratings that were not used for training or testing models \n",
        "%cd $data_wd\n",
        "\n",
        "# Get list of images used for 7k training/testing datasets\n",
        "imclasses = filters\n",
        "used_images = list_train_images(imclasses)\n",
        "\n",
        "# Remove images already used for training/testing from EOL rating dataset\n",
        "df = read_datafile(\"image_ratings.txt\", disp_head=False)\n",
        "unused_ratings = remove_used_images(df, used_images, \"Ratings\")\n",
        "unused_ratings.to_csv('unused_image_ratings_foreval.txt', sep=\"\\t\", index=False, header=True)\n",
        "\n",
        "# Remove images already used for training/testing from EOL exemplar dataset (used to supplment rating=5)\n",
        "df = read_datafile(\"images_selected_as_exemplar.txt\", disp_head=False)\n",
        "unused_exemplars = remove_used_images(df, used_images, \"Exemplars\")\n",
        "unused_exemplars.to_csv('unused_image_exemplars_foreval.txt', sep=\"\\t\", index=False, header=True)\n",
        "\n",
        "# Make master unused images dataset for ratings and exemplars\n",
        "unused_images = make_master_unused_df(unused_ratings, unused_exemplars)\n",
        "unused_images.to_csv('unused_images_foreval_master.txt', sep=\"\\t\", index=False, header=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MC_uxbhWyHag"
      },
      "source": [
        "## Run images through for classification and validating predictions (Run 1x for each trained model)   \n",
        "---\n",
        "Selected models from rating_train.ipynb   \n",
        "* Run 06: Inception v3 (trained on numerical rating classes 1-5)\n",
        "* Run 18: Mobilenet SSD v2 (trained on 'good' and 'bad' classes)\n",
        "* Run 20: Inception v3 (trained on 'good' and 'bad' classes)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "efIHQCtAAmYg",
        "cellView": "code"
      },
      "source": [
        "# Define functions\n",
        "\n",
        "# Define start and stop indices in EOL bundle for running inference   \n",
        "def set_start_stop(run, df):\n",
        "    # To test with a tiny subset, use 50 random bundle images\n",
        "    N = len(df)\n",
        "    if \"tiny subset\" in run:\n",
        "        start=np.random.choice(a=N, size=1)[0]\n",
        "        stop=start+50\n",
        "    # To run for a larger set, use 500 random images\n",
        "    else:\n",
        "        start=np.random.choice(a=N, size=1)[0]\n",
        "        stop=start+500\n",
        "    \n",
        "    return start, stop\n",
        "\n",
        "# Load saved model from directory\n",
        "def load_saved_model(models_wd, TRAIN_SESS_NUM, module_selection):\n",
        "    # Load trained model from path\n",
        "    saved_model_path = models_wd + '/' + TRAIN_SESS_NUM\n",
        "    model = tf.keras.models.load_model(saved_model_path)\n",
        "    # Get name and image size for model type\n",
        "    handle_base, pixels = module_selection\n",
        "\n",
        "    return model, pixels, handle_base\n",
        "\n",
        "# Get info about model based on training attempt number\n",
        "def get_model_info(TRAIN_SESS_NUM):\n",
        "    # Session 18\n",
        "    if int(TRAIN_SESS_NUM) == 18:\n",
        "        module_selection =(\"mobilenet_v2_1.0_224\", 224)\n",
        "        dataset_labels = ['bad', 'good'] # Classes aggregated after attempt 7: 1/2 -> bad, 4/5 -> good\n",
        "    # Session 20\n",
        "    elif int(TRAIN_SESS_NUM) == 20:\n",
        "        module_selection = (\"inception_v3\", 299)\n",
        "        dataset_labels = ['bad', 'good'] # Classes aggregated after attempt 7: 1/2 -> bad, 4/5 -> good\n",
        "    # Session 6\n",
        "    elif int(TRAIN_SESS_NUM) == 6:\n",
        "        module_selection = (\"inception_v3\", 299)\n",
        "        dataset_labels = ['1', '2', '3', '4', '5'] # Before aggregating classes\n",
        "\n",
        "    return module_selection, dataset_labels\n",
        "\n",
        "# Set filename for saving classification results\n",
        "def set_outfpath(true_imclass):\n",
        "    outfpath = cwd + '/ratings_' + TRAIN_SESS_NUM + '_' + true_imclass + '.csv'\n",
        "\n",
        "    return outfpath\n",
        "\n",
        "# Load in image from URL\n",
        "# Modified from https://colab.research.google.com/github/tensorflow/docs/blob/master/site/en/guide/saved_model.ipynb#scrollTo=JhVecdzJTsKE\n",
        "def image_from_url(url, fn):\n",
        "    file = tf.keras.utils.get_file(fn, url) # Filename doesn't matter\n",
        "    disp_img = tf.keras.preprocessing.image.load_img(file)\n",
        "    image = tf.keras.preprocessing.image.load_img(file, target_size=[pixels, pixels])\n",
        "    image = tf.keras.preprocessing.image.img_to_array(image)\n",
        "    image = tf.keras.applications.mobilenet_v2.preprocess_input(\n",
        "        image[tf.newaxis,...])\n",
        "\n",
        "    return image, disp_img\n",
        "\n",
        "# Get info from predictions to display on images\n",
        "def get_predict_info(predictions, i, stop, start):\n",
        "    # Get info from predictions\n",
        "    label_num = np.argmax(predictions[0], axis=-1)\n",
        "    conf = predictions[0][label_num]\n",
        "    im_class = dataset_labels[label_num]\n",
        "    # Display progress message after each image\n",
        "    print(\"Completed for {} of {} files\".format(i+1, format(stop-start, '.0f')))\n",
        "    \n",
        "    return label_num, conf, im_class\n",
        "\n",
        "# Make placeholder lists to fill for each rating class\n",
        "def make_placeholders():\n",
        "    filenames = []\n",
        "    confidences = []\n",
        "    true_imclasses = []\n",
        "    det_imclasses = []\n",
        "    ancestries = []\n",
        "\n",
        "    return filenames, confidences, true_imclasses, det_imclasses, ancestries\n",
        "    \n",
        "# Add values for each image to placeholder list\n",
        "def record_results(fn, conf, true_imclass, det_imclass, ancestry):\n",
        "    filenames.append(fn)\n",
        "    confidences.append(conf)\n",
        "    true_imclasses.append(true_imclass)\n",
        "    det_imclasses.append(str(det_imclass))\n",
        "    ancestries.append(ancestry)\n",
        "    results = [filenames, confidences, true_imclasses, det_imclasses, ancestries]\n",
        "\n",
        "    return results\n",
        "\n",
        "# Export results\n",
        "def export_results(results, outfpath):\n",
        "    results = pd.DataFrame(results)\n",
        "    results = results.transpose()\n",
        "    results.to_csv(outfpath, index=False, header=(\"filename\", \"confidence\", \n",
        "                                                     \"true_id\", \"det_id\", \"ancestry\"))\n",
        "    print(\"\\nClassification predictions for image class {} being saved to : \\n{}\\n\".format(\n",
        "          true_imclass, outfpath))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NS95n46BnbJ5"
      },
      "source": [
        "#@title Run inference for chosen Training Session Number (06, 18, 20) and dataset size\n",
        "%cd $cwd\n",
        "\n",
        "# Choose training attempt number to inspect results for\n",
        "TRAIN_SESS_NUM = \"18\" #@param [\"20\", \"18\", \"06\"] {allow-input: true}\n",
        "\n",
        "# Test pipeline with a smaller subset than 5k images?\n",
        "run = \"test with tiny subset\" #@param [\"test with tiny subset\", \"for 500 images\"]\n",
        "print(\"Run: \", run)\n",
        "\n",
        "# Load saved model\n",
        "module_selection, dataset_labels = get_model_info(TRAIN_SESS_NUM)\n",
        "print(\"Loading saved model \", module_selection)\n",
        "model, pixels, handle_base = load_saved_model(models_wd, TRAIN_SESS_NUM, module_selection)\n",
        "\n",
        "# Run inference for each image class to compare known versus predicted ratings\n",
        "true_imclasses = filters\n",
        "for true_imclass in true_imclasses:\n",
        "    print(\"Runing inference for class: {}\\n\".format(true_imclass))\n",
        "    # Set filename for saving classification results\n",
        "    outfpath = set_outfpath(true_imclass)\n",
        "\n",
        "    # Make placeholder lists to record values for each image\n",
        "    filenames, confidences, true_imclasses, det_imclasses, ancestries = make_placeholders()\n",
        "\n",
        "    # Load subset of in validation images df for each image class\n",
        "    df = unused_images.copy()\n",
        "    df = df[df.overall_rating==int(true_imclass)]\n",
        "\n",
        "    # Run 500 random EOL bundle images through trained model\n",
        "    start, stop = set_start_stop(run, df)\n",
        "    for i, row in enumerate(df.iloc[start:stop].iterrows()):\n",
        "        try:\n",
        "            # Read in image from url\n",
        "            url = df['obj_url'][i]\n",
        "            fn = str(i) + '.jpg'\n",
        "            img, disp_img = image_from_url(url, fn)\n",
        "            ancestry = df['ancestry'][i]\n",
        "        \n",
        "            # Image classification\n",
        "            start_time = time.time() # Record inference time\n",
        "            predictions = model.predict(img, batch_size=1)\n",
        "            label_num, conf, det_imclass = get_predict_info(predictions, i, stop, start)\n",
        "            end_time = time.time()\n",
        "            print(\"Inference time: {} sec\".format(format(end_time-start_time, '.2f')))\n",
        "\n",
        "            # Record results in placeholder lists to inspect results in next step\n",
        "            results = record_results(url, conf, true_imclass, str(det_imclass), ancestry)\n",
        "\n",
        "        except:\n",
        "            pass\n",
        "\n",
        "    # Combine to df and export results\n",
        "    export_results(results, outfpath)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mnUCpn8sWVzi",
        "cellView": "code"
      },
      "source": [
        "#@title Aggregate model outputs for numerical classes into 'bad' (1-2) and 'good' (4-5)\n",
        "\n",
        "# Combine prediction files created in codeblock above\n",
        "base = 'ratings_' + TRAIN_SESS_NUM + '_'\n",
        "imclasses = filters\n",
        "all_filenames = [base + imclass + '.csv' for imclass in imclasses]\n",
        "all_predictions = pd.concat([pd.read_csv(f, sep=',', header=0, na_filter = False) for f in all_filenames])\n",
        "print(\"No. Images: {}\\n\".format(len(all_predictions)))\n",
        "print(\"Model predictions for Training Attempt {}, {} with numeric classes:\\n{}\".format(\\\n",
        "      TRAIN_SESS_NUM, handle_base, all_predictions[['filename', 'true_id', 'det_id']].head()))\n",
        "print(\"\\n\\nAggregating numeric class predictions to 'bad' or 'good'...\\n\")\n",
        "\n",
        "# Aggregate numerical rating classes into 'bad' (1-2) and 'good' (4-5)\n",
        "c0 = \"bad\" #@param {type:\"string\"}\n",
        "c1 = \"good\" #@param {type:\"string\"}\n",
        "imclasses = [c0, c1]\n",
        "\n",
        "# Predictions of 1 or 2 -> 'bad'\n",
        "all_predictions.true_id[(all_predictions.true_id==1) | (all_predictions.true_id==2)] = c0\n",
        "all_predictions.det_id[(all_predictions.det_id==1) | (all_predictions.det_id==2)] = c0\n",
        "\n",
        "# Predictions of 4 or 5 -> 'good'\n",
        "all_predictions.true_id[(all_predictions.true_id==4) | (all_predictions.true_id==5)] = c1\n",
        "all_predictions.det_id[(all_predictions.det_id==4) | (all_predictions.det_id==5)] = c1\n",
        "\n",
        "# Remove predictions of 3\n",
        "all_predictions = all_predictions[all_predictions.det_id!=3]\n",
        "all_predictions = all_predictions[all_predictions.true_id!=3]\n",
        "\n",
        "print(\"\\nImage ratings aggregated into {} (1-2) and {} (4-5):\\n{}\".format(c0, c1, all_predictions[['filename', 'true_id', 'det_id']].head()))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bL_56etnd0Rd"
      },
      "source": [
        "## Plot prediction error and confidence for each class (Run 1x for each trained model)\n",
        "---   \n",
        "Use these histograms to find a confidence threshold value to optimize dataset coverage and accuracy"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "81N24FjAJqQV",
        "cellView": "code"
      },
      "source": [
        "# Define functions\n",
        "\n",
        "# Calculate prediction accuracy\n",
        "def get_accuracy(obs, all_vals):\n",
        "    # obs = observed, all_vals = observed + expected\n",
        "    if obs:\n",
        "        accuracy = format((obs/all_vals), '.2f')\n",
        "    else:\n",
        "        accuracy = 0\n",
        "    \n",
        "    return accuracy\n",
        "\n",
        "# Valide predictions by image class (and optionally, by: taxon)\n",
        "def validate_predict(df, inspect_by_taxon, taxon):\n",
        "    # If inspecting for taxon-specific images only\n",
        "    if inspect_by_taxon:\n",
        "        taxon = taxon\n",
        "        df = df.loc[df.ancestry.str.contains(taxon, case=False, na=False)]\n",
        "        print(\"Inspecting results for {}:\\n{}\".format(taxon, df.head()))\n",
        "    \n",
        "    # Validate predictions\n",
        "    # Check where true ratings and model-determined classes match\n",
        "    df['det'] = (df['true_id'] == df['det_id'])\n",
        "    tru = df.loc[df.det, :] # True ID\n",
        "    fal = df.loc[~df.det, :] # False ID\n",
        "\n",
        "    return tru, fal, taxon\n",
        "\n",
        "# Plot results by image class\n",
        "def plot_predict_x_conf(tru, fal, thresh, imclasses):\n",
        "    # Break up predictions by image class and confidence values\n",
        "    c0,c1 = [imclasses[i] for i in range(0, len(imclasses))]\n",
        "    # Check how many true/false predictions are at each confidence value\n",
        "    # Class 0 - 'Bad'\n",
        "    c0t = tru.loc[tru['true_id'] == c0, :] # True dets\n",
        "    c0f = fal.loc[fal['true_id'] == c0, :] # False dets\n",
        "    # Class 1 - 'Good'\n",
        "    c1t = tru.loc[tru['true_id'] == c1, :] \n",
        "    c1f = fal.loc[fal['true_id'] == c1, :] \n",
        "    \n",
        "    # Plot parameters to make 1 subplot per image class\n",
        "    kwargs = dict(alpha=0.5, bins=15)\n",
        "    fig, axes = plt.subplots(len(imclasses), figsize=(10, 10), constrained_layout=True)\n",
        "    fig.suptitle('Prediction Confidence by Class\\n Overall Accuracy: {}'.format(\n",
        "                  get_accuracy(len(tru), (len(tru)+len(fal)))))\n",
        "    \n",
        "    # Make subplots\n",
        "    # Class 0 - 'Bad'\n",
        "    # True predictions\n",
        "    axes[0].hist(c0t['confidence'], color='y', label='True Det', **kwargs)\n",
        "    # False predictions\n",
        "    axes[0].hist(c0f['confidence'], color='r', label='False Det', **kwargs)\n",
        "    axes[0].set_title(\"{} (n={} images)\\n Accuracy: {}\".format(imclasses[0], \n",
        "                      len(c0t+c0f), get_accuracy(len(c0t), (len(c0t)+len(c0f)))))\n",
        "    axes[0].legend();\n",
        "\n",
        "    # Class 1 - 'Good'\n",
        "    # True predictions\n",
        "    axes[1].hist(c1t['confidence'], color='y', label='True Det', **kwargs)\n",
        "    # False predictions\n",
        "    axes[1].hist(c1f['confidence'], color='r', label='False Det', **kwargs)\n",
        "    axes[1].set_title(\"{} (n={} images)\\n Accuracy: {}\".format(imclasses[1], \n",
        "                      len(c1t+c1f), get_accuracy(len(c1t), (len(c1t)+len(c1f)))))\n",
        "    axes[1].legend();\n",
        "\n",
        "    # Add Y-axis labels\n",
        "    for ax in fig.get_axes():\n",
        "        ax.set(ylabel='Freq (# imgs)')\n",
        "        if thresh:\n",
        "            ax.axvline(thresh, color='k', linestyle='dashed', linewidth=1)\n",
        "\n",
        "    return fig\n",
        "\n",
        "# To save the figure\n",
        "def save_figure(fig, taxon, TRAIN_SESS_NUM=TRAIN_SESS_NUM, handle_base=handle_base):\n",
        "    # Make filename\n",
        "    if taxon: # If for a specific taxon\n",
        "        if 'plant' in taxon:\n",
        "            handle_base = handle_base + '_plantae'\n",
        "        elif 'anim' in taxon:\n",
        "            handle_base = handle_base + '_animalia'\n",
        "\n",
        "    outfpath = TRAIN_SESS_NUM + '_' + handle_base + '.png'\n",
        "    fig.savefig(outfpath)\n",
        "    print(\"Histograms saved to \", outfpath)\n",
        "\n",
        "    return outfpath"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Plot histograms of accuracy for each image class\n",
        "Use these plots to determine confidence thresholds or class predictions to keep or filter out during post-processing. \n",
        "\n",
        "For example, we found that model predictions for \"bad\" had high accuracy at all confidence levels, but predictions for \"good\" had low accuracy for all confidence levels. We used these plots to determine that we should keep all predictions for \"bad\" and discarded predictions for \"good\"."
      ],
      "metadata": {
        "id": "dX0aChfP2CPI"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "10GhFabiCj3c"
      },
      "source": [
        "#@title (Optional: inspect for specific taxon and/or add a confidence threshold line)\n",
        "\n",
        "# Load combined prediction results from above\n",
        "df = all_predictions.copy()\n",
        "\n",
        "# Optional: Inspect predictions for taxon-specific images only?\n",
        "inspect_by_taxon = False #@param {type:\"boolean\"}\n",
        "taxon = \"\" #@param {type:\"string\"}\n",
        "\n",
        "# Optional: Draw threshold value to help choose optimal balance b/w maximizing useful data and minimizing error\n",
        "thresh = 0 #@param {type:\"number\"}\n",
        "\n",
        "# Valide predictions by image class (optionally, by taxon)\n",
        "tru, fal, taxon = validate_predict(df, inspect_by_taxon, taxon)\n",
        "\n",
        "# Plot result accuracy by image class (optionally, with confidence threshold line)\n",
        "fig = plot_predict_x_conf(tru, fal, thresh, imclasses)\n",
        "\n",
        "# Export histograms\n",
        "save_figure(fig, taxon)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}