{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "rating_train.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "ikRQ9LLbVHXQ"
      ],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.8"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/aubricot/computer_vision_with_eol_images/blob/master/classification_for_image_tagging/rating/rating_train.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4Rnwb_rgmJZB"
      },
      "source": [
        "# Training Tensorflow MobileNetSSD v2 and Inception v3 models to classify maps, phylogenies, illustrations, and herbarium sheets from EOL images\n",
        "---\n",
        "*Last Updated 23 December 2020*   \n",
        "Train [MobileNet SSD v2](https://tfhub.dev/google/tf2-preview/mobilenet_v2/classification/4) and [Inception v3](https://tfhub.dev/google/imagenet/inception_v3/classification/4) to rating EOL image quality from 1 (bad) to 5 (good). The training dataset is from EOL user-generated image ratings. Classifications will be used to generate image tags to improve sorting of EOLv3 images from high to low quality.\n",
        "\n",
        "Training images were downloaded to Google Drive and processed using [rating_preprocessing.ipynb](https://colab.research.google.com/github/aubricot/computer_vision_with_eol_images/blob/master/classification_for_image_tagging/rating/rating_preprocessing.ipynb). \n",
        "\n",
        "Pre-trained MobileNet SSD v2 and Inception v3 models were fine-tuned (via unfreezing lower layers) to classify image ratings. \n",
        "\n",
        "**Best results for each model from 60+ trials (some using early-stopping because of long train times and large detasets):**   \n",
        "Upon inspection of training data, there was too much inconsistency for humans to reliably predict image ratings that matched EOL users. For future rating classifiers, it is expected that creating a curated dataset would give better results.\n",
        "* MobileNet SSD v2 was trained for 12 hours to 10 epochs with Batch Size=16, Lr=0.001, Dropout=0.2. Final validation accuracy = 0.55\n",
        "* **Inception v3 was trained for 12 hours to 10 epochs with Batch Size=32 Lr=0.001, Dropout=0. Final validation accuracy = 0.60**\n",
        "\n",
        "**Notes**\n",
        "* Change filepaths or information using the form fields to the right of code blocks (also noted in code with 'TO DO')\n",
        "* Make sure to set the runtime to GPU Hardware Accelerator with a High Ram Runtime Shape (Runtime -> Change runtime type)\n",
        "\n",
        "**References**   \n",
        "* https://www.tensorflow.org/tutorials/customization/custom_training_walkthrough\n",
        "* https://www.tensorflow.org/tutorials/images/classification\n",
        "* https://medium.com/analytics-vidhya/create-tensorflow-image-classification-model-with-your-own-dataset-in-google-colab-63e9d7853a3e\n",
        "* https://colab.research.google.com/github/tensorflow/hub/blob/master/examples/colab/tf2_image_retraining.ipynb#scrollTo=umB5tswsfTEQ\n",
        "* https://medium.com/analytics-vidhya/how-to-do-image-classification-on-custom-dataset-using-tensorflow-52309666498e\n",
        "* https://blog.keras.io/building-powerful-image-classification-models-using-very-little-data.html\n",
        "* https://www.pyimagesearch.com/2018/12/31/keras-conv2d-and-convolutional-layers/"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nwKdj73Wpnlz"
      },
      "source": [
        "## Imports   \n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yWAbU5tW1ONu"
      },
      "source": [
        "# Mount google drive to import/export files\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QSLXg6G7mJZP"
      },
      "source": [
        "# For working with data and plotting graphs\n",
        "import itertools\n",
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# For image classification and training\n",
        "import tensorflow as tf\n",
        "import tensorflow_hub as hub\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Conv2D, Flatten, Dropout, MaxPooling2D, InputLayer\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "print(\"TF version:\", tf.__version__)\n",
        "print(\"Hub version:\", hub.__version__)\n",
        "print(\"GPU is\", \"available\" if tf.config.list_physical_devices('GPU') else \"NOT AVAILABLE\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ikRQ9LLbVHXQ"
      },
      "source": [
        "## Train Classification Model(s)\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mvOpxBvKWCht"
      },
      "source": [
        "### Training Dataset Preparation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YWylHChz4JTh"
      },
      "source": [
        "Use dropdown menu on the right to choose which pre-trained model to use and set the image batch size for training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "77MDrSHntvWK"
      },
      "source": [
        "# TO DO: Select pre-trained model to use from Tensorflow Hub Model Zoo\n",
        "module_selection = (\"inception_v3\", 299) #@param [\"(\\\"mobilenet_v2_1.0_224\\\", 224)\", \"(\\\"inception_v3\\\", 299)\"] {type:\"raw\", allow-input: true}\n",
        "handle_base, pixels = module_selection\n",
        "\n",
        "if handle_base == \"inception_v3\":\n",
        "  MODULE_HANDLE =\"https://tfhub.dev/google/imagenet/inception_v3/classification/4\".format(handle_base)\n",
        "  epsilon = 1\n",
        "elif handle_base == \"mobilenet_v2_1.0_224\":\n",
        "  MODULE_HANDLE =\"https://tfhub.dev/google/tf2-preview/mobilenet_v2/classification/4\".format(handle_base) \n",
        "  epsilon = 1e-07\n",
        "# TO DO: adjust batch size to make training faster or slower\n",
        "BATCH_SIZE = \"32\" #@param [\"16\", \"32\", \"64\", \"128\"]\n",
        "\n",
        "IMAGE_SIZE = (pixels, pixels)\n",
        "print(\"Using {} with input size {} and batch size {}\".format(handle_base, IMAGE_SIZE, BATCH_SIZE))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IvfFTR9DvKCN"
      },
      "source": [
        "Make sure the second line does not say \"Found 0 images belonging to...\" and run again until a non-zero number is given to build a test dataset. Some images aren't read properly by ImageDataGenerator and they can be skipped during training without problems, but will result in no training class being generated during this step."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "code",
        "id": "ocQ6gDasveZ5"
      },
      "source": [
        "# To suppress warnings from pillow about image sizes\n",
        "from PIL import ImageFile, Image\n",
        "ImageFile.LOAD_TRUNCATED_IMAGES = True\n",
        "Image.MAX_IMAGE_PIXELS = 95000000\n",
        "\n",
        "# TO DO: Change directory to wherever images are stored\n",
        "PATH = '/content/drive/My Drive/summer20/classification/rating/images/agg' #@param {type:\"string\"}\n",
        "TRAINING_DATA_DIR = str(PATH)\n",
        "print(TRAINING_DATA_DIR)\n",
        "\n",
        "# TO DO: Adjust interpolation method and see how training results change\n",
        "interpolation = \"nearest\" #@param [\"nearest\", \"bilinear\"]\n",
        "\n",
        "# Set data generation and flow parameters\n",
        "datagen_kwargs = dict(rescale=1./255, validation_split=.20)\n",
        "dataflow_kwargs = dict(target_size=IMAGE_SIZE, batch_size=int(BATCH_SIZE),\n",
        "                    interpolation = interpolation, color_mode='rgb')\n",
        "\n",
        "# Make test dataset\n",
        "test_datagen = ImageDataGenerator(**datagen_kwargs)\n",
        "test_generator = test_datagen.flow_from_directory(\n",
        "TRAINING_DATA_DIR,\n",
        "subset=\"validation\",\n",
        "shuffle=True,\n",
        "**dataflow_kwargs\n",
        ")\n",
        "\n",
        "# Make train dataset\n",
        "train_datagen = ImageDataGenerator(**datagen_kwargs)\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "    TRAINING_DATA_DIR, subset=\"training\", shuffle=True, **dataflow_kwargs)\n",
        "\n",
        "# Learn more about data batches\n",
        "image_batch_train, label_batch_train = next(iter(train_generator))\n",
        "print(\"Image batch shape: \", image_batch_train.shape)\n",
        "print(\"Label batch shape: \", label_batch_train.shape)\n",
        "dataset_labels = sorted(train_generator.class_indices.items(), key=lambda pair:pair[1])\n",
        "dataset_labels = np.array([key.title() for key, value in dataset_labels])\n",
        "print(dataset_labels)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "72N6UtPiVQNW"
      },
      "source": [
        "### Model Preparation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g1pGKmlkVS1k"
      },
      "source": [
        "# Build model\n",
        "print(\"Building model with\", handle_base)\n",
        "# TO DO: If model is overfitting, add/increase dropout rate\n",
        "dropout_rate = 0.1 #@param {type:\"slider\", min:0, max:0.5, step:0.1}\n",
        "lr = 0.001 #@param [\"0.1\", \"0.01\", \"0.001\", \"0.0001\", \"0.00001\"] {type:\"raw\"}\n",
        "# Freeze or unfreeze lower layers for transfer learning and fine tuning\n",
        "trainable = True #@param [\"True\", \"False\"] {type:\"raw\"} \n",
        "\n",
        "def create_model():\n",
        "  model = tf.keras.Sequential([\n",
        "    InputLayer(input_shape=IMAGE_SIZE + (3,)),\n",
        "    hub.KerasLayer(MODULE_HANDLE, trainable=trainable), #False freezes lower layers so only top classifier is retrained\n",
        "    Dropout(rate = dropout_rate), \n",
        "    Dense(train_generator.num_classes, kernel_regularizer=tf.keras.regularizers.l2(0.0001))\n",
        "  ])\n",
        "  \n",
        "  # Build model\n",
        "  model.build((None,)+IMAGE_SIZE+(3,))\n",
        "  \n",
        "  # Compile model\n",
        "  model.compile(\n",
        "    # Parameters for Adam optimizer\n",
        "    optimizer=tf.keras.optimizers.Adam(\n",
        "      learning_rate=lr, beta_1=0.9, beta_2=0.999, epsilon=epsilon, amsgrad=False,\n",
        "      name='Adam'), \n",
        "      # Categorical cross entropy because 5 exclusive classes\n",
        "    loss=tf.keras.losses.CategoricalCrossentropy(from_logits=True, label_smoothing=0),\n",
        "    metrics=['accuracy'])\n",
        "  return model\n",
        "\n",
        "# Create new model instance\n",
        "model = create_model()\n",
        "\n",
        "# Steps per epoch and testing\n",
        "steps_per_epoch = train_generator.samples // train_generator.batch_size\n",
        "test_steps = test_generator.samples // test_generator.batch_size\n",
        "\n",
        "# Display model architecture\n",
        "model.summary()\n",
        "tf.keras.utils.plot_model(model, show_shapes=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A7ycnwnKkkfa"
      },
      "source": [
        "### Actual Training "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "CNbToKXYlEo5"
      },
      "source": [
        "# TO DO: Resume training from saved checkpoint?\n",
        "resume = \"N\" #@param [\"Y\", \"N\"]\n",
        "TRAIN_SESS_NUM = \"12\" #@param {type:\"string\"}\n",
        "\n",
        "# TO DO: Adjust number of epochs to find balance between underfit and overfit for training\n",
        "num_epochs = '10' #@param {type:\"string\"}\n",
        "\n",
        "if resume == 'Y':\n",
        "  TRAIN_SESS_NUM = TRAIN_SESS_NUM\n",
        "  CKPTS_PATH = '/content/drive/My Drive/summer20/classification/rating/saved_models/' + TRAIN_SESS_NUM + '/ckpt/'\n",
        "  CKPT_PATH = CKPTS_PATH + 'cp-{epoch:04d}.ckpt'\n",
        "  latest = tf.train.latest_checkpoint(CKPTS_PATH)\n",
        "  print(\"Restoring weights from Model {}, Checkpoint {}\".format(TRAIN_SESS_NUM, latest))\n",
        "  model.load_weights(latest)\n",
        "\n",
        "else:\n",
        "  # Save each new training attempt results in new folder\n",
        "  last_attempt = !ls /content/drive/'My Drive'/summer20/classification/rating/saved_models/ | tail -n 1\n",
        "  if not last_attempt:\n",
        "    last_attempt = 0\n",
        "  else:\n",
        "    last_attempt = int(last_attempt.n)\n",
        "    if last_attempt < 9:\n",
        "      TRAIN_SESS_NUM = \"0\" + str(last_attempt + 1)\n",
        "    else:\n",
        "      TRAIN_SESS_NUM = str(last_attempt + 1)\n",
        "  CKPT_PATH = '/content/drive/My Drive/summer20/classification/rating/saved_models/' + TRAIN_SESS_NUM + '/ckpt/cp-{epoch:04d}.ckpt' \n",
        "\n",
        "  print(\"Last training attempt number:\", last_attempt)\n",
        "  print(\"Training attempt number: {}, for {} epochs\".format(TRAIN_SESS_NUM, num_epochs))\n",
        "  # Save weights for 0th epoch\n",
        "  model.save_weights(CKPT_PATH.format(epoch=0))\n",
        "\n",
        "# Create a callback that saves the model's weights during training\n",
        "ckpt_callback = tf.keras.callbacks.ModelCheckpoint(filepath=CKPT_PATH,\n",
        "                                                 save_weights_only=True,\n",
        "                                                 verbose=1) #verbose: Integer. 0, 1, or 2. Verbosity mode. 0 = silent, 1 = progress bar, 2 = one line per epoch\n",
        "\n",
        "# Train the model with the new callback\n",
        "hist = model.fit(\n",
        "    train_generator,\n",
        "    epochs=int(num_epochs), steps_per_epoch=steps_per_epoch,\n",
        "    callbacks=[ckpt_callback],\n",
        "    validation_data=test_generator,\n",
        "    validation_steps=test_steps).history\n",
        "\n",
        "# Save trained model \n",
        "saved_model_path = '/content/drive/My Drive/summer20/classification/rating/saved_models/' + TRAIN_SESS_NUM\n",
        "tf.saved_model.save(model, saved_model_path)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ionhn0UvmE-x"
      },
      "source": [
        "#### Plot loss and accuracy for training session"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-kfOjJ3llGVY"
      },
      "source": [
        "# Plot loss\n",
        "plt.figure()\n",
        "plt.title(\"Attempt {}:Training and Validation Loss\".format(TRAIN_SESS_NUM))\n",
        "plt.xlabel(\"Training Steps\")\n",
        "plt.ylim([0,2])\n",
        "plt.plot(hist[\"loss\"], label='Train')\n",
        "plt.plot(hist[\"val_loss\"], label='Test')\n",
        "plt.legend(loc='lower right')\n",
        "\n",
        "# Plot accuracy\n",
        "plt.figure()\n",
        "plt.title(\"Attempt {}:Training and Validation Accuracy\".format(TRAIN_SESS_NUM))\n",
        "plt.xlabel(\"Training Steps\")\n",
        "plt.ylim([0,1])\n",
        "plt.plot(hist[\"accuracy\"], label='Train')\n",
        "plt.plot(hist[\"val_accuracy\"], label='Test')\n",
        "plt.legend(loc='upper right')\n",
        "path = '/content/drive/My Drive/summer20/classification/rating/train_graphs/' + TRAIN_SESS_NUM + '.png'\n",
        "plt.savefig(path)\n",
        "\n",
        "# Print final loss and accuracy values\n",
        "final_loss, final_accuracy = model.evaluate(test_generator, steps = test_steps)\n",
        "print('Final loss: {:.2f}'.format(final_loss))\n",
        "print('Final accuracy: {:.2f}%'.format(final_accuracy * 100))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Cpjn2qz-57p_"
      },
      "source": [
        "## Review training results\n",
        "---   \n",
        "Display classification results on images"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UNxq35BeEi-k"
      },
      "source": [
        "# Define functions\n",
        "\n",
        "# TO DO: Do you want to display classification results for the most recently trained model?\n",
        "answer = \"Yes\" #@param [\"Yes\", \"No\"]\n",
        "# TO DO: If No, manually input desired training attempt number to the right\n",
        "if answer == \"Yes\":\n",
        "  # Display results from most recent training attempt\n",
        "  last_attempt = !ls /content/drive/'My Drive'/summer20/classification/rating/saved_models/ | tail -n 1\n",
        "  TRAIN_SESS_NUM = str(last_attempt.n)\n",
        "else:\n",
        "  TRAIN_SESS_NUM = \"20\" #@param [\"13\", \"11\", \"15\"] {allow-input: true}\n",
        "\n",
        "# Load trained model from path\n",
        "saved_model_path = '/content/drive/My Drive/summer20/classification/rating/saved_models/' + TRAIN_SESS_NUM\n",
        "imtype_model = tf.keras.models.load_model(saved_model_path)\n",
        "\n",
        "# TO DO: Select model type\n",
        "module_selection = (\"inception_v3\", 299) #@param [\"(\\\"mobilenet_v2_1.0_224\\\", 224)\", \"(\\\"inception_v3\\\", 299)\"] {type:\"raw\", allow-input: true}\n",
        "handle_base, pixels = module_selection\n",
        "IMAGE_SIZE = (pixels, pixels)\n",
        "\n",
        "# Function for plotting classification results with color-coded label if true or false prediction\n",
        "label_names = ['bad', 'good']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "awIMvGFtGlvE"
      },
      "source": [
        "# Run inference\n",
        "from PIL import Image\n",
        "import time\n",
        "\n",
        "# TO DO: Choose which image class to inspect results for in true_imclass to right\n",
        "# TO DO: Choose start and end image numbers to inspect (inspect up to 50 images at a time)\n",
        "base = '/content/drive/My Drive/summer20/classification/'\n",
        "classifier = \"rating/\" #@param [\"flower_fruit/\", \"image_type/\", \"rating/\"]\n",
        "true_imclass = \"agg/good\" #@param [\"agg/good\", \"agg/bad\"]\n",
        "PATH_TO_TEST_IMAGES_DIR = base + classifier + \"images/\" + true_imclass\n",
        "names = os.listdir(PATH_TO_TEST_IMAGES_DIR)\n",
        "TEST_IMAGE_PATHS = [os.path.join(PATH_TO_TEST_IMAGES_DIR, name) for name in names]\n",
        "\n",
        "# Loops through first 5 image urls from the text file\n",
        "start = 250 #@param {type:\"number\"}\n",
        "end =   300#@param {type:\"number\"}\n",
        "for im_num, im_path in enumerate(TEST_IMAGE_PATHS[start:end], start=1):\n",
        "    # Load in image\n",
        "    imga = Image.open(im_path)\n",
        "    img = imga.convert('RGB')\n",
        "    image = img.resize(IMAGE_SIZE)\n",
        "    image = np.reshape(image,[1,pixels,pixels,3])\n",
        "    image = image*1./255\n",
        "    # Record inference time\n",
        "    start_time = time.time()\n",
        "    # Detection and draw boxes on image\n",
        "    predictions = imtype_model.predict(image, batch_size=1)\n",
        "    label_num = np.argmax(predictions[0], axis=-1)\n",
        "    conf = predictions[0][label_num]\n",
        "    imclass = label_names[label_num]\n",
        "    end_time = time.time()\n",
        "    # Display progress message after each image\n",
        "    print('Inference complete for {} of {} images'.format(im_num, (end-start)))\n",
        "    # Plot and show detection boxes on images\n",
        "    _, ax = plt.subplots(figsize=(10, 10))\n",
        "    ax.imshow(img)\n",
        "    plt.title('{}) Prediction: {}, Confidence: {}, Inference time: {}'.format(im_num, imclass, \\\n",
        "    format(conf, '.2f'), format(end_time-start_time, '.2f')))"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}