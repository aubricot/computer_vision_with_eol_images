{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "rating_train.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.8"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/aubricot/computer_vision_with_eol_images/blob/master/classification_for_image_tagging/rating/rating_train.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4Rnwb_rgmJZB"
      },
      "source": [
        "# Training Tensorflow MobileNetSSD v2 and Inception v3 models to classify maps, phylogenies, illustrations, and herbarium sheets from EOL images\n",
        "---\n",
        "*Last Updated 20 October 2021*   \n",
        "Use EOL user generated image quality ratings to train [MobileNet SSD v2](https://tfhub.dev/google/tf2-preview/mobilenet_v2/classification/4) and [Inception v3](https://tfhub.dev/google/imagenet/inception_v3/classification/4)via fine-tuning (unfreezing lower layers). Training data consists of the user-determined image quality ratings from 1 (bad) to 5 (good), so model outputs will be image tags used to sort EOLv3 image galleries from high to low quality.\n",
        "\n",
        "Training dataset was downloaded to Google Drive in [rating_preprocessing.ipynb](https://colab.research.google.com/github/aubricot/computer_vision_with_eol_images/blob/master/classification_for_image_tagging/rating/rating_preprocessing.ipynb). \n",
        "\n",
        "***MobileNet SSD v2 was trained for 12 hours to 10 epochs with Batch Size=16, Lr=0.001, Dropout=0.2. Inception v3 was trained for 12 hours to 10 epochs with Batch Size=32 Lr=0.001, Dropout=0.***\n",
        "\n",
        "Notes:\n",
        "* Before you you start: change the runtime to \"GPU\" with \"High RAM\"\n",
        "* Change parameters using form fields on right (/where you see 'TO DO' in code)\n",
        "* For each 24 hour period on Google Colab, you have up to 12 hours of free GPU access. \n",
        "\n",
        "References:   \n",
        "* https://www.tensorflow.org/tutorials/customization/custom_training_walkthrough\n",
        "* https://www.tensorflow.org/tutorials/images/classification\n",
        "* https://medium.com/analytics-vidhya/create-tensorflow-image-classification-model-with-your-own-dataset-in-google-colab-63e9d7853a3e\n",
        "* https://colab.research.google.com/github/tensorflow/hub/blob/master/examples/colab/tf2_image_retraining.ipynb#scrollTo=umB5tswsfTEQ\n",
        "* https://medium.com/analytics-vidhya/how-to-do-image-classification-on-custom-dataset-using-tensorflow-52309666498e\n",
        "* https://blog.keras.io/building-powerful-image-classification-models-using-very-little-data.html\n",
        "* https://www.pyimagesearch.com/2018/12/31/keras-conv2d-and-convolutional-layers/"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nwKdj73Wpnlz"
      },
      "source": [
        "## Installs & Imports   \n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yWAbU5tW1ONu"
      },
      "source": [
        "# Mount google drive to import/export files\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QSLXg6G7mJZP"
      },
      "source": [
        "# For working with data and plotting graphs\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import os\n",
        "import csv\n",
        "import itertools\n",
        "\n",
        "# For measuring the inference time\n",
        "import time\n",
        "\n",
        "# For downloading and displaying images\n",
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "from PIL import ImageFile, Image\n",
        "\n",
        "# For image classification and training through TF-Hub\n",
        "import tensorflow as tf\n",
        "import tensorflow_hub as hub\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Conv2D, Flatten, Dropout, MaxPooling2D, InputLayer\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "# Print Tensorflow version\n",
        "print('Tensorflow Version: %s' % tf.__version__)\n",
        "\n",
        "# Check available GPU devices\n",
        "print('The following GPU devices are available: %s' % tf.test.gpu_device_name())\n",
        "\n",
        "# Define functions\n",
        "\n",
        "# Set checkpoint paths for training\n",
        "def set_ckpt_path(saved_models_dir, resume_train_ckpt, TRAIN_SESS_NUM, num_epochs):\n",
        "    # If resuming from a previous training attempt (= saved checkpoint)\n",
        "    if resume_train_ckpt:\n",
        "        TRAIN_SESS_NUM = TRAIN_SESS_NUM\n",
        "        CKPTS_PATH = saved_models_dir + TRAIN_SESS_NUM + '/ckpt/'\n",
        "        CKPT_PATH = CKPTS_PATH + 'cp-{epoch:04d}.ckpt'\n",
        "        latest = tf.train.latest_checkpoint(CKPTS_PATH)\n",
        "        print(\"Restoring weights from Model {}, Checkpoint {}\".format(TRAIN_SESS_NUM, latest))\n",
        "        model.load_weights(latest)\n",
        "    # If new training attempt\n",
        "    else:\n",
        "        # Save each new training attempt results in new folder\n",
        "        last_attempt = !ls $saved_models_dir | tail -n 1\n",
        "        if not last_attempt:\n",
        "            last_attempt = 0\n",
        "        # Name folder to sort by attempt number (useful if many training runs)\n",
        "        else:\n",
        "            last_attempt = int(last_attempt.n)\n",
        "            if last_attempt < 9:\n",
        "                TRAIN_SESS_NUM = \"0\" + str(last_attempt + 1)\n",
        "            else:\n",
        "                TRAIN_SESS_NUM = str(last_attempt + 1)\n",
        "    # Set checkpoint naming scheme\n",
        "    CKPT_PATH = saved_models_dir + TRAIN_SESS_NUM + '/ckpt/cp-{epoch:04d}.ckpt' \n",
        "    print(\"Last training attempt number:\", last_attempt)\n",
        "    print(\"Training attempt number: {}, for {} epochs\".format(TRAIN_SESS_NUM, num_epochs))\n",
        "\n",
        "    return CKPT_PATH, last_attempt, TRAIN_SESS_NUM\n",
        "\n",
        "# Set checkpoint callbacks for training\n",
        "def set_ckpt_callbacks(CKPT_PATH):\n",
        "    # Save weights for 0th epoch\n",
        "    model.save_weights(CKPT_PATH.format(epoch=0))\n",
        "    # Create a callback that saves the model's weights during training\n",
        "    ckpt_callback = tf.keras.callbacks.ModelCheckpoint(filepath=CKPT_PATH,\n",
        "                                                       save_weights_only=True,\n",
        "                                                       verbose=1) # Verbosity mode: 0 = silent, 1 = progress bar, 2 = one line per epoch\n",
        "    \n",
        "    return ckpt_callback\n",
        "\n",
        "# Plot loss and accuracy for training session\n",
        "def plot_train_graph(train_graphs_dir, TRAIN_SESS_NUM, hist, test_generator):\n",
        "    # Plot loss\n",
        "    plt.figure()\n",
        "    plt.title(\"Attempt {}: Training and Validation Loss\".format(TRAIN_SESS_NUM))\n",
        "    plt.xlabel(\"Training Steps\")\n",
        "    plt.ylim([0,2])\n",
        "    plt.plot(hist[\"loss\"], label='Train')\n",
        "    plt.plot(hist[\"val_loss\"], label='Test')\n",
        "    plt.legend(loc='lower right')\n",
        "    # Plot accuracy\n",
        "    plt.figure()\n",
        "    plt.title(\"Attempt {}: Training and Validation Accuracy\".format(TRAIN_SESS_NUM))\n",
        "    plt.xlabel(\"Training Steps\")\n",
        "    plt.ylim([0,1])\n",
        "    plt.plot(hist[\"accuracy\"], label='Train')\n",
        "    plt.plot(hist[\"val_accuracy\"], label='Test')\n",
        "    plt.legend(loc='upper right')\n",
        "    train_graph_path = train_graphs_dir + TRAIN_SESS_NUM + '.png'\n",
        "    plt.savefig(train_graph_path)\n",
        "    # Print final loss and accuracy values\n",
        "    final_loss, final_accuracy = model.evaluate(test_generator, steps = test_steps)\n",
        "    print('Final loss: {:.2f}'.format(final_loss))\n",
        "    print('Final accuracy: {:.2f}%'.format(final_accuracy * 100))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mvOpxBvKWCht"
      },
      "source": [
        "## Model & Training Dataset Preparaion\n",
        "---\n",
        "Run these blocks every time you train to choose which model hyperparameters and training dataset pre-processing to do."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YWylHChz4JTh"
      },
      "source": [
        "### Choose model and batch size\n",
        "These values will be used to prepare training dataset with the dimensions needed for chosen model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "77MDrSHntvWK"
      },
      "source": [
        "# TO DO: Select pre-trained model to use from Tensorflow Hub Model Zoo\n",
        "module_selection = (\"inception_v3\", 299) #@param [\"(\\\"mobilenet_v2_1.0_224\\\", 224)\", \"(\\\"inception_v3\\\", 299)\"] {type:\"raw\", allow-input: true}\n",
        "handle_base, pixels = module_selection\n",
        "IMAGE_SIZE = (pixels, pixels)\n",
        "\n",
        "if handle_base == \"inception_v3\":\n",
        "    MODULE_HANDLE =\"https://tfhub.dev/google/imagenet/inception_v3/classification/4\".format(handle_base)\n",
        "    epsilon = 1\n",
        "elif handle_base == \"mobilenet_v2_1.0_224\":\n",
        "    MODULE_HANDLE =\"https://tfhub.dev/google/tf2-preview/mobilenet_v2/classification/4\".format(handle_base) \n",
        "    epsilon = 1e-07\n",
        "\n",
        "# TO DO: adjust batch size to make training faster or slower\n",
        "BATCH_SIZE = \"32\" #@param [\"16\", \"32\", \"64\", \"128\"]\n",
        "\n",
        "print(\"Using {} with input size {} and batch size {}\".format(handle_base, IMAGE_SIZE, BATCH_SIZE))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IvfFTR9DvKCN"
      },
      "source": [
        "### Prepare training dataset\n",
        "\n",
        "*Note: If the second line says \"Found 0 images belonging to...\" run again until a non-zero number is given. Some images aren't read properly by ImageDataGenerator and they result in problems during training dataset generation but don't throw errors during training.*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "code",
        "id": "ocQ6gDasveZ5"
      },
      "source": [
        "# To suppress warnings from pillow about image sizes\n",
        "ImageFile.LOAD_TRUNCATED_IMAGES = True\n",
        "Image.MAX_IMAGE_PIXELS = 95000000\n",
        "\n",
        "# TO DO: Set path to folder where training images were stored in rating_preprocessing.ipynb\n",
        "TRAINING_DATA_DIR = '/content/drive/MyDrive/train/pre-processing/images/agg' #@param {type:\"string\"}\n",
        "print(\"Loading training images from: \\n\", TRAINING_DATA_DIR)\n",
        "\n",
        "# TO DO: Adjust interpolation method and see how training results change\n",
        "interpolation = \"nearest\" #@param [\"nearest\", \"bilinear\"]\n",
        "\n",
        "# Set data generation and flow parameters\n",
        "datagen_kwargs = dict(rescale=1./255, validation_split=.20)\n",
        "dataflow_kwargs = dict(target_size=IMAGE_SIZE, batch_size=int(BATCH_SIZE),\n",
        "                       interpolation = interpolation, color_mode='rgb')\n",
        "\n",
        "# Make test dataset\n",
        "test_datagen = ImageDataGenerator(**datagen_kwargs)\n",
        "test_generator = test_datagen.flow_from_directory(TRAINING_DATA_DIR, \n",
        "                                                  subset=\"validation\",\n",
        "                                                  shuffle=True, **dataflow_kwargs)\n",
        "\n",
        "# Make train dataset\n",
        "train_datagen = ImageDataGenerator(**datagen_kwargs)\n",
        "train_generator = train_datagen.flow_from_directory(TRAINING_DATA_DIR, \n",
        "                                                    subset=\"training\", shuffle=True, \n",
        "                                                    **dataflow_kwargs)\n",
        "\n",
        "# Learn more about data batches\n",
        "image_batch_train, label_batch_train = next(iter(train_generator))\n",
        "print(\"Image batch shape: \", image_batch_train.shape)\n",
        "print(\"Label batch shape: \", label_batch_train.shape)\n",
        "dataset_labels = sorted(train_generator.class_indices.items(), key=lambda pair:pair[1])\n",
        "dataset_labels = np.array([key.title() for key, value in dataset_labels])\n",
        "print(\"Dataset label classes: \\n\", dataset_labels)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "72N6UtPiVQNW"
      },
      "source": [
        "### Prepare model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g1pGKmlkVS1k",
        "cellView": "code"
      },
      "source": [
        "# Build model and set hyperparameters\n",
        "\n",
        "# TO DO: If model is overfitting, add/increase dropout rate\n",
        "dropout_rate = 0.1 #@param {type:\"slider\", min:0, max:0.5, step:0.1}\n",
        "lr = 0.001 #@param [\"0.1\", \"0.01\", \"0.001\", \"0.0001\", \"0.00001\"] {type:\"raw\"}\n",
        "\n",
        "# TO DO: Freeze or unfreeze lower layers for transfer learning and fine tuning\n",
        "## False freezes lower layers so only top classifier is retrained\n",
        "trainable = True #@param [\"True\", \"False\"] {type:\"raw\"} \n",
        "\n",
        "# Build model\n",
        "print(\"Building model with\", handle_base)\n",
        "def create_model():\n",
        "    model = tf.keras.Sequential([InputLayer(input_shape=IMAGE_SIZE + (3,)),\n",
        "                                 hub.KerasLayer(MODULE_HANDLE, trainable=trainable),\n",
        "                                 Dropout(rate = dropout_rate),\n",
        "                                 Dense(train_generator.num_classes,\n",
        "                                       kernel_regularizer=tf.keras.regularizers.l2(0.0001))])\n",
        "  \n",
        "    # Build model\n",
        "    model.build((None,)+IMAGE_SIZE+(3,))\n",
        "  \n",
        "    # Compile model\n",
        "    model.compile(\n",
        "        # Parameters for Adam optimizer\n",
        "        optimizer=tf.keras.optimizers.Adam(learning_rate=lr, beta_1=0.9, \n",
        "                                           beta_2=0.999, epsilon=epsilon, \n",
        "                                           amsgrad=False, name='Adam'), \n",
        "                  # Categorical cross entropy because 5 exclusive classes\n",
        "                  loss=tf.keras.losses.CategoricalCrossentropy(from_logits=True, \n",
        "                                                               label_smoothing=0),\n",
        "                  metrics=['accuracy'])\n",
        "    return model\n",
        "\n",
        "# Create new model instance\n",
        "model = create_model()\n",
        "\n",
        "# Steps per epoch and testing\n",
        "steps_per_epoch = train_generator.samples // train_generator.batch_size\n",
        "test_steps = test_generator.samples // test_generator.batch_size\n",
        "\n",
        "# Display model architecture\n",
        "model.summary()\n",
        "tf.keras.utils.plot_model(model, show_shapes=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A7ycnwnKkkfa"
      },
      "source": [
        "## Train\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CNbToKXYlEo5"
      },
      "source": [
        "# Actual training\n",
        "\n",
        "# TO DO: How many epochs to train for\n",
        "## Adjust number of epochs to find balance between underfit and overfit for training\n",
        "num_epochs = '10' #@param {type:\"string\"}\n",
        "\n",
        "# TO DO: Resume training from previous training attempt/checkpoint ?\n",
        "resume_train_ckpt = False #@param {type:\"boolean\"}\n",
        "# (Optional: Only if above is True) TO DO: Resume from which saved checkpoint?\n",
        "if resume_train_ckpt:\n",
        "    TRAIN_SESS_NUM = \"12\" #@param {type:\"string\"}\n",
        "\n",
        "# Set path to saved model checkpoints\n",
        "# TO DO: Set path to folder to store saved models\n",
        "saved_models_dir = '/content/drive/MyDrive/train/' #@param\n",
        "saved_models_dir = saved_models_dir + 'saved_models/'\n",
        "!mkdir $saved_models_dir\n",
        "\n",
        "CKPT_PATH, last_attempt, TRAIN_SESS_NUM = set_ckpt_path(saved_models_dir, \n",
        "                                                        resume_train_ckpt, \n",
        "                                                        TRAIN_SESS_NUM,\n",
        "                                                        num_epochs)\n",
        "\n",
        "# Set up checkpoint callbacks for saving during training \n",
        "ckpt_callback = set_ckpt_callbacks(CKPT_PATH)\n",
        "\n",
        "# Train the model with the new callback\n",
        "hist = model.fit(train_generator,\n",
        "                 epochs=int(num_epochs), steps_per_epoch=steps_per_epoch,\n",
        "                 callbacks=[ckpt_callback],\n",
        "                 validation_data=test_generator,\n",
        "                 validation_steps=test_steps).history\n",
        "\n",
        "# Save trained model \n",
        "saved_model_path = saved_models_dir + TRAIN_SESS_NUM\n",
        "tf.keras.models.save_model(model, saved_model_path)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-kfOjJ3llGVY"
      },
      "source": [
        "# Plot loss and accuracy for training session\n",
        "\n",
        "# TO DO: Set path to save train graphs\n",
        "train_graphs_dir = '/content/drive/MyDrive/train/' #@param\n",
        "train_graphs_dir = train_graphs_dir + 'train_graphs'\n",
        "!mkdir $train_graphs_dir\n",
        "\n",
        "# Plot training graph\n",
        "plot_train_graph(train_graphs_dir, TRAIN_SESS_NUM, hist, test_generator)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Cpjn2qz-57p_"
      },
      "source": [
        "## Review training results\n",
        "---   \n",
        "Display classification results on images and adjust model hyperparameters and/or image augmentation steps before retraining if needed."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UNxq35BeEi-k"
      },
      "source": [
        "# Define functions & parameters\n",
        "\n",
        "# TO DO: Display results for the most recently trained model?\n",
        "use_last_attempt = True #@param {type:\"boolean\"}\n",
        "# (Optional: Only if above is False) TO DO: Resume from which saved checkpoint?\n",
        "TRAIN_SESS_NUM = \"20\" #@param [\"13\", \"11\", \"15\"] {allow-input: true}\n",
        "\n",
        "# TO DO: Only need to set parameters if not running images through last attempt\n",
        "if not use_last_attempt:\n",
        "    # TO DO: Set path to folder to store saved models\n",
        "    saved_models_dir = \"/content/drive/MyDrive/train/saved_models/\" #@param {type:\"string\"}\n",
        "\n",
        "    # TO DO: Select model type for train attempt number\n",
        "    module_selection = (\"inception_v3\", 299) #@param [\"(\\\"mobilenet_v2_1.0_224\\\", 224)\", \"(\\\"inception_v3\\\", 299)\"] {type:\"raw\", allow-input: true}\n",
        "\n",
        "    # Label names\n",
        "    dataset_labels = ['bad', 'good'] #@param\n",
        "\n",
        "    # TO DO: Choose directory where images are stored \n",
        "    base = \"/content/drive/MyDrive/train/preprocessing/images/\" #@param {type:\"string\"}\n",
        "\n",
        "# TO DO: Choose which image class to inspect results for\n",
        "true_imclass = \"agg/good\" #@param [\"agg/good\", \"agg/bad\"]\n",
        "\n",
        "# Get test image paths\n",
        "PATH_TO_TEST_IMAGES_DIR = base + true_imclass\n",
        "names = os.listdir(PATH_TO_TEST_IMAGES_DIR)\n",
        "TEST_IMAGE_PATHS = [os.path.join(PATH_TO_TEST_IMAGES_DIR, name) for name in names]\n",
        "\n",
        "# Load saved model from directory\n",
        "def load_saved_model(use_last_attempt, saved_models_dir, TRAIN_SESS_NUM, module_selection):\n",
        "    # If using last training attempt, get number from director\n",
        "    if use_last_attempt:\n",
        "        # Display results from most recent training attempt\n",
        "        last_attempt = !ls $saved_models_dir | tail -n 1\n",
        "        TRAIN_SESS_NUM = str(last_attempt.n)\n",
        "\n",
        "    # Load trained model from path\n",
        "    saved_model_path = saved_models_dir + TRAIN_SESS_NUM\n",
        "    model = tf.keras.models.load_model(saved_model_path)\n",
        "\n",
        "    # Get name and image size for model type\n",
        "    handle_base, pixels = module_selection\n",
        "\n",
        "    return model, pixels\n",
        "\n",
        "# Define start and stop indices in EOL bundle for running inference   \n",
        "def set_start_stop():\n",
        "    # To test with a tiny subset, use 5 random bundle images\n",
        "    N = len(TEST_IMAGE_PATHS)\n",
        "    if test_with_tiny_subset:\n",
        "        start=np.random.choice(a=N, size=1)[0]\n",
        "        stop=start+5\n",
        "    # To run for larger set, use 50 random images\n",
        "    else : \n",
        "        start=np.random.choice(a=N, size=1)[0]\n",
        "        stop=start+50\n",
        "    print(\"Running inference on images\")\n",
        "    \n",
        "    return start, stop\n",
        "\n",
        "# For reading an image from filename\n",
        "def filename_to_image(fn):\n",
        "    img = Image.open(im_path)\n",
        "    disp_img = img.convert('RGB')\n",
        "    inf_img = disp_img.resize((pixels, pixels))\n",
        "    inf_img = np.reshape(inf_img,[1,pixels,pixels,3])\n",
        "    image = inf_img*1./255\n",
        "\n",
        "    return image, disp_img\n",
        "\n",
        "# Get info from predictions to display on images\n",
        "def get_predict_info(predictions, im_num, stop, start):\n",
        "    # Get info from predictions\n",
        "    label_num = np.argmax(predictions[0], axis=-1)\n",
        "    conf = predictions[0][label_num]\n",
        "    im_class = dataset_labels[label_num]\n",
        "    # Display progress message after each image\n",
        "    print('Inference complete for {} of {} images'.format(im_num, (stop-start)))\n",
        "\n",
        "    return label_num, conf, im_class"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "awIMvGFtGlvE",
        "cellView": "code"
      },
      "source": [
        "# Run inference\n",
        "\n",
        "# Load saved model\n",
        "model, pixels = load_saved_model(use_last_attempt, saved_models_dir, \n",
        "                                 TRAIN_SESS_NUM, module_selection)\n",
        "\n",
        "# Test with tiny subset (5 images)\n",
        "# TO DO: If yes, check test_with_tiny_subset box\n",
        "test_with_tiny_subset = True #@param {type: \"boolean\"}\n",
        "\n",
        "# Run EOL images through trained model and display results\n",
        "start, stop = set_start_stop()\n",
        "for im_num, im_path in enumerate(TEST_IMAGE_PATHS[start:stop], start=1):\n",
        "    print(im_path)\n",
        "    # Load in image\n",
        "    image, disp_img = filename_to_image(im_path)\n",
        "    \n",
        "    # Image classification\n",
        "    start_time = time.time() # Record inference time\n",
        "    predictions = model.predict(image, batch_size=1)\n",
        "    label_num, conf, im_class = get_predict_info(predictions, im_num, stop, start)\n",
        "    end_time = time.time()\n",
        "\n",
        "    # Display classification results with images\n",
        "    _, ax = plt.subplots(figsize=(10, 10))\n",
        "    ax.imshow(disp_img)\n",
        "    plt.title('{}) Prediction: {}, Confidence: {}, Inference time: {}'.format(\n",
        "              im_num, im_class, format(conf, '.2f'), format(end_time-start_time, '.2f')))"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}