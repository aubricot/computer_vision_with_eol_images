{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "object_detection_for_image_cropping_colab_tf_ssd_rcnn.ipynb",
      "provenance": [],
      "private_outputs": true,
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.9"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/aubricot/object_detection_for_image_cropping/blob/master/COLAB_object_detection_for_image_cropping_tf_ssd_rcnn.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1Uj9xtRVpMTa",
        "colab_type": "text"
      },
      "source": [
        "# Using Faster-RCNN and SSD in Tensorflow to detect birds from images\n",
        "---\n",
        "*Last Updated 19 November 2019*   \n",
        "This notebook is meant to be run enitrely in Google Colab and doesn't require any software installation or downloads to your local machine. To get started, just click the "Open in Colab" button above.  \n",
        "\n",
        "It is modified from the [Tensorflow Object Detection API Tutorial](https://github.com/tensorflow/models/tree/master/research/object_detection). Tensorflow Object Detection API is meant for building models for custom object detection, see more information here: [Tensorflow Object Detection API](https://tensorflow-object-detection-api-tutorial.readthedocs.io/en/latest/install.html#tensorflow-models-installation). \n",
        "\n",
        "Tensorflow Hub is a library for reusable  machine learning models, and a useful resource meant for off the shelf inference. There is a Google Colab tutorial on it here: [Tensorflow Hub Object Detection](https://colab.research.google.com/github/tensorflow/hub/blob/master/examples/colab/object_detection.ipynb)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "p3UGXxUii5Ym"
      },
      "source": [
        "## Install in Google Colab Session\n",
        "---\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uOSWRf-gpMTc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# tensorflow-gpu version 2.0 \n",
        "# this is the library for the machine learning models and resources used here\n",
        "!pip install tensorflow-gpu==2.0"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "96xgSiiO5epq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# pycocotools is from the COCO API\n",
        "# COCO is a large image database for machine learning\n",
        "# the COCO API is for loading, parsing, and visualizing the annotations in COCO.\n",
        "!pip install pycocotools"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kTAkbF2Kpwb0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# download tensorflow model zoo\n",
        "# it contains models designed for re-use \n",
        "import os\n",
        "import pathlib\n",
        "\n",
        "\n",
        "if \"models\" in pathlib.Path.cwd().parts:\n",
        "  while \"models\" in pathlib.Path.cwd().parts:\n",
        "    os.chdir('..')\n",
        "elif not pathlib.Path('models').exists():\n",
        "  !git clone --depth 1 https://github.com/tensorflow/models"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iEbRcmZfq5hp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# compile Tensorflow Object Detection API using Google Protobuf\n",
        "%%bash\n",
        "cd models/research/\n",
        "protoc object_detection/protos/*.proto --python_out=."
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E5gvS-VTsMNz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# install Tensorflow Object Detection API\n",
        "%%bash \n",
        "cd models/research\n",
        "pip install ."
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "LBdjK2G5ywuc"
      },
      "source": [
        "## Imports\n",
        "---\n",
        "Set your working directory to 'models\\research\\object_detection'. These folders were downloaded with the Tensorflow Object Detection API."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "hV4P5gyTWKMI",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf # tensorflow-gpu==2.0\n",
        "\n",
        "# For importing/exporting files, working with arrays, etc\n",
        "import pathlib\n",
        "import numpy as np # numpy==1.16.4\n",
        "import csv\n",
        "import os\n",
        "import matplotlib\n",
        "import time\n",
        "import pandas as pd\n",
        "\n",
        "# For downloading the image\n",
        "import matplotlib.pyplot as plt\n",
        "import tempfile\n",
        "from six.moves.urllib.request import urlopen\n",
        "from six import BytesIO\n",
        "\n",
        "# For drawing onto the image\n",
        "from PIL import Image\n",
        "from PIL import ImageColor\n",
        "from PIL import ImageDraw\n",
        "from PIL import ImageFont\n",
        "from PIL import ImageOps\n",
        "\n",
        "from IPython.display import display\n",
        "\n",
        "from object_detection.utils import ops as utils_ops\n",
        "from object_detection.utils import label_map_util\n",
        "from object_detection.utils import visualization_utils as vis_util"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "mF-YlMl8c_bM",
        "colab": {}
      },
      "source": [
        "# Patch tf1 into `utils.ops`, if using tf==1.15 can make tf ops compatible between v1 and v2\n",
        "utils_ops.tf = tf.compat.v1\n",
        "\n",
        "# Patch the location of gfile\n",
        "tf.gfile = tf.io.gfile"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "cfn_tRFOWKMO"
      },
      "source": [
        "# Model preparation \n",
        "---\n",
        "\n",
        "Load in and inspect a model from the Tensorflow Model Zoo.\n",
        "\n",
        "Tested here: Faster RCNN Resnet 50 trained on COCO (89 ms, 30 mAP), SSD Resnet 50 trained on COCO (76 ms, 35 mAP)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2wyyZ143svCf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def load_model(model_name):\n",
        "  base_url = 'http://download.tensorflow.org/models/object_detection/'\n",
        "  model_file = model_name + '.tar.gz'\n",
        "  model_dir = tf.keras.utils.get_file(\n",
        "    fname=model_name, \n",
        "    origin=base_url + model_file,\n",
        "    untar=True)\n",
        "\n",
        "  model_dir = pathlib.Path(model_dir)/\"saved_model\"\n",
        "\n",
        "  model = tf.saved_model.load(str(model_dir))\n",
        "  model = model.signatures['serving_default']\n",
        "\n",
        "  return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F--UQJg-pMTn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Load in the model\n",
        "# Tested here: faster_rcnn_resnet50_coco_2018_01_28 or ssd_resnet50_v1_fpn_shared_box_predictor_640x640_coco14_sync_2018_07_03\n",
        "model_name = 'faster_rcnn_resnet50_coco_2018_01_28' \n",
        "model = load_model(model_name)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "CK4cnry6wsHY",
        "colab": {}
      },
      "source": [
        "# Check the model's input signature, it expects a batch of 3-color images of type uint8\n",
        "print(model.inputs)\n",
        "\n",
        "# And retuns several outputs\n",
        "model.output_dtypes\n",
        "model.output_shapes"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "_1MVVTcLWKMW"
      },
      "source": [
        "## Load in label map\n",
        "Label maps map indices to category names, so that when our convolution network predicts `16`, we know that this corresponds to `bird`.  Here we use internal utility functions, but anything that returns a dictionary mapping integers to appropriate string labels would be fine."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "hDbpHkiWWKMX",
        "colab": {}
      },
      "source": [
        "# List of the strings that is used to add correct label for each box.\n",
        "PATH_TO_LABELS = 'models/research/object_detection/data/mscoco_label_map.pbtxt'\n",
        "category_index = label_map_util.create_category_index_from_labelmap(PATH_TO_LABELS, use_display_name=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "72TdyVmppMTs"
      },
      "source": [
        "## Define functions to load in sample images\n",
        "---  "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LCNUmdyB0S0n",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def display_image(image):\n",
        "  fig = plt.figure() #figsize=(20, 15)\n",
        "  plt.grid(True)\n",
        "  plt.imshow(image)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PrNFfbkbznWU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def download_and_convert_image(url, display=False):\n",
        "  _, filename = tempfile.mkstemp(suffix=\".jpg\")\n",
        "  response = urlopen(url)\n",
        "  image_data = response.read()\n",
        "  image_data = BytesIO(image_data)\n",
        "  pil_image = Image.open(image_data)\n",
        "  pil_image_rgb = pil_image.convert(\"RGB\")\n",
        "  pil_image_rgb.save(filename, format=\"JPEG\", quality=90)\n",
        "  # print(\"Image downloaded to %s.\" % filename)\n",
        "  if display:\n",
        "    display_image(pil_image)\n",
        "  return filename"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AKWm4iqq17Fr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def load_img(path):\n",
        "  img = tf.io.read_file(path)\n",
        "  img = tf.image.decode_jpeg(img, channels=3)\n",
        "  return img"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "39qVHBc1pMTu",
        "colab_type": "text"
      },
      "source": [
        "## Define functions for object detection\n",
        "The first function reads in the image and converts it to a format that the program can detect objects from using pre-trained models. The second function displays the results of detection and exports the bounding box values to 'sample_crops_tf.tsv'. You can adjust the parameters so that bounding boxes are only shown for certain confidence or class values. Here boxes are shown when confidence > 0.6 and object class is 'bird' (class '16')."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_cPVYxd8pMTv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def run_inference_for_single_image(model, image):\n",
        "  image_np = np.array(image)\n",
        "  # The input needs to be a tensor, convert it using `tf.convert_to_tensor`\n",
        "  input_tensor = tf.convert_to_tensor(image_np)\n",
        "  # The model expects a batch of images, so add an axis with `tf.newaxis`\n",
        "  input_tensor = input_tensor[tf.newaxis,...]\n",
        "\n",
        "  # Run inference\n",
        "  output_dict = model(input_tensor)\n",
        "\n",
        "  # All outputs are batches tensors\n",
        "  # Convert to numpy arrays, and take index [0] to remove the batch dimension\n",
        "  # We're only interested in the first num_detections\n",
        "  num_detections = int(output_dict.pop('num_detections'))\n",
        "  output_dict = {key:value[0, :num_detections].numpy() \n",
        "                 for key,value in output_dict.items()}\n",
        "  output_dict['num_detections'] = num_detections\n",
        "\n",
        "  # Detection_classes should be ints.\n",
        "  output_dict['detection_classes'] = output_dict['detection_classes'].astype(np.int64)\n",
        "   \n",
        "  # Handle models with masks:\n",
        "  if 'detection_masks' in output_dict:\n",
        "    # Reframe the the bbox mask to the image size.\n",
        "    detection_masks_reframed = utils_ops.reframe_box_masks_to_image_masks(\n",
        "              output_dict['detection_masks'], output_dict['detection_boxes'],\n",
        "               image.shape[0], image.shape[1])      \n",
        "    detection_masks_reframed = tf.cast(detection_masks_reframed > 0.5,\n",
        "                                       tf.uint8)\n",
        "    output_dict['detection_masks_reframed'] = detection_masks_reframed.numpy()\n",
        "    \n",
        "  return output_dict"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7KKP5BNKpMTx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def show_inference(model, image_path):\n",
        "  # The array based representation of the image will be used later in order to prepare the\n",
        "  # result image with boxes and labels on it\n",
        "  image_np = np.array(Image.open(image_path))\n",
        "  \n",
        "  # Actual detection\n",
        "  output_dict = run_inference_for_single_image(model, image_np)\n",
        "  \n",
        "  # Name parts of tensor, set score threshold\n",
        "  boxes = output_dict['detection_boxes'] \n",
        "  #max_boxes_to_draw = boxes.shape[0] # add this line and remove (i) and (ii) below to show multiple detection boxes\n",
        "  scores = output_dict['detection_scores']\n",
        "  classes = output_dict['detection_classes']\n",
        "  min_score_thresh = .6\n",
        "    \n",
        "  # (i) Eliminate not_birds from detection results \n",
        "  # bird class = 16, for all not_birds set score < min_score_thresh\n",
        "  not_bird_elements = np.where(classes != 16)\n",
        "  for j in not_bird_elements:\n",
        "    scores[j] = 0.01\n",
        "\n",
        "  # (ii) Eliminate overlapping boxes/detections using non_max_suppression \n",
        "  selected_indices = tf.image.non_max_suppression(\n",
        "    boxes, scores, score_threshold=min_score_thresh, max_output_size=1, iou_threshold=0.5) # selects the box/detection with highest core\n",
        "  selected_box = tf.constant(tf.gather(boxes, selected_indices))\n",
        "\n",
        "  # Write results of detection to tsv\n",
        "  with open('models/research/object_detection/test_images/sample_crops_tf.tsv', 'a') as out_file:\n",
        "    tsv_writer = csv.writer(out_file, delimiter='\\t')\n",
        "    im_width, im_height, channels = np.array(image_np).shape\n",
        "    ymin, xmin, ymax, xmax = np.squeeze(np.array(selected_box))\n",
        "    crop_width = (xmax-xmin) * im_width\n",
        "    crop_height = (ymax-ymin) * im_height\n",
        "    tsv_writer.writerow([os.path.splitext((os.path.basename(image_path)))[0], im_height, im_width, \n",
        "                            xmin * im_width, ymin * im_height, crop_height, crop_width])\n",
        "    \n",
        "  # Visualize the results of detection on images\n",
        "  vis_util.visualize_boxes_and_labels_on_image_array(\n",
        "      image_np,\n",
        "      np.array(selected_box), # only visualize the box resulting from non_max_suppression\n",
        "      output_dict['detection_classes'],\n",
        "      output_dict['detection_scores'],\n",
        "      category_index,\n",
        "      instance_masks=output_dict.get('detection_masks_reframed', None),\n",
        "      use_normalized_coordinates=True, # absolute pixel values (FALSE) or relative corrected by img width & height (TRUE)\n",
        "      line_thickness=8, min_score_thresh=min_score_thresh) \n",
        "        \n",
        "  display(Image.fromarray(image_np)) # delete this when running on cluster"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7q1iMiAbpMTy",
        "colab_type": "text"
      },
      "source": [
        "## Load in sample images and run detector\n",
        "---\n",
        "You can either **A) Load individual images in by URL**, or for large image batches, you can use other methods for importing to Google Colab listed [here](https://towardsdatascience.com/3-ways-to-load-csv-files-into-colab-7c14fcbdcb92). In our case, we **B) Load multiple images from a text file of image URLs**."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fdtd-vtMDaCL",
        "colab_type": "text"
      },
      "source": [
        "**A) Load individual images in by URL**  \n",
        "Load in images by URL and run the image detector for all images. Plotted results include the image with bounding box around detected objects (birds), class type, and confidence score. Inference times are printed below images. The bounding box coordinates are also written to 'sample_crops_tf.tsv'. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KopscaVYzqhz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "image_urls = [\"https://content.eol.org/data/media/7e/9c/7a/542.15445377044.jpg\",\n",
        "              \"https://content.eol.org/data/media/81/1c/0d/542.7816025222.jpg\",\n",
        "              \"https://content.eol.org/data/media/7e/3c/0b/542.10578857864.jpg\"]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DJmR4bek28dz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for image_url in image_urls:\n",
        "  start_time = time.time()\n",
        "  image_path = download_and_convert_image(image_url)\n",
        "  show_inference(model, image_path)\n",
        "  end_time = time.time()\n",
        "  print(\"Inference time:\", end_time-start_time)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ICgJPMdqD6un",
        "colab_type": "text"
      },
      "source": [
        "**B) Load multiple images from a text file of image URLs**  \n",
        "Load in multiple images from a text file of URLS and run the image detector for all images. Plotted results include the image with bounding box around detected objects (birds), class type, and confidence score. Inference times are printed below images. The bounding box coordinates are also written to 'sample_crops_tf.tsv'. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i7gQvak4Btf8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "urls = 'https://editors.eol.org/other_files/bundle_images/files/images_for_Aves_breakdown_download_000001.txt'\n",
        "df1 = pd.read_csv(urls)\n",
        "df1.columns = [\"link\"]\n",
        "pd.DataFrame.head(df1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qf_s_zzfBvNn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# loops through first 5 image urls from the text file\n",
        "for i, row in df1.head(5).itertuples(index=True, name='Pandas'):\n",
        "  start_time = time.time()\n",
        "  link = df1.get_value(i, \"link\")\n",
        "  image_path = download_and_convert_image(link)\n",
        "  show_inference(model, image_path)\n",
        "  end_time = time.time()\n",
        "  print(\"Inference time:\", end_time-start_time)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}
