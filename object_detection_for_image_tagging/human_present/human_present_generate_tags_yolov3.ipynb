{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "human_present_generate_tags_yolov3.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/aubricot/computer_vision_with_eol_images/blob/master/object_detection_for_image_tagging/human_present/human_present_generate_tags_yolov3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j-PBcUKyc95M"
      },
      "source": [
        "# Using YOLO v3 pre-trained on Google Open Images to add human present tags to EOL images\n",
        "---\n",
        "*Last Updated 10 June 2021*   \n",
        "Using a YOLOv3 model (downloaded from [here](https://github.com/AlexeyAB/darknet) ) pre-trained on [Google Open Images](https://storage.googleapis.com/openimages/web/visualizer/index.html?set=train&type=detection&c=%2Fm%2F03vt0) as a method to do customized, large-scale image processing. EOL images will be tagged for human(s) present (body, eye, head, hand, foot, face, arm, leg ear, eye, face, nose, beard) to further extend EOLv3 image search functions."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fX9LGz3Ydu27"
      },
      "source": [
        "## Installs & Imports\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q5lC8PSbGCyN"
      },
      "source": [
        "# Mount google drive to import/export files\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yDdbBYnp2nCK"
      },
      "source": [
        "# For importing/exporting files, working with arrays, etc\n",
        "import os\n",
        "import glob\n",
        "import pathlib\n",
        "import six.moves.urllib as urllib\n",
        "import sys\n",
        "import tarfile\n",
        "import zipfile\n",
        "import numpy as np \n",
        "import csv\n",
        "import matplotlib.pyplot as plt\n",
        "import time\n",
        "import pandas as pd\n",
        "\n",
        "# For downloading images\n",
        "!apt-get install aria2\n",
        "\n",
        "# For drawing onto and plotting images\n",
        "import matplotlib.pyplot as plt\n",
        "from PIL import Image\n",
        "from PIL import ImageColor\n",
        "from PIL import ImageDraw\n",
        "from PIL import ImageFont\n",
        "from PIL import ImageOps\n",
        "import cv2\n",
        "%matplotlib inline\n",
        "%config InlineBackend.figure_format = 'svg'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "isysjRGl21_D"
      },
      "source": [
        "## Model preparation (only run once)\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xym8_m8CIyXK"
      },
      "source": [
        "# Install darknet\n",
        "\n",
        "# TO DO: Type in the path to your working directory in form field to right\n",
        "basewd = \"/content/drive/MyDrive/train\" #@param {type:\"string\"}\n",
        "wd = 'darknet'\n",
        "%cd $basewd\n",
        "\n",
        "# Download darknet (the native implementation of YOLO)\n",
        "if os.path.exists(wd):\n",
        "    %cd $wd\n",
        "\n",
        "elif not os.path.exists(wd):\n",
        "    !git clone https://github.com/AlexeyAB/darknet\n",
        "    # Compile darknet\n",
        "    %cd $wd\n",
        "    !python setup.py build_ext --inplace\n",
        "    # Change makefile to have GPU and OPENCV enabled\n",
        "    !sed -i 's/OPENCV=0/OPENCV=1/' Makefile\n",
        "    !sed -i 's/GPU=0/GPU=1/' Makefile\n",
        "    !sed -i 's/CUDNN=0/CUDNN=1/' Makefile\n",
        "    !sed -i 's/CUDNN_HALF=0/CUDNN_HALF=1/' Makefile\n",
        "    # Download pretrained YOLOv3 weights for Open Images\n",
        "    !wget https://pjreddie.com/media/files/yolov3-openimages.weights\n",
        "\n",
        "# Verify CUDA version (for using GPU)\n",
        "!/usr/local/cuda/bin/nvcc --version\n",
        "\n",
        "# Make darknet\n",
        "!make"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cKovA4-aifP5"
      },
      "source": [
        "## Generate cropping coordinates for images\n",
        "---\n",
        "Run EOL 20k image bundles through pre-trained object detection models and save results in 4 batches (A-D). "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fuZL4TGzitNZ"
      },
      "source": [
        "### Prepare object detection functions and settings"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wqoLKpXveeAt"
      },
      "source": [
        "# Functions\n",
        "\n",
        "# Read in data file\n",
        "def read_datafile(fpath, sep=\"\\t\", header=0, disp_head=True):\n",
        "    \"\"\"\n",
        "    Defaults to tab-separated data files with header in row 0\n",
        "    \"\"\"\n",
        "    try:\n",
        "        df = pd.read_csv(fpath, sep=sep, header=header)\n",
        "        if disp_head:\n",
        "            print(\"Data header: \\n\", df.head())\n",
        "    except FileNotFoundError as e:\n",
        "        raise Exception(\"File not found: Enter the path to your file in form field and re-run\").with_traceback(e.__traceback__)\n",
        "    \n",
        "    return df\n",
        "\n",
        "# Read in bundle images\n",
        "def read_eolbundle(bundle, no_bundles):\n",
        "    # Get first 20k images for Lepidoptera bundles using initial bundle basename\n",
        "    base = os.path.splitext(os.path.basename(bundle))[0].rsplit('_',1)[0]\n",
        "    # Load in all sub-bundles (ex: 000001 - 000031 for Lepidoptera)\n",
        "    nums1 = list(range(1, 10))\n",
        "    nums2 = list(range(10, no_bundles))\n",
        "    exts1 = [\"00000\" + str(num) + \".txt\" for num in nums1]\n",
        "    exts2 = [\"0000\" + str(num) + \".txt\" for num in nums2]\n",
        "    exts = exts1 + exts2\n",
        "    all_filenames = [\"https://editors.eol.org/other_files/bundle_images/files/\" + base + \"_\" + e for e in exts]\n",
        "    bundles = pd.concat([pd.read_csv(f, sep='\\t', header=None) for f in all_filenames], ignore_index=True)\n",
        "    print(\"EOL image bundle with {} images: \".format(bundles.head(), len(bundles))\n",
        "\n",
        "# Define start and stop indices in EOL bundle for running inference   \n",
        "def set_start_stop():\n",
        "    # To test with a tiny subset, use 5 random bundle images\n",
        "    if test_with_tiny_subset:\n",
        "        start=np.random.choice(a=1000, size=1)[0]\n",
        "        stop=start+5\n",
        "    # To run inference on 4 batches of 5k images each\n",
        "    elif \"_a.\" in outfpath: # batch a is from 0-5000\n",
        "        start=0\n",
        "        stop=5000\n",
        "    elif \"_b.\" in outfpath: # batch b is from 5000-1000\n",
        "        start=5000\n",
        "        stop=10000\n",
        "    elif \"_c.\" in outfpath: # batch c is from 10000-15000\n",
        "        start=10000\n",
        "        stop=15000\n",
        "    elif \"_d.\" in outfpath: # batch d is from 15000-20000\n",
        "        start=15000\n",
        "        stop=20000\n",
        "    \n",
        "    return start, stop\n",
        "\n",
        "# To display results\n",
        "def imShow(path):\n",
        "    image = cv2.imread(path)\n",
        "    height, width = image.shape[:2]\n",
        "    resized_image = cv2.resize(image,(3*width, 3*height), interpolation = cv2.INTER_CUBIC)\n",
        "\n",
        "    fig = plt.gcf()\n",
        "    fig.set_size_inches(18, 10)\n",
        "    plt.axis(\"off\")\n",
        "    plt.imshow(cv2.cvtColor(resized_image, cv2.COLOR_BGR2RGB))\n",
        "    plt.show()\n",
        "\n",
        "# For uploading an image from url\n",
        "# Modified from https://www.pyimagesearch.com/2015/03/02/convert-url-to-image-with-python-and-opencv/\n",
        "def url_to_image(url):\n",
        "    resp = urllib.request.urlopen(url)\n",
        "    image = np.asarray(bytearray(resp.read()), dtype=\"uint8\")\n",
        "    image = cv2.imdecode(image, cv2.IMREAD_COLOR)\n",
        "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "    im_h, im_w = image.shape[:2]\n",
        " \n",
        "    return image"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wjTgajd3keAi"
      },
      "source": [
        "### Temporarily download images from EOL bundle to Google Drive (YOLO cannot directly parse URL images)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zCxtKyRPij8R"
      },
      "source": [
        "# Download images for 20K bundle of Lepidoptera images with 31 sub-bundles\n",
        "# To DO: Enter any EOL Lepidoptera image bundle URL\n",
        "bundle = \"https://editors.eol.org/other_files/bundle_images/files/images_for_Chiroptera_breakdown_download_000001.txt\" #@param {type:\"string\"}\n",
        "df = read_eolbundle(bundle, 18)\n",
        "\n",
        "# Test with a smaller subset than 5k images?\n",
        "# TO DO: If yes, check test_with_tiny_subset box\n",
        "test_with_tiny_subset = True #@param {type: \"boolean\"}\n",
        "\n",
        "# Take 5k subset of bundle for running inference\n",
        "# TO DO: Change file name for each bundle/run abcd if doing 4 batches using dropdown form to right\n",
        "subset = \"human_present_tags_a\" #@param [\"human_present_tags_a\", \"human_present_tags_b\", \"human_present_tags_c\", \"human_present_tags_d\"] {allow-input: true}\n",
        "outfpath = wd + \"/data/imgs/\" + subset + \".txt\"\n",
        "\n",
        "# Save 5k subset to text file for image download\n",
        "start, stop = set_start_stop()\n",
        "df = df.iloc[start:stop]\n",
        "df.to_csv(outfpath, sep='\\n', index=False, header=False)\n",
        "\n",
        "# Download images \n",
        "# Note: Takes 7-10 min per 5k imgs, aria2 downloads 16imgs at a time\n",
        "img_outfpath = wd + \"/data/imgs\"\n",
        "%cd $img_outfpath\n",
        "!aria2c -x 16 -s 1 -i $subset\n",
        "\n",
        "# Verify how many images downloaded\n",
        "print(\"Number of images downloaded to Google Drive: \")\n",
        "!ls . | wc -l"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "we9gsoPXksxH"
      },
      "source": [
        "# If images downloaded correctly, move text file to data/img_info/\n",
        "%cd ../\n",
        "!mv imgs/*.txt img_info/"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O_nGr7A7pGfW"
      },
      "source": [
        "# Make imgs.txt file to run images through YOLO for inference in batches by filename\n",
        "%cd $wd\n",
        "%cd data\n",
        "\n",
        "inf_subset = img_outfpath + '/' + subset\n",
        "with open(inf_subset, 'w', encoding='utf-8') as f:\n",
        "    for dir, dirs, files in os.walk(path):\n",
        "        files = [fn for fn in files]\n",
        "        for fn in files:\n",
        "            if 'txt' not in fn:\n",
        "                out = \"data/imgs/\" + fn\n",
        "                f.writelines(out + '\\n')\n",
        "\n",
        "# Inspect imgs.txt file to confirm length and content\n",
        "print(\"\\nNumber of images in {}: {}\".format(inf_subset, len(df)))\n",
        "print(\"\\nImages textfile: \\n\")\n",
        "df = read_datafile(inf_subset, header=None, sep='\\n', disp_head=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NnITAALxmoKY"
      },
      "source": [
        "### Run images through trained model\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YdNG8YEWaqsX"
      },
      "source": [
        "#### Test: Run individual image through by filename and display results"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kIDpIFWsOZo5"
      },
      "source": [
        "# Run inference on a single image by filename and show results\n",
        "%cd $wd\n",
        "\n",
        "# Run inference on a single image from file\n",
        "# TO DO: Put image in data/imgs & enter filename in formfield\n",
        "fn = \"bat.jpeg\" #@param {type:\"string\"}\n",
        "img_fpath = 'data/imgs/' + fn\n",
        "\n",
        "# Run darknet and show bounding box coordinates\n",
        "!./darknet detector test cfg/openimages.data cfg/yolov3-openimages.cfg yolov3-openimages.weights {img_fpath}\n",
        "\n",
        "# Display detection results\n",
        "imShow('predictions.jpg')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GJ6h9PqTh-BE"
      },
      "source": [
        "### Generate crops: Run inference on EOL images & save results for cropping\n",
        "Use 20K EOL Lepidoptera image bundles to get bounding boxes of detected pollinators. Results are saved to [crops_file].tsv.   \n",
        "Run in 4 batches of 5K images to backup regularly in case of Colab timeouts."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZljsbwXnubZc"
      },
      "source": [
        "# Run inference on 5k image subset using darknet\n",
        "%cd $wd\n",
        "\n",
        "# Create a symbolic link so that /content/gdrive/My\\ Drive/ is equal to /mydrive\n",
        "!ln -s /content/gdrive/My\\ Drive/ /mydrive\n",
        "\n",
        "# Filepath to image file list for inference\n",
        "fpath = os.path.basename(inf_subset) \n",
        "\n",
        "# Run darknet with flag to not show bounding box coordinates\n",
        "!./darknet detector test cfg/openimages.data cfg/yolov3-openimages.cfg yolov3-openimages.weights -dont_show -save_labels < {fpath}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BcfHlZ7QNXHc"
      },
      "source": [
        "## Post-process detection results\n",
        "--- \n",
        "Combine output files for batches A-D. Then, convert detection boxes into plant-pollinator co-occurrence tags."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H5RHwpgKmMMb"
      },
      "source": [
        "# Combine individual prediction files for each image to all_predictions.txt\n",
        "\n",
        "# Delete image file list for inference\n",
        "inf_subset = 'data/imgs/' + os.path.basename(inf_subset)\n",
        "!rm $inf_subset\n",
        "\n",
        "# Combine individual text files and image filenames into all_predictions.txt\n",
        "fns = os.listdir('data/imgs')\n",
        "with open('data/results/all_predictions.txt', 'w') as outfile:\n",
        "  header = \"class_id x y w h img_id\"\n",
        "  outfile.write(header + \"\\n\")\n",
        "  for fn in fns:\n",
        "        if 'txt' in fn:\n",
        "          with open('data/imgs/'+fn) as infile:\n",
        "            lines = infile.readlines()\n",
        "            newlines = [''.join([x.strip(), ' ' + os.path.splitext(fn)[0] + '\\n']) for x in lines]\n",
        "            outfile.writelines(newlines)\n",
        "\n",
        "# Inspect saved predictions\n",
        "df = pd.read_csv('data/results/all_predictions.txt')\n",
        "print(\"Model predictions: \\n\", df.head())\n",
        "\n",
        "# Delete all individual prediction files\n",
        "!rm -r data/imgs/*.txt\n",
        "\n",
        "# Delete all image files now that they have been used for inference\n",
        "!rm -r data/imgs/*"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "code",
        "id": "8-RCvF3NNlt5"
      },
      "source": [
        "# Create final predictions dataframe with class names (instead of numbers) and image urls\n",
        "# EOL 20k image url bundle\n",
        "df = pd.read_csv(bundle)\n",
        "df.columns = ['url']\n",
        "print(\"EOL media URL's corresponding to inference images: \\n\", df)\n",
        "\n",
        "# Model predictions with number-coded classes\n",
        "predict = pd.read_csv('data/results/all_predictions.txt', header=0, sep=\" \")\n",
        "predict.class_id = predict.class_id - 1 #class_id counts started from 1 instead of 0 from YOLO\n",
        "print(\"\\nModel predictions by class id: \\n\", predict)\n",
        "\n",
        "# Add class names to model predictions\n",
        "classnames = pd.read_table('data/openimages.names')\n",
        "classnames.columns = ['classname']\n",
        "#print(\"Verifying class names: \\n\", classnames)\n",
        "tag_df = predict.copy()\n",
        "di = pd.Series(classnames.classname.values,index=classnames.index).to_dict()\n",
        "tag_df.replace({\"class_id\":di}, inplace=True)\n",
        "tag_df['class_id'] = tag_df['class_id'].astype(str)\n",
        "print(\"\\nModel prediction classes translated from class id's: \\n\", tag_df)\n",
        "\n",
        "# Add EOL media URL's to model predictions\n",
        "map_urls = df.copy()\n",
        "img_ids = map_urls['url'].apply(lambda x: os.path.splitext((os.path.basename(x)))[0])\n",
        "map_urls['img_id'] = img_ids\n",
        "tag_df.set_index('img_id', inplace=True, drop=True)\n",
        "map_urls.set_index('img_id', inplace=True, drop=True)\n",
        "mapped_tagdf = tag_df.merge(map_urls, left_index=True, right_index=True)\n",
        "mapped_tagdf.reset_index(drop=False, inplace=True)\n",
        "mapped_tagdf.drop_duplicates(inplace=True, ignore_index=True)\n",
        "print(\"\\nModel predictions with EOL media URL's: \\n\", mapped_tagdf.head())\n",
        "\n",
        "# Save final tags to file\n",
        "fn = os.path.splitext(os.path.basename(inf_subset))[0]\n",
        "outpath = 'data/results/' + fn + '.tsv'\n",
        "mapped_tagdf.to_csv(outpath, sep=\"\\t\", index=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o7N0hAHDFpN_"
      },
      "source": [
        "#### Merge batch output files A-D"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qbm0_nfQFtkI"
      },
      "source": [
        "# Write header row of output tagging file\n",
        "# TO DO: Enter any filename from 4 batches of tagging files\n",
        "tags_file = \"human_present_tags_d\" #@param {type:\"string\"}\n",
        "tags_fpath = \"data/results/\" + tags_file + \".tsv\"\n",
        "\n",
        "# Combine exported model predictions and confidence values for all batches\n",
        "fpath =  os.path.splitext(tags_fpath)[0]\n",
        "base = fpath.rsplit('_',1)[0] + '_'\n",
        "exts = ['a.tsv', 'b.tsv', 'c.tsv', 'd.tsv'] \n",
        "all_filenames = [base + e for e in exts]\n",
        "df1 = pd.concat([pd.read_csv(f, sep='\\t', header=0, na_filter = False) for f in all_filenames], ignore_index=True)\n",
        "\n",
        "# Filter for desired classes\n",
        "# TO DO: Enter class to filter by\n",
        "# Note: Human will catch tags for Human body, eye, head, hand, foot, face, arm, leg ear, eye, face, nose, beard\n",
        "filter = \"Human\" #@param {type:\"string\"}\n",
        "filter_class = 'Human Present'\n",
        "pattern = filter\n",
        "df = df1.copy()\n",
        "df.loc[df['class_id'].str.contains(pattern), 'class_id'] = filter_class\n",
        "print(\"No. tags matching filtered class - {}: \\n\".format(filter_class, len(df.class_id[df.class_id.str.contains(pattern)])))\n",
        "print(\"\\nTags matching filtered class - {}: \\n\".format(filter_class, df.class_id[df.class_id.str.contains(pattern)]))\n",
        "\n",
        "# Set images with no Humans to 'None'\n",
        "patterns = '|'.join(filter+filter_class)\n",
        "df.loc[~df['class_id'].str.contains(patterns), 'class_id'] = 'None'\n",
        "print(\"\\nNo. not tags matching filtered classes: \\n\", len(df.class_id[~df.class_id.str.contains(patterns)]))\n",
        "print(\"\\nTags not matching filtered classes: \\n\", df[~df.class_id.str.contains(patterns)])\n",
        "\n",
        "# Write results to tsv\n",
        "outfpath = base + 'finaltags.tsv'\n",
        "df.to_csv(outfpath, sep='\\t', index=False)\n",
        "print(\"\\n\\nFinal output tagging file {}: \\n{}\".format(outfpath, df.head()))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vmmCI1jCVNxl"
      },
      "source": [
        "## Display cropping results on images\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gSmno0yFVPsS"
      },
      "source": [
        "# TO DO: Do you want to use the tagging file exported above?\n",
        "use_outfpath = \"no\" #@param [\"yes\", \"no\"]\n",
        "# If no, choose other path to use\n",
        "otherpath = \"data/results/human_present_tags_finaltags.tsv\" #@param {type:\"string\"}\n",
        "if use_outfpath == \"yes\":\n",
        "  outfpath = outfpath\n",
        "else:\n",
        "  outfpath = otherpath\n",
        "df = pd.read_csv(outfpath, sep=\"\\t\", header=0)\n",
        "print(\"File for tag export {}: \\n{}\".format(outfpath, df.head()))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7NN4fOicvcl0"
      },
      "source": [
        "# Display tags on images\n",
        "\n",
        "# TO DO: Adjust line below to see up to 50 images displayed at a time\n",
        "start = 0 #@param {type:\"slider\", min:0, max:5000, step:50}\n",
        "stop = start+50\n",
        "\n",
        "# Loop through images\n",
        "for i, row in df.iloc[start:stop].iterrows():\n",
        "    # Read in image \n",
        "    url = df['eolMediaURL'][i]\n",
        "    img = url_to_image(url)\n",
        "\n",
        "    # Fetch image tag\n",
        "    tag = df['class_id'][i]\n",
        "  \n",
        "    # Plot cropping box on image\n",
        "    _, ax = plt.subplots(figsize=(10, 10))\n",
        "    ax.imshow(img)\n",
        "\n",
        "    # Display image URL and coordinatesabove image\n",
        "    # Helps with fine-tuning data transforms in post-processing steps above\n",
        "    plt.title('{}) {} \\n Tag: {}'.format(i+1, url, tag))"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}