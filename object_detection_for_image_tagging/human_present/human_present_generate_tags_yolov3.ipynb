{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/aubricot/computer_vision_with_eol_images/blob/master/object_detection_for_image_tagging/human_present/human_present_generate_tags_yolov3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j-PBcUKyc95M"
      },
      "source": [
        "# Using YOLO v3 pre-trained on Google Open Images to add human present tags to EOL images\n",
        "---\n",
        "*Last Updated 5 January 2025*  \n",
        "-Runs in Python 3 with Darknet and YOLOv3-   \n",
        "\n",
        "Using a YOLOv3 model (downloaded from [here](https://github.com/AlexeyAB/darknet) ) pre-trained on [Google Open Images](https://storage.googleapis.com/openimages/web/visualizer/index.html?set=train&type=detection&c=%2Fm%2F03vt0) as a method to do customized, large-scale image processing. EOL Chiroptera (bat) images will be tagged for human(s) present (body, eye, head, hand, foot, face, arm, leg ear, eye, face, nose, beard) using object detection. Tags will further extend EOLv3 image search functions.\n",
        "\n",
        "Notes:   \n",
        "* Run code blocks by pressing play button in brackets on left\n",
        "* Change parameters using form fields on right (find details at corresponding lines of code by searching '#@param')\n",
        "\n",
        "References:   \n",
        "* Check out [AlexeyAB's darknet repo](https://github.com/AlexeyAB/darknet) for Colab tutorials like [this one](https://colab.research.google.com/drive/12QusaaRj_lUwCGDvQNfICpa7kA7_a2dE)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fX9LGz3Ydu27"
      },
      "source": [
        "## Installs & Imports\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q5lC8PSbGCyN"
      },
      "outputs": [],
      "source": [
        "#@title Choose where to save results\n",
        "import os\n",
        "\n",
        "# Use dropdown menu on right\n",
        "save = \"in Colab runtime (files deleted after each session)\" #@param [\"in my Google Drive\", \"in Colab runtime (files deleted after each session)\"]\n",
        "\n",
        "# Mount google drive to export image tagging file(s)\n",
        "if 'Google Drive' in save:\n",
        "    from google.colab import drive\n",
        "    drive.mount('/content/drive', force_remount=True)\n",
        "\n",
        "# Type in the path to your project wd in form field on right\n",
        "basewd = \"/content/drive/MyDrive/train\" #@param [\"/content/drive/MyDrive/train\"] {allow-input: true}\n",
        "\n",
        "# Type in the folder that you want to contain TF2 files\n",
        "folder = \"darknet\" #@param [\"darknet\"] {allow-input: true}\n",
        "cwd = basewd + '/' + folder\n",
        "\n",
        "# Download helper_funcs folder\n",
        "!pip3 -q install --upgrade gdown\n",
        "!gdown 1-BaybePbv810CTuHrF8JGRJfuEsHRQYH\n",
        "!tar -xzvf helper_funcs.tar.gz -C .\n",
        "\n",
        "# Install requirements.txt\n",
        "!pip3 -q install -r requirements.txt\n",
        "print('\\n\\n\\n \\033[91m If ERROR from pip dependency solver listed above, please check through conflicting version dependencies and/or open an issue on the CV for EOL images Github: https://github.com/aubricot/computer_vision_with_eol_images/issues. \\033[0m')\n",
        "\n",
        "# Set up directory structure & make darknet\n",
        "!python setup.py $cwd $basewd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yDdbBYnp2nCK"
      },
      "outputs": [],
      "source": [
        "#@title Import libraries\n",
        "\n",
        "# For importing/exporting files, working with arrays, etc\n",
        "import glob\n",
        "import pathlib\n",
        "import six.moves.urllib as urllib\n",
        "import sys\n",
        "import tarfile\n",
        "import zipfile\n",
        "import numpy as np\n",
        "import csv\n",
        "import time\n",
        "import pandas as pd\n",
        "\n",
        "# For downloading images\n",
        "!apt-get -qq install aria2\n",
        "\n",
        "# For drawing onto and plotting images\n",
        "import matplotlib.pyplot as plt\n",
        "import cv2\n",
        "%matplotlib inline\n",
        "%config InlineBackend.figure_format = 'svg'\n",
        "sys.path.append('/content')\n",
        "\n",
        "# Define EOL CV custom functions\n",
        "from wrangle_data import *"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cKovA4-aifP5"
      },
      "source": [
        "## Generate tags for images\n",
        "---\n",
        "Run EOL 20k image bundles through pre-trained object detection models and save results in 4 batches (A-D) of 5000 images each."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kIDpIFWsOZo5"
      },
      "outputs": [],
      "source": [
        "#@title Test: Run with sample EOL Chiroptera image (To test with your own image, upload file to data/imgs and update fn formfield)\n",
        "\n",
        "# Run with sample EOL image\n",
        "# Define image filepath and name\n",
        "fn = \"18.032f7703433402aa15bdccae63f5e94c.260x190.jpg\" #@param [\"18.032f7703433402aa15bdccae63f5e94c.260x190.jpg\"] {allow-input: true}\n",
        "img_fpath = 'data/imgs/' + fn\n",
        "\n",
        "# Download image\n",
        "%cd $cwd\n",
        "%cd data/imgs\n",
        "!gdown 10Ov02YgnjJo0gSQ0MC7B2o0WiJPl8rvN\n",
        "%cd $cwd\n",
        "\n",
        "# Run darknet and show bounding box coordinates\n",
        "!./darknet detector test cfg/openimages.data cfg/yolov3-openimages.cfg yolov3-openimages.weights {img_fpath}\n",
        "\n",
        "# Display detection results\n",
        "print(\"\\nObject detection results:\")\n",
        "imShow('predictions.jpg')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wjTgajd3keAi"
      },
      "source": [
        "### Generate tags: Run inference on EOL images & save results for tagging - Run 4X for batches A-D\n",
        "Use 20K EOL Chiroptera image bundle to identify humans present. Results are saved to [tags_file].tsv. Run this section 4 times (to make batches A-D) of 5K images each to incrementally save in case of Colab timeouts."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zCxtKyRPij8R"
      },
      "outputs": [],
      "source": [
        "#@title Enter EOL image bundle and choose inference settings. Change **tags_file** for each batch A-D\n",
        "%cd $cwd\n",
        "\n",
        "# Load in EOL Chiroptera 20k image bundle\n",
        "bundle = \"https://editors.eol.org/other_files/bundle_images/files/images_for_Chiroptera_breakdown_download_000001.txt\" #@param [\"https://editors.eol.org/other_files/bundle_images/files/images_for_Chiroptera_breakdown_download_000001.txt\"] {allow-input: true}\n",
        "df = read_datafile(bundle)\n",
        "print(\"EOL image bundle with {} images: \\n{}\".format(len(df), df.head()))\n",
        "\n",
        "# Test pipeline with a smaller subset than 5k images?\n",
        "run = \"test with tiny subset\" #@param [\"test with tiny subset\", \"for all images\"]\n",
        "\n",
        "# Display detection results on images?\n",
        "display_results = \"yes (use this option if testing tiny subsets; only works for \\u003C50 images)\" #@param [\"yes (use this option if testing tiny subsets; only works for \\u003C50 images)\", \"no (use this option if running batches)\"]\n",
        "\n",
        "# Take 5k subset of bundle for running inference\n",
        "# Change filename for each batch\n",
        "tags_file = \"human_present_tags_d\" #@param [\"human_present_tags_a\", \"human_present_tags_b\", \"human_present_tags_c\", \"human_present_tags_d\"] {allow-input: true}\n",
        "tags_file = tags_file + \".txt\"\n",
        "imgs_dir = \"data/imgs/\"\n",
        "outfpath = imgs_dir + tags_file\n",
        "print(\"\\nSaving tagging results to: \\n{}\".format(outfpath))\n",
        "\n",
        "# Add 5k subset of image bundle urls as column in tags file\n",
        "start, stop, cutoff = set_start_stop(run, df)\n",
        "df = df.iloc[start:stop]\n",
        "df.to_csv(outfpath, sep='\\n', index=False, header=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eKUThVvV-66K"
      },
      "outputs": [],
      "source": [
        "#@title Run inference for batches A-D\n",
        "# Note: YOLO cannot parse images from URL, so images are temporarily downloaded\n",
        "# Note: Takes 7-10 min per 5k imgs, aria2 downloads 16imgs at a time\n",
        "%cd $imgs_dir\n",
        "!aria2c -x 16 -s 1 -i $tags_file\n",
        "\n",
        "# Check how many images downloaded\n",
        "print(\"Number of files downloaded to Google Drive: \")\n",
        "no_files = len([1 for x in list(os.scandir('.')) if x.is_file()])-1 # -1 because .txt file contains image filenames\n",
        "if (no_files < cutoff) and (\"tiny subset\" not in run):\n",
        "    print(\"\\n\\n\\n \\033[93m WARNING: Less than {} files were downloaded. This is likely due to broken EOL image bundle URLs.\")\n",
        "\n",
        "# Move tags file used for downloading images to data/img_info/\n",
        "%cd $cwd\n",
        "!mv data/imgs/*.txt data/img_info/\n",
        "\n",
        "# Make a new list of successfully downloaded image files for running inference\n",
        "inf_imgs = imgs_dir + tags_file\n",
        "with open(inf_imgs, 'w', encoding='utf-8') as f:\n",
        "    # Walk through data/imgs/ to list files\n",
        "    for dir, dirs, files in os.walk(imgs_dir):\n",
        "        files = [fn for fn in files]\n",
        "        for fn in files:\n",
        "            if 'txt' not in fn:\n",
        "                out = \"data/imgs/\" + fn\n",
        "                f.writelines(out + '\\n')\n",
        "\n",
        "# Inspect textfile of images for inference\n",
        "df = pd.read_table(inf_imgs, header=None, sep='\\r')\n",
        "print(\"\\nNumber of valid images ready for inference in {}: {}\".format(inf_imgs, len(df)))\n",
        "\n",
        "# Run darknet with flag to not show bounding box coordinates\n",
        "!./darknet detector test cfg/openimages.data cfg/yolov3-openimages.cfg yolov3-openimages.weights -dont_show -save_labels < {outfpath}\n",
        "\n",
        "print(\"\\n\\n~~~\\n \\033[92m Inference complete! Post-process inference results in next code blocks before running these steps for remaining batches A-D. \\033[0m \\n~~~\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H5RHwpgKmMMb"
      },
      "outputs": [],
      "source": [
        "#@title Post-process detection results for batches A-D\n",
        "\n",
        "# Combine individual prediction files for each image to all_predictions.txt\n",
        "df = combine_predictions(imgs_dir, outfpath)\n",
        "\n",
        "# Delete inference text files and images (only needed them for inference)\n",
        "!rm -r data/imgs/*\n",
        "\n",
        "# Add class names to numeric image tags\n",
        "tags = add_class_names('data/results/all_predictions.txt')\n",
        "\n",
        "# Add EOL media URL's from bundle to image tags df\n",
        "final_tags = add_eolMediaURLs(tags, bundle)\n",
        "\n",
        "# Save final tags to file\n",
        "outpath = set_outpath(tags_file, cwd)\n",
        "final_tags.to_csv(outpath, sep=\"\\t\", index=False)\n",
        "\n",
        "print(\"\\n\\n~~~\\n \\033[93m Post-processing complete! Run above steps for remaining batches A-D before proceeding to next steps. \\033[0m \\n~~~\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o7N0hAHDFpN_"
      },
      "source": [
        "## Combine tags from batches A-D\n",
        "---\n",
        "After running steps above for each image batch, combine tag files to one 20k tag dataset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qbm0_nfQFtkI"
      },
      "outputs": [],
      "source": [
        "#@title Define parameters for converting detected classes to desired image tags\n",
        "%cd $cwd\n",
        "\n",
        "# Write header row of output tagging file\n",
        "# Enter any filename from 4 batches of tagging files\n",
        "tags_file = \"human_present_tags_a\" #@param [\"human_present_tags_a\"] {allow-input: true}\n",
        "tags_fpath = \"data/results/\" + tags_file + \".tsv\"\n",
        "\n",
        "# Combine exported model predictions and confidence values for all batches\n",
        "df = combine_tag_files(tags_fpath)\n",
        "\n",
        "# Filter for desired classes\n",
        "# These classes will be converted to 'human present'\n",
        "filter1 = ['Human', 'Person'] #@param\n",
        "pattern1 = '|'.join(filter1)\n",
        "\n",
        "# Remove all detections that aren't for filtered class(es)\n",
        "df.loc[~df.tag.str.contains(pattern1), 'tag'] = 'None'\n",
        "print(\"\\nNo. tags not matching filtered classes: \\n\", len(df[~df.tag.str.contains(pattern1)]))\n",
        "print(\"\\nTags not matching filtered classes: \\n\", df[~df.tag.str.contains(pattern1)])\n",
        "\n",
        "# Set all detections for 'Human' to 'Human present'\n",
        "# (Human + body, eye, head, hand, foot, face, arm, leg ear, eye, face, nose, beard)print(\"\\nNo. tags matching filtered class(es) {}: \\n{}\\n\".format(filter, len(df[df.tag.str.contains(pattern1)])))\n",
        "print(\"\\nNo. tags matching filtered class(es) {}: \\n{}\\n\".format(filter1, len(df[df.tag.str.contains(pattern1)])))\n",
        "print(\"\\nTags matching filtered class(es): \\n\", df[df.tag.str.contains(pattern1)])\n",
        "df.loc[df.tag.str.contains(pattern1), 'tag'] = 'human present'\n",
        "\n",
        "# Write results to tsv\n",
        "outpath = 'data/results/' + tags_file.rsplit('_', 1)[0] + '_final.tsv'\n",
        "df.to_csv(outpath, sep='\\t', index=False)\n",
        "print(\"\\n\\nFinal tagging file {}: \\n{}\".format(outpath, df.head()))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vmmCI1jCVNxl"
      },
      "source": [
        "## Display tagging results on images\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "7NN4fOicvcl0"
      },
      "outputs": [],
      "source": [
        "#@title Adjust start index and display up to 50 images with their tags\n",
        "# Suppress warning about too many figures opened\n",
        "plt.rcParams.update({'figure.max_open_warning': 0})\n",
        "\n",
        "# Set number of seconds to timeout if image url taking too long to open\n",
        "import socket\n",
        "socket.setdefaulttimeout(10)\n",
        "\n",
        "# Adjust start index using slider\n",
        "start = 0 #@param {type:\"slider\", min:0, max:5000, step:50}\n",
        "stop = min((start+50), len(df))\n",
        "\n",
        "# Loop through images\n",
        "for i, row in df.iloc[start:stop].iterrows():\n",
        "    try:\n",
        "        # Read in image\n",
        "        url = df['eolMediaURL'][i]\n",
        "        img = url_to_image(url)\n",
        "\n",
        "        # Fetch image tag\n",
        "        tag = df['tag'][i]\n",
        "\n",
        "        # Display progress message after each image is loaded\n",
        "        print('Successfully loaded {} of {} images'.format(i+1, (stop-start)))\n",
        "\n",
        "        # Plot image with tag\n",
        "        _, ax = plt.subplots(figsize=(10, 10))\n",
        "        ax.imshow(img)\n",
        "        plt.axis('off')\n",
        "        plt.title('{}) Tag: {}'.format(i+1, tag))\n",
        "\n",
        "    except:\n",
        "        print('Check if URL from {} is valid'.format(url))"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}