{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/aubricot/computer_vision_with_eol_images/blob/master/object_detection_for_image_tagging/human_present/human_present_generate_tags_yolov8.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j-PBcUKyc95M"
      },
      "source": [
        "# Using YOLO v8 pre-trained on Google Open Images to add human present tags to EOL images\n",
        "---\n",
        "*Last Updated 12 September 2025*  \n",
        "-Updated Sep 2025: Now runs in Python 3 with YOLOv8 pretrained on Google Open Images v7-   \n",
        "\n",
        "Using a [YOLOv8 Nano](https://yolov8.com/) trained on [Open Images V7](https://docs.ultralytics.com/datasets/detect/open-images-v7) as a method to do customized, large-scale image processing. EOL Chiroptera (bat) images will be tagged for human(s) present (body, eye, head, hand, foot, face, arm, leg ear, eye, face, nose, beard) using object detection. Tags will further extend EOLv3 image search functions.\n",
        "\n",
        "Notes:   \n",
        "* Run code blocks by pressing play button in brackets on left\n",
        "* Change parameters using form fields on right (find details at corresponding lines of code by searching '#@param')\n",
        "\n",
        "References:   \n",
        "* Code modified from the [Ultralytics YOLOv8 tutorial](https://docs.ultralytics.com/datasets/detect/open-images-v7)\n",
        "* Check out the [Ultralytics YOLO repo](https://github.com/ultralytics/ultralytics) for more documetation and tutorials"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fX9LGz3Ydu27"
      },
      "source": [
        "## Installs & Imports\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q5lC8PSbGCyN"
      },
      "outputs": [],
      "source": [
        "#@title Choose where to save results\n",
        "import os\n",
        "\n",
        "# Use dropdown menu on right\n",
        "save = \"in Colab runtime (files deleted after each session)\" #@param [\"in my Google Drive\", \"in Colab runtime (files deleted after each session)\"]\n",
        "\n",
        "# TO DO: Define filter classes\n",
        "filter_classes = ['Human', 'Person'] #@param\n",
        "\n",
        "# Mount google drive to export image tagging file(s)\n",
        "if 'Google Drive' in save:\n",
        "    from google.colab import drive\n",
        "    drive.mount('/content/drive', force_remount=True)\n",
        "\n",
        "# Download helper_funcs folder\n",
        "!pip3 -q install --upgrade gdown\n",
        "!gdown 1yCB9SH5vJmleW84A3k7qVlkwpupp2F1q\n",
        "!tar -xzvf helper_funcs_yolov8.tar.gz -C .\n",
        "\n",
        "# Set up directory structure\n",
        "from setup import *\n",
        "cwd, basewd = setup_dirs() # Optional: specify basewd and folder to build your own pipelines"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yDdbBYnp2nCK"
      },
      "outputs": [],
      "source": [
        "#@title Import libraries\n",
        "!uv pip install ultralytics\n",
        "import ultralytics\n",
        "ultralytics.checks()\n",
        "from ultralytics import YOLO\n",
        "import os\n",
        "\n",
        "# Load the pretrained model (YOLOv8 Nano trained on Open Images V7)\n",
        "model = YOLO(\"yolov8n-oiv7.pt\")\n",
        "\n",
        "# For importing/exporting files, working with arrays, etc\n",
        "import glob\n",
        "import pathlib\n",
        "import sys\n",
        "import tarfile\n",
        "import zipfile\n",
        "import numpy as np\n",
        "import csv\n",
        "import time\n",
        "import pandas as pd\n",
        "import urllib.request\n",
        "\n",
        "# For drawing onto and plotting images\n",
        "import matplotlib.pyplot as plt\n",
        "import cv2\n",
        "%matplotlib inline\n",
        "%config InlineBackend.figure_format = 'svg'\n",
        "sys.path.append('/content')\n",
        "\n",
        "# Define EOL CV custom functions\n",
        "from wrangle_data import *"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cKovA4-aifP5"
      },
      "source": [
        "## Generate tags for images\n",
        "---\n",
        "Run EOL 20k image bundles through pre-trained object detection models and save results in 4 batches (A-D) of 5000 images each."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kIDpIFWsOZo5"
      },
      "outputs": [],
      "source": [
        "#@title Test: Run with sample EOL Chiroptera image (To test with your own image, upload file to data/imgs and update fn formfield)\n",
        "\n",
        "# Run with sample EOL image\n",
        "# Define image filepath and name\n",
        "fn = \"18.032f7703433402aa15bdccae63f5e94c.260x190.jpg\" #@param [\"18.032f7703433402aa15bdccae63f5e94c.260x190.jpg\"] {allow-input: true}\n",
        "img_fpath = 'data/imgs/' + fn\n",
        "\n",
        "# Download image\n",
        "%cd $cwd\n",
        "%cd data/imgs\n",
        "!gdown 10Ov02YgnjJo0gSQ0MC7B2o0WiJPl8rvN\n",
        "%cd $cwd\n",
        "\n",
        "# Run darknet and show bounding box coordinates\n",
        "results = model(img_fpath)\n",
        "\n",
        "# Display detection results\n",
        "print(\"\\nObject detection results:\")\n",
        "result_img = results[0].plot()  # returns an image (numpy array) with bounding boxes\n",
        "plt.figure(figsize=(10, 8))\n",
        "plt.imshow(cv2.cvtColor(result_img, cv2.COLOR_BGR2RGB))\n",
        "plt.axis('off')\n",
        "plt.title(\"YOLOv8 Detection Results\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wjTgajd3keAi"
      },
      "source": [
        "### Generate tags: Run inference on EOL images & save results for tagging - Run 4X for batches A-D\n",
        "Use 20K EOL Chiroptera image bundle to identify humans present. Results are saved to [tags_file].tsv. Run this section 4 times (to make batches A-D) of 5K images each to incrementally save in case of Colab timeouts."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zCxtKyRPij8R"
      },
      "outputs": [],
      "source": [
        "#@title Enter EOL image bundle and choose inference settings. Change **tags_file** for each batch A-D\n",
        "%cd $cwd\n",
        "\n",
        "# Load in EOL Chiroptera 20k image bundle\n",
        "bundle = \"https://editors.eol.org/other_files/bundle_images/files/images_for_Chiroptera_breakdown_download_000001.txt\" #@param [\"https://editors.eol.org/other_files/bundle_images/files/images_for_Chiroptera_breakdown_download_000001.txt\"] {allow-input: true}\n",
        "df = read_datafile(bundle)\n",
        "print(\"EOL image bundle with {} images: \\n{}\".format(len(df), df.head()))\n",
        "\n",
        "# Test pipeline with a smaller subset than 5k images?\n",
        "run = \"test with tiny subset\" #@param [\"test with tiny subset\", \"for all images\"]\n",
        "\n",
        "# Display detection results on images?\n",
        "display_results = \"yes (use this option if testing tiny subsets; only works for \\u003C50 images)\" #@param [\"yes (use this option if testing tiny subsets; only works for \\u003C50 images)\", \"no (use this option if running batches)\"]\n",
        "\n",
        "# Take 5k subset of bundle for running inference\n",
        "# Change filename for each batch\n",
        "tags_file = \"human_present_tags_c\" #@param [\"human_present_tags_a\", \"human_present_tags_b\", \"human_present_tags_c\", \"human_present_tags_d\"] {allow-input: true}\n",
        "tags_file = tags_file + \".txt\"\n",
        "imgs_dir = \"data/img_info/\"\n",
        "outfpath = imgs_dir + tags_file\n",
        "print(\"\\nSaving tagging results to: \\n{}\".format(outfpath))\n",
        "\n",
        "# Add 5k subset of image bundle urls as column in tags file\n",
        "start, stop, cutoff = set_start_stop(run, df)\n",
        "df = df.iloc[start:stop]\n",
        "df.columns = ['url']\n",
        "df.to_csv(outfpath, sep='\\t', index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eKUThVvV-66K"
      },
      "outputs": [],
      "source": [
        "#@title Run inference on images\n",
        "\n",
        "# Display detection results on image? (only use for <50 images)\n",
        "# TO DO: Use form field on right to select/deselect\n",
        "display_results = True #@param {type:\"boolean\"}\n",
        "\n",
        "# Save image with bounding boxes?\n",
        "# TO DO: Use form field on right to select/deselect\n",
        "save_image_wboxes = True #@param {type:\"boolean\"}\n",
        "\n",
        "print(f\"\\nNumber of valid images ready for inference: {len(df)}\")\n",
        "all_predictions = []\n",
        "for i, (idx, row) in enumerate(df.iterrows()):\n",
        "    try:\n",
        "        image_url = row['url']\n",
        "        print(\"Running infernce for image from: \", image_url)\n",
        "        img_wboxes, tag, predictions = detect_and_draw_tags(image_url, tags = filter_classes)\n",
        "        all_predictions.append(predictions)\n",
        "\n",
        "        # Plot detections on image\n",
        "        if display_results:\n",
        "            plt.figure(figsize=(10, 10))\n",
        "            plt.imshow(img_wboxes)\n",
        "            plt.axis('off')\n",
        "            plt.title(f\"Detected {tag}\")\n",
        "            plt.show()\n",
        "\n",
        "        # Save image with boxes\n",
        "        if save_image_wboxes:\n",
        "            # Convert back to BGR for saving with OpenCV\n",
        "            img_bgr = cv2.cvtColor(img_wboxes, cv2.COLOR_RGB2BGR)\n",
        "            # Define filename\n",
        "            fname = os.path.splitext(image_url.split(\"/\")[-1].split(\"?\")[0])[0]  # Get name from URL\n",
        "            fname = fname + \"_w_bboxes.jpg\"\n",
        "            # Save image\n",
        "            img_outfpath = os.path.join('/data/results', fname)\n",
        "            cv2.imwrite(img_outfpath, img_bgr)\n",
        "            print(f\"Image with bounding boxes saved to to: {img_outfpath}\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error processing {image_url}: {e}\")\n",
        "\n",
        "print(\"\\n\\n~~~\\n \\033[92m Inference complete! Post-process inference results in next code blocks before running these steps for remaining batches A-D. \\033[0m \\n~~~\")\n",
        "\n",
        "# Save rseults/bounding boxes to file\n",
        "df_preds = pd.DataFrame(all_predictions, columns=[\"url\", \"tag\", \"xmin\", \"ymin\", \"bbox_w\", \"bbox_h\", \"confidence\"])\n",
        "df_preds.to_csv(('data/results/' + os.path.splitext(os.path.basename(outfpath))[0] + '.tsv'), sep='\\t', index=False)\n",
        "print(f\"Predictions saved to: {('data/results/' + os.path.splitext(os.path.basename(outfpath))[0] + '.tsv')}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o7N0hAHDFpN_"
      },
      "source": [
        "## Combine tags from batches A-D\n",
        "---\n",
        "After running steps above for each image batch, combine tag files to one 20k tag dataset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qbm0_nfQFtkI"
      },
      "outputs": [],
      "source": [
        "#@title Define parameters for converting detected classes to desired image tags\n",
        "%cd $cwd\n",
        "\n",
        "# Write header row of output tagging file\n",
        "# Enter any filename from 4 batches of tagging files\n",
        "tags_file = \"human_present_tags_d\" #@param [\"human_present_tags_d\"] {allow-input: true}\n",
        "tags_fpath = \"data/results/\" + tags_file + \".tsv\"\n",
        "\n",
        "# Combine exported model predictions and confidence values for all batches\n",
        "df = combine_tag_files(tags_fpath)\n",
        "df['tag'] = df['tag'].astype(str)\n",
        "\n",
        "# Filter for desired classes\n",
        "# These classes will be kept as is\n",
        "filter1 = filter_classes\n",
        "pattern1 = '|'.join(filter1)\n",
        "\n",
        "# Inspect tags matching desired classes\n",
        "print(f\"\\nNo. tags matching filtered class(es) {filter1}: {len(df[df.tag.str.match(pattern1)])}\")\n",
        "print(\"\\nTags matching filtered class(es):\")\n",
        "print(df[df.tag.str.match(pattern1)].head())\n",
        "\n",
        "df.loc[df['tag'].str.match(pattern1), 'tag'] = 'Human_present'\n",
        "\n",
        "# Tag all unmatched predictions as \"None\"\n",
        "print(f\"\\nNo. tags not matching filtered classes: {len(df[~df.tag.str.match(pattern1)])}\")\n",
        "print(\"\\nTags not matching filtered classes:\")\n",
        "print(df[~df.tag.str.match(pattern1)].head())\n",
        "\n",
        "df.loc[~df['tag'].str.match(pattern1), 'tag'] = 'None'\n",
        "\n",
        "# Write results to tsv\n",
        "outpath = 'data/results/' + tags_file.rsplit('_', 1)[0] + '_final.tsv'\n",
        "df.to_csv(outpath, sep='\\t', index=False)\n",
        "print(\"\\n\\nFinal tagging file {}: \\n{}\".format(outpath, df.head()))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vmmCI1jCVNxl"
      },
      "source": [
        "## Display tagging results on images\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7NN4fOicvcl0"
      },
      "outputs": [],
      "source": [
        "#@title Adjust start index and display up to 50 images with their tags\n",
        "# Suppress warning about too many figures opened\n",
        "plt.rcParams.update({'figure.max_open_warning': 0})\n",
        "\n",
        "# Set number of seconds to timeout if image url taking too long to open\n",
        "import socket\n",
        "socket.setdefaulttimeout(10)\n",
        "\n",
        "# Adjust start index using slider\n",
        "start = 0 #@param {type:\"slider\", min:0, max:5000, step:50}\n",
        "stop = min((start+50), len(df))\n",
        "\n",
        "# Loop through images\n",
        "for i, row in df.iloc[start:stop].iterrows():\n",
        "    try:\n",
        "        # Read in image\n",
        "        url = df['url'][i]\n",
        "        img = load_image_from_url(url)\n",
        "\n",
        "        # Fetch image tag\n",
        "        tag = df['tag'][i]\n",
        "\n",
        "        # Display progress message after each image is loaded\n",
        "        print('Successfully loaded {} of {} images'.format(i+1, (stop-start)))\n",
        "\n",
        "        # Plot image with tag\n",
        "        _, ax = plt.subplots(figsize=(10, 10))\n",
        "        ax.imshow(img)\n",
        "        plt.axis('off')\n",
        "        plt.title('{} ) Tag: {}'.format(i + 1, tag))\n",
        "\n",
        "    except:\n",
        "        print('Check if URL from {} is valid'.format(url))"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}