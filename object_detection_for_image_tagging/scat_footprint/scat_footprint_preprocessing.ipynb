{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "scat_footprint_preprocessing.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "LZlJ7Rjaub3O",
        "bOJEcY_BYYjl",
        "uELne7tJrEDZ",
        "b8yUIF7PduqX",
        "PjaIMtZU7YtA",
        "Cw94uPUQ0h9V",
        "mWleD4FoU9Zn",
        "AOxjL-KOfFMw",
        "mjz7qEKO5QHv"
      ],
      "toc_visible": true,
      "authorship_tag": "ABX9TyO2m96FG7cWzkgUWIXYg9Zq",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/aubricot/computer_vision_with_eol_images/blob/master/object_detection_for_image_tagging/scat_footprint/scat_footprint_preprocessing.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WGFNOrAs0pMf"
      },
      "source": [
        "# Pre-process Scat/Footprint Detector Training Images\n",
        "---\n",
        "*Last Updated 23 February 2021*   \n",
        "Follow steps below to download images from iNaturalist observation bundles to Google Drive, then perform image augmentation on them, and last move files to their appropriate folders for use training scat/footprint detection models.     \n",
        "\n",
        "**Notes**\n",
        "* Change filepaths or information using the form fields to the right of code blocks (also noted in code with 'TO DO')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F53iiacTFVz7"
      },
      "source": [
        "### Connect to Google Drive\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MeNoVQDN0I1q"
      },
      "source": [
        "# Mount google drive to import/export files\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lxIUuGkDa__r"
      },
      "source": [
        "# Imports and Installs\n",
        "import os\n",
        "import pandas as pd"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LZlJ7Rjaub3O"
      },
      "source": [
        "### 1) Build image bundles\n",
        "---\n",
        "Bundles were downloaded from iNaturalist under \"Explore\" for all terrestrial vertebrate taxa (no fish) with all creative commons licenses and the keywords \"scat\" or \"footprint\""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s67Ly5pmL6LD"
      },
      "source": [
        "# Unzip iNaturalist image bundles\n",
        "%cd /content/drive/My Drive/spr21/classification/scat_footprint/images\n",
        "#!unzip '*.zip' -d .\n",
        "#!rm ./*.zip\n",
        "\n",
        "# Read in unzipped iNaturalist image bundles for CC0 and CC-BY exports\n",
        "# For scat\n",
        "num = '128689'\n",
        "fn = 'observations-' + num + '.csv'\n",
        "dfs = pd.read_csv(fn, sep=',', header=0, na_filter = False)\n",
        "print(\"Total number of training images for scat: \\n {}\".format(len(dfs)))\n",
        "\n",
        "# For footprint\n",
        "num = '128749'\n",
        "fn = 'observations-' + num + '.csv'\n",
        "dff = pd.read_csv(fn, sep=',', header=0, na_filter = False)\n",
        "print(\"Total number of training images for footprint: \\n {}\".format(len(dff)))\n",
        "\n",
        "# Write combined bundles to file for each training class\n",
        "#!mkdir scat\n",
        "#!mkdir footprint\n",
        "dfs['image_url'].to_csv('scat_imgs.txt', sep='\\n', index=False, header=False)\n",
        "dff['image_url'].to_csv('footprint_imgs.txt', sep='\\n', index=False, header=False)\n",
        "\n",
        "# Take 1200 images from each bundle to use for training\n",
        "import os\n",
        "import pandas as pd\n",
        "\n",
        "# Bundle filenames\n",
        "classes = ['scat', 'footprint']\n",
        "fns = [clas + '_imgs.txt' for clas in classes] # Bulk image filenames\n",
        "fns_subset = [clas + '/' + clas + '_download_subset.txt' for clas in classes] # Future n=1200 image bundle filenames\n",
        "print(fns)\n",
        "\n",
        "# Take the first 1200 images (best rated) for each class and write to csv\n",
        "for num, f in enumerate(fns):\n",
        "  df = pd.read_table(f, sep='\\n')\n",
        "  bundle = df.head(1200)\n",
        "  fn = str(fns_subset[num])\n",
        "  print(fn)\n",
        "  print(bundle.head())\n",
        "  bundle.to_csv(fn, sep='\\n', index=False, header=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bOJEcY_BYYjl"
      },
      "source": [
        "### 2) Download images to Google Drive\n",
        "---\n",
        "Run all steps once per rating class 1-5. Where you see 'TO DO' (3 places), change number to match rating class each time you run "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xRYy0cCAI_6n"
      },
      "source": [
        "# Install aria2 for downloading images in parallel\n",
        "!apt-get install aria2"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yZIZpuuwOhaD"
      },
      "source": [
        "# Download scat images \r\n",
        "%cd /content/drive/My Drive/spr21/classification/scat_footprint/images\r\n",
        "%cd scat \r\n",
        "!aria2c -x 16 -s 1 -i \"scat_download_subset.txt\"\r\n",
        "# Check how many images downloaded\r\n",
        "print(\"Number of images downloaded to Google Drive: \")\r\n",
        "!ls . | wc -l"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H1FEL48SOxdP"
      },
      "source": [
        "# Download footprint images \r\n",
        "%cd /content/drive/My Drive/spr21/classification/scat_footprint/images\r\n",
        "%cd footprint \r\n",
        "!aria2c -x 16 -s 1 -i \"footprint_download_subset.txt\"\r\n",
        "# Check how many images downloaded\r\n",
        "print(\"Number of images downloaded to Google Drive: \")\r\n",
        "!ls . | wc -l"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7y1GZ-IRKVnz"
      },
      "source": [
        "# Move text file to image_data/bundles\n",
        "%cd /content/drive/My Drive/spr21/classification/scat_footprint\n",
        "#!mkdir -p image_data/bundles\n",
        "#!mv images/*.csv image_data/bundles/\n",
        "#!mv images/*.txt image_data/bundles/\n",
        "#!mv images/**/*.txt image_data/bundles/"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uELne7tJrEDZ"
      },
      "source": [
        "### 3) Delete all downloaded non-image files\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bTPAxR5V-wTm"
      },
      "source": [
        "from os import listdir\n",
        "from PIL import Image\n",
        "Image.MAX_IMAGE_PIXELS = 95000000 # To suppress errors from Pillow about decompression bombs\n",
        "import io\n",
        "import os\n",
        "\n",
        "# Scat\n",
        "%cd /content/drive/My Drive/spr21/objdet/scat_footprint/images/scat\n",
        "# Loop through downloaded files and delete non-images\n",
        "for num, path in enumerate(listdir('./'), start=1):\n",
        "  with open(path, 'rb') as f:\n",
        "    try:\n",
        "      img = Image.open(io.BytesIO(f.read()))\n",
        "      img.verify() # verify that it is an image\n",
        "      if len(str(os.path.splitext(path)[1])) < 3:\n",
        "        newpath = str(num) + '.jpg' # add jpg extension to image files without exts \n",
        "      else:\n",
        "        newpath = str(num) + str(os.path.splitext(path)[1]) # make sure all filenames and exts are unique \n",
        "      os.rename(path, newpath)\n",
        "    except (IOError, SyntaxError) as e:\n",
        "      print('Bad file:', filename)\n",
        "      if '(' in filename: # rm doesn't work for files with parenthesis in name, need to manually remove\n",
        "        print(\"Manually remove from Google Drive: {}\".format(filename)) \n",
        "      else:\n",
        "        !rm $filename\n",
        "newstart = int(num)\n",
        "print(\"Number of images in scat after non-image files removed: \")\n",
        "!ls . | wc -l\n",
        "\n",
        "# Footprint\n",
        "%cd /content/drive/My Drive/spr21/objdet/scat_footprint/images/footprint\n",
        "# Loop through downloaded files and delete non-images\n",
        "for num, path in enumerate(listdir('./'), start=newstart):\n",
        "  with open(path, 'rb') as f:\n",
        "    try:\n",
        "      img = Image.open(io.BytesIO(f.read()))\n",
        "      img.verify() # verify that it is an image\n",
        "      if len(str(os.path.splitext(path)[1])) < 3:\n",
        "        newpath = str(num) + '.jpg' # add jpg extension to image files without exts \n",
        "      else:\n",
        "        newpath = str(num) + str(os.path.splitext(path)[1]) # make sure all filenames and exts are unique \n",
        "      os.rename(path, newpath)\n",
        "    except (IOError, SyntaxError) as e:\n",
        "      print('Bad file:', filename)\n",
        "      if '(' in filename: # rm doesn't work for files with parenthesis in name, need to manually remove\n",
        "        print(\"Manually remove from Google Drive: {}\".format(filename)) \n",
        "      else:\n",
        "        !rm $filename\n",
        "\n",
        "print(\"Number of images in footprint after non-image files removed: \")\n",
        "!ls . | wc -l"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b8yUIF7PduqX"
      },
      "source": [
        "### 4) Make number of images per class even\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NJXH0UnYeav5"
      },
      "source": [
        "%cd /content/drive/My Drive/spr21/objdet/scat_footprint/images\n",
        "\n",
        "# Randomly delete all but 600 images from scat and footprint folders\n",
        "#!find \"scat\" -type f -print0 | sort -zR | tail -zn +601 | xargs -0 rm\n",
        "#!find \"footprint\" -type f -print0 | sort -zR | tail -zn +601 | xargs -0 rm\n",
        "\n",
        "print(\"Final number of scat images:\")\n",
        "!ls /content/drive/'My Drive'/spr21/objdet/scat_footprint/images/scat | wc -l\n",
        "print(\"Final number of footprint images:\")\n",
        "!ls /content/drive/'My Drive'/spr21/objdet/scat_footprint/images/footprint | wc -l"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PjaIMtZU7YtA"
      },
      "source": [
        "### 5) Zip image folders for download to local machine and annotation with labelImg\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0e66cIn8nqrC"
      },
      "source": [
        "!zip -r \"/content/drive/My Drive/spr21/objdet/scat_footprint/images_fordl.zip\" \"/content/drive/My Drive/spr21/objdet/scat_footprint/images\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Cw94uPUQ0h9V"
      },
      "source": [
        "### 6) Upload zipped images and annotations to Google Drive and resume here\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mSQS2HcV6UTj"
      },
      "source": [
        "# Images\n",
        "!unzip /content/drive/'My Drive'/spr21/objdet/scat_footprint/images_foranns.zip -d /content/drive/'My Drive'/train/images"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rWauDNiiN8mZ"
      },
      "source": [
        "# Delete Mac OS file from subfolders\n",
        "%cd /content/drive/'My Drive'/train/images\n",
        "!find . -name \"*.DS_Store\" -type f -delete"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5D986WR803pQ"
      },
      "source": [
        "# Annotations\n",
        "!unzip /content/drive/'My Drive'/spr21/objdet/scat_footprint/annotations.zip -d /content/drive/'My Drive'/train/darkflow-master/test/training/annotations"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PiPFb1x02Gmu"
      },
      "source": [
        "# Move all xml files from subfolds to main annotations folder\n",
        "!mv -v /content/drive/'My Drive'/train/darkflow-master/test/training/annotations/annotations/scat/* /content/drive/'My Drive'/train/darkflow-master/test/training/annotations\n",
        "!mv -v /content/drive/'My Drive'/train/darkflow-master/test/training/annotations/annotations/footprint/* /content/drive/'My Drive'/train/darkflow-master/test/training/annotations"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wItNeAOGBEd7"
      },
      "source": [
        "# Remove empty folders from uploaded labelImg zipped files\n",
        "%cd /content/drive/'My Drive'/train/darkflow-master/test/training/annotations/\n",
        "!rm -r */"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0iG5MkuvOJAw"
      },
      "source": [
        "# Delete Mac OS file from subfolders\n",
        "%cd /content/drive/'My Drive'/train/darkflow-master/test/training/annotations\n",
        "!find . -name \"*.DS_Store\" -type f -delete"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qq091EbQejET"
      },
      "source": [
        "print(\"Final number of scat images:\")\n",
        "!ls /content/drive/'My Drive'/train/images/images/scat | wc -l\n",
        "print(\"Final number of footprint images:\")\n",
        "!ls /content/drive/'My Drive'/train/images/images/footprint | wc -l\n",
        "\n",
        "print(\"Final number of annotations:\")\n",
        "!ls /content/drive/'My Drive'/train/darkflow-master/test/training/annotations | wc -l"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JqEjJeRLK12A"
      },
      "source": [
        "### 7) Prepare Train and Test image datasets\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mWleD4FoU9Zn"
      },
      "source": [
        "#### A) 80/20 split into Train/Test"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uPtEYkDaK6NL"
      },
      "source": [
        "import os\n",
        "import random\n",
        "import shutil\n",
        "\n",
        "# Take subset of un-augmented images\n",
        "# TO DO: Run 1x per class\n",
        "base = '/content/drive/My Drive/train/images/'\n",
        "imclass = \"footprint/\" #@param [\"scat/\", \"footprint/\"]\n",
        "path = base + 'images/' + imclass\n",
        "files = []\n",
        "for fname in os.listdir(path):\n",
        "    files.append(fname)\n",
        "\n",
        "# Select 20% of unaugmented images to use for testing the trained model\n",
        "print(\"Number of images in class\", imclass, len(files))\n",
        "subset = int(0.2*(len(files)*2))\n",
        "print(\"20% of images in class to be used for testing:\", subset)\n",
        "test_imgs = random.sample(files, subset)\n",
        "\n",
        "# Move test images to train/test_images/\n",
        "test_dir = '/content/drive/My Drive/train/test_images'\n",
        "\n",
        "mv_imgs = []\n",
        "for file in test_imgs:\n",
        "  name = os.path.join(path, file)\n",
        "  if os.path.isfile(name):\n",
        "      shutil.move(name, test_dir)\n",
        "      print('successfully moved {} to {}'.format(name, test_dir))\n",
        "      mv_imgs.append(name)\n",
        "      #print('files already moved, un-comment out 27 to run with new images')\n",
        "  else:\n",
        "      print('file does not exist', name)\n",
        "\n",
        "print(\"Number of images moved to test_images/:\", len(mv_imgs))\n",
        "print(\"New number of test images:\")\n",
        "!ls /content/drive/'My Drive'/train/test_images | wc -l"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "72A5xgwgjWlq"
      },
      "source": [
        "# Move training images to train/images/\n",
        "!mv -v /content/drive/'My Drive'/train/images/images/footprint/* /content/drive/'My Drive'/train/images\n",
        "!mv -v /content/drive/'My Drive'/train/images/images/scat/* /content/drive/'My Drive'/train/images\n",
        "\n",
        "print(\"Number of train images before augmentation:\")\n",
        "!ls /content/drive/'My Drive'/train/images | wc -l"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TG21DYBkDlfm"
      },
      "source": [
        "# Remove extra folders from uploaded labelImg zipped files\n",
        "%cd /content/drive/'My Drive'/train/images/\n",
        "!rm -r */"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W_pueihmYKQD"
      },
      "source": [
        "!ls -a -l /content/drive/'My Drive'/train/images/"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TsIH4lcXVDzK"
      },
      "source": [
        "# Move matching 20% of test annotations to the appropriate folder\n",
        "ann_dir = '/content/drive/My Drive/train/darkflow-master/test/training/annotations/'\n",
        "test_dir = '/content/drive/My Drive/train/test_images/'\n",
        "testann_dir = '/content/drive/My Drive/train/test_ann/'\n",
        "files = os.listdir(test_dir)\n",
        "\n",
        "# Find xml files matching test images and move to test_ann/\n",
        "for file in files:\n",
        "  base = os.path.splitext(os.path.basename(file))[0]\n",
        "  test_xml = ann_dir + base + '.xml'\n",
        "  if os.path.exists(test_xml):\n",
        "    #shutil.move(test_xml, testann_dir)\n",
        "    print(\"moved {} to test_ann\".format(file))\n",
        "    #print(\"matching xmls already moved, un-comment out line 12 to run for new anns\")\n",
        "  else:\n",
        "    print(\"!!!xml missing for image {}\".format(file))\n",
        "    #os.remove(file)\n",
        "\n",
        "print(\"Number of test images:\")\n",
        "!ls /content/drive/'My Drive'/train/test_images | wc -l\n",
        "\n",
        "print(\"Number of test annotations:\")\n",
        "!ls /content/drive/'My Drive'/train/test_ann | wc -l"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bd0PlNaYEJAq"
      },
      "source": [
        "# Check that all train images have corresponding annotation\n",
        "ann_dir = '/content/drive/My Drive/train/darkflow-master/test/training/annotations/'\n",
        "train_dir = '/content/drive/My Drive/train/images/'\n",
        "files = os.listdir(train_dir)\n",
        "\n",
        "# Loop through train images to see if xml for each one\n",
        "for file in files:\n",
        "  base = os.path.splitext(os.path.basename(file))[0]\n",
        "  train_xml = ann_dir + base + '.xml'\n",
        "  if os.path.exists(train_xml):\n",
        "    print(\"xml exists for {}\".format(file))\n",
        "  else:\n",
        "    print(\"!!!xml missing for image {}\".format(file))\n",
        "    #os.remove(file)\n",
        "\n",
        "print(\"Number of train images:\")\n",
        "!ls /content/drive/'My Drive'/train/images | wc -l\n",
        "\n",
        "print(\"Number of train annotations:\")\n",
        "!ls /content/drive/'My Drive'/train/darkflow-master/test/training/annotations/ | wc -l"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AOxjL-KOfFMw"
      },
      "source": [
        "#### B) Augment images and bounding boxes\n",
        "Some code modified from https://github.com/asetkn/Tutorial-Image-and-Multiple-Bounding-Boxes-Augmentation-for-Deep-Learning-in-4-Steps/blob/master/Tutorial-Image-and-Multiple-Bounding-Boxes-Augmentation-for-Deep-Learning-in-4-Steps.ipynb"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5TWR_RcVlN8F"
      },
      "source": [
        "# Change to your training directory within Google Drive\n",
        "%cd /content/drive/My Drive/train\n",
        "\n",
        "# For importing/exporting files, working with arrays, xmls, etc\n",
        "import pathlib\n",
        "import os\n",
        "import glob\n",
        "import re\n",
        "import imageio\n",
        "import time\n",
        "import csv\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import xml.etree.ElementTree as ET\n",
        "import shutil\n",
        "\n",
        "# For augmenting the images and bounding boxes\n",
        "!pip install imgaug\n",
        "!pip install pillow\n",
        "import imgaug as ia\n",
        "import imgaug.augmenters as iaa\n",
        "from imgaug.augmentables.bbs import BoundingBox, BoundingBoxesOnImage\n",
        "\n",
        "# For drawing onto and plotting the images\n",
        "import matplotlib.pyplot as plt\n",
        "import cv2\n",
        "%config InlineBackend.figure_format = 'svg'\n",
        "%matplotlib inline"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KjQD7RU0ajsC"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GBmjB8oiqEtT"
      },
      "source": [
        "#### Run all steps B1-B4 below in a row 1x for Train and 1x for Test images"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "284hddFRbjHY"
      },
      "source": [
        "B1) Load in, inspect, and convert image and bounding box files to prep for augmentation and future use with Tensorflow"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TsB2s1QNfK3Z"
      },
      "source": [
        "## TO DO: Run 1x for Train and Test images\n",
        "imtype = \"test\" #@param [\"train\", \"test\"]\n",
        "\n",
        "if imtype == \"train\":\n",
        "  path = 'images/*'\n",
        "  annpath = '/content/drive/My Drive/train/darkflow-master/test/training/annotations/'\n",
        "else:\n",
        "  path = 'test_images/*'\n",
        "  annpath = '/content/drive/My Drive/train/test_ann/'\n",
        "\n",
        "# Images\n",
        "# Load images as numpy arrays and append them to images list\n",
        "images = []\n",
        "for index, file in enumerate(glob.glob(path)):\n",
        "    images.append(imageio.imread(file))\n",
        "    \n",
        "# Count total training images before augmentation\n",
        "print('Total training images: {}'.format(len(images)))\n",
        "\n",
        "# Inspect two images\n",
        "ia.imshow(images[2])\n",
        "ia.imshow(images[7])\n",
        "\n",
        "# Annotations\n",
        "# See 5 annotation filenames (that match image file names)\n",
        "for index, file in enumerate(glob.glob(annpath + '/*.xml')[:5]):\n",
        "    print(os.path.basename(file))\n",
        "\n",
        "# Inspect an xml file\n",
        "# Notice there are multiple bounding boxes of footprints\n",
        "#shutil.copy('/content/drive/My Drive/train/test_ann/638.xml', '/content/638.txt')\n",
        "#ann_text = open(\"/content/638.txt\", \"r\")\n",
        "#print(ann_text.read())\n",
        "#ann_text.close()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8O7stl0VqXMg"
      },
      "source": [
        "# Function that will extract column data for our CSV file\n",
        "# From https://github.com/datitran/raccoon_dataset/blob/master/xml_to_csv.py\n",
        "def xml_to_csv(path):\n",
        "    xml_list = []\n",
        "    for xml_file in glob.glob(path + '/*.xml'):\n",
        "        tree = ET.parse(xml_file)\n",
        "        root = tree.getroot()\n",
        "        for member in root.findall('object'):\n",
        "            value = (root.find('filename').text,\n",
        "                     int(root.find('size')[0].text),\n",
        "                     int(root.find('size')[1].text),\n",
        "                     member[0].text,\n",
        "                     int(member[4][0].text),\n",
        "                     int(member[4][1].text),\n",
        "                     int(member[4][2].text),\n",
        "                     int(member[4][3].text)\n",
        "                     )\n",
        "            xml_list.append(value)\n",
        "    column_name = ['filename', 'width', 'height', 'class', 'xmin', 'ymin', 'xmax', 'ymax']\n",
        "    xml_df = pd.DataFrame(xml_list, columns=column_name)\n",
        "    return xml_df\n",
        "\n",
        "# Convert xml annotations to labels.csv\n",
        "labels = xml_to_csv(annpath)\n",
        "\n",
        "if imtype == \"train\":\n",
        "  labels.to_csv(('pre-processing/train_labels_notaug.csv'), index=None)\n",
        "  #pass\n",
        "else:\n",
        "  labels.to_csv(('pre-processing/test_labels_notaug.csv'), index=None)\n",
        "  #pass\n",
        "\n",
        "print('Successfully converted xmls to csv')\n",
        "labels\n",
        "\n",
        "if imtype == \"train\":\n",
        "  print(\"Number of train images:\")\n",
        "  !sudo ls /content/drive/'My Drive'/train/images | wc -l\n",
        "else:\n",
        "  print(\"Number of test images:\")\n",
        "  !sudo ls /content/drive/'My Drive'/train/test_images | wc -l\n",
        "\n",
        "print(\"Number of files with annotations in labels csv:\")\n",
        "print(len(labels.groupby('filename')))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pq01xCEvlwr1"
      },
      "source": [
        "# Optional: Only run in case mismatch in images in folder and images in labels csv\n",
        "from os import listdir\n",
        "from os.path import isfile, join\n",
        "path = '/content/drive/My Drive/train/test_ann'\n",
        "fns_orig = [f for f in listdir(path) if isfile(join(path, f))]\n",
        "non_fns = [f for f in listdir(path) if not isfile(join(path, f))]\n",
        "df = pd.read_csv('pre-processing/test_labels_notaug.csv')\n",
        "fns_csv = df.filename.unique()\n",
        "print(len(fns_orig))\n",
        "print(len(fns_csv))\n",
        "print(non_fns)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mjz7qEKO5QHv"
      },
      "source": [
        "#### B2) Resize images to make training faster"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nygIBirM7NMv"
      },
      "source": [
        "# to resize the images we create two augmenters\n",
        "# one is used when the image height is more than 600px and the other when the width is more than 600px\n",
        "height_resize = iaa.Sequential([ \n",
        "    iaa.Resize({\"height\": 600, \"width\": 'keep-aspect-ratio'})\n",
        "])\n",
        "\n",
        "width_resize = iaa.Sequential([ \n",
        "    iaa.Resize({\"height\": 'keep-aspect-ratio', \"width\": 600})\n",
        "])\n",
        "\n",
        "# function to convert BoundingBoxesOnImage object into DataFrame\n",
        "def bbs_obj_to_df(bbs_object):\n",
        "#     convert BoundingBoxesOnImage object into array\n",
        "    bbs_array = bbs_object.to_xyxy_array()\n",
        "#     convert array into a DataFrame ['xmin', 'ymin', 'xmax', 'ymax'] columns\n",
        "    df_bbs = pd.DataFrame(bbs_array, columns=['xmin', 'ymin', 'xmax', 'ymax'])\n",
        "    return df_bbs\n",
        "\n",
        "def resize_imgaug(df, images_path, aug_images_path, image_prefix):\n",
        "    # create data frame which we're going to populate with augmented image info\n",
        "    aug_bbs_xy = pd.DataFrame(columns=\n",
        "                              ['filename','width','height','class', 'xmin', 'ymin', 'xmax', 'ymax']\n",
        "                             )\n",
        "    grouped = df.groupby('filename')    \n",
        "    \n",
        "    for filename in df['filename'].unique():\n",
        "    #   Get separate data frame grouped by file name\n",
        "        group_df = grouped.get_group(filename)\n",
        "        group_df = group_df.reset_index()\n",
        "        group_df = group_df.drop(['index'], axis=1)\n",
        "        \n",
        "    #   The only difference between if and elif statements below is the use of height_resize and width_resize augmentors\n",
        "    #   deffined previously.\n",
        "\n",
        "    #   If image height is greater than or equal to image width \n",
        "    #   AND greater than 600px perform resizing augmentation shrinking image height to 600px.\n",
        "        if group_df['height'].unique()[0] >= group_df['width'].unique()[0] and group_df['height'].unique()[0] > 600:\n",
        "        #   read the image\n",
        "            image = imageio.imread(images_path+filename)\n",
        "        #   get bounding boxes coordinates and write into array        \n",
        "            bb_array = group_df.drop(['filename', 'width', 'height', 'class'], axis=1).values\n",
        "        #   pass the array of bounding boxes coordinates to the imgaug library\n",
        "            bbs = BoundingBoxesOnImage.from_xyxy_array(bb_array, shape=image.shape)\n",
        "        #   apply augmentation on image and on the bounding boxes\n",
        "            image_aug, bbs_aug = height_resize(image=image, bounding_boxes=bbs)\n",
        "        #   write augmented image to a file\n",
        "            imageio.imwrite(aug_images_path+image_prefix+filename, image_aug)  \n",
        "        #   create a data frame with augmented values of image width and height\n",
        "            info_df = group_df.drop(['xmin', 'ymin', 'xmax', 'ymax'], axis=1)        \n",
        "            for index, _ in info_df.iterrows():\n",
        "                info_df.at[index, 'width'] = image_aug.shape[1]\n",
        "                info_df.at[index, 'height'] = image_aug.shape[0]\n",
        "        #   rename filenames by adding the predifined prefix\n",
        "            info_df['filename'] = info_df['filename'].apply(lambda x: image_prefix+x)\n",
        "        #   create a data frame with augmented bounding boxes coordinates using the function we created earlier\n",
        "            bbs_df = bbs_obj_to_df(bbs_aug)\n",
        "        #   concat all new augmented info into new data frame\n",
        "            aug_df = pd.concat([info_df, bbs_df], axis=1)\n",
        "        #   append rows to aug_bbs_xy data frame\n",
        "            aug_bbs_xy = pd.concat([aug_bbs_xy, aug_df])\n",
        "            \n",
        "    #   if image width is greater than image height \n",
        "    #   AND greater than 600px perform resizing augmentation shrinking image width to 600px\n",
        "        elif group_df['width'].unique()[0] > group_df['height'].unique()[0] and group_df['width'].unique()[0] > 600:\n",
        "        #   read the image\n",
        "            image = imageio.imread(images_path+filename)\n",
        "        #   get bounding boxes coordinates and write into array        \n",
        "            bb_array = group_df.drop(['filename', 'width', 'height', 'class'], axis=1).values\n",
        "        #   pass the array of bounding boxes coordinates to the imgaug library\n",
        "            bbs = BoundingBoxesOnImage.from_xyxy_array(bb_array, shape=image.shape)\n",
        "        #   apply augmentation on image and on the bounding boxes\n",
        "            image_aug, bbs_aug = width_resize(image=image, bounding_boxes=bbs)\n",
        "        #   write augmented image to a file\n",
        "            imageio.imwrite(aug_images_path+image_prefix+filename, image_aug)  \n",
        "        #   create a data frame with augmented values of image width and height\n",
        "            info_df = group_df.drop(['xmin', 'ymin', 'xmax', 'ymax'], axis=1)        \n",
        "            for index, _ in info_df.iterrows():\n",
        "                info_df.at[index, 'width'] = image_aug.shape[1]\n",
        "                info_df.at[index, 'height'] = image_aug.shape[0]\n",
        "        #   rename filenames by adding the predifined prefix\n",
        "            info_df['filename'] = info_df['filename'].apply(lambda x: image_prefix+x)\n",
        "        #   create a data frame with augmented bounding boxes coordinates using the function we created earlier\n",
        "            bbs_df = bbs_obj_to_df(bbs_aug)\n",
        "        #   concat all new augmented info into new data frame\n",
        "            aug_df = pd.concat([info_df, bbs_df], axis=1)\n",
        "        #   append rows to aug_bbs_xy data frame\n",
        "            aug_bbs_xy = pd.concat([aug_bbs_xy, aug_df])\n",
        "\n",
        "    #     append image info without any changes if it's height and width are both less than 600px \n",
        "        else:\n",
        "            aug_bbs_xy = pd.concat([aug_bbs_xy, group_df])\n",
        "    # return dataframe with updated images and bounding boxes annotations \n",
        "    aug_bbs_xy = aug_bbs_xy.reset_index()\n",
        "    aug_bbs_xy = aug_bbs_xy.drop(['index'], axis=1)\n",
        "    return aug_bbs_xy\n",
        "\n",
        "# Save resized images and bounding boxes to file\n",
        "if imtype == \"train\":\n",
        "  resized_df = resize_imgaug(labels, 'images/', 'images/', '')\n",
        "  resized_df\n",
        "  resized_df.to_csv('pre-processing/train_labels_notaug_rsz.csv', index=False)\n",
        "\n",
        "else:\n",
        "  resized_df = resize_imgaug(labels, 'test_images/', 'test_images/', '')\n",
        "  resized_df\n",
        "  resized_df.to_csv('pre-processing/test_labels_notaug_rsz.csv', index=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LwqF5jCS8hdV"
      },
      "source": [
        "#### B3) Actual augmentation of images and bounding boxes"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cEzpQstT8jrw"
      },
      "source": [
        "# Set up augmentation parameters and augment images\n",
        "aug = iaa.SomeOf(2, [    \n",
        "    iaa.Affine(scale=(0.5, 1.5)),\n",
        "    iaa.Affine(rotate=(-60, 60)),\n",
        "    iaa.Affine(translate_percent={\"x\": (-0.3, 0.3), \"y\": (-0.3, 0.3)}),\n",
        "    iaa.Fliplr(1),\n",
        "    iaa.Multiply((0.5, 1.5)),\n",
        "    iaa.GaussianBlur(sigma=(1.0, 3.0)),\n",
        "    iaa.AdditiveGaussianNoise(scale=(0.03*255, 0.05*255))\n",
        "])\n",
        "\n",
        "def image_aug(df, images_path, aug_images_path, image_prefix, augmentor):\n",
        "    # create data frame which we're going to populate with augmented image info\n",
        "    aug_bbs_xy = pd.DataFrame(columns=\n",
        "                              ['filename','width','height','class', 'xmin', 'ymin', 'xmax', 'ymax']\n",
        "                             )\n",
        "    grouped = df.groupby('filename')\n",
        "    \n",
        "    for filename in df['filename'].unique():\n",
        "    #   get separate data frame grouped by file name\n",
        "        group_df = grouped.get_group(filename)\n",
        "        group_df = group_df.reset_index()\n",
        "        group_df = group_df.drop(['index'], axis=1)   \n",
        "    #   read the image\n",
        "        image = imageio.imread(images_path+filename)\n",
        "    #   get bounding boxes coordinates and write into array        \n",
        "        bb_array = group_df.drop(['filename', 'width', 'height', 'class'], axis=1).values\n",
        "    #   pass the array of bounding boxes coordinates to the imgaug library\n",
        "        bbs = BoundingBoxesOnImage.from_xyxy_array(bb_array, shape=image.shape)\n",
        "    #   apply augmentation on image and on the bounding boxes\n",
        "        image_aug, bbs_aug = augmentor(image=image, bounding_boxes=bbs)\n",
        "    #   disregard bounding boxes which have fallen out of image pane    \n",
        "        bbs_aug = bbs_aug.remove_out_of_image()\n",
        "    #   clip bounding boxes which are partially outside of image pane\n",
        "        bbs_aug = bbs_aug.clip_out_of_image()\n",
        "        \n",
        "    #   don't perform any actions with the image if there are no bounding boxes left in it    \n",
        "        if re.findall('Image...', str(bbs_aug)) == ['Image([]']:\n",
        "            pass\n",
        "        \n",
        "    #   otherwise continue\n",
        "        else:\n",
        "        #   write augmented image to a file\n",
        "            imageio.imwrite(aug_images_path+image_prefix+filename, image_aug)  \n",
        "        #   create a data frame with augmented values of image width and height\n",
        "            info_df = group_df.drop(['xmin', 'ymin', 'xmax', 'ymax'], axis=1)    \n",
        "            for index, _ in info_df.iterrows():\n",
        "                info_df.at[index, 'width'] = image_aug.shape[1]\n",
        "                info_df.at[index, 'height'] = image_aug.shape[0]\n",
        "        #   rename filenames by adding the predifined prefix\n",
        "            info_df['filename'] = info_df['filename'].apply(lambda x: image_prefix+x)\n",
        "        #   create a data frame with augmented bounding boxes coordinates using the function we created earlier\n",
        "            bbs_df = bbs_obj_to_df(bbs_aug)\n",
        "        #   concat all new augmented info into new data frame\n",
        "            aug_df = pd.concat([info_df, bbs_df], axis=1)\n",
        "        #   append rows to aug_bbs_xy data frame\n",
        "            aug_bbs_xy = pd.concat([aug_bbs_xy, aug_df])            \n",
        "    \n",
        "    # return dataframe with updated images and bounding boxes annotations \n",
        "    aug_bbs_xy = aug_bbs_xy.reset_index()\n",
        "    aug_bbs_xy = aug_bbs_xy.drop(['index'], axis=1)\n",
        "    return aug_bbs_xy\n",
        "\n",
        "# Apply augmentation to our images and save files into 'aug_images/' folder with 'aug_' prefix.\n",
        "# Write the updated images and bounding boxes annotations to the augmented_images_df dataframe.\n",
        "if imtype == \"train\":\n",
        "  augmented_df = image_aug(resized_df, 'images/', 'images/', 'aug_', aug)\n",
        "\n",
        "else:\n",
        "  augmented_df = image_aug(resized_df, 'test_images/', 'test_images/', 'aug_', aug)\n",
        "\n",
        "print(augmented_df)\n",
        "\n",
        "# Save augmented images and bounding boxes to file\n",
        "all_labels_df = pd.concat([resized_df, augmented_df])\n",
        "\n",
        "if imtype == \"train\":\n",
        "  all_labels_df.to_csv('pre-processing/train_labels_augall.csv', index=False)\n",
        "  #pass\n",
        "\n",
        "else:\n",
        "  all_labels_df.to_csv('pre-processing/test_labels_augall.csv', index=False)\n",
        "  #pass"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ObEiROxP9Jf0"
      },
      "source": [
        "# Inspect augmentation results\n",
        "if imtype == \"train\":\n",
        "  imgs = \"images/\"\n",
        "else:\n",
        "  imgs = \"test_images/\"\n",
        "\n",
        "grouped_resized = resized_df.groupby('filename')\n",
        "grouped_augmented = augmented_df.groupby('filename')\n",
        "\n",
        "for filename in resized_df['filename'].unique()[:5]:    \n",
        "    group_r_df = grouped_resized.get_group(filename)\n",
        "    group_r_df = group_r_df.reset_index()\n",
        "    group_r_df = group_r_df.drop(['index'], axis=1)\n",
        "    bb_r_array = group_r_df.drop(['filename', 'width', 'height', 'class'], axis=1).values\n",
        "    resized_img = imageio.imread(imgs+filename)\n",
        "    bbs_r = BoundingBoxesOnImage.from_xyxy_array(bb_r_array, shape=resized_img.shape)\n",
        "    \n",
        "    group_a_df = grouped_augmented.get_group('aug_'+filename)\n",
        "    group_a_df = group_a_df.reset_index()\n",
        "    group_a_df = group_a_df.drop(['index'], axis=1)\n",
        "    bb_a_array = group_a_df.drop(['filename', 'width', 'height', 'class'], axis=1).values\n",
        "    bb_a_array = bb_a_array[~np.isnan(bb_a_array).any(axis=1)]\n",
        "    augmented_img = imageio.imread(imgs+'aug_'+filename)\n",
        "    bbs_a = BoundingBoxesOnImage.from_xyxy_array(bb_a_array, shape=augmented_img.shape)\n",
        "    \n",
        "    ia.imshow(np.hstack([\n",
        "            bbs_r.draw_on_image(resized_img, size=2),\n",
        "            bbs_a.draw_on_image(augmented_img, size=2)\n",
        "            ]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X1MCjxXuc04-"
      },
      "source": [
        "#### B4) Remove out of bounds values resulting from augmentation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hrvmumSbrZ72"
      },
      "source": [
        "# Remove out of bounds values\n",
        "if imtype == \"train\":\n",
        "  df = pd.read_csv(\"pre-processing/train_labels_augall.csv\")\n",
        "else:\n",
        "  df = pd.read_csv(\"pre-processing/test_labels_augall.csv\")\n",
        "df.head()\n",
        "\n",
        "# Remove out of bounds (OOB) cropping dimensions\n",
        "# Set positive out of bounds values (OOB +) equal to image dimensions\n",
        "for i, row in df.iterrows():\n",
        "    # When crop height > image height, set crop height equal to image height:\n",
        "    if df.ymax[i] > df.height[i]:\n",
        "        df.ymax[i] = df.height[i]\n",
        "    # When crop width > image width, set crop width equal to image width:\n",
        "    if df.xmax[i] > df.width[i]:\n",
        "        df.xmax[i] = df.width[i]  \n",
        "df.dropna(inplace=True)\n",
        "df.xmin = df.xmin.astype(int)\n",
        "df.ymin = df.ymin.astype(int)\n",
        "df.xmax = df.xmax.astype(int)\n",
        "df.ymax = df.ymax.astype(int)\n",
        "# Set negative values (OOB -) equal to 1 # was getting errors when mins = 0\n",
        "df.xmin[df.xmin <= 0] = 1\n",
        "df.ymin[df.ymin <= 0] = 1\n",
        "\n",
        "if imtype == \"train\":\n",
        "  df.to_csv('pre-processing/train_labels_augall_oobrem.csv', sep=',', index=False)\n",
        "else:\n",
        "  df.to_csv('pre-processing/test_labels_augall_oobrem.csv', sep=',', index=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qEW9GPBhagGh"
      },
      "source": [
        "----"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7QbIV_A2d80j"
      },
      "source": [
        "#### C) Loop through images and annotations to confirm all files are valid to avoid problems training downstream"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YMHcCfaD7J5t"
      },
      "source": [
        "# to find problematic images\n",
        "# modified from https://github.com/AjayZinngg/random-scripts/blob/master/check_images.py \n",
        "# also errors https://github.com/tensorflow/models/issues/5474\n",
        "# about error messages https://github.com/tensorflow/models/issues/1754\n",
        "import csv\n",
        "import cv2 \n",
        "import os\n",
        "import numpy as np\n",
        "\n",
        "csv_files = ['pre-processing/train_labels_augall_oobrem.csv', 'pre-processing/test_labels_augall_oobrem.csv']\n",
        "folders = ['images', 'test_images']\n",
        "\n",
        "for i in range(len(folders)):\n",
        "    FOLDER = folders[i]\n",
        "    CSV_FILE = csv_files[i]\n",
        "\n",
        "    with open(CSV_FILE, 'r') as fid:\n",
        "        \n",
        "        print('Checking file:', CSV_FILE, 'in folder:', FOLDER)\n",
        "        \n",
        "        file = csv.reader(fid, delimiter=',')\n",
        "        first = True\n",
        "        \n",
        "        cnt = 0\n",
        "        error_cnt = 0\n",
        "        error = False\n",
        "        for row in file:\n",
        "            if error == True:\n",
        "                error_cnt += 1\n",
        "                error = False\n",
        "                \n",
        "            if first == True:\n",
        "                first = False\n",
        "                continue\n",
        "            \n",
        "            cnt += 1\n",
        "            \n",
        "            name, width, height, xmin, ymin, xmax, ymax = row[0], int(float(row[1])), int(float(row[2])), int(float(row[4])), int(float(row[5])), int(float(row[6])), int(float(row[7]))\n",
        "            \n",
        "            path = os.path.join(FOLDER, name)\n",
        "            img = cv2.imread(path)\n",
        "            \n",
        "            if type(img) == type(None):\n",
        "                error = True\n",
        "                print('Could not read image', path)\n",
        "                continue\n",
        "            \n",
        "            org_height, org_width = img.shape[:2]\n",
        "            \n",
        "            if org_width != width:\n",
        "                error = True\n",
        "                print('Width mismatch for image: ', name, width, '!=', org_width)\n",
        "            \n",
        "            if org_height != height:\n",
        "                error = True\n",
        "                print('Height mismatch for image: ', name, height, '!=', org_height)\n",
        "            \n",
        "            if xmin > org_width:\n",
        "                error = True\n",
        "                print('XMIN > org_width for file', name)\n",
        "                \n",
        "            if xmin <= 0:\n",
        "                error = True\n",
        "                print('XMIN < 0 for file', name)\n",
        "                \n",
        "            if xmax > org_width:\n",
        "                error = True\n",
        "                print('XMAX > org_width for file', name)\n",
        "            \n",
        "            if ymin > org_height:\n",
        "                error = True\n",
        "                print('YMIN > org_height for file', name)\n",
        "            \n",
        "            if ymin <= 0:\n",
        "                error = True\n",
        "                print('YMIN < 0 for file', name)\n",
        "            \n",
        "            if ymax > org_height:\n",
        "                error = True\n",
        "                print('YMAX > org_height for file', name)\n",
        "            \n",
        "            if xmin >= xmax:\n",
        "                error = True\n",
        "                print('xmin >= xmax for file', name)\n",
        "                \n",
        "            if ymin >= ymax:\n",
        "                error = True\n",
        "                print('ymin >= ymax for file', name)\n",
        "            \n",
        "            if error == True:\n",
        "                print('Error for file: %s' % name)\n",
        "                print()\n",
        "            \n",
        "        print('Checked %d bounding boxes and realized %d errors' % (cnt, error_cnt))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5FaP3u0_Qkrv"
      },
      "source": [
        "#Manually deleted random files from abo e that say xmin > xmax when values werent greater than\n",
        "#df = pd.read_csv('pre-processing/train_labels_augall_oobrem.csv')\n",
        "#df1 = df[df.filename != 'aug_912.jpeg']\n",
        "#df1.to_csv('pre-processing/train_labels_augall_oobrem.csv', index=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xxezeb_JXgQG"
      },
      "source": [
        "### 8) Generate xmls (annotations) for new annotated image dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jW88jqYm9neC"
      },
      "source": [
        "# Run this block 1x per class\n",
        "\n",
        "# Convert train and test csvs to xmls with updated filepaths\n",
        "# modified from here https://gist.github.com/calisir/568190a5e55a79e08be318c285688457\n",
        "\n",
        "%cd /content/drive/My Drive/train\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import lxml\n",
        "from lxml import etree\n",
        "import xml.etree.cElementTree as ET\n",
        "\n",
        "def indent(elem, level=0):\n",
        "    i = \"\\n\" + level*\"  \"\n",
        "    if len(elem):\n",
        "        if not elem.text or not elem.text.strip():\n",
        "            elem.text = i + \"  \"\n",
        "        if not elem.tail or not elem.tail.strip():\n",
        "            elem.tail = i\n",
        "        for elem in elem:\n",
        "            indent(elem, level+1)\n",
        "        if not elem.tail or not elem.tail.strip():\n",
        "            elem.tail = i\n",
        "    else:\n",
        "        if level and (not elem.tail or not elem.tail.strip()):\n",
        "            elem.tail = i\n",
        "\n",
        "imtype = \"test\" #@param [\"train\", \"test\"]\n",
        "\n",
        "# Read in train or test image label data\n",
        "if imtype == \"train\":\n",
        "  folder = \"images\" \n",
        "  fpath = \"content/drive/My Drive/train/images/\" \n",
        "  labfile = \"pre-processing/train_labels_augall_oobrem.csv\"\n",
        "else:\n",
        "  folder = \"test_images\" \n",
        "  fpath = \"content/drive/My Drive/train/test_images/\" \n",
        "  labfile = \"pre-processing/test_labels_augall_oobrem.csv\"\n",
        "df1 = pd.read_csv(labfile)\n",
        "\n",
        "df = df1.groupby('filename', as_index=False).agg(lambda x: list(x))\n",
        "\n",
        "# Change the name of the file.\n",
        "# Replace any / with - to avoid errors in xmls\n",
        "def nameChange(x):\n",
        "    x = x.replace(\"/\", \"-\")\n",
        "    return x\n",
        "\n",
        "df['filename'] = df['filename'].apply(nameChange)\n",
        "\n",
        "for i in range(0, len(df)):\n",
        "#for i in range(0, 5):\n",
        "    height = df['height'].iloc[i][0]\n",
        "    width = df['width'].iloc[i][0]\n",
        "    depth = 3\n",
        "\n",
        "    annotation = ET.Element('annotation')\n",
        "    ET.SubElement(annotation, 'folder').text = folder\n",
        "    ET.SubElement(annotation, 'filename').text = str(df['filename'].iloc[i])\n",
        "    ET.SubElement(annotation, 'path').text = fpath + str(df['filename'].iloc[i])\n",
        "    \n",
        "    source = ET.SubElement(annotation, 'source')\n",
        "    ET.SubElement(source, 'database').text = 'Unknown'\n",
        "    \n",
        "    size = ET.SubElement(annotation, 'size')\n",
        "    ET.SubElement(size, 'width').text = str(width)\n",
        "    ET.SubElement(size, 'height').text = str(height)\n",
        "    ET.SubElement(size, 'depth').text = str(depth)\n",
        "\n",
        "    ET.SubElement(annotation, 'segmented').text = '0'\n",
        "    \n",
        "    # To handle images with >1 annotation\n",
        "    for x in range(0, len(df['xmin'].iloc[i])):\n",
        "      ob = ET.SubElement(annotation, 'object')\n",
        "      ET.SubElement(ob, 'name').text = str(df['class'].iloc[i][x])\n",
        "      ET.SubElement(ob, 'pose').text = 'Unspecified'\n",
        "      ET.SubElement(ob, 'truncated').text = '0'\n",
        "      ET.SubElement(ob, 'difficult').text = '0'\n",
        "\n",
        "      bbox = ET.SubElement(ob, 'bndbox')\n",
        "      ET.SubElement(bbox, 'xmin').text = str(int(df['xmin'].iloc[i][x]))\n",
        "      ET.SubElement(bbox, 'ymin').text = str(int(df['ymin'].iloc[i][x]))\n",
        "      ET.SubElement(bbox, 'xmax').text = str(int(df['xmax'].iloc[i][x]))\n",
        "      ET.SubElement(bbox, 'ymax').text = str(int(df['ymax'].iloc[i][x]))\n",
        "\n",
        "    fileName = str(df['filename'].iloc[i])\n",
        "    tree = ET.ElementTree(annotation)\n",
        "    indent(annotation)\n",
        "    if imtype == \"train\":\n",
        "      outf = \"pre-processing/train_ann/\"\n",
        "    else:\n",
        "      outf = \"pre-processing/test_ann/\"\n",
        "    outpath = outf + os.path.splitext(fileName)[0] + \".xml\"\n",
        "    tree.write(outpath, encoding='utf8', xml_declaration=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OEoU84pUUdbt"
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "# Check that all train images have corresponding annotation\n",
        "ann_dir = '/content/drive/My Drive/train/pre-processing/test_ann/'\n",
        "train_dir = '/content/drive/My Drive/train/test_images/'\n",
        "files = os.listdir(train_dir)\n",
        "\n",
        "# Loop through train images to see if xml for each one\n",
        "for file in files:\n",
        "  base = os.path.splitext(os.path.basename(file))[0]\n",
        "  train_xml = ann_dir + base + '.xml'\n",
        "  if os.path.exists(train_xml):\n",
        "    print(\"xml exists for {}\".format(file))\n",
        "  else:\n",
        "    print(\"!!!xml missing for image {}\".format(file))\n",
        "    #os.remove(file)\n",
        "\n",
        "# Check for duplicate xmls\n",
        "#import collections\n",
        "#print([item for item, count in collections.Counter(files).items() if count > 1])\n",
        "#!ls -l -a /content/drive/'My Drive'/train/pre-processing/test_ann/\n",
        "\n",
        "# Check for xmls that don't have corresp img\n",
        "%cd /content/drive/My Drive/train\n",
        "xmls = os.listdir('pre-processing/test_ann/')\n",
        "imgs = os.listdir('test_images/')\n",
        "xbases = []\n",
        "ibases = []\n",
        "for xml in xmls:\n",
        "  xbase = os.path.splitext(os.path.basename(xml))[0]\n",
        "  xbases.append(xbase)\n",
        "for img in imgs:\n",
        "  ibase = os.path.splitext(os.path.basename(img))[0]\n",
        "  ibases.append(ibase)\n",
        "\n",
        "# yields the elements in `list_2` that are NOT in `list_1`\n",
        "diffs = np.setdiff1d(xbases,ibases)\n",
        "print(\"xml(s) that need to be deleted bc have no corresp img: {}\".format(diffs))\n",
        "\n",
        "print(\"Number of test images:\")\n",
        "!ls /content/drive/'My Drive'/train/test_images | wc -l\n",
        "\n",
        "print(\"Number of test annotations:\")\n",
        "!ls /content/drive/'My Drive'/train/pre-processing/test_ann/ | wc -l"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nRYGgY50STmd"
      },
      "source": [
        "# Check that all train images have corresponding annotation\n",
        "ann_dir = '/content/drive/My Drive/train/pre-processing/train_ann/'\n",
        "train_dir = '/content/drive/My Drive/train/images/'\n",
        "files = os.listdir(train_dir)\n",
        "\n",
        "# Check for duplicate xmls\n",
        "import collections\n",
        "print([item for item, count in collections.Counter(files).items() if count > 1])\n",
        "#!ls -l -a /content/drive/'My Drive'/train/pre-processing/train_ann/\n",
        "\n",
        "# Loop through train images to see if xml for each one\n",
        "for file in files:\n",
        "  base = os.path.splitext(os.path.basename(file))[0]\n",
        "  train_xml = ann_dir + base + '.xml'\n",
        "  if os.path.exists(train_xml):\n",
        "    print(\"xml exists for {}\".format(file))\n",
        "  else:\n",
        "    print(\"!!!xml missing for image {}\".format(file))\n",
        "    #os.remove(file)\n",
        "\n",
        "# Check for xmls that don't have corresp img\n",
        "%cd /content/drive/My Drive/train\n",
        "xmls = os.listdir('pre-processing/train_ann/')\n",
        "imgs = os.listdir('images/')\n",
        "xbases = []\n",
        "ibases = []\n",
        "for xml in xmls:\n",
        "  xbase = os.path.splitext(os.path.basename(xml))[0]\n",
        "  xbases.append(xbase)\n",
        "for img in imgs:\n",
        "  ibase = os.path.splitext(os.path.basename(img))[0]\n",
        "  ibases.append(ibase)\n",
        "\n",
        "# yields the elements in `list_2` that are NOT in `list_1`\n",
        "diffs = np.setdiff1d(xbases,ibases)\n",
        "print(\"xml(s) that need to be deleted bc have no corresp img: {}\".format(diffs))\n",
        "\n",
        "print(\"Number of train images:\")\n",
        "!ls /content/drive/'My Drive'/train/images | wc -l\n",
        "\n",
        "print(\"Number of train annotations:\")\n",
        "!ls /content/drive/'My Drive'/train/pre-processing/train_ann/ | wc -l"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "airk9OZXbips"
      },
      "source": [
        "# Delete augmented test images and annotations\n",
        "# Hacky fix bc steps above do resizing and aug for test and train images\n",
        "\n",
        "import glob\n",
        "import os\n",
        "import pandas as pd\n",
        "\n",
        "# Check that all train images have corresponding annotation\n",
        "ann_dir = '/content/drive/My Drive/train/pre-processing/test_ann/'\n",
        "im_dir = '/content/drive/My Drive/train/test_images/'\n",
        "files = os.listdir(im_dir)\n",
        "\n",
        "# Delete all augmented xmls\n",
        "fns = glob.glob(ann_dir + \"*aug_*\")\n",
        "print(fns)\n",
        "print(len(fns))\n",
        "for fn in fns:\n",
        "    try:\n",
        "        os.remove(fn)\n",
        "    except:\n",
        "        print(\"Error while deleting file : \", fn)\n",
        "\n",
        "# Delete all augmented imgs\n",
        "fns = glob.glob(im_dir + \"*aug_*\")\n",
        "print(fns)\n",
        "print(len(fns))\n",
        "for fn in fns:\n",
        "    try:\n",
        "        os.remove(fn)\n",
        "    except:\n",
        "        print(\"Error while deleting file : \", fn)\n",
        "\n",
        "# Delete aug img rows from test_labels_augall_oobrem.csv\n",
        "df = pd.read_csv('pre-processing/test_labels_augall_oobrem.csv')\n",
        "df = df[~df.filename.str.contains(\"aug_\")]\n",
        "df.to_csv('pre-processing/test_labels_augall_oobrem.csv', sep=',', index=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tTdkuEpc8Dko"
      },
      "source": [
        "# Inspect number of images and annotations for train and test (should be 1 image/annotation in each group and test should be ~20-30% of train)\n",
        "!ls /content/drive/'My Drive'/train/pre-processing/train_ann | wc -l\n",
        "!ls /content/drive/'My Drive'/train/images | wc -l\n",
        "\n",
        "!ls /content/drive/'My Drive'/train/pre-processing/test_ann | wc -l\n",
        "!ls /content/drive/'My Drive'/train/test_images | wc -l"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vOxw1XtKByyT"
      },
      "source": [
        "# Copy final datasets to train and test folders for object detection\n",
        "#!mv /content/drive/'My Drive'/train/pre-processing/train_ann/* /content/drive/'My Drive'/train/darkflow-master/test/training/annotations\n",
        "!rm -r /content/drive/'My Drive'/train/pre-processing/train_ann\n",
        "\n",
        "#!mv /content/drive/'My Drive'/train/pre-processing/test_ann/* /content/drive/'My Drive'/train/test_ann\n",
        "!rm -r /content/drive/'My Drive'/train/pre-processing/test_ann"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}