{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.8"
    },
    "colab": {
      "name": "scat_footprint_train_yolo_darkflow.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "X2fF0fSxmJZR",
        "feTIhGuIvUkZ",
        "1zL-PctVuqZv",
        "AV08UMa0wjd0"
      ],
      "toc_visible": true,
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/aubricot/computer_vision_with_eol_images/blob/master/object_detection_for_image_tagging/scat_footprint/scat_footprint_train_yolo_darkflow.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4Rnwb_rgmJZB"
      },
      "source": [
        "# Training YOLOv2 in Darkflow to detect scat and footprints from EOL images\n",
        "---\n",
        "*Last Updated 23 February 2021*   \n",
        "Use images with annotations to train YOLOv2 implemented in Tensorflow (via darkflow) to detect scat and footprints from EOL images.\n",
        "\n",
        "Datasets were downloaded to Google Drive in [scat_footprint_preprocessing.ipynb](https://github.com/aubricot/computer_vision_with_eol_images/blob/master/object_detection_for_image_tagging/scat_footprint/scat_footprint_preprocessing.ipynb). \n",
        "\n",
        "**YOLOv2 was trained for 4,000 epochs on 5 images to overfit, then for 1,000 epochs at lr=0.001 to reach a stable loss value (3), and finally for 1,000 epochs to refine learning with a slow rate at lr=0.0001.** Custom anchor boxes were used to optimize coverage for the dataset and image augmentation was used to increase dataset size from 500 img per class to 1000 img, but loss never decreased below 3 and final mAP was <10%. \n",
        "\n",
        "Notes:   \n",
        "* Change filepaths/taxon names where you see 'TO DO' \n",
        "* Make sure to set the runtime to Python 2 with GPU Hardware Accelerator.    \n",
        "\n",
        "References:   \n",
        "* [Official Darkflow training instructions](https://github.com/thtrieu/darkflow)   \n",
        "* [Medium Blog on training using YOLO via Darkflow in Colab](https://medium.com/coinmonks/detecting-custom-objects-in-images-video-using-yolo-with-darkflow-1ff119fa002f)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iJz5m4BKmJZD"
      },
      "source": [
        "## Installs\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yWAbU5tW1ONu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7c85dda5-f2cd-46e3-94fd-b103f808e958"
      },
      "source": [
        "# Mount google drive to import/export files\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yj3-JKOsIPtc"
      },
      "source": [
        "# Change to your working directory\n",
        "%cd /content/drive/My Drive/train\n",
        "\n",
        "# Install libraries\n",
        "# Make sure you are using Python 3.6\n",
        "!python --version\n",
        "!pip install tensorflow-gpu==1.15.0rc2\n",
        "!pip install cython\n",
        "!pip install opencv-python\n",
        "\n",
        "import os\n",
        "import pathlib\n",
        "import shutil "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X2fF0fSxmJZR"
      },
      "source": [
        "### Only run once: Model preparation uploads to Google Drive\n",
        "For detailed instructions on training YOLO using a custom dataset, see the [Darkflow GitHub Repository](https://github.com/thtrieu/darkflow)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wKYxuyq5Ib_f"
      },
      "source": [
        "# Download train and test dataset annotation files and install darkflow\n",
        "\n",
        "# Download darkflow (the tensorflow implementation of YOLO)\n",
        "if os.path.exists(\"darkflow-master\"):\n",
        "  %cd darkflow-master\n",
        "  !pwd\n",
        "\n",
        "elif not os.path.exists(\"darkflow-master\"):\n",
        "  !git clone --depth 1 https://github.com/thtrieu/darkflow.git\n",
        "  # Compile darkflow\n",
        "  %cd darkflow\n",
        "  !python setup.py build_ext --inplace\n",
        "  # Rename darkflow to darkflow-master to distinguish between folder names\n",
        "  shutil.move('/content/drive/My Drive/fall19_smithsonian_informatics/train/darkflow', \n",
        "          '/content/drive/My Drive/fall19_smithsonian_informatics/train/darkflow-master')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "268I2Ev_mJZL"
      },
      "source": [
        "# Test installation, you should see an output with different parameters for flow\n",
        "!python flow --h"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7SXQ5bjUzA0u"
      },
      "source": [
        "# Download other needed files for training\n",
        "\n",
        "# Upload yolo.weights, pre-trained weights file (for YOLO v2) from Google drive \n",
        "weights_file = 'bin/yolo.weights'\n",
        "if not os.path.exists('weights_file'):\n",
        "  #!gdown --id 0B1tW_VtY7oniTnBYYWdqSHNGSUU\n",
        "  #!mkdir bin\n",
        "  #!mv yolo.weights bin\n",
        "  print('double check if weights file was already downloaded')\n",
        "\n",
        "# Make new label file/overwrite existing labels.txt downloaded with darkflow\n",
        "!echo 'scat' >labels.txt\n",
        "!echo 'footprint' >>labels.txt\n",
        "\n",
        "# Download model config file edited for training darkflow to identify 2 classes (yolo-2c = 2 classes)\n",
        "mod_config_file = 'cfg/yolo-2c-slowlr-anch.cfg'\n",
        "if not os.path.exists('mod_config_file'):\n",
        "  #%cd cfg\n",
        "  print('double check if config file was already downloaded')\n",
        "  #!gdown --id 1wgKwWsnmJDOWzrimp3GTPtpKLoBGoyMg\n",
        "  #%cd ../"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nwKdj73Wpnlz"
      },
      "source": [
        "## Imports   \n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QSLXg6G7mJZP"
      },
      "source": [
        "%cd darkflow-master\n",
        "%tensorflow_version 1.0\n",
        "\n",
        "# For importing/exporting files, working with arrays, etc\n",
        "from google.colab import files\n",
        "import os\n",
        "import pathlib\n",
        "import imageio\n",
        "import time\n",
        "import csv\n",
        "import urllib\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "# For the actual object detection\n",
        "!python setup.py build_ext --inplace\n",
        "from darkflow.net.build import TFNet\n",
        "\n",
        "# For drawing onto and plotting the images\n",
        "import matplotlib.pyplot as plt\n",
        "import cv2\n",
        "%config InlineBackend.figure_format = 'svg'\n",
        "%matplotlib inline"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w3ouL5RM-mpX"
      },
      "source": [
        "## Train the model\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QnBpq-ytrAxi"
      },
      "source": [
        "# List different parameters for flow\n",
        "!python flow --h"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "peYeF3SpvRRj"
      },
      "source": [
        "#### Step 1) Pre-train by overfitting model on 3 images per class for 4000 epochs (or until loss gets as low as possible and accuracy gets as high as possible)\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5zAVMR93vQlY"
      },
      "source": [
        "# Start training\n",
        "\n",
        "# Train model (yolo-2c_slowlr_anch.cfg) using pre-trained weights from basal layers of yolo.weights, the top layer will be trained from scracth to detect scat and footprints\n",
        "# Change the dataset and annotation directories to your paths in Google Drive\n",
        "%cd darkflow-master\n",
        "!python flow --model cfg/yolo-2c_slowlr_anch.cfg --train --trainer adam --load bin/yolo.weights --gpu 0.8 --epoch 4000 --dataset \"/content/drive/My Drive/train/pretrain/img\" --annotation \"/content/drive/My Drive/train/pretrain/ann\" --savepb"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lIxcPlzAwP2k"
      },
      "source": [
        "# Resume training from last checkpoint (useful if Drive timeout happens or if you want to train for a few more epochs)\n",
        "!python flow --load -1 --model cfg/yolo-2c_slowlr_anch.cfg --train --savepb --trainer adam --gpu 0.8 --epoch 1000 --dataset \"/content/drive/My Drive/train/pretrain/img\" --annotation \"/content/drive/My Drive/train/pretrain/ann\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "feTIhGuIvUkZ"
      },
      "source": [
        "#### Step 2) Train on full dataset with high learning rate until loss starts to stabilize (usually at a value b/w 1 - 5)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pn4U3HOTgPVX"
      },
      "source": [
        "# Train model (yolo-2c_slowlr_anch.cfg) using pre-trained weights from basal layers of yolo.weights that were pre-fit in Step 1 above\n",
        "# Change the dataset and annotation directories to your paths in Google Drive\n",
        "%cd darkflow-master\n",
        "!python flow --model cfg/yolo-2c_slowlr_anch.cfg --train --trainer adam --load bin/yolo.weights --gpu 0.8 --epoch 100 --dataset \"/content/drive/My Drive/train/images\" --annotation \"test/training/annotations\" --savepb"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jdh2pHhkvXxE"
      },
      "source": [
        "#### Step 3) Train on full dataset with low learning rate (10x lower than step 1) to get best loss/accuracy values (loss <1, accuracy as close to 100% as possible)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LZoKtS-xhbQm"
      },
      "source": [
        "# Resume training from last checkpoint #100 epochs with 0.0001, 100 with .00001\n",
        "!python flow --load -1 --model cfg/yolo-2c_slowlr_anch.cfg --train --savepb --trainer adam --gpu 0.8 --epoch 100 --dataset \"/content/drive/My Drive/train/images\" --annotation \"test/training/annotations\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HL_ZNF6QFQBS"
      },
      "source": [
        "#### Step 4) Save trained model to protobuf file (.pb)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UqA_lW7tbLeH"
      },
      "source": [
        "# Save the last checkpoint to protobuf file\n",
        "!python flow --model cfg/yolo-2c_slowlr_anch.cfg --load -1 --savepb"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0IZw-HlWrVxn"
      },
      "source": [
        "# If decide want to keep training, can resume training from protobuf file using cmds below\n",
        "!python flow --load -1 --pbLoad built_graph/yolo-2c_slowlr_anch.pb --metaLoad built_graph/yolo-4c.meta --train --savepb --trainer adam --gpu 0.8 --epoch 3000 --dataset \"/content/drive/My Drive/fall19_smithsonian_informatics/train/images\" --annotation \"test/training/annotations\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sLGOQiwSr-Gd"
      },
      "source": [
        "## Evaluate model accuracy\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5Anc0dZjf7os"
      },
      "source": [
        "### Step 1) Export detection results as JSON"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5GhWXLLlPNrr"
      },
      "source": [
        "# Export detection results for test images as json files to calculate mAP (mean average precision, a performance measure to compare models) using calculate_error_mAP.ipynb\n",
        "!python flow --pbLoad built_graph/yolo-2c_slowlr_anch.pb --gpu 0.8 --metaLoad built_graph/yolo-2c_slowlr_anch.meta --imgdir \"/content/drive/My Drive/train/test_images\" --json"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xqJOkggMgAVA"
      },
      "source": [
        "### Step 2) Use Cartucho's mAP library to evaluate model accuracy"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kj3qsk3BgQob",
        "outputId": "326ecb25-2a8e-4c9a-d976-87cd458bb2f2"
      },
      "source": [
        "# Install the mAP repository to calculate error from detection results\n",
        "import os\n",
        "%cd /content/drive/My Drive/train\n",
        "if not os.path.exists(\"eval\"):\n",
        "  !mkdir eval\n",
        "  %cd eval\n",
        "  #!git clone https://github.com/Cartucho/mAP\n",
        "  pritn(\"check installation of mAP or working directory, should already be installed\")\n",
        "  %cd ../\n",
        "\n",
        "# Move yolo detection results (jsons exported above) to detection-results/\n",
        "!mv test_images/out/* eval/mAP/input/detection-results/\n",
        "!rm -rf test_images/out\n",
        "\n",
        "# Copy image annotations (xmls formatted with ground truth bounding boxes) to ground-truth/\n",
        "!cp test_ann/* eval/mAP/input/ground-truth/\n",
        "\n",
        "# Convert jsons to format needed for mAP calc\n",
        "%cd /content/drive/My Drive/train/eval/mAP/scripts/extra\n",
        "!python convert_dr_darkflow_json.py\n",
        "\n",
        "# Convert xmls to format needed for mAP calc\n",
        "%cd  /content/drive/My Drive/train/eval/mAP/scripts/extra\n",
        "!python convert_gt_xml.py\n",
        "\n",
        "# Remove sample images in input/images-optional\n",
        "# cd to mAP\n",
        "%cd  /content/drive/My Drive/train/eval/mAP\n",
        "!rm -rf input/images-optional/*\n",
        "\n",
        "# Calculate mAP for detection results\n",
        "# Output will be in mAP/results\n",
        "!python main.py"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/My Drive/train\n",
            "/content/drive/My Drive/train/eval/mAP/scripts/extra\n",
            "Conversion completed!\n",
            "/content/drive/My Drive/train/eval/mAP/scripts/extra\n",
            "Conversion completed!\n",
            "/content/drive/My Drive/train/eval/mAP\n",
            "6.50% = footprint AP \n",
            "4.49% = scat AP \n",
            "mAP = 5.49%\n",
            "<Figure size 640x480 with 1 Axes>\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}