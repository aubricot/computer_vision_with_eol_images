{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "plant_poll_generate_tags_yolov3.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/aubricot/computer_vision_with_eol_images/blob/master/object_detection_for_image_tagging/plant_pollinator/plant_poll_generate_tags_yolov3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j-PBcUKyc95M"
      },
      "source": [
        "# Using YOLO v3 pre-trained on Google Open Images to add plant-pollinator co-occurrence tags for ladybugs, beetles, and insects in plant images\n",
        "---\n",
        "*Last Updated 31 October 2021*   \n",
        "Using a YOLOv3 model (downloaded from [here](https://github.com/AlexeyAB/darknet) ) pre-trained on [Google Open Images](https://storage.googleapis.com/openimages/web/visualizer/index.html?set=train&type=detection&c=%2Fm%2F03vt0) as a method to do customized, large-scale image processing. EOL Angiosperm images will be tagged for plant-pollinator co-occurrence using object detection. Tags will further extend EOLv3 image search functions.\n",
        "\n",
        "Notes:   \n",
        "* Before you you start: change the runtime to \"GPU\" and with \"High RAM\" (if available)\n",
        "* Follow instructions at form fields to interact with code (change filepaths, adjust parameters, etc.; also noted in code with 'TO DO')\n",
        "* For each 24 hour period on Google Colab, you have up to 12 hours of free GPU access.\n",
        "\n",
        "References:   \n",
        "* Check out [AlexeyAB's darknet repo](https://github.com/AlexeyAB/darknet) for Colab tutorials like [this one](https://colab.research.google.com/drive/12QusaaRj_lUwCGDvQNfICpa7kA7_a2dE)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fX9LGz3Ydu27"
      },
      "source": [
        "## Installs & Imports\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q5lC8PSbGCyN"
      },
      "source": [
        "# (Optional): Mount google drive to import/export files\n",
        "# Note: Only run this cell if want to save results\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yDdbBYnp2nCK"
      },
      "source": [
        "# For importing/exporting files, working with arrays, etc\n",
        "import os\n",
        "import glob\n",
        "import pathlib\n",
        "import six.moves.urllib as urllib\n",
        "import sys\n",
        "import tarfile\n",
        "import zipfile\n",
        "import numpy as np \n",
        "import csv\n",
        "import matplotlib.pyplot as plt\n",
        "import time\n",
        "import pandas as pd\n",
        "\n",
        "# For downloading images\n",
        "!apt-get install aria2\n",
        "\n",
        "# For drawing onto and plotting images\n",
        "import matplotlib.pyplot as plt\n",
        "from PIL import Image\n",
        "from PIL import ImageColor\n",
        "from PIL import ImageDraw\n",
        "from PIL import ImageFont\n",
        "from PIL import ImageOps\n",
        "import cv2\n",
        "%matplotlib inline\n",
        "%config InlineBackend.figure_format = 'svg'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "isysjRGl21_D"
      },
      "source": [
        "## Model preparation\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xym8_m8CIyXK",
        "cellView": "code"
      },
      "source": [
        "# Install darknet\n",
        "# Note: Ignore warnings and output text, even most recent build shows them\n",
        "\n",
        "# Only if connecting to Google Drive\n",
        "# TO DO: Type in the path to your working directory in form field to right\n",
        "wd = \"/content/drive/MyDrive/train/darknet3\" #@param {type:\"string\"}\n",
        "cwd = 'darknet'\n",
        "%cd $wd\n",
        "\n",
        "# Download darknet (the native implementation of YOLO)\n",
        "if os.path.exists(cwd):\n",
        "    %cd $cwd\n",
        "elif not os.path.exists(cwd):\n",
        "    !git clone https://github.com/AlexeyAB/darknet\n",
        "    # Compile darknet\n",
        "    %cd $cwd\n",
        "    # Make folders for detection datafiles\n",
        "    os.makedirs('data/imgs')\n",
        "    os.makedirs('data/img_info')\n",
        "    os.makedirs('data/results')\n",
        "\n",
        "# Change makefile to have GPU and OPENCV enabled\n",
        "!sed -i 's/OPENCV=0/OPENCV=1/' Makefile\n",
        "!sed -i 's/GPU=0/GPU=1/' Makefile\n",
        "!sed -i 's/CUDNN=0/CUDNN=1/' Makefile\n",
        "!sed -i 's/CUDNN_HALF=0/CUDNN_HALF=1/' Makefile\n",
        "# Download pretrained YOLOv3 weights for Open Images\n",
        "!wget https://pjreddie.com/media/files/yolov3-openimages.weights\n",
        "\n",
        "# Verify CUDA version (for using GPU)\n",
        "!/usr/local/cuda/bin/nvcc --version\n",
        "\n",
        "# Make darknet\n",
        "!make"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cKovA4-aifP5"
      },
      "source": [
        "## Generate cropping coordinates for images (Run 1x for each batch)\n",
        "---\n",
        "Run EOL 20k image bundles through pre-trained object detection models and save results in 4 batches (A-D). "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fuZL4TGzitNZ"
      },
      "source": [
        "### Prepare object detection functions and settings"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wqoLKpXveeAt"
      },
      "source": [
        "# Define functions\n",
        "\n",
        "# Display full URLs in outputs so you can click them and inspect images\n",
        "pd.set_option('display.max_colwidth', None)\n",
        "\n",
        "# Read in data file\n",
        "def read_datafile(fpath, sep=\"\\t\", header=0, disp_head=True):\n",
        "    try:\n",
        "        df = pd.read_csv(fpath, sep=sep, header=header)\n",
        "        if disp_head:\n",
        "            print(\"Data header: \\n\", df.head())\n",
        "    except FileNotFoundError as e:\n",
        "        raise Exception(\"File not found: Enter the path to your file in form field and re-run\").with_traceback(e.__traceback__)\n",
        "    \n",
        "    return df\n",
        "\n",
        "# Read in bundle images\n",
        "def read_eolbundle(bundle, no_bundles):\n",
        "    # Get first 20k images for Angiosperm bundles using initial bundle basename\n",
        "    eol_addr = \"https://editors.eol.org/other_files/bundle_images/files/\"\n",
        "    bundle_base = os.path.splitext(os.path.basename(bundle))[0].rsplit('_',1)[0]\n",
        "    # Add zero suffix to dynamically load in sub-bundles \n",
        "    # (ex: 000001 - 000031 for Angiosperms)\n",
        "    tens = list(range(1, 10))\n",
        "    hundreds = list(range(10, no_bundles))\n",
        "    tens_w_zeros = [\"00000\" + str(num) + \".txt\" for num in tens]\n",
        "    hundreds_w_zeros = [\"0000\" + str(num) + \".txt\" for num in hundreds]\n",
        "    zero_suffices = tens_w_zeros + hundreds_w_zeros\n",
        "    all_filenames = [eol_addr + bundle_base + \"_\" + zs for zs in zero_suffices]\n",
        "    bundles = pd.concat([pd.read_csv(f, sep='\\t', header=None) for f in all_filenames], ignore_index=True)\n",
        "    print(\"EOL image bundle with {} images: \\n{}\".format(len(bundles), bundles.head()))\n",
        "    \n",
        "    return bundles\n",
        "\n",
        "# Define start and stop indices in EOL bundle for running inference   \n",
        "def set_start_stop(df):\n",
        "    # To test with a tiny subset, use 5 random bundle images\n",
        "    if test_with_tiny_subset:\n",
        "        N = len(df)\n",
        "        start=np.random.choice(a=N, size=1)[0]\n",
        "        stop=start+5\n",
        "    # To run inference on 4 batches of 5k images each\n",
        "    elif \"_a.\" in outfpath: # batch a is from 0-5000\n",
        "        start=0\n",
        "        stop=5000\n",
        "    elif \"_b.\" in outfpath: # batch b is from 5000-1000\n",
        "        start=5000\n",
        "        stop=10000\n",
        "    elif \"_c.\" in outfpath: # batch c is from 10000-15000\n",
        "        start=10000\n",
        "        stop=15000\n",
        "    elif \"_d.\" in outfpath: # batch d is from 15000-20000\n",
        "        start=15000\n",
        "        stop=20000\n",
        "    \n",
        "    return start, stop\n",
        "\n",
        "# To display results\n",
        "def imShow(path):\n",
        "    image = cv2.imread(path)\n",
        "    height, width = image.shape[:2]\n",
        "    resized_image = cv2.resize(image,(3*width, 3*height), interpolation = cv2.INTER_CUBIC)\n",
        "    fig = plt.gcf()\n",
        "    fig.set_size_inches(9, 9)\n",
        "    plt.axis(\"off\")\n",
        "    plt.imshow(cv2.cvtColor(resized_image, cv2.COLOR_BGR2RGB))\n",
        "    plt.show()\n",
        "\n",
        "# For uploading an image from url\n",
        "# Modified from https://www.pyimagesearch.com/2015/03/02/convert-url-to-image-with-python-and-opencv/\n",
        "def url_to_image(url):\n",
        "    resp = urllib.request.urlopen(url)\n",
        "    image = np.asarray(bytearray(resp.read()), dtype=\"uint8\")\n",
        "    image = cv2.imdecode(image, cv2.IMREAD_COLOR)\n",
        "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "    im_h, im_w = image.shape[:2]\n",
        " \n",
        "    return image"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wjTgajd3keAi"
      },
      "source": [
        "### Temporarily download images from EOL bundle to Google Drive (YOLO cannot directly parse URL images)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zCxtKyRPij8R"
      },
      "source": [
        "# Download images for 20K bundle of Angiosperm images with 31 sub-bundles\n",
        "# To DO: Enter any EOL Angiosperm image bundle URL\n",
        "bundle = \"https://editors.eol.org/other_files/bundle_images/files/images_for_Angiosperms_20K_breakdown_download_000030.txt\" #@param {type:\"string\"}\n",
        "df = read_eolbundle(bundle, 31)\n",
        "\n",
        "# Test with a smaller subset than 5k images?\n",
        "# TO DO: If yes, check test_with_tiny_subset box\n",
        "test_with_tiny_subset = True #@param {type: \"boolean\"}\n",
        "\n",
        "# Take 5k subset of bundle for running inference\n",
        "# TO DO: Change filename for each batch\n",
        "tags_file = \"plant_poll_coocc_tags_a\" #@param [\"plant_poll_coocc_tags_a\", \"plant_poll_coocc_tags_b\", \"plant_poll_coocc_tags_c\", \"plant_poll_coocc_tags_d\"] {allow-input: true}\n",
        "tags_file = tags_file + \".txt\"\n",
        "imgs_dir = \"data/imgs/\"\n",
        "tags_outpath = imgs_dir + tags_file\n",
        "\n",
        "# Save 5k subset to tags file\n",
        "start, stop = set_start_stop(df)\n",
        "df = df.iloc[start:stop]\n",
        "df.to_csv(tags_outpath, sep='\\n', index=False, header=False)\n",
        "\n",
        "# Download images \n",
        "# Note: Takes 7-10 min per 5k imgs, aria2 downloads 16imgs at a time\n",
        "%cd $imgs_dir\n",
        "!aria2c -x 16 -s 1 -i $tags_file\n",
        "\n",
        "# Check how many images downloaded\n",
        "print(\"Number of files downloaded to Google Drive: \")\n",
        "len([1 for x in list(os.scandir('.')) if x.is_file()])-1 # -1 because .txt file contains image filenames"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O_nGr7A7pGfW"
      },
      "source": [
        "# Move tags file used for downloading images to data/img_info/\n",
        "%cd ../\n",
        "!mv imgs/*.txt img_info/\n",
        "%cd ../\n",
        "\n",
        "# Make a new list of successfully downloaded image files for running inference\n",
        "inf_imgs = imgs_dir + '/' + tags_file\n",
        "with open(inf_imgs, 'w', encoding='utf-8') as f:\n",
        "    # Walk through data/imgs/ to list files\n",
        "    for dir, dirs, files in os.walk(imgs_dir):\n",
        "        files = [fn for fn in files]\n",
        "        for fn in files:\n",
        "            if 'txt' not in fn:\n",
        "                out = \"data/imgs/\" + fn\n",
        "                f.writelines(out + '\\n')\n",
        "\n",
        "# Inspect textfile of images for inference\n",
        "df = read_datafile(inf_imgs, header=None, sep='\\n', disp_head=True)\n",
        "print(\"\\nNumber of images ready for inference in {}: {}\".format(inf_imgs, len(df)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NnITAALxmoKY"
      },
      "source": [
        "### Run images through trained model\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YdNG8YEWaqsX"
      },
      "source": [
        "#### Test: Run individual image through by filename and display results"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kIDpIFWsOZo5"
      },
      "source": [
        "# Run inference on a single image by filename and show results\n",
        "# TO DO: First, run with sample EOL 'butterfly bush' image\n",
        "# To test with your own image, upload file to data/imgs and update fn formfield\n",
        "\n",
        "# First, download sample EOL 'butterfly bush' image \n",
        "%cd data/imgs\n",
        "!gdown --id 1A7dHlbnAlRS-pHwS2QHg--HzTQc1CLx3\n",
        "%cd ../..\n",
        "\n",
        "# TO DO: Put image in data/imgs & enter filename in formfield\n",
        "fn = \"542.8209936861.jpg\" #@param {type:\"string\"}\n",
        "img_fpath = 'data/imgs/' + fn\n",
        "\n",
        "# Run darknet and show bounding box coordinates\n",
        "!./darknet detector test cfg/openimages.data cfg/yolov3-openimages.cfg yolov3-openimages.weights {img_fpath}\n",
        "\n",
        "# Display detection results\n",
        "imShow('predictions.jpg')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GJ6h9PqTh-BE"
      },
      "source": [
        "### Generate crops: Run inference on EOL images & save results for cropping\n",
        "Use 20K EOL Angiosperm image bundles to get bounding boxes of detected pollinators. Results are saved to [crops_file].tsv.   \n",
        "Run in 4 batches of 5K images to backup regularly in case of Colab timeouts."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZljsbwXnubZc"
      },
      "source": [
        "# Run inference on 5k image subset using darknet\n",
        "\n",
        "# Run darknet with flag to not show bounding box coordinates\n",
        "!./darknet detector test cfg/openimages.data cfg/yolov3-openimages.cfg yolov3-openimages.weights -dont_show -save_labels < {tags_outpath}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BcfHlZ7QNXHc"
      },
      "source": [
        "## Post-process detection results\n",
        "--- \n",
        "Combine predictions for each image (YOLO saves them as individual text files) to all_predictions.txt. Then, delete images and prediction files. Next, convert detection boxes into flower/fruit tags. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6MjEUb-cZwsl"
      },
      "source": [
        "# Define functions\n",
        "\n",
        "# Combine individual prediction files for each image to all_predictions.txt\n",
        "def combine_predictions(imgs_dir):\n",
        "    # Delete inference images file list\n",
        "    !rm $tags_outpath\n",
        "    # Combine inference text files for each image and save to all_predictions.txt\n",
        "    fns = os.listdir(imgs_dir)\n",
        "    with open('data/results/all_predictions.txt', 'w') as outfile:\n",
        "        header = \"class_id x y w h img_id\"\n",
        "        outfile.write(header + \"\\n\")\n",
        "        for fn in fns:\n",
        "            if '.txt' in fn:\n",
        "                with open('data/imgs/'+fn) as infile:\n",
        "                    lines = infile.readlines()\n",
        "                    newlines = [''.join([x.strip(), ' ' + os.path.splitext(fn)[0] + '\\n']) for x in lines]\n",
        "                    outfile.writelines(newlines)\n",
        "    # Load all_predictions.txt\n",
        "    df = pd.read_csv('data/results/all_predictions.txt')\n",
        "    print(\"Model predictions: \\n\", df.head())\n",
        "\n",
        "    return df\n",
        "\n",
        "# Combine tagging files for batches A-D\n",
        "def combine_tag_files(tags_fpath):\n",
        "    # Combine tag files for batches A-D\n",
        "    fpath =  os.path.splitext(tags_fpath)[0]\n",
        "    base = fpath.rsplit('_',1)[0] + '_'\n",
        "    exts = ['a.tsv', 'b.tsv', 'c.tsv', 'd.tsv'] \n",
        "    all_filenames = [base + e for e in exts]\n",
        "    print(all_filenames)\n",
        "    df = pd.concat([pd.read_csv(f, sep='\\t', header=0, na_filter = False) for f in all_filenames], ignore_index=True)\n",
        "    # Choose desired columns for tagging\n",
        "    df = df[['url', 'img_id', 'class_id']]\n",
        "    df.rename(columns={'url': 'eolMediaURL', 'img_id': 'identifier', 'class_id': 'tag'}, inplace=True)\n",
        "    print(\"\\nNew concatenated dataframe with all 4 batches: \\n\", df[['eolMediaURL', 'tag']].head())\n",
        "\n",
        "    return df\n",
        "\n",
        "def add_class_names(all_predictions):\n",
        "    # Model predictions with number-coded classes\n",
        "    numbered_tags = pd.read_csv(all_predictions, header=0, sep=\" \")\n",
        "    numbered_tags.class_id = numbered_tags.class_id - 1 # python counts from 0, Yolo from 1\n",
        "    print(\"\\nModel predictions by class id: \\n\", numbered_tags)\n",
        "\n",
        "    # Add class names to model predictions\n",
        "    classes = pd.read_table('data/openimages.names')\n",
        "    classes.columns = ['name']\n",
        "    classes_dict = pd.Series(classes.name.values, index=classes.index).to_dict()\n",
        "    tags = numbered_tags.copy()\n",
        "    tags.replace({\"class_id\":classes_dict}, inplace=True)\n",
        "    tags['class_id'] = tags['class_id'].astype(str)\n",
        "    print(\"\\nModel prediction classes translated from class id's: \\n\", tags)\n",
        "\n",
        "    return tags\n",
        "\n",
        "# Add EOL media URL's to named image tags\n",
        "def add_eolMediaURLs(tags, bundle):\n",
        "    # Read in EOL 20k image url bundle\n",
        "    bundle = read_eolbundle(bundle, 31)\n",
        "    bundle.columns = ['url']\n",
        "    print(\"EOL media URL's corresponding to inference images: \\n\", bundle)\n",
        "    \n",
        "    # Map eolMediaURLs to tags using image filenames\n",
        "    img_fns = bundle['url'].apply(lambda x: os.path.splitext((os.path.basename(x)))[0])\n",
        "    bundle['img_id'] = img_fns\n",
        "    tags.set_index('img_id', inplace=True, drop=True)\n",
        "    bundle.set_index('img_id', inplace=True, drop=True)\n",
        "    final_tags = tags.merge(bundle, left_index=True, right_index=True)\n",
        "    final_tags.reset_index(drop=False, inplace=True)\n",
        "    final_tags.drop_duplicates(inplace=True, ignore_index=True)\n",
        "    print(\"\\nModel predictions with EOL media URL's: \\n\", final_tags.head())\n",
        "\n",
        "    return final_tags\n",
        "\n",
        "# Set filename for saving classification results\n",
        "def set_outpath(tags_file):\n",
        "    tags_file = os.path.splitext(tags_file)[0]\n",
        "    outpath = wd + '/' + cwd + '/data/results/' + tags_file + '.tsv'\n",
        "    print(outpath)\n",
        "    print(\"Saving results to: \\n\", outpath)\n",
        "\n",
        "    return outpath"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2lZ5bdi4bgsV"
      },
      "source": [
        "### Combine predictions for each image"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H5RHwpgKmMMb"
      },
      "source": [
        "# Combine individual prediction files for each image to all_predictions.txt\n",
        "df = combine_predictions(imgs_dir)\n",
        "\n",
        "# Delete inference text files and images (only needed them for inference)\n",
        "!rm -r data/imgs/*"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wi62Y8JacGvh"
      },
      "source": [
        "### Convert detection boxes to flower/fruit tags"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "code",
        "id": "8-RCvF3NNlt5"
      },
      "source": [
        "# Create final predictions dataframe with class names (instead of numbers) and image urls\n",
        "\n",
        "# Add class names to numeric image tags\n",
        "tags = add_class_names('data/results/all_predictions.txt')\n",
        "\n",
        "# Add EOL media URL's from bundle to image tags df\n",
        "final_tags = add_eolMediaURLs(tags, bundle)\n",
        "\n",
        "# Save final tags to file\n",
        "outpath = set_outpath(tags_file)\n",
        "final_tags.to_csv(outpath, sep=\"\\t\", index=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o7N0hAHDFpN_"
      },
      "source": [
        "## Combine tags for 5k image batches A-D\n",
        "---\n",
        "After running steps above for each image batch, combine tag files to one 20k tag dataset."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qbm0_nfQFtkI",
        "cellView": "code"
      },
      "source": [
        "# Write header row of output tagging file\n",
        "# TO DO: Enter any filename from 4 batches of tagging files\n",
        "tags_file = \"plant_poll_coocc_tags_d\" #@param {type:\"string\"}\n",
        "tags_fpath = \"data/results/\" + tags_file + \".tsv\"\n",
        "\n",
        "# Combine exported model predictions and confidence values for all batches\n",
        "df = combine_tag_files(tags_fpath)\n",
        "\n",
        "# Filter for desired classes\n",
        "# TO DO: Enter classes to filter by\n",
        "filter = ['Butterfly', 'Insect', 'Beetle', 'Ant', 'Bat (Animal)', 'Bird', 'Bee', 'Invertebrate', 'Animal'] #@param\n",
        "pattern = '|'.join(filter1)\n",
        "\n",
        "# Set all detections for filtered classes to 'Pollinator'\n",
        "print(\"\\nNo. tags matching filtered class(es) {}: {}\\n\".format(filter, len(df[df.tag.str.contains(pattern)])))\n",
        "print(\"\\nTags matching filtered class(es): \\n\", df[df.tag.str.contains(pattern)])\n",
        "df.loc[df.tag.str.contains(pattern), 'tag'] = 'Pollinator'\n",
        "\n",
        "# Remove all detections that aren't for filtered classes\n",
        "df.loc[~df.tag.str.contains(pattern), 'tag'] = 'None'\n",
        "print(\"\\nNo. tags not matching filtered classes: \\n\", len(df.tag[~df.tag.str.contains(pattern)]))\n",
        "print(\"\\nTags not matching filtered classes: \\n\", df[~df.tag.str.contains(pattern)])\n",
        "\n",
        "# Write results to tsv\n",
        "outpath = base + 'finaltags.tsv'\n",
        "df.to_csv(outpath, sep='\\t', index=False)\n",
        "print(\"\\n\\nFinal tagging file {}: \\n{}\".format(outpath, df.head()))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vmmCI1jCVNxl"
      },
      "source": [
        "## Display cropping results on images\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7NN4fOicvcl0"
      },
      "source": [
        "# Set number of seconds to timeout if image url taking too long to open\n",
        "import socket\n",
        "socket.setdefaulttimeout(10)\n",
        "\n",
        "# TO DO: Adjust line below to see up to 50 images displayed at a time\n",
        "start = 0 #@param {type:\"slider\", min:0, max:5000, step:50}\n",
        "stop = start+50\n",
        "\n",
        "# Loop through images\n",
        "for i, row in df.iloc[start:stop].iterrows():\n",
        "    try:\n",
        "        # Read in image \n",
        "        url = df['eolMediaURL'][i]\n",
        "        img = url_to_image(url)\n",
        "\n",
        "        # Fetch image tag\n",
        "        tag = df['tag'][i]\n",
        "  \n",
        "        # Display progress message after each image is loaded\n",
        "        print('Successfully loaded {} of {} images'.format(i+1, (stop-start)))\n",
        "\n",
        "        # Plot cropping box on image\n",
        "        _, ax = plt.subplots(figsize=(10, 10))\n",
        "        ax.imshow(img)\n",
        "        plt.axis('off')\n",
        "        plt.title('{}) Tag: {}'.format(i+1, tag))\n",
        "\n",
        "    except:\n",
        "        print('Check if URL from {} is valid'.format(url))"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}