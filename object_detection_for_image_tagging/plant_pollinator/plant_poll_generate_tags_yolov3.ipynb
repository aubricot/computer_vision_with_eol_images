{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "plant_poll_generate_tags_yolov3.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "YdNG8YEWaqsX",
        "BcfHlZ7QNXHc",
        "o7N0hAHDFpN_",
        "vmmCI1jCVNxl"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/aubricot/computer_vision_with_eol_images/blob/master/object_detection_for_image_tagging/plant_pollinator/plant_poll_generate_tags_yolov3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j-PBcUKyc95M"
      },
      "source": [
        "# Using YOLO v3 pre-trained on Google Open Images to add plant-pollinator co-occurrence tags for ladybugs, beetles, and insects in plant images\n",
        "---\n",
        "*Last Updated 5 June 2021*   \n",
        "Using a YOLOv3 model (downloaded from [here](https://github.com/AlexeyAB/darknet) ) pre-trained on [Google Open Images](https://storage.googleapis.com/openimages/web/visualizer/index.html?set=train&type=detection&c=%2Fm%2F03vt0) as a method to do customized, large-scale image processing. EOL Angiosperm images will be tagged for plant-pollinator co-occurrence using the detected insects. Tags will further extend EOLv3 image search functions."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fX9LGz3Ydu27"
      },
      "source": [
        "## Installs & Imports\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q5lC8PSbGCyN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ca0ba9b0-c9aa-42b0-bf39-daa94dbc972e"
      },
      "source": [
        "# Mount google drive to import/export files\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yDdbBYnp2nCK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "80e2b1ed-7c4e-4b6d-a50f-5b2ffd3d0344"
      },
      "source": [
        "# For importing/exporting files, working with arrays, etc\n",
        "import os\n",
        "import glob\n",
        "import pathlib\n",
        "import six.moves.urllib as urllib\n",
        "import sys\n",
        "import tarfile\n",
        "import zipfile\n",
        "import numpy as np \n",
        "import csv\n",
        "import matplotlib.pyplot as plt\n",
        "import time\n",
        "import pandas as pd\n",
        "\n",
        "# For downloading images\n",
        "!apt-get install aria2\n",
        "\n",
        "# For drawing onto and plotting images\n",
        "import matplotlib.pyplot as plt\n",
        "from PIL import Image\n",
        "from PIL import ImageColor\n",
        "from PIL import ImageDraw\n",
        "from PIL import ImageFont\n",
        "from PIL import ImageOps\n",
        "import cv2\n",
        "\n",
        "%matplotlib inline\n",
        "%config InlineBackend.figure_format = 'svg'"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "The following additional packages will be installed:\n",
            "  libc-ares2\n",
            "The following NEW packages will be installed:\n",
            "  aria2 libc-ares2\n",
            "0 upgraded, 2 newly installed, 0 to remove and 39 not upgraded.\n",
            "Need to get 1,274 kB of archives.\n",
            "After this operation, 4,912 kB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu bionic/main amd64 libc-ares2 amd64 1.14.0-1 [37.1 kB]\n",
            "Get:2 http://archive.ubuntu.com/ubuntu bionic/universe amd64 aria2 amd64 1.33.1-1 [1,236 kB]\n",
            "Fetched 1,274 kB in 0s (7,577 kB/s)\n",
            "Selecting previously unselected package libc-ares2:amd64.\n",
            "(Reading database ... 160772 files and directories currently installed.)\n",
            "Preparing to unpack .../libc-ares2_1.14.0-1_amd64.deb ...\n",
            "Unpacking libc-ares2:amd64 (1.14.0-1) ...\n",
            "Selecting previously unselected package aria2.\n",
            "Preparing to unpack .../aria2_1.33.1-1_amd64.deb ...\n",
            "Unpacking aria2 (1.33.1-1) ...\n",
            "Setting up libc-ares2:amd64 (1.14.0-1) ...\n",
            "Setting up aria2 (1.33.1-1) ...\n",
            "Processing triggers for man-db (2.8.3-2ubuntu0.1) ...\n",
            "Processing triggers for libc-bin (2.27-3ubuntu1.2) ...\n",
            "/sbin/ldconfig.real: /usr/local/lib/python3.7/dist-packages/ideep4py/lib/libmkldnn.so.0 is not a symbolic link\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "isysjRGl21_D"
      },
      "source": [
        "## Model preparation (only run once)\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xym8_m8CIyXK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "87106b27-af99-4e4d-cf4a-ed3e7eb10a6f"
      },
      "source": [
        "# Install darknet\n",
        "\n",
        "# TO DO: Type in the path to your working directory in form field to right\n",
        "basewd = \"/content/drive/MyDrive/train\" #@param {type:\"string\"}\n",
        "wd = 'darknet'\n",
        "%cd $basewd\n",
        "\n",
        "# Download darknet (the native implementation of YOLO)\n",
        "if os.path.exists(wd):\n",
        "    %cd $wd\n",
        "\n",
        "elif not os.path.exists(wd):\n",
        "    !git clone https://github.com/AlexeyAB/darknet\n",
        "    # Compile darknet\n",
        "    %cd $wd\n",
        "    !python setup.py build_ext --inplace\n",
        "    # Change makefile to have GPU and OPENCV enabled\n",
        "    !sed -i 's/OPENCV=0/OPENCV=1/' Makefile\n",
        "    !sed -i 's/GPU=0/GPU=1/' Makefile\n",
        "    !sed -i 's/CUDNN=0/CUDNN=1/' Makefile\n",
        "    !sed -i 's/CUDNN_HALF=0/CUDNN_HALF=1/' Makefile\n",
        "    # Download pretrained YOLOv3 weights for Open Images\n",
        "    !wget https://pjreddie.com/media/files/yolov3-openimages.weights\n",
        "\n",
        "# Verify CUDA version (for using GPU)\n",
        "!/usr/local/cuda/bin/nvcc --version\n",
        "\n",
        "# Make darknet\n",
        "!make"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/MyDrive/train\n",
            "/content/drive/MyDrive/train/darknet2\n",
            "nvcc: NVIDIA (R) Cuda compiler driver\n",
            "Copyright (c) 2005-2020 NVIDIA Corporation\n",
            "Built on Wed_Jul_22_19:09:09_PDT_2020\n",
            "Cuda compilation tools, release 11.0, V11.0.221\n",
            "Build cuda_11.0_bu.TC445_37.28845127_0\n",
            "/content/drive/MyDrive/train/darknet2/darknet\n",
            "chmod +x *.sh\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cKovA4-aifP5"
      },
      "source": [
        "# Classify images\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wjTgajd3keAi"
      },
      "source": [
        "### Temporarily download images from EOL bundle to Google Drive (YOLO cannot directly parse URL images)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zCxtKyRPij8R"
      },
      "source": [
        "# Download images\n",
        "bundle = \"https://editors.eol.org/other_files/bundle_images/files/images_for_Angiosperms_20K_breakdown_download_000031.txt\" #@param {type:\"string\"}\n",
        "df = pd.read_csv(bundle)\n",
        "\n",
        "# Take subset of bundle\n",
        "# TO DO: Change file name for each bundle/run abcd if doing 4 batches using dropdown form to right\n",
        "ss = \"plant_poll_coocc_tags_a\" #@param [\"plant_poll_coocc_tags_a\", \"plant_poll_coocc_tags_b\", \"plant_poll_coocc_tags_c\", \"plant_poll_coocc_tags_d\"] {allow-input: true}\n",
        "ss = ss + \".txt\"\n",
        "\n",
        "# Run in 4 batches of 5k images each (batch a is from 0-5000, b from 5000 to 10000, etc)\n",
        "if \"_a\" in ss:\n",
        "  a=0\n",
        "  b=5000\n",
        "elif \"_b\" in ss:\n",
        "  a=5000\n",
        "  b=10000\n",
        "elif \"_c\" in ss:\n",
        "  a=10000\n",
        "  b=15000\n",
        "elif \"_d\" in ss:\n",
        "  a=15000\n",
        "  b=20000\n",
        "\n",
        "# Save subset to text file for image download\n",
        "df = df.iloc[a:b]\n",
        "outfpath = wd + \"/data/imgs/\" + ss\n",
        "df.to_csv(outfpath, sep='\\n', index=False, header=False)\n",
        "\n",
        "# Download images (takes 7-10 min per 5k imgs, aria2 downloads 16imgs at a time)\n",
        "img_outfpath = wd + \"/data/imgs\"\n",
        "%cd $img_outfpath\n",
        "!aria2c -x 16 -s 1 -i $ss\n",
        "\n",
        "# Check how many images downloaded\n",
        "print(\"Number of images downloaded to Google Drive: \")\n",
        "!ls . | wc -l"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "we9gsoPXksxH"
      },
      "source": [
        "# If images downloaded correctly, move text file to image_data/bundles\n",
        "%cd ../\n",
        "!mv imgs/*.txt img_info/"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O_nGr7A7pGfW"
      },
      "source": [
        "# Make imgs.txt file to run images through YOLO for inference in batches\n",
        "%cd $wd\n",
        "%cd data\n",
        "\n",
        "inf_ss = img_outfpath +'/'+ss\n",
        "with open(inf_ss, 'w', encoding='utf-8') as f:\n",
        "  for dir, dirs, files in os.walk(path):\n",
        "    files = [fn for fn in files]\n",
        "    for fn in files:\n",
        "      if 'txt' not in fn:\n",
        "        out = \"data/imgs/\" + fn\n",
        "        f.writelines(out + '\\n')\n",
        "\n",
        "# Inspect imgs.txt file to confirm length and content\n",
        "df = pd.read_csv(inf_ss, header=None)\n",
        "print(\"\\nNumber of images in {}: {}\".format(inf_ss, len(df)))\n",
        "print(\"\\nImages textfile: \\n\", df.head())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NnITAALxmoKY"
      },
      "source": [
        "### Run images through trained model\n",
        "These steps take ~3 hours for 5,000 images"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j30QBhJvsveE"
      },
      "source": [
        "# this creates a symbolic link so that now the path /content/gdrive/My\\ Drive/ is equal to /mydrive\n",
        "!ln -s /content/gdrive/My\\ Drive/ /mydrive\n",
        "!ls /mydrive\n",
        "\n",
        "# TO DO: In next bloc, change inference image file list name at end of line after \"<\" to match inf_ss defined above\n",
        "# ex: data/imgs/plant_poll_coocc_tags_a.txt\n",
        "print(\"filename to copy-paste into code block below:\", os.path.basename(inf_ss))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZljsbwXnubZc"
      },
      "source": [
        "# TO DO: Change inference image file list name at end of line after \"<\" to match inf_ss defined above\n",
        "%cd $wd\n",
        "filepath = 'data/imgs/plant_poll_coocc_tags_d.txt'\n",
        "\n",
        "# darknet run with external output flag to print bounding box coordinates\n",
        "!./darknet detector test cfg/openimages.data cfg/yolov3-openimages.cfg yolov3-openimages.weights -dont_show -save_labels < {filepath}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YdNG8YEWaqsX"
      },
      "source": [
        "#### To run individual images through by filename and display results"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kIDpIFWsOZo5"
      },
      "source": [
        "# TO DO: Change inference image file list name at end of line after \"<\" to match inf_ss defined above\n",
        "%cd /content/drive/My Drive/train/darknet2/darknet\n",
        "\n",
        "# darknet run with external output flag to print bounding box coordinates\n",
        "!./darknet detector test cfg/openimages.data cfg/yolov3-openimages.cfg yolov3-openimages.weights data/imgs/caterpillar_3.jpg"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "syAc61g3QMxg"
      },
      "source": [
        "# define helper functions\n",
        "def imShow(path):\n",
        "  import cv2\n",
        "  import matplotlib.pyplot as plt\n",
        "  %matplotlib inline\n",
        "\n",
        "  image = cv2.imread(path)\n",
        "  height, width = image.shape[:2]\n",
        "  resized_image = cv2.resize(image,(3*width, 3*height), interpolation = cv2.INTER_CUBIC)\n",
        "\n",
        "  fig = plt.gcf()\n",
        "  fig.set_size_inches(18, 10)\n",
        "  plt.axis(\"off\")\n",
        "  plt.imshow(cv2.cvtColor(resized_image, cv2.COLOR_BGR2RGB))\n",
        "  plt.show()\n",
        "\n",
        "imShow('predictions.jpg')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BcfHlZ7QNXHc"
      },
      "source": [
        "### Post-process model output"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H5RHwpgKmMMb"
      },
      "source": [
        "# Combine individual prediction files for each image to all_predictions.txt\n",
        "\n",
        "# Delete image file list for inference\n",
        "inf_ss = 'data/imgs/' + os.path.basename(inf_ss)\n",
        "!rm $inf_ss\n",
        "\n",
        "# Combine individual text files and image filenames into all_predictions.txt\n",
        "fns = os.listdir('data/imgs')\n",
        "with open('data/results/all_predictions.txt', 'w') as outfile:\n",
        "  header = \"class_id x y w h img_id\"\n",
        "  outfile.write(header + \"\\n\")\n",
        "  for fn in fns:\n",
        "        if 'txt' in fn:\n",
        "          with open('data/imgs/'+fn) as infile:\n",
        "            lines = infile.readlines()\n",
        "            newlines = [''.join([x.strip(), ' ' + os.path.splitext(fn)[0] + '\\n']) for x in lines]\n",
        "            outfile.writelines(newlines)\n",
        "\n",
        "# Inspect saved predictions\n",
        "df = pd.read_csv('data/results/all_predictions.txt')\n",
        "print(df.head())\n",
        "\n",
        "# Delete all individual prediction files\n",
        "!rm -r data/imgs/*.txt\n",
        "\n",
        "# Delete all image files now that they have been used for inference\n",
        "!rm -r data/imgs/*"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "code",
        "id": "8-RCvF3NNlt5"
      },
      "source": [
        "# Create final predictions dataframe with class names (instead of numbers) and image urls\n",
        "# EOL image url bundle\n",
        "df = pd.read_csv(bundle)\n",
        "df.columns = ['url']\n",
        "print(df)\n",
        "\n",
        "# Model predictions with number-coded classes\n",
        "predict = pd.read_csv('data/results/all_predictions.txt', header=0, sep=\" \")\n",
        "predict.class_id = predict.class_id - 1 #class_id counts started from 1 instead of 0 from YOLO\n",
        "print(predict)\n",
        "\n",
        "# Add class names to model predictions\n",
        "classnames = pd.read_table('data/openimages.names')\n",
        "classnames.columns = ['classname']\n",
        "#print(classnames)\n",
        "tag_df = predict.copy()\n",
        "di = pd.Series(classnames.classname.values,index=classnames.index).to_dict()\n",
        "tag_df.replace({\"class_id\":di}, inplace=True)\n",
        "tag_df['class_id'] = tag_df['class_id'].astype(str)\n",
        "print(tag_df)\n",
        "\n",
        "# Add urls to model predictions\n",
        "map_urls = df.copy()\n",
        "img_ids = map_urls['url'].apply(lambda x: os.path.splitext((os.path.basename(x)))[0])\n",
        "map_urls['img_id'] = img_ids\n",
        "#print(map_urls)\n",
        "\n",
        "tag_df.set_index('img_id', inplace=True, drop=True)\n",
        "map_urls.set_index('img_id', inplace=True, drop=True)\n",
        "mapped_tagdf = tag_df.merge(map_urls, left_index=True, right_index=True)\n",
        "mapped_tagdf.reset_index(drop=False, inplace=True)\n",
        "mapped_tagdf.drop_duplicates(inplace=True, ignore_index=True)\n",
        "print(mapped_tagdf.head())\n",
        "\n",
        "# Save final tags to file\n",
        "fn = os.path.splitext(os.path.basename(inf_ss))[0]\n",
        "outpath = 'data/results/' + fn + '.tsv'\n",
        "mapped_tagdf.to_csv(outpath, sep=\"\\t\", index=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o7N0hAHDFpN_"
      },
      "source": [
        "# Combine tag files A-D\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qbm0_nfQFtkI"
      },
      "source": [
        "# Write header row of output tagging file\n",
        "# TO DO: Change file name for each bundle/run abcd if doing 4 batches using dropdown form to right\n",
        "tags_file = \"plant_poll_coocc_tags_d\" #@param {type:\"string\"}\n",
        "tags_fpath = \"/content/drive/My Drive/train/darknet2/darknet/data/results/\" + tags_file + \".tsv\"\n",
        "\n",
        "# Combine exported model predictions and confidence values from above to one dataframe\n",
        "fpath =  os.path.splitext(tags_fpath)[0]\n",
        "base = fpath.rsplit('_',1)[0] + '_'\n",
        "exts = ['a.tsv', 'b.tsv', 'd.tsv']\n",
        "#exts = ['a.tsv', 'b.tsv', 'c.tsv', 'd.tsv']\n",
        "all_filenames = [base + e for e in exts]\n",
        "df1 = pd.concat([pd.read_csv(f, sep='\\t', header=0, na_filter = False) for f in all_filenames], ignore_index=True)\n",
        "\n",
        "# Filter for desired classes\n",
        "filter = ['Butterfly', 'Insect', 'Beetle', 'Ant', 'Bat (Animal)', 'Bird', 'Bee', \\\n",
        "          'Invertebrate', 'Animal']\n",
        "pattern = '|'.join(filter)\n",
        "df = df1.copy()\n",
        "print(df.class_id)\n",
        "df.loc[df['class_id'].str.contains(pattern), 'class_id'] = 'Pollinator'\n",
        "print(df.class_id[df.class_id.str.contains(pattern)])\n",
        "print(len(df.class_id[df.class_id.str.contains(pattern)]))\n",
        "df.loc[~df.class_id.str.contains(pattern), 'class_id'] = 'None'\n",
        "print(df[~df.class_id.str.contains(pattern)])\n",
        "\n",
        "# Write results to tsv\n",
        "print(df.head())\n",
        "outfpath = base + 'finaltags.tsv'\n",
        "df.to_csv(outfpath, sep='\\t', index=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vmmCI1jCVNxl"
      },
      "source": [
        "# Display predictions on images\n",
        "---\n",
        "Inspect detection results and verify that they are as expected"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gSmno0yFVPsS"
      },
      "source": [
        "# TO DO: Do you want to use the tagging file exported above?\n",
        "use_outfpath = \"no\" #@param [\"yes\", \"no\"]\n",
        "# If no, choose other path to use\n",
        "otherpath = \"data/results/plant_poll_coocc_tags_finaltags.tsv\" #@param {type:\"string\"}\n",
        "if use_outfpath == \"yes\":\n",
        "  outfpath = outfpath\n",
        "else:\n",
        "  outfpath = otherpath\n",
        "df = pd.read_csv(outfpath, sep=\"\\t\", header=0)\n",
        "print(df.head())\n",
        "\n",
        "# For uploading an image from url\n",
        "# Modified from https://www.pyimagesearch.com/2015/03/02/convert-url-to-image-with-python-and-opencv/\n",
        "def url_to_image(url):\n",
        "  resp = urllib.request.urlopen(url)\n",
        "  image = np.asarray(bytearray(resp.read()), dtype=\"uint8\")\n",
        "  image = cv2.imdecode(image, cv2.IMREAD_COLOR)\n",
        "  image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        " \n",
        "  return image"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9-zpaQi2W8sE"
      },
      "source": [
        "# Display crop dimensions on images\n",
        "# Adjust line below to see up to 50 images displayed at a time\n",
        "a = 0 #@param {type:\"slider\", min:0, max:5000, step:50}\n",
        "b = a+50\n",
        "\n",
        "for i, row in df.iloc[a:b].iterrows():\n",
        "  # Read in image \n",
        "  url = df['url'][i]\n",
        "  img = url_to_image(url)\n",
        "  h,w = img.shape[:2]\n",
        "  # Define variables needed to draw bounding box on image\n",
        "  xmin = round((df['x'][i] - (df['w'][i]/2))*w)\n",
        "  if (xmin < 0): xmin = 0\n",
        "  ymin = round((df['y'][i] - (df['h'][i]/2))*h)\n",
        "  if (ymin < 0): ymin = 0\n",
        "  xmax = round(xmin + (df['w'][i]) * w)\n",
        "  if (xmax > w-1): xmax = w-1\n",
        "  ymax = round(ymin + (df['h'][i].astype(int)) * h)\n",
        "  if (ymax > 0): ymax = h-1\n",
        "\n",
        "  # Set box/font color and size\n",
        "  maxdim = max(df['w'][i],df['h'][i])\n",
        "  fontScale = 1\n",
        "  box_col = (255, 0, 157)\n",
        "  \n",
        "  # Set box/font color and size\n",
        "  maxdim = max(df['w'][i],df['h'][i])\n",
        "  fontScale = 1\n",
        "  box_col = (255, 0, 157)\n",
        "\n",
        "  # Draw tag label on image\n",
        "  tag = df['class_id'][i]\n",
        "  image_wbox = cv2.putText(img, tag, (xmin+7, ymax-12), cv2.FONT_HERSHEY_SIMPLEX, fontScale, box_col, 2, cv2.LINE_AA)  \n",
        "  \n",
        "  # Draw box label on image\n",
        "  image_wbox = cv2.rectangle(img, (xmin, ymax), (xmax, ymin), box_col, 5)\n",
        "  \n",
        "  # Plot and show cropping boxes on images\n",
        "  _, ax = plt.subplots(figsize=(10, 10))\n",
        "  ax.imshow(image_wbox)\n",
        "  # Display image URL above image to facilitate troubleshooting/fine-tuning of data reformatting and tidying steps in convert_bboxdims.py or preprocessing.ipynb\n",
        "  plt.title('{}'.format(url, xmin, ymin, xmax, ymax))"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}