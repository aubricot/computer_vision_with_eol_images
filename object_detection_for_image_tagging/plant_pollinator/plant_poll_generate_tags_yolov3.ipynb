{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "plant_poll_generate_tags_yolov3.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/aubricot/computer_vision_with_eol_images/blob/master/object_detection_for_image_tagging/plant_pollinator/plant_poll_generate_tags_yolov3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j-PBcUKyc95M"
      },
      "source": [
        "# Using YOLO v3 pre-trained on Google Open Images to add plant-pollinator co-occurrence tags for ladybugs, beetles, and insects in plant images\n",
        "---\n",
        "*Last Updated 9 June 2021*   \n",
        "Using a YOLOv3 model (downloaded from [here](https://github.com/AlexeyAB/darknet) ) pre-trained on [Google Open Images](https://storage.googleapis.com/openimages/web/visualizer/index.html?set=train&type=detection&c=%2Fm%2F03vt0) as a method to do customized, large-scale image processing. EOL Angiosperm images will be tagged for plant-pollinator co-occurrence using the detected insects. Tags will further extend EOLv3 image search functions."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fX9LGz3Ydu27"
      },
      "source": [
        "## Installs & Imports\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q5lC8PSbGCyN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ca0ba9b0-c9aa-42b0-bf39-daa94dbc972e"
      },
      "source": [
        "# Mount google drive to import/export files\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yDdbBYnp2nCK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "80e2b1ed-7c4e-4b6d-a50f-5b2ffd3d0344"
      },
      "source": [
        "# For importing/exporting files, working with arrays, etc\n",
        "import os\n",
        "import glob\n",
        "import pathlib\n",
        "import six.moves.urllib as urllib\n",
        "import sys\n",
        "import tarfile\n",
        "import zipfile\n",
        "import numpy as np \n",
        "import csv\n",
        "import matplotlib.pyplot as plt\n",
        "import time\n",
        "import pandas as pd\n",
        "\n",
        "# For downloading images\n",
        "!apt-get install aria2\n",
        "\n",
        "# For drawing onto and plotting images\n",
        "import matplotlib.pyplot as plt\n",
        "from PIL import Image\n",
        "from PIL import ImageColor\n",
        "from PIL import ImageDraw\n",
        "from PIL import ImageFont\n",
        "from PIL import ImageOps\n",
        "import cv2\n",
        "%matplotlib inline\n",
        "%config InlineBackend.figure_format = 'svg'"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "The following additional packages will be installed:\n",
            "  libc-ares2\n",
            "The following NEW packages will be installed:\n",
            "  aria2 libc-ares2\n",
            "0 upgraded, 2 newly installed, 0 to remove and 39 not upgraded.\n",
            "Need to get 1,274 kB of archives.\n",
            "After this operation, 4,912 kB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu bionic/main amd64 libc-ares2 amd64 1.14.0-1 [37.1 kB]\n",
            "Get:2 http://archive.ubuntu.com/ubuntu bionic/universe amd64 aria2 amd64 1.33.1-1 [1,236 kB]\n",
            "Fetched 1,274 kB in 0s (7,577 kB/s)\n",
            "Selecting previously unselected package libc-ares2:amd64.\n",
            "(Reading database ... 160772 files and directories currently installed.)\n",
            "Preparing to unpack .../libc-ares2_1.14.0-1_amd64.deb ...\n",
            "Unpacking libc-ares2:amd64 (1.14.0-1) ...\n",
            "Selecting previously unselected package aria2.\n",
            "Preparing to unpack .../aria2_1.33.1-1_amd64.deb ...\n",
            "Unpacking aria2 (1.33.1-1) ...\n",
            "Setting up libc-ares2:amd64 (1.14.0-1) ...\n",
            "Setting up aria2 (1.33.1-1) ...\n",
            "Processing triggers for man-db (2.8.3-2ubuntu0.1) ...\n",
            "Processing triggers for libc-bin (2.27-3ubuntu1.2) ...\n",
            "/sbin/ldconfig.real: /usr/local/lib/python3.7/dist-packages/ideep4py/lib/libmkldnn.so.0 is not a symbolic link\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "isysjRGl21_D"
      },
      "source": [
        "## Model preparation (only run once)\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xym8_m8CIyXK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "87106b27-af99-4e4d-cf4a-ed3e7eb10a6f"
      },
      "source": [
        "# Install darknet\n",
        "\n",
        "# TO DO: Type in the path to your working directory in form field to right\n",
        "basewd = \"/content/drive/MyDrive/train\" #@param {type:\"string\"}\n",
        "wd = 'darknet'\n",
        "%cd $basewd\n",
        "\n",
        "# Download darknet (the native implementation of YOLO)\n",
        "if os.path.exists(wd):\n",
        "    %cd $wd\n",
        "\n",
        "elif not os.path.exists(wd):\n",
        "    !git clone https://github.com/AlexeyAB/darknet\n",
        "    # Compile darknet\n",
        "    %cd $wd\n",
        "    !python setup.py build_ext --inplace\n",
        "    # Change makefile to have GPU and OPENCV enabled\n",
        "    !sed -i 's/OPENCV=0/OPENCV=1/' Makefile\n",
        "    !sed -i 's/GPU=0/GPU=1/' Makefile\n",
        "    !sed -i 's/CUDNN=0/CUDNN=1/' Makefile\n",
        "    !sed -i 's/CUDNN_HALF=0/CUDNN_HALF=1/' Makefile\n",
        "    # Download pretrained YOLOv3 weights for Open Images\n",
        "    !wget https://pjreddie.com/media/files/yolov3-openimages.weights\n",
        "\n",
        "# Verify CUDA version (for using GPU)\n",
        "!/usr/local/cuda/bin/nvcc --version\n",
        "\n",
        "# Make darknet\n",
        "!make"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/MyDrive/train\n",
            "/content/drive/MyDrive/train/darknet2\n",
            "nvcc: NVIDIA (R) Cuda compiler driver\n",
            "Copyright (c) 2005-2020 NVIDIA Corporation\n",
            "Built on Wed_Jul_22_19:09:09_PDT_2020\n",
            "Cuda compilation tools, release 11.0, V11.0.221\n",
            "Build cuda_11.0_bu.TC445_37.28845127_0\n",
            "/content/drive/MyDrive/train/darknet2/darknet\n",
            "chmod +x *.sh\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cKovA4-aifP5"
      },
      "source": [
        "## Generate cropping coordinates for images\n",
        "---\n",
        "Run EOL 20k image bundles through pre-trained object detection models and save results in 4 batches (A-D). "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fuZL4TGzitNZ"
      },
      "source": [
        "### Prepare object detection functions and settings"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wqoLKpXveeAt"
      },
      "source": [
        "# Functions\n",
        "\n",
        "# Read in data file\n",
        "def read_datafile(fpath, sep=\"\\t\", header=0, disp_head=True):\n",
        "    \"\"\"\n",
        "    Defaults to tab-separated data files with header in row 0\n",
        "    \"\"\"\n",
        "    try:\n",
        "        df = pd.read_csv(fpath, sep=sep, header=header)\n",
        "        if disp_head:\n",
        "            print(\"Data header: \\n\", df.head())\n",
        "    except FileNotFoundError as e:\n",
        "        raise Exception(\"File not found: Enter the path to your file in form field and re-run\").with_traceback(e.__traceback__)\n",
        "    \n",
        "    return df\n",
        "\n",
        "# Read in bundle images\n",
        "def read_eolbundle(bundle, no_bundles):\n",
        "    # Get first 20k images for Lepidoptera bundles using initial bundle basename\n",
        "    base = os.path.splitext(os.path.basename(bundle))[0].rsplit('_',1)[0]\n",
        "    # Load in all sub-bundles (ex: 000001 - 000031 for Angiosperms)\n",
        "    nums1 = list(range(1, 10))\n",
        "    nums2 = list(range(10, no_bundles))\n",
        "    exts1 = [\"00000\" + str(num) + \".txt\" for num in nums1]\n",
        "    exts2 = [\"0000\" + str(num) + \".txt\" for num in nums2]\n",
        "    exts = exts1 + exts2\n",
        "    all_filenames = [\"https://editors.eol.org/other_files/bundle_images/files/\" + base + \"_\" + e for e in exts]\n",
        "    bundles = pd.concat([pd.read_csv(f, sep='\\t', header=None) for f in all_filenames], ignore_index=True)\n",
        "    print(\"EOL image bundle with {} images: \".format(bundles.head(), len(bundles))\n",
        "\n",
        "# Define start and stop indices in EOL bundle for running inference   \n",
        "def set_start_stop():\n",
        "    # To test with a tiny subset, use 5 random bundle images\n",
        "    if test_with_tiny_subset:\n",
        "        start=np.random.choice(a=1000, size=1)[0]\n",
        "        stop=start+5\n",
        "    # To run inference on 4 batches of 5k images each\n",
        "    elif \"_a.\" in outfpath: # batch a is from 0-5000\n",
        "        start=0\n",
        "        stop=5000\n",
        "    elif \"_b.\" in outfpath: # batch b is from 5000-1000\n",
        "        start=5000\n",
        "        stop=10000\n",
        "    elif \"_c.\" in outfpath: # batch c is from 10000-15000\n",
        "        start=10000\n",
        "        stop=15000\n",
        "    elif \"_d.\" in outfpath: # batch d is from 15000-20000\n",
        "        start=15000\n",
        "        stop=20000\n",
        "    \n",
        "    return start, stop\n",
        "\n",
        "# To display results\n",
        "def imShow(path):\n",
        "    image = cv2.imread(path)\n",
        "    height, width = image.shape[:2]\n",
        "    resized_image = cv2.resize(image,(3*width, 3*height), interpolation = cv2.INTER_CUBIC)\n",
        "\n",
        "    fig = plt.gcf()\n",
        "    fig.set_size_inches(18, 10)\n",
        "    plt.axis(\"off\")\n",
        "    plt.imshow(cv2.cvtColor(resized_image, cv2.COLOR_BGR2RGB))\n",
        "    plt.show()\n",
        "\n",
        "# For uploading an image from url\n",
        "# Modified from https://www.pyimagesearch.com/2015/03/02/convert-url-to-image-with-python-and-opencv/\n",
        "def url_to_image(url):\n",
        "    resp = urllib.request.urlopen(url)\n",
        "    image = np.asarray(bytearray(resp.read()), dtype=\"uint8\")\n",
        "    image = cv2.imdecode(image, cv2.IMREAD_COLOR)\n",
        "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "    im_h, im_w = image.shape[:2]\n",
        " \n",
        "    return image"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wjTgajd3keAi"
      },
      "source": [
        "### Temporarily download images from EOL bundle to Google Drive (YOLO cannot directly parse URL images)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zCxtKyRPij8R"
      },
      "source": [
        "# Download images for 20K bundle of Angiosperm images with 31 sub-bundles\n",
        "# To DO: Enter any EOL Angiosperm image bundle URL\n",
        "bundle = \"https://editors.eol.org/other_files/bundle_images/files/images_for_Angiosperms_20K_breakdown_download_000031.txt\" #@param {type:\"string\"}\n",
        "df = read_eolbundle(bundle, 31)\n",
        "\n",
        "# Test with a smaller subset than 5k images?\n",
        "# TO DO: If yes, check test_with_tiny_subset box\n",
        "test_with_tiny_subset = True #@param {type: \"boolean\"}\n",
        "\n",
        "# Take 5k subset of bundle for running inference\n",
        "# TO DO: Change file name for each bundle/run abcd if doing 4 batches using dropdown form to right\n",
        "subset = \"plant_poll_coocc_tags_a\" #@param [\"plant_poll_coocc_tags_a\", \"plant_poll_coocc_tags_b\", \"plant_poll_coocc_tags_c\", \"plant_poll_coocc_tags_d\"] {allow-input: true}\n",
        "outfpath = wd + \"/data/imgs/\" + subset + \".txt\"\n",
        "\n",
        "# Save 5k subset to text file for image download\n",
        "start, stop = set_start_stop()\n",
        "df = df.iloc[start:stop]\n",
        "df.to_csv(outfpath, sep='\\n', index=False, header=False)\n",
        "\n",
        "# Download images \n",
        "# Note: Takes 7-10 min per 5k imgs, aria2 downloads 16imgs at a time\n",
        "img_outfpath = wd + \"/data/imgs\"\n",
        "%cd $img_outfpath\n",
        "!aria2c -x 16 -s 1 -i $subset\n",
        "\n",
        "# Verify how many images downloaded\n",
        "print(\"Number of images downloaded to Google Drive: \")\n",
        "!ls . | wc -l"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "we9gsoPXksxH"
      },
      "source": [
        "# If images downloaded correctly, move text file to data/img_info/\n",
        "%cd ../\n",
        "!mv imgs/*.txt img_info/"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O_nGr7A7pGfW"
      },
      "source": [
        "# Make imgs.txt file to run images through YOLO for inference in batches by filename\n",
        "%cd $wd\n",
        "%cd data\n",
        "\n",
        "inf_subset = img_outfpath + '/' + subset\n",
        "with open(inf_subset, 'w', encoding='utf-8') as f:\n",
        "    for dir, dirs, files in os.walk(path):\n",
        "        files = [fn for fn in files]\n",
        "        for fn in files:\n",
        "            if 'txt' not in fn:\n",
        "                out = \"data/imgs/\" + fn\n",
        "                f.writelines(out + '\\n')\n",
        "\n",
        "# Inspect imgs.txt file to confirm length and content\n",
        "print(\"\\nNumber of images in {}: {}\".format(inf_subset, len(df)))\n",
        "print(\"\\nImages textfile: \\n\")\n",
        "df = read_datafile(inf_subset, header=None, sep='\\n', disp_head=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NnITAALxmoKY"
      },
      "source": [
        "### Run images through trained model\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YdNG8YEWaqsX"
      },
      "source": [
        "#### Test: Run individual image through by filename and display results"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kIDpIFWsOZo5"
      },
      "source": [
        "# Run inference on a single image by filename and show results\n",
        "%cd $wd\n",
        "\n",
        "#\n",
        "# TO DO: Enter image filename to run inference on\n",
        "\n",
        "# Run darknet and show bounding box coordinates\n",
        "!./darknet detector test cfg/openimages.data cfg/yolov3-openimages.cfg yolov3-openimages.weights data/imgs/caterpillar_3.jpg\n",
        "\n",
        "# Display detection results\n",
        "imShow('predictions.jpg')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GJ6h9PqTh-BE"
      },
      "source": [
        "### Generate crops: Run inference on EOL images & save results for cropping\n",
        "Use 20K EOL Angiosperm image bundles to get bounding boxes of detected pollinators. Results are saved to [crops_file].tsv.   \n",
        "Run in 4 batches of 5K images to backup regularly in case of Colab timeouts."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZljsbwXnubZc"
      },
      "source": [
        "# Run inference on 5k image subset using darknet\n",
        "%cd $wd\n",
        "\n",
        "# Create a symbolic link so that /content/gdrive/My\\ Drive/ is equal to /mydrive\n",
        "!ln -s /content/gdrive/My\\ Drive/ /mydrive\n",
        "\n",
        "# Filepath to image file list for inference\n",
        "filepath = os.path.basename(inf_subset) \n",
        "\n",
        "# Run darknet with flag to not show bounding box coordinates\n",
        "!./darknet detector test cfg/openimages.data cfg/yolov3-openimages.cfg yolov3-openimages.weights -dont_show -save_labels < {filepath}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BcfHlZ7QNXHc"
      },
      "source": [
        "## Post-process detection results\n",
        "--- \n",
        "Combine output files for batches A-D. Then, convert detection boxes into plant-pollinator co-occurrence tags."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H5RHwpgKmMMb"
      },
      "source": [
        "# Combine individual prediction files for each image to all_predictions.txt\n",
        "\n",
        "# Delete image file list for inference\n",
        "inf_subset = 'data/imgs/' + os.path.basename(inf_subset)\n",
        "!rm $inf_subset\n",
        "\n",
        "# Combine individual text files and image filenames into all_predictions.txt\n",
        "fns = os.listdir('data/imgs')\n",
        "with open('data/results/all_predictions.txt', 'w') as outfile:\n",
        "  header = \"class_id x y w h img_id\"\n",
        "  outfile.write(header + \"\\n\")\n",
        "  for fn in fns:\n",
        "        if 'txt' in fn:\n",
        "          with open('data/imgs/'+fn) as infile:\n",
        "            lines = infile.readlines()\n",
        "            newlines = [''.join([x.strip(), ' ' + os.path.splitext(fn)[0] + '\\n']) for x in lines]\n",
        "            outfile.writelines(newlines)\n",
        "\n",
        "# Inspect saved predictions\n",
        "df = pd.read_csv('data/results/all_predictions.txt')\n",
        "print(df.head())\n",
        "\n",
        "# Delete all individual prediction files\n",
        "!rm -r data/imgs/*.txt\n",
        "\n",
        "# Delete all image files now that they have been used for inference\n",
        "!rm -r data/imgs/*"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "code",
        "id": "8-RCvF3NNlt5"
      },
      "source": [
        "# Create final predictions dataframe with class names (instead of numbers) and image urls\n",
        "# EOL 20k image url bundle\n",
        "df = pd.read_csv(bundle)\n",
        "df.columns = ['url']\n",
        "print(\"EOL media URL's corresponding to inference images: \\n\", df)\n",
        "\n",
        "# Model predictions with number-coded classes\n",
        "predict = pd.read_csv('data/results/all_predictions.txt', header=0, sep=\" \")\n",
        "predict.class_id = predict.class_id - 1 #class_id counts started from 1 instead of 0 from YOLO\n",
        "print(\"\\nModel predictions by class id: \\n\", predict)\n",
        "\n",
        "# Add class names to model predictions\n",
        "classnames = pd.read_table('data/openimages.names')\n",
        "classnames.columns = ['classname']\n",
        "#print(\"Verifying class names: \\n\", classnames)\n",
        "tag_df = predict.copy()\n",
        "di = pd.Series(classnames.classname.values,index=classnames.index).to_dict()\n",
        "tag_df.replace({\"class_id\":di}, inplace=True)\n",
        "tag_df['class_id'] = tag_df['class_id'].astype(str)\n",
        "print(\"\\nModel prediction classes translated from class id's: \\n\", tag_df)\n",
        "\n",
        "# Add EOL media URL's to model predictions\n",
        "map_urls = df.copy()\n",
        "img_ids = map_urls['url'].apply(lambda x: os.path.splitext((os.path.basename(x)))[0])\n",
        "map_urls['img_id'] = img_ids\n",
        "tag_df.set_index('img_id', inplace=True, drop=True)\n",
        "map_urls.set_index('img_id', inplace=True, drop=True)\n",
        "mapped_tagdf = tag_df.merge(map_urls, left_index=True, right_index=True)\n",
        "mapped_tagdf.reset_index(drop=False, inplace=True)\n",
        "mapped_tagdf.drop_duplicates(inplace=True, ignore_index=True)\n",
        "print(\"\\nModel predictions with EOL media URL's: \\n\", mapped_tagdf.head())\n",
        "\n",
        "# Save final tags to file\n",
        "fn = os.path.splitext(os.path.basename(inf_subset))[0]\n",
        "outpath = 'data/results/' + fn + '.tsv'\n",
        "mapped_tagdf.to_csv(outpath, sep=\"\\t\", index=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o7N0hAHDFpN_"
      },
      "source": [
        "#### Merge batch output files A-D"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qbm0_nfQFtkI"
      },
      "source": [
        "# Write header row of output tagging file\n",
        "# TO DO: Enter any filename from 4 batches of tagging files\n",
        "tags_file = \"plant_poll_coocc_tags_d\" #@param {type:\"string\"}\n",
        "tags_fpath = \"data/results/\" + tags_file + \".tsv\"\n",
        "\n",
        "# Combine exported model predictions and confidence values for all batches\n",
        "fpath =  os.path.splitext(tags_fpath)[0]\n",
        "base = fpath.rsplit('_',1)[0] + '_'\n",
        "exts = ['a.tsv', 'b.tsv', 'c.tsv', 'd.tsv'] \n",
        "all_filenames = [base + e for e in exts]\n",
        "df1 = pd.concat([pd.read_csv(f, sep='\\t', header=0, na_filter = False) for f in all_filenames], ignore_index=True)\n",
        "\n",
        "# Filter for desired classes\n",
        "# TO DO: Enter a list of pollinator classes to filter by\n",
        "filter = ['Butterfly', 'Insect', 'Beetle', 'Ant', 'Bat (Animal)', 'Bird', 'Bee', 'Invertebrate', 'Animal'] #@param\n",
        "pattern = '|'.join(filter)\n",
        "df = df1.copy()\n",
        "df.loc[df['class_id'].str.contains(pattern), 'class_id'] = 'Pollinator'\n",
        "print(\"No. tags matching filtered classes: \\n\", len(df.class_id[df.class_id.str.contains(pattern)]))\n",
        "print(\"\\nTags matching filtered classes: \\n\", df.class_id[df.class_id.str.contains(pattern)])\n",
        "df.loc[~df.class_id.str.contains(pattern), 'class_id'] = 'None'\n",
        "print(\"\\nNo. not tags matching filtered classes: \\n\", len(df.class_id[~df.class_id.str.contains(pattern)]))\n",
        "print(\"\\nTags not matching filtered classes: \\n\", df[~df.class_id.str.contains(pattern)])\n",
        "\n",
        "# Write results to tsv\n",
        "outfpath = base + 'finaltags.tsv'\n",
        "df.to_csv(outfpath, sep='\\t', index=False)\n",
        "print(\"\\n\\nFinal output tagging file {}: \\n{}\".format(outfpath, df.head()))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vmmCI1jCVNxl"
      },
      "source": [
        "## Display cropping results on images\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gSmno0yFVPsS"
      },
      "source": [
        "# TO DO: Do you want to use the tagging file exported above?\n",
        "use_outfpath = \"no\" #@param [\"yes\", \"no\"]\n",
        "# If no, choose other path to use\n",
        "otherpath = \"data/results/plant_poll_coocc_tags_finaltags.tsv\" #@param {type:\"string\"}\n",
        "if use_outfpath == \"yes\":\n",
        "  outfpath = outfpath\n",
        "else:\n",
        "  outfpath = otherpath\n",
        "df = pd.read_csv(outfpath, sep=\"\\t\", header=0)\n",
        "print(\"File for tag export {}: \\n{}\".format(outfpath, df.head()))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7NN4fOicvcl0"
      },
      "source": [
        "# Display tags on images\n",
        "\n",
        "# TO DO: Adjust line below to see up to 50 images displayed at a time\n",
        "start = 0 #@param {type:\"slider\", min:0, max:5000, step:50}\n",
        "stop = start+50\n",
        "\n",
        "# Loop through images\n",
        "for i, row in df.iloc[start:stop].iterrows():\n",
        "    # Read in image \n",
        "    url = df['eolMediaURL'][i]\n",
        "    img = url_to_image(url)\n",
        "\n",
        "    # Fetch image tag\n",
        "    tag = df['class_id'][i]\n",
        "  \n",
        "    # Plot cropping box on image\n",
        "    _, ax = plt.subplots(figsize=(10, 10))\n",
        "    ax.imshow(img)\n",
        "\n",
        "    # Display image URL and coordinatesabove image\n",
        "    # Helps with fine-tuning data transforms in post-processing steps above\n",
        "    plt.title('{}) {} \\n Tag: {}'.format(i+1, url, tag))"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}