{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "insect_lifestages_yolov4.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "vmmCI1jCVNxl"
      ],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/aubricot/computer_vision_with_eol_images/blob/master/object_detection_for_image_tagging/life_stages/insect_lifestages_yolov4.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j-PBcUKyc95M"
      },
      "source": [
        "# Using YOLO v3 pre-trained on Google Open Images to detect insect life stages (juvenile, adult) from EOL images\n",
        "---\n",
        "*Last Updated 22 February 2021*   \n",
        "Using a YOLOv3 model pre-trained on Google Open Images as a method to do customized, large-scale image processing. Insect images will be tagged using the location and dimensions of the detected life stages to improve search features of EOL."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fX9LGz3Ydu27"
      },
      "source": [
        "# Installs\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q5lC8PSbGCyN"
      },
      "source": [
        "# Mount google drive to import/export files\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xym8_m8CIyXK"
      },
      "source": [
        "# clone darknet repo\n",
        "%cd /content/drive/My Drive/train/darknet\n",
        "#!git clone https://github.com/AlexeyAB/darknet\n",
        "\n",
        "# change makefile to have GPU and OPENCV enabled\n",
        "%cd darknet\n",
        "!sed -i 's/OPENCV=0/OPENCV=1/' Makefile\n",
        "!sed -i 's/GPU=0/GPU=1/' Makefile\n",
        "!sed -i 's/CUDNN=0/CUDNN=1/' Makefile\n",
        "!sed -i 's/CUDNN_HALF=0/CUDNN_HALF=1/' Makefile\n",
        "\n",
        "# verify CUDA\n",
        "!/usr/local/cuda/bin/nvcc --version\n",
        "\n",
        "# make darknet (builds darknet so that you can then use the darknet executable file to run or train object detectors)\n",
        "!make\n",
        "\n",
        "# download pre-trained weights (only run once)\n",
        "#!wget https://pjreddie.com/media/files/yolov3-openimages.weights\n",
        "\n",
        "# For importing/exporting files, working with arrays, etc\n",
        "import os\n",
        "import pathlib\n",
        "import six.moves.urllib as urllib\n",
        "import sys\n",
        "import tarfile\n",
        "import zipfile\n",
        "import numpy as np \n",
        "import csv\n",
        "import matplotlib.pyplot as plt\n",
        "import time\n",
        "import pandas as pd\n",
        "\n",
        "# For downloading the images\n",
        "!apt-get install aria2\n",
        "\n",
        "# For drawing onto and plotting the images\n",
        "import matplotlib.pyplot as plt\n",
        "from PIL import Image\n",
        "from PIL import ImageColor\n",
        "from PIL import ImageDraw\n",
        "from PIL import ImageFont\n",
        "from PIL import ImageOps\n",
        "import cv2\n",
        "\n",
        "%matplotlib inline\n",
        "%config InlineBackend.figure_format = 'svg'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cKovA4-aifP5"
      },
      "source": [
        "# Classify images\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wjTgajd3keAi"
      },
      "source": [
        "### Temporarily download images from EOL bundle to Google Drive (YOLO cannot directly parse URL images)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zCxtKyRPij8R"
      },
      "source": [
        "# Download images\n",
        "bundle = \"https://editors.eol.org/other_files/bundle_images/files/images_for_Lepidoptera_20K_breakdown_download_000001.txt\" #@param {type:\"string\"}\n",
        "df = pd.read_csv(bundle)\n",
        "\n",
        "# Take subset of bundle\n",
        "# TO DO: Change file name for each bundle/run abcd if doing 4 batches using dropdown form to right\n",
        "ss = \"life_stage_tags_c\" #@param [\"life_stage_tags_a\", \"life_stage_tags_b\", \"life_stage_tags_c\", \"life_stage_tags_d\"] {allow-input: true}\n",
        "ss = ss + \".txt\"\n",
        "\n",
        "# Run in 4 batches of 5k images each (batch a is from 0-5000, b from 5000 to 10000, etc)\n",
        "if \"a\" in ss:\n",
        "  a=0\n",
        "  b=5000\n",
        "elif \"b\" in ss:\n",
        "  a=5000\n",
        "  b=10000\n",
        "elif \"c\" in ss:\n",
        "  a=10000\n",
        "  b=15000\n",
        "elif \"d\" in ss:\n",
        "  a=15000\n",
        "  b=20000\n",
        "\n",
        "# Save subset to text file for image download\n",
        "df = df.iloc[a:b]\n",
        "outpath = \"/content/drive/My Drive/train/darknet/data/imgs/\" + ss\n",
        "df.to_csv(outpath, sep='\\n', index=False, header=False)\n",
        "\n",
        "# Download images (takes 7-10 min per 5k imgs, aria2 downloads 16imgs at a time)\n",
        "%cd /content/drive/My Drive/train/darknet/data/imgs\n",
        "!aria2c -x 16 -s 1 -i $ss\n",
        "\n",
        "# Check how many images downloaded\n",
        "print(\"Number of images downloaded to Google Drive: \")\n",
        "!ls . | wc -l"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "we9gsoPXksxH"
      },
      "source": [
        "# Move text file to image_data/bundles\n",
        "%cd ../\n",
        "!mv imgs/*.txt img_info/"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O_nGr7A7pGfW"
      },
      "source": [
        "# Make imgs.txt file to run images through YOLO for inference in batches\n",
        "%cd /content/drive/My Drive/train/darknet/data/\n",
        "\n",
        "import glob\n",
        "import os\n",
        "\n",
        "path = \"/content/drive/My Drive/train/darknet/data/imgs\"\n",
        "inf_ss = path+'/'+ss\n",
        "with open(inf_ss, 'w', encoding='utf-8') as f:\n",
        "  for dir, dirs, files in os.walk(path):\n",
        "    files = [fn for fn in files]\n",
        "    for fn in files:\n",
        "      if 'txt' not in fn:\n",
        "        out = \"data/imgs/\" + fn\n",
        "        f.writelines(out + '\\n')\n",
        "\n",
        "# Inspect imgs.txt file to confirm length and content\n",
        "df = pd.read_csv(inf_ss, header=None)\n",
        "print(df.head())\n",
        "print(len(df))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NnITAALxmoKY"
      },
      "source": [
        "### Run images through trained model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j30QBhJvsveE"
      },
      "source": [
        "# this creates a symbolic link so that now the path /content/gdrive/My\\ Drive/ is equal to /mydrive\n",
        "!ln -s /content/gdrive/My\\ Drive/ /mydrive\n",
        "!ls /mydrive\n",
        "\n",
        "# TO DO: In next bloc, change inference image file list name at end of line after \"<\" to match inf_ss defined above\n",
        "# ex: data/imgs/plant_poll_coocc_tags_a.txt\n",
        "print(\"filename to copy-paste into code block below:\", os.path.basename(inf_ss))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZljsbwXnubZc"
      },
      "source": [
        "# TO DO: Change inference image file list name at end of line after \"<\" to match inf_ss defined above\n",
        "%cd /content/drive/My Drive/train/darknet\n",
        "\n",
        "# darknet run with external output flag to print bounding box coordinates\n",
        "!./darknet detector test cfg/openimages.data cfg/yolov3-openimages.cfg yolov3-openimages.weights -dont_show -save_labels < data/imgs/life_stage_tags_c.txt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BcfHlZ7QNXHc"
      },
      "source": [
        "# Post-process model output\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H5RHwpgKmMMb"
      },
      "source": [
        "# Combine individual prediction files for each image to all_predictions.txt\n",
        "\n",
        "# Delete image file list for inference\n",
        "path = \"/content/drive/My Drive/train/darknet/data/imgs\"\n",
        "inf_ss = path+'/'+ss\n",
        "inf_ss = \"data/imgs/\"+ss\n",
        "!rm $inf_ss\n",
        "\n",
        "# Combine individual text files and image filenames into all_predictions.txt\n",
        "fns = os.listdir('data/imgs')\n",
        "with open('data/results/all_predictions.txt', 'w') as outfile:\n",
        "  header = \"class_id x y w h img_id\"\n",
        "  outfile.write(header + \"\\n\")\n",
        "  for fn in fns:\n",
        "        if 'txt' in fn:\n",
        "          with open('data/imgs/'+fn) as infile:\n",
        "            lines = infile.readlines()\n",
        "            newlines = [''.join([x.strip(), ' ' + os.path.splitext(fn)[0] + '\\n']) for x in lines]\n",
        "            outfile.writelines(newlines)\n",
        "\n",
        "# Inspect saved predictions\n",
        "df = pd.read_csv('data/results/all_predictions.txt')\n",
        "print(df.head())\n",
        "\n",
        "# Delete all individual prediction files\n",
        "!rm -r data/imgs/*.txt\n",
        "\n",
        "# Delete all image files now that they have been used for inference\n",
        "!rm -r data/imgs/*"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "code",
        "id": "8-RCvF3NNlt5"
      },
      "source": [
        "# Create final predictions dataframe with class names (instead of numbers) and image urls\n",
        "# EOL image url bundle\n",
        "df = pd.read_csv(bundle)\n",
        "df.columns = ['url']\n",
        "print(df)\n",
        "\n",
        "# Model predictions with number-coded classes\n",
        "predict = pd.read_csv('data/results/all_predictions.txt', header=0, sep=\" \")\n",
        "predict.class_id = predict.class_id - 1 #class_id counts started from 1 instead of 0 from YOLO\n",
        "print(predict)\n",
        "\n",
        "# Add class names to model predictions\n",
        "classnames = pd.read_table('data/openimages.names')\n",
        "classnames.columns = ['classname']\n",
        "#print(classnames)\n",
        "tag_df = predict.copy()\n",
        "di = pd.Series(classnames.classname.values,index=classnames.index).to_dict()\n",
        "tag_df.replace({\"class_id\":di}, inplace=True)\n",
        "tag_df['class_id'] = tag_df['class_id'].astype(str)\n",
        "print(tag_df)\n",
        "\n",
        "# Filter for desired classes\n",
        "filter = ['Butterfly', 'Insect', 'Beetle', 'Ant', 'Bat (Animal)', 'Bird', 'Bee', \\\n",
        "          'Invertebrate']\n",
        "\n",
        "# Add urls to model predictions\n",
        "map_urls = df.copy()\n",
        "img_ids = map_urls['url'].apply(lambda x: os.path.splitext((os.path.basename(x)))[0])\n",
        "map_urls['img_id'] = img_ids\n",
        "#print(map_urls)\n",
        "\n",
        "tag_df.set_index('img_id', inplace=True, drop=True)\n",
        "map_urls.set_index('img_id', inplace=True, drop=True)\n",
        "mapped_tagdf = tag_df.merge(map_urls, left_index=True, right_index=True)\n",
        "mapped_tagdf.reset_index(drop=False, inplace=True)\n",
        "mapped_tagdf.drop_duplicates(inplace=True, ignore_index=True)\n",
        "print(mapped_tagdf.head())\n",
        "\n",
        "# Save final tags to file\n",
        "fn = os.path.splitext(os.path.basename(inf_ss))[0]\n",
        "outpath = 'data/results/' + fn + '.tsv'\n",
        "mapped_tagdf.to_csv(outpath, sep=\"\\t\", index=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vmmCI1jCVNxl"
      },
      "source": [
        "# Display predictions on images\n",
        "---\n",
        "Inspect detection results and verify that they are as expected"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gSmno0yFVPsS"
      },
      "source": [
        "# TO DO: Do you want to use the tagging file exported above?\n",
        "use_outpath = \"yes\" #@param [\"yes\", \"no\"]\n",
        "# If no, choose other path to use\n",
        "otherpath = \"\\u003Cpath to other tag file> \" #@param {type:\"string\"}\n",
        "if use_outpath == \"yes\":\n",
        "  outpath = outpath\n",
        "else:\n",
        "  outpath = otherpath\n",
        "df = pd.read_csv(outpath, sep=\"\\t\", header=0)\n",
        "\n",
        "# For uploading an image from url\n",
        "# Modified from https://www.pyimagesearch.com/2015/03/02/convert-url-to-image-with-python-and-opencv/\n",
        "def url_to_image(url):\n",
        "  resp = urllib.request.urlopen(url)\n",
        "  image = np.asarray(bytearray(resp.read()), dtype=\"uint8\")\n",
        "  image = cv2.imdecode(image, cv2.IMREAD_COLOR)\n",
        "  image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        " \n",
        "  return image"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9-zpaQi2W8sE"
      },
      "source": [
        "# Display crop dimensions on images\n",
        "# Adjust line below to see up to 50 images displayed at a time\n",
        "for i, row in df.iloc[0:5].iterrows():\n",
        "  # Read in image \n",
        "  url = df['url'][i]\n",
        "  img = url_to_image(url)\n",
        "  h,w = img.shape[:2]\n",
        "  # Define variables needed to draw bounding box on image\n",
        "  xmin = round((df['x'][i] - (df['w'][i]/2))*w)\n",
        "  if (xmin < 0): xmin = 0\n",
        "  ymin = round((df['y'][i] - (df['h'][i]/2))*h)\n",
        "  if (ymin < 0): ymin = 0\n",
        "  xmax = round(xmin + (df['w'][i]) * w)\n",
        "  if (xmax > w-1): xmax = w-1\n",
        "  ymax = round(ymin + (df['h'][i].astype(int)) * h)\n",
        "  if (ymax > 0): ymax = h-1\n",
        "\n",
        "  # Set box/font color and size\n",
        "  maxdim = max(df['w'][i],df['h'][i])\n",
        "  fontScale = 1\n",
        "\n",
        "  box_col = (255, 0, 157)\n",
        "  \n",
        "  # If using multitaxa dataset, draw color-coded boxes and class labels on images\n",
        "  if 'class_id' in df:\n",
        "    taxon = df['class_id'][i]\n",
        "    if taxon == \"Ladybug\":\n",
        "      box_col = (255,199,15)\n",
        "    elif taxon == \"Beetle\":\n",
        "      box_col = (255,127,0)\n",
        "    elif taxon == \"Insect\":\n",
        "      box_col = (255,42,22)\n",
        "\n",
        "    # Draw taxon label on image\n",
        "    image_wbox = cv2.putText(img, taxon, (xmin+7, ymax-12), cv2.FONT_HERSHEY_SIMPLEX, fontScale, box_col, 2, cv2.LINE_AA)\n",
        "  \n",
        "  # Draw box on image\n",
        "  image_wbox = cv2.rectangle(img, (xmin, ymax), (xmax, ymin), box_col, 5)\n",
        "  \n",
        "  # Plot and show cropping boxes on images\n",
        "  _, ax = plt.subplots(figsize=(10, 10))\n",
        "  ax.imshow(image_wbox)\n",
        "  # Display image URL above image to facilitate troubleshooting/fine-tuning of data reformatting and tidying steps in convert_bboxdims.py or preprocessing.ipynb\n",
        "  plt.title('{}'.format(url, xmin, ymin, xmax, ymax))"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}