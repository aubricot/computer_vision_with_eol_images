{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/aubricot/computer_vision_with_eol_images/blob/master/object_detection_for_image_tagging/life_stages/insect_life_stages_generate_tags_yolov3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j-PBcUKyc95M"
      },
      "source": [
        "# Using YOLO v3 pre-trained on Google Open Images to add insect life stage (juvenile, adult) tags to EOL images\n",
        "---\n",
        "*Last Updated 6 September 2022*   \n",
        "Use a YOLOv3 model (downloaded from [here](https://github.com/AlexeyAB/darknet) ) pre-trained on [Google Open Images](https://storage.googleapis.com/openimages/web/visualizer/index.html?set=train&type=detection&c=%2Fm%2F03vt0) as a method to do customized, large-scale image processing. EOL Insect images will be tagged for insect life stages (Adult: Ant, Bee, Beetle, Butterfly, Dragonfly, Insect, Invertebrate, Moths and butterflies; Juvenile: Caterpillar, Centipede, Worm) using object detection. Tags will further extend EOLv3 image search functions.\n",
        "\n",
        "Notes:   \n",
        "* Run code blocks by pressing play button in brackets on left\n",
        "* Change parameters using form fields on right (find details at corresponding lines of code by searching '#@param')\n",
        "\n",
        "References:   \n",
        "* Check out [AlexeyAB's darknet repo](https://github.com/AlexeyAB/darknet) for Colab tutorials like [this one](https://colab.research.google.com/drive/12QusaaRj_lUwCGDvQNfICpa7kA7_a2dE)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fX9LGz3Ydu27"
      },
      "source": [
        "## Installs & Imports\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q5lC8PSbGCyN"
      },
      "outputs": [],
      "source": [
        "#@title Choose where to save results\n",
        "# Use dropdown menu on right\n",
        "save = \"in Colab runtime (files deleted after each session)\" #@param [\"in my Google Drive\", \"in Colab runtime (files deleted after each session)\"]\n",
        "\n",
        "# Mount google drive to export image tagging file(s)\n",
        "if 'Google Drive' in save:\n",
        "    from google.colab import drive\n",
        "    drive.mount('/content/drive', force_remount=True)\n",
        "\n",
        "# Type in the path to your project wd in form field on right\n",
        "basewd = \"/content/drive/MyDrive/train\" #@param [\"/content/drive/MyDrive/train\"] {allow-input: true}\n",
        "\n",
        "# Type in the folder that you want to contain TF2 files\n",
        "folder = \"darknet\" #@param [\"darknet\"] {allow-input: true}\n",
        "cwd = basewd + '/' + folder"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xym8_m8CIyXK"
      },
      "outputs": [],
      "source": [
        "#@title Set up directory structure & Make darknet\n",
        "import os\n",
        "\n",
        "# Download darknet (the native implementation of YOLO)\n",
        "if not os.path.exists(cwd):\n",
        "    os.makedirs(cwd)\n",
        "    %cd $basewd\n",
        "    print(\"\\nBuilding directory structure\\n\")\n",
        "    !git clone https://github.com/AlexeyAB/darknet\n",
        "    # Compile darknet\n",
        "    %cd $cwd\n",
        "    # Make folders for detection datafiles\n",
        "    os.makedirs('data/imgs')\n",
        "    os.makedirs('data/img_info')\n",
        "    os.makedirs('data/results')\n",
        "    # Download pretrained YOLOv3 weights for Open Images\n",
        "    !wget https://pjreddie.com/media/files/yolov3-openimages.weights\n",
        "\n",
        "print(\"\\nWorking directory set to:\")\n",
        "%cd $cwd\n",
        "\n",
        "# Change makefile to have GPU and OPENCV enabled\n",
        "print(\"\\nEnabling GPU and OpenCV in makefile...\")\n",
        "!sed -i 's/OPENCV=0/OPENCV=1/' Makefile\n",
        "!sed -i 's/GPU=0/GPU=1/' Makefile\n",
        "!sed -i 's/CUDNN=0/CUDNN=1/' Makefile\n",
        "!sed -i 's/CUDNN_HALF=0/CUDNN_HALF=1/' Makefile\n",
        "\n",
        "# Verify CUDA version (for using GPU)\n",
        "!/usr/local/cuda/bin/nvcc --version\n",
        "\n",
        "# Make darknet\n",
        "print(\"\\n~~~Making darknet~~~\\n\")\n",
        "!make\n",
        "if os.path.exists('./darknet'):\n",
        "    print(\"\\n\\n~~~\\nDarknet successfully installed! Move onto next steps to do object detection with YOLOv3.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yDdbBYnp2nCK"
      },
      "outputs": [],
      "source": [
        "#@title Import libraries\n",
        "\n",
        "# For importing/exporting files, working with arrays, etc\n",
        "import os\n",
        "import glob\n",
        "import pathlib\n",
        "import six.moves.urllib as urllib\n",
        "import sys\n",
        "import tarfile\n",
        "import zipfile\n",
        "import numpy as np \n",
        "import csv\n",
        "import matplotlib.pyplot as plt\n",
        "import time\n",
        "import pandas as pd\n",
        "\n",
        "# For downloading images\n",
        "!apt-get install aria2\n",
        "\n",
        "# For drawing onto and plotting images\n",
        "import matplotlib.pyplot as plt\n",
        "from PIL import Image\n",
        "from PIL import ImageColor\n",
        "from PIL import ImageDraw\n",
        "from PIL import ImageFont\n",
        "from PIL import ImageOps\n",
        "import cv2\n",
        "%matplotlib inline\n",
        "%config InlineBackend.figure_format = 'svg'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fuZL4TGzitNZ"
      },
      "source": [
        "### Prepare object detection functions and settings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wqoLKpXveeAt"
      },
      "outputs": [],
      "source": [
        "#@title Define functions\n",
        "\n",
        "# Display full URLs in outputs so you can click them and inspect images\n",
        "pd.set_option('display.max_colwidth', None)\n",
        "\n",
        "# Read in data file\n",
        "def read_datafile(fpath, sep=\"\\t\", header=0, disp_head=True):\n",
        "    try:\n",
        "        df = pd.read_csv(fpath, sep=sep, header=header)\n",
        "        if disp_head:\n",
        "            print(\"Data header: \\n\", df.head())\n",
        "    except FileNotFoundError as e:\n",
        "        raise Exception(\"File not found: Enter the path to your file in form field and re-run\").with_traceback(e.__traceback__)\n",
        "    \n",
        "    return df\n",
        "\n",
        "# Read in bundle images\n",
        "def read_eolbundle(bundle):\n",
        "    # Get first 20k images for Angiosperm bundles using initial bundle basename\n",
        "    df = pd.read_csv(bundle, sep='\\t', header=None)\n",
        "    print(\"EOL image bundle with {} images: \\n{}\".format(len(df), df.head()))\n",
        "    \n",
        "    return df\n",
        "\n",
        "# Define start and stop indices in EOL bundle for running inference   \n",
        "def set_start_stop(df):\n",
        "    # To test with a tiny subset, use 5 random bundle images\n",
        "    if \"tiny subset\" in run:\n",
        "        start=np.random.choice(a=1000, size=1)[0]\n",
        "        stop=start+5\n",
        "    # To run inference on 4 batches of 5k images each\n",
        "    elif \"_a.\" in outfpath: # batch a is from 0-5000\n",
        "        start=0\n",
        "        stop=5000\n",
        "    elif \"_b.\" in outfpath: # batch b is from 5000-1000\n",
        "        start=5000\n",
        "        stop=10000\n",
        "    elif \"_c.\" in outfpath: # batch c is from 10000-15000\n",
        "        start=10000\n",
        "        stop=15000\n",
        "    elif \"_d.\" in outfpath: # batch d is from 15000-20000\n",
        "        start=15000\n",
        "        stop=20000\n",
        "    \n",
        "    return start, stop\n",
        "\n",
        "# To display results\n",
        "def imShow(path):\n",
        "    image = cv2.imread(path)\n",
        "    height, width = image.shape[:2]\n",
        "    resized_image = cv2.resize(image,(3*width, 3*height), interpolation = cv2.INTER_CUBIC)\n",
        "    fig = plt.gcf()\n",
        "    fig.set_size_inches(9, 9)\n",
        "    plt.axis(\"off\")\n",
        "    plt.imshow(cv2.cvtColor(resized_image, cv2.COLOR_BGR2RGB))\n",
        "    plt.show()\n",
        "\n",
        "# For uploading an image from url\n",
        "# Modified from https://www.pyimagesearch.com/2015/03/02/convert-url-to-image-with-python-and-opencv/\n",
        "def url_to_image(url):\n",
        "    resp = urllib.request.urlopen(url)\n",
        "    image = np.asarray(bytearray(resp.read()), dtype=\"uint8\")\n",
        "    image = cv2.imdecode(image, cv2.IMREAD_COLOR)\n",
        "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "    im_h, im_w = image.shape[:2]\n",
        " \n",
        "    return image\n",
        "\n",
        "# Define functions\n",
        "\n",
        "# Combine individual prediction files for each image to all_predictions.txt\n",
        "def combine_predictions(imgs_dir):\n",
        "    # Delete inference images file list\n",
        "    !rm $outfpath\n",
        "    # Combine inference text files for each image and save to all_predictions.txt\n",
        "    fns = os.listdir(imgs_dir)\n",
        "    with open('data/results/all_predictions.txt', 'w') as outfile:\n",
        "        header = \"class_id x y w h img_id\"\n",
        "        outfile.write(header + \"\\n\")\n",
        "        for fn in fns:\n",
        "            if '.txt' in fn:\n",
        "                with open('data/imgs/'+fn) as infile:\n",
        "                    lines = infile.readlines()\n",
        "                    newlines = [''.join([x.strip(), ' ' + os.path.splitext(fn)[0] + '\\n']) for x in lines]\n",
        "                    outfile.writelines(newlines)\n",
        "    # Load all_predictions.txt\n",
        "    df = pd.read_csv('data/results/all_predictions.txt')\n",
        "    print(\"Model predictions: \\n\", df.head())\n",
        "\n",
        "    return df\n",
        "\n",
        "# Combine tagging files for batches A-D\n",
        "def combine_tag_files(tags_fpath):\n",
        "    # Combine tag files for batches A-D\n",
        "    fpath =  os.path.splitext(tags_fpath)[0]\n",
        "    base = fpath.rsplit('_',1)[0] + '_'\n",
        "    exts = ['a.tsv', 'b.tsv', 'c.tsv', 'd.tsv'] \n",
        "    all_filenames = [base + e for e in exts]\n",
        "    df = pd.concat([pd.read_csv(f, sep='\\t', header=0, na_filter = False) for f in all_filenames], ignore_index=True)\n",
        "    # Choose desired columns for tagging\n",
        "    df = df[['url', 'img_id', 'class_id']]\n",
        "    df.rename(columns={'url': 'eolMediaURL', 'img_id': 'identifier', 'class_id': 'tag'}, inplace=True)\n",
        "    print(\"\\nNew concatenated dataframe with all 4 batches: \\n\", df[['eolMediaURL', 'tag']].head())\n",
        "\n",
        "    return df\n",
        "\n",
        "def add_class_names(all_predictions):\n",
        "    # Model predictions with number-coded classes\n",
        "    numbered_tags = pd.read_csv(all_predictions, header=0, sep=\" \")\n",
        "    numbered_tags.class_id = numbered_tags.class_id - 1 # python counts from 0, Yolo from 1\n",
        "    print(\"\\nModel predictions by class id (number): \\n\", numbered_tags)\n",
        "\n",
        "    # Add class names to model predictions\n",
        "    classes = pd.read_table('data/openimages.names')\n",
        "    classes.columns = ['name']\n",
        "    classes_dict = pd.Series(classes.name.values, index=classes.index).to_dict()\n",
        "    tags = numbered_tags.copy()\n",
        "    tags.replace({\"class_id\":classes_dict}, inplace=True)\n",
        "    tags['class_id'] = tags['class_id'].astype(str)\n",
        "    print(\"\\nModel predictions by class id (name): \\n\", tags)\n",
        "\n",
        "    return tags\n",
        "\n",
        "# Add EOL media URL's to named image tags\n",
        "def add_eolMediaURLs(tags, bundle):\n",
        "    # Read in EOL 20k image url bundle\n",
        "    bundle = read_eolbundle(bundle)\n",
        "    bundle.columns = ['url']\n",
        "    \n",
        "    # Map eolMediaURLs to tags using image filenames\n",
        "    img_fns = bundle['url'].apply(lambda x: os.path.splitext((os.path.basename(x)))[0])\n",
        "    bundle['img_id'] = img_fns\n",
        "    # Make datatypes consistent for bundle and tags\n",
        "    bundle['img_id'] = bundle['img_id'].astype(\"string\")\n",
        "    tags['img_id'] = tags['img_id'].astype(\"string\")\n",
        "    # Add URLs to tags with img_id as a key\n",
        "    final_tags = tags.merge(bundle, on='img_id')\n",
        "    final_tags.reset_index(drop=True, inplace=True)\n",
        "    final_tags.drop_duplicates(inplace=True, ignore_index=True)\n",
        "    print(\"\\nModel predictions with EOL media URL's added: \\n\", final_tags.head())\n",
        "\n",
        "    return final_tags\n",
        "\n",
        "# Set filename for saving classification results\n",
        "def set_outpath(tags_file):\n",
        "    tags_file = os.path.splitext(tags_file)[0]\n",
        "    outpath = cwd + '/data/results/' + tags_file + '.tsv'\n",
        "    print(\"Saving results to: \\n\", outpath)\n",
        "\n",
        "    return outpath"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cKovA4-aifP5"
      },
      "source": [
        "## Generate tags for images\n",
        "---\n",
        "Run EOL 20k image bundles through pre-trained object detection models and save results in 4 batches (A-D). "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YdNG8YEWaqsX"
      },
      "source": [
        "#### Test: Run individual image through by filename and display results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kIDpIFWsOZo5"
      },
      "outputs": [],
      "source": [
        "#@title Run with sample EOL image (To test with your own image, upload file to data/imgs and update fn formfield)\n",
        "\n",
        "# Run with sample EOL image\n",
        "# Define filepath to image\n",
        "fn = \"542.6248219776.jpg\" #@param [\"542.6248219776.jpg\"] {allow-input: true}\n",
        "img_fpath = 'data/imgs/' + fn\n",
        "\n",
        "# Download image\n",
        "%cd $cwd\n",
        "%cd data/imgs\n",
        "!gdown --id 1WVafbU3htUUiSo-Qvs3sA1Y0Medz4o7D\n",
        "%cd $cwd\n",
        "\n",
        "# Run darknet and show bounding box coordinates\n",
        "!./darknet detector test cfg/openimages.data cfg/yolov3-openimages.cfg yolov3-openimages.weights {img_fpath}\n",
        "\n",
        "# Display detection results\n",
        "print(\"\\nObject detection results:\")\n",
        "imShow('predictions.jpg')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wjTgajd3keAi"
      },
      "source": [
        "### Generate tags: Run inference on EOL images & save results for tagging - Run 4X for batches A-D\n",
        "Use 20K EOL Angiosperm image bundle to identify insect life stages in images. Results are saved to [tags_file].tsv. Run this section 4 times (to make batches A-D) of 5K images each to incrementally save in case of Colab timeouts."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zCxtKyRPij8R"
      },
      "outputs": [],
      "source": [
        "#@title Enter EOL image bundle and choose inference settings. Change **tags_file** for each batch A-D\n",
        "%cd $cwd\n",
        "\n",
        "# Load in EOL Insect 20k image bundle\n",
        "bundle = \"https://editors.eol.org/other_files/bundle_images/files/images_for_Lepidoptera_20K_breakdown_download_000001.txt\" #@param [\"https://editors.eol.org/other_files/bundle_images/files/images_for_Lepidoptera_20K_breakdown_download_000001.txt\"] {allow-input: true}\n",
        "df = read_eolbundle(bundle)\n",
        "\n",
        "# Test pipeline with a smaller subset than 5k images?\n",
        "run = \"test with tiny subset\" #@param [\"test with tiny subset\", \"for all images\"]\n",
        "\n",
        "# Display detection results on images?\n",
        "display_results = \"yes (use this option if testing tiny subsets; only works for \\u003C50 images)\" #@param [\"yes (use this option if testing tiny subsets; only works for \\u003C50 images)\", \"no (use this option if running batches)\"]\n",
        "\n",
        "# Take 5k subset of bundle for running inference\n",
        "# Change filename for each batch\n",
        "tags_file = \"life_stage_tags_c\" #@param [\"life_stage_tags_a\", \"life_stage_tags_b\", \"life_stage_tags_c\", \"life_stage_tags_d\"] {allow-input: true}\n",
        "tags_file = tags_file + \".txt\"\n",
        "imgs_dir = \"data/imgs/\"\n",
        "outfpath = imgs_dir + tags_file\n",
        "print(\"Saving tagging results to: \\n{}\".format(outfpath))\n",
        "\n",
        "# Add 5k subset of image bundle urls as column in tags file\n",
        "start, stop = set_start_stop(df)\n",
        "df = df.iloc[start:stop]\n",
        "df.to_csv(outfpath, sep='\\n', index=False, header=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eKUThVvV-66K"
      },
      "outputs": [],
      "source": [
        "#@title Run inference (Note: YOLO cannot parse images from URL, so images are temporarily downloaded) \n",
        "# Note: Takes 7-10 min per 5k imgs, aria2 downloads 16imgs at a time\n",
        "%cd $imgs_dir\n",
        "!aria2c -x 16 -s 1 -i $tags_file\n",
        "\n",
        "# Check how many images downloaded\n",
        "print(\"Number of files downloaded to Google Drive: \")\n",
        "len([1 for x in list(os.scandir('.')) if x.is_file()])-1 # -1 because .txt file contains image filenames\n",
        "\n",
        "# Move tags file used for downloading images to data/img_info/\n",
        "%cd $cwd\n",
        "!mv data/imgs/*.txt data/img_info/\n",
        "\n",
        "# Make a new list of successfully downloaded image files for running inference\n",
        "inf_imgs = imgs_dir + tags_file\n",
        "with open(inf_imgs, 'w', encoding='utf-8') as f:\n",
        "    # Walk through data/imgs/ to list files\n",
        "    for dir, dirs, files in os.walk(imgs_dir):\n",
        "        files = [fn for fn in files]\n",
        "        for fn in files:\n",
        "            if 'txt' not in fn:\n",
        "                out = \"data/imgs/\" + fn\n",
        "                f.writelines(out + '\\n')\n",
        "\n",
        "# Inspect textfile of images for inference\n",
        "df = read_datafile(inf_imgs, header=None, sep='\\n', disp_head=True)\n",
        "print(\"\\nNumber of valid images ready for inference in {}: {}\".format(inf_imgs, len(df)))\n",
        "\n",
        "# Run darknet with flag to not show bounding box coordinates\n",
        "!./darknet detector test cfg/openimages.data cfg/yolov3-openimages.cfg yolov3-openimages.weights -dont_show -save_labels < {outfpath}\n",
        "\n",
        "print(\"\\n\\n~~~\\nInference complete! Post-process inference results in next code blocks before running these steps for remaining batches A-D.\\n~~~\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H5RHwpgKmMMb"
      },
      "outputs": [],
      "source": [
        "#@title Post-process detection results for each batch\n",
        "\n",
        "# Combine individual prediction files for each image to all_predictions.txt\n",
        "df = combine_predictions(imgs_dir)\n",
        "\n",
        "# Delete inference text files and images (only needed them for inference)\n",
        "!rm -r data/imgs/*\n",
        "\n",
        "# Add class names to numeric image tags\n",
        "tags = add_class_names('data/results/all_predictions.txt')\n",
        "\n",
        "# Add EOL media URL's from bundle to image tags df\n",
        "final_tags = add_eolMediaURLs(tags, bundle)\n",
        "\n",
        "# Save final tags to file\n",
        "outpath = set_outpath(tags_file)\n",
        "final_tags.to_csv(outpath, sep=\"\\t\", index=False)\n",
        "\n",
        "print(\"\\n\\n~~~\\nPost-processing complete! Run above steps for remaining batches A-D before proceeding to next steps.\\n~~~\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o7N0hAHDFpN_"
      },
      "source": [
        "## Combine tags for 5k image batches A-D\n",
        "---\n",
        "After running steps above for each image batch, combine tag files to one 20k tag dataset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qbm0_nfQFtkI"
      },
      "outputs": [],
      "source": [
        "#@title Define parameters for converting detected classes to desired image tags\n",
        "%cd $cwd\n",
        "\n",
        "# Write header row of output tagging file\n",
        "# Enter any filename from 4 batches of tagging files\n",
        "tags_file = \"life_stage_tags_a\" #@param [\"life_stage_tags_a\"] {allow-input: true}\n",
        "tags_fpath = \"data/results/\" + tags_file + \".tsv\"\n",
        "\n",
        "# Combine exported model predictions and confidence values for all batches\n",
        "df = combine_tag_files(tags_fpath)\n",
        "\n",
        "# Filter for desired classes\n",
        "# These will be converted to 'adult'\n",
        "filter1 = ['Ant', 'Bee', 'Beetle', 'Butterfly', 'Dragonfly', 'Insect', 'Invertebrate', 'Moths and butterflies'] #@param\n",
        "pattern1 = '|'.join(filter1)\n",
        "# These will be converted to juvenile\n",
        "filter2 = ['Caterpillar', 'Centipede', 'Worm'] #@param\n",
        "pattern2 = '|'.join(filter2)\n",
        "\n",
        "# Set all detections for filtered adult classes to 'Adult'\n",
        "print(\"\\nNo. tags matching filtered class(es) {}: {}\\n\".format(pattern1, len(df[df.tag.str.contains(pattern1)])))\n",
        "print(\"\\nTags matching filtered class(es): \\n\", df[df.tag.str.contains(pattern1)])\n",
        "df.loc[df.tag.str.contains(pattern1), 'tag'] = 'Adult'\n",
        "\n",
        "# Set all detections for filtered adult classes to 'Juvenile'\n",
        "print(\"\\nNo. tags matching filtered class(es) {}: {}\\n\".format(pattern2, len(df[df.tag.str.contains(pattern2)])))\n",
        "print(\"\\nTags matching filtered class(es): \\n\", df[df.tag.str.contains(pattern2)])\n",
        "df.loc[df.tag.str.contains(pattern2), 'tag'] = 'Juvenile'\n",
        "\n",
        "# Remove all detections that aren't 'Adult' or 'Juvenile'\n",
        "patterns = '|'.join(filter1+filter2+['Adult','Juvenile'])\n",
        "print(\"\\nNo. tags not matching filtered class(es) {}: {}\\n\".format(['Adult', 'Juvenile'], len(df[~df.tag.str.contains(patterns)])))\n",
        "print(\"\\nTags not matching filtered class(es): \\n\", df[~df.tag.str.contains(patterns)])\n",
        "df.loc[~df.tag.str.contains(patterns), 'tag'] = 'None'\n",
        "\n",
        "# Write results to tsv\n",
        "outpath = 'data/results/' + tags_file.rsplit('_', 1)[0] + '_final.tsv'\n",
        "df.to_csv(outpath, sep='\\t', index=False)\n",
        "print(\"\\n\\nFinal tagging file {}: \\n{}\".format(outpath, df.head()))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vmmCI1jCVNxl"
      },
      "source": [
        "## Display tagging results on images\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7NN4fOicvcl0"
      },
      "outputs": [],
      "source": [
        "#@title Adjust start index and display up to 50 images with their tags\n",
        "\n",
        "# Set number of seconds to timeout if image url taking too long to open\n",
        "import socket\n",
        "socket.setdefaulttimeout(10)\n",
        "\n",
        "# Adjust start index using slider\n",
        "start = 0 #@param {type:\"slider\", min:0, max:5000, step:50}\n",
        "stop = min((start+50), len(df))\n",
        "\n",
        "# Loop through images\n",
        "for i, row in df.iloc[start:stop].iterrows():\n",
        "    try:\n",
        "        # Read in image \n",
        "        url = df['eolMediaURL'][i]\n",
        "        img = url_to_image(url)\n",
        "\n",
        "        # Fetch image tag\n",
        "        tag = df['tag'][i]\n",
        "  \n",
        "        # Display progress message after each image is loaded\n",
        "        print('Successfully loaded {} of {} images'.format(i+1, (stop-start)))\n",
        "\n",
        "        # Plot image with tag\n",
        "        _, ax = plt.subplots(figsize=(10, 10))\n",
        "        ax.imshow(img)\n",
        "        plt.axis('off')\n",
        "        plt.title('{}) Tag: {}'.format(i+1, tag))\n",
        "\n",
        "    except:\n",
        "        print('Check if URL from {} is valid'.format(url))"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "insect_life_stages_generate_tags_yolov3.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
