{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "scat_footprint_preprocessing.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "LZlJ7Rjaub3O",
        "bOJEcY_BYYjl",
        "uELne7tJrEDZ",
        "b8yUIF7PduqX",
        "PjaIMtZU7YtA",
        "Cw94uPUQ0h9V",
        "mWleD4FoU9Zn"
      ],
      "toc_visible": true,
      "authorship_tag": "ABX9TyMYqIVHr2sDkRp+C/tNEdBM",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/aubricot/computer_vision_with_eol_images/blob/master/object_detection_for_image_tagging/scat_footprint/scat_footprint_preprocessing.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WGFNOrAs0pMf"
      },
      "source": [
        "# Pre-process Scat/Footprint Detector Training Images\n",
        "---\n",
        "*Last Updated 2 June 2021*   \n",
        "Follow steps below to download images from iNaturalist observation bundles to Google Drive, then  then augment images to increase training dataset size, and last move files to their appropriate folders for use training scat/footprint detection models.     \n",
        "\n",
        "**Notes**\n",
        "* The steps in this notebook took several days to complete for a training dataset size of 1200 images per class. Preparing datasets is often the most time-consuming step of a machine learning pipeline, especially for object detection where you must manage images and their corresponding annotation files.\n",
        "* After Step 5, one step needs to be completed on your local machine - image annotation using [labelImg](https://github.com/tzutalin/labelImg) - before moving onto step 6. \n",
        "* Change filepaths or information using the form fields to the right of code blocks (also noted in code with 'TO DO')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F53iiacTFVz7"
      },
      "source": [
        "## Installs & Imports\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MeNoVQDN0I1q"
      },
      "source": [
        "# Mount google drive to import/export files\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lxIUuGkDa__r"
      },
      "source": [
        "# For importing/exporting files, working with arrays, xmls, etc\n",
        "import pathlib\n",
        "import os\n",
        "from os import listdir\n",
        "import glob\n",
        "import re\n",
        "import imageio\n",
        "import io\n",
        "import time\n",
        "import csv\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import shutil\n",
        "import random\n",
        "\n",
        "# For drawing onto and plotting images\n",
        "import matplotlib.pyplot as plt\n",
        "import cv2\n",
        "from PIL import Image\n",
        "%config InlineBackend.figure_format = 'svg'\n",
        "%matplotlib inline\n",
        "\n",
        "# For augmenting images\n",
        "!pip install imgaug\n",
        "import imgaug as ia\n",
        "import imgaug.augmenters as iaa\n",
        "from imgaug.augmentables.bbs import BoundingBox, BoundingBoxesOnImage\n",
        "\n",
        "# For handling annotations\n",
        "import lxml\n",
        "from lxml import etree\n",
        "import xml.etree.cElementTree as ET"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LZlJ7Rjaub3O"
      },
      "source": [
        "### 1) Build image bundles for each class\n",
        "---\n",
        "Bundles were downloaded from [iNaturalist](https://www.inaturalist.org/observations) under \"Explore\" for all terrestrial vertebrate taxa (no fish) with all creative commons licenses and the keywords \"scat\" or \"footprint\""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s67Ly5pmL6LD"
      },
      "source": [
        "# TO DO: Type in the path to your working directory in form field to right\n",
        "wd = \"/content/drive/MyDrive/train/tf2/pre-processing/scat_footprint\" #@param {type:\"string\"}\n",
        "%cd $wd\n",
        "\n",
        "# Download iNaturalist image bundles for CC0 and CC-BY images\n",
        "# Scat\n",
        "fn = 'observations-128689.csv'\n",
        "if not os.path.exists(fn):\n",
        "    !gdown --id 1KnRRusRVXpGEATmkSEhAVPB2_htiVfWm\n",
        "scat = pd.read_csv(fn, sep=',', header=0, na_filter = False)\n",
        "print(\"Total number of available images for scat: \\n {}\".format(len(scat)))\n",
        "\n",
        "# Footprint\n",
        "fn = 'observations-128749.csv'\n",
        "if not os.path.exists(fn):\n",
        "    !gdown --id 1KlfqTu_dS_hpqQJI_A2e0RYCZNllRDz9\n",
        "footprint = pd.read_csv(fn, sep=',', header=0, na_filter = False)\n",
        "print(\"\\nTotal number of available images for footprint: \\n {}\".format(len(footprint)))\n",
        "\n",
        "# Set up directories for pre-processing images\n",
        "def directory_setup(df, folder): \n",
        "    if not os.path.exists(folder):\n",
        "        # Make directory for image class\n",
        "        os.makedirs(folder)\n",
        "        # List all image urls\n",
        "        outfpath = os.path.split(folder)[0] + '/' + os.path.split(folder)[1] + '_imgs.txt'\n",
        "        df['image_url'].to_csv(outfpath, sep='\\n', index=False, header=False)\n",
        "        # Make subset of image urls for download\n",
        "        outfpath = os.path.split(folder)[0] + '/' + os.path.split(folder)[1] + '/' + os.path.split(folder)[1] + '_download_subset.txt' \n",
        "        # TO DO: Choose how many images to download\n",
        "        num_imgs = 1200 #@param {type:\"integer\"}\n",
        "        bundle = df.head(num_imgs)\n",
        "        bundle.to_csv(outfpath, sep='\\n', index=False, header=False)\n",
        "        print(\"Bundle with {} {} images for download saved to {}\\n\".format(num_imgs, folder, outfpath))\n",
        "\n",
        "# Set up directory and bundle for scat\n",
        "directory_setup(scat, \"images/scat\")\n",
        "\n",
        "# Set up directory and bundle for footprint\n",
        "directory_setup(footprint, \"images/footprint\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bOJEcY_BYYjl"
      },
      "source": [
        "### 2) Download images to Google Drive\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xRYy0cCAI_6n"
      },
      "source": [
        "# Install aria2 for downloading images in parallel\n",
        "!apt-get install aria2"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yZIZpuuwOhaD"
      },
      "source": [
        "# Download scat images \n",
        "%cd $wd\n",
        "%cd images/scat \n",
        "!aria2c -x 16 -s 1 -i \"scat_download_subset.txt\"\n",
        "# Check how many images downloaded\n",
        "print(\"Number of images downloaded to Google Drive: \")\n",
        "!ls . | wc -l"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H1FEL48SOxdP"
      },
      "source": [
        "# Download footprint images \n",
        "%cd $wd\n",
        "%cd images/footprint \n",
        "!aria2c -x 16 -s 1 -i \"footprint_download_subset.txt\"\n",
        "# Check how many images downloaded\n",
        "print(\"Number of images downloaded to Google Drive: \")\n",
        "!ls . | wc -l"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7y1GZ-IRKVnz"
      },
      "source": [
        "# Move image data files to image_data/\n",
        "%cd $wd\n",
        "!mkdir -p image_data\n",
        "!mv ./*.csv image_data/\n",
        "!mv images/*.txt image_data/\n",
        "!mv images/scat/*.txt image_data/\n",
        "!mv images/footprint/*.txt image_data/"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uELne7tJrEDZ"
      },
      "source": [
        "### 3) Delete all downloaded non-image files\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bTPAxR5V-wTm"
      },
      "source": [
        "Image.MAX_IMAGE_PIXELS = 95000000 # To suppress errors from Pillow about decompression bombs\n",
        "\n",
        "# Remove bad image files\n",
        "def remove_bad_images(folder):\n",
        "    %cd $wd\n",
        "    %cd $folder\n",
        "    # Loop through downloaded files and delete non-images\n",
        "    for num, path in enumerate(listdir('./'), start=1):\n",
        "        try:\n",
        "            with open(path, 'rb') as f:\n",
        "                try:\n",
        "                    img = Image.open(io.BytesIO(f.read()))\n",
        "                    img.verify() # verify that it is an image\n",
        "                    if len(str(os.path.splitext(path)[1])) < 3:\n",
        "                        newpath = str(num) + '.jpg' # add jpg extension to image files without exts \n",
        "                    else:\n",
        "                        newpath = str(num) + str(os.path.splitext(path)[1]) # make sure all filenames and exts are unique \n",
        "                        os.rename(path, newpath)\n",
        "                except (IOError, SyntaxError) as e:\n",
        "                    print('Bad file:', path)\n",
        "                    if '(' in path: # rm doesn't work for files with parenthesis in name, need to manually remove\n",
        "                        print(\"Manually remove from Google Drive: {}\".format(filename)) \n",
        "                    else:\n",
        "                        !rm $path\n",
        "        except IsADirectoryError as e:\n",
        "            print(\"{} is a directory. \\nRemoving directory...\".format(path))\n",
        "            os.removedirs(path)\n",
        "    print(\"Number of images in {} after non-image files removed: \".format(folder))\n",
        "    !ls . | wc -l\n",
        "\n",
        "# Remove bad image files from scat/\n",
        "remove_bad_images(\"images/scat\")\n",
        "\n",
        "# Remove bad image files from footprint/\n",
        "remove_bad_images(\"images/footprint\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b8yUIF7PduqX"
      },
      "source": [
        "### 4) Make number of images per class even\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NJXH0UnYeav5"
      },
      "source": [
        "%cd $wd\n",
        "\n",
        "# Randomly delete all but N-images from scat and footprint folders\n",
        "# TO DO: Choose how many images to keep for each class\n",
        "to_keep = 600 #@param {type:\"integer\"}\n",
        "!find \"images/scat\" -type f -print0 | sort -zR | tail -zn +{to_keep} | xargs -0 rm\n",
        "!find \"images/footprint\" -type f -print0 | sort -zR | tail -zn +{to_keep} | xargs -0 rm\n",
        "\n",
        "print(\"Final number of scat images:\")\n",
        "!ls images/scat | wc -l\n",
        "print(\"Final number of footprint images:\")\n",
        "!ls images/footprint | wc -l"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PjaIMtZU7YtA"
      },
      "source": [
        "### 5) Zip image folders for download to local machine and annotation with labelImg\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0e66cIn8nqrC"
      },
      "source": [
        "!zip -r \"images_fordl.zip\" \"images\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Cw94uPUQ0h9V"
      },
      "source": [
        "### 6) Upload zipped images and annotations to Google Drive and resume here\n",
        "---\n",
        "Upload files to tf2/ or your base wd"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mSQS2HcV6UTj"
      },
      "source": [
        "# TO DO: Type in the path to your working directory in form field to right\n",
        "wd = \"/content/drive/MyDrive/train/tf2\" #@param {type:\"string\"}\n",
        "%cd $wd\n",
        "\n",
        "# TO DO: Type in filename of zipped images folder\n",
        "filename = \"images_foranns.zip\" #@param {type:\"string\"}\n",
        "\n",
        "# Unzip images to tf2/images\n",
        "!mkdir images\n",
        "!mkdir test_images\n",
        "!unzip {filename} -d images"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wl2QJznmXBfg"
      },
      "source": [
        "# Move all images from subfolders to main annotations folder\n",
        "os.makedirs('images/scat')\n",
        "os.makedirs('images/footprint')\n",
        "!mv -v images/images/scat/* images/scat\n",
        "!mv -v images/images/footprint/* images/footprint\n",
        "\n",
        "# Remove empty folders from uploaded labelImg zipped files\n",
        "!rm -r images/images"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rWauDNiiN8mZ"
      },
      "source": [
        "# Optional: If used Mac for labelImg, delete Mac OS files from subfolders\n",
        "!find images/ -name \"*.DS_Store\" -type f -delete\n",
        "!rm -r images/__MACOSX"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5D986WR803pQ"
      },
      "source": [
        "# Unzip annotations to tf2/annotations\n",
        "!mkdir annotations\n",
        "!mkdir test_ann\n",
        "!unzip annotations.zip -d annotations\n",
        "\n",
        "# Move all xml files from subfolders to main annotations folder\n",
        "!mv -v annotations/annotations/scat/* annotations\n",
        "!mv -v annotations/annotations/footprint/* annotations\n",
        "\n",
        "# Remove empty folders from uploaded labelImg zipped files\n",
        "!rm -r annotations/annotations"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0iG5MkuvOJAw"
      },
      "source": [
        "# Optional: If used Mac for labelImg, delete Mac OS files from subfolders\n",
        "!find annotations/ -name \"*.DS_Store\" -type f -delete\n",
        "!rm -r annotations/__MACOSX"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qq091EbQejET"
      },
      "source": [
        "%cd $wd\n",
        "\n",
        "print(\"\\nFinal number of scat images:\")\n",
        "!ls images/scat | wc -l\n",
        "print(\"Final number of footprint images:\")\n",
        "!ls images/footprint | wc -l\n",
        "\n",
        "print(\"Final number of annotations (scat and footprint combined):\")\n",
        "!ls annotations | wc -l"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JqEjJeRLK12A"
      },
      "source": [
        "### 7) Pre-process train and test images\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IpYpFNLMpdrl"
      },
      "source": [
        "# Define functions\n",
        "\n",
        "# TO DO: Type in the path to your working directory in form field to right\n",
        "wd = \"/content/drive/MyDrive/train/tf2\" #@param {type:\"string\"}\n",
        "%cd $wd\n",
        "\n",
        "# List all images contained in folder\n",
        "def list_dir_images(dir):    \n",
        "    basepath = 'images/'\n",
        "    fpath = basepath + dir\n",
        "    filenames = os.listdir(fpath)\n",
        "    \n",
        "    return filenames\n",
        "\n",
        "# Split into train and test datasets\n",
        "def split_train_test(filenames, img_class):\n",
        "    # Select 30% of images to use for testing the trained model\n",
        "    # Ratios will be 80/20 after augmenting training images\n",
        "    print(\"Number of images in {}\\n\".format(img_class, len(filenames)))\n",
        "    subset = int(0.3*(len(filenames)*2))\n",
        "    test_imgs = random.sample(filenames, subset)\n",
        "    print(\"30% of images in {} to be used for testing: {}\".format(img_class, subset))\n",
        "\n",
        "    return test_imgs\n",
        "\n",
        "# Move test images to test_images/\n",
        "def move_test_images(test_imgs, img_class):\n",
        "    test_dir = 'test_images'\n",
        "    train_dir = 'images/' + img_class\n",
        "    filenames = []\n",
        "    for i, filename in enumerate(test_imgs, start=1):\n",
        "        fpath = os.path.join(train_dir, filename)\n",
        "        if os.path.isfile(fpath):\n",
        "            shutil.move(fpath, test_dir)\n",
        "            print('{}) Successfully moved {} to {}'.format(i, fpath, test_dir))\n",
        "            filenames.append(fpath)\n",
        "        else:\n",
        "            print('File not found: ', fpath)\n",
        "\n",
        "# Move test annotations to test_ann/\n",
        "def move_test_anns(test_imgs):\n",
        "    ann_dir = 'annotations/'\n",
        "    testann_dir = 'test_ann/'\n",
        "    # Find xml files matching test images and move to test_ann/\n",
        "    for test_img in test_imgs:\n",
        "        base = os.path.splitext(os.path.basename(test_img))[0]\n",
        "        test_xml = ann_dir + base + '.xml'\n",
        "        if os.path.exists(test_xml):\n",
        "            shutil.move(test_xml, testann_dir)\n",
        "            print(\"Moved {} to test_ann\".format(test_xml))\n",
        "        else:\n",
        "            print(\"!!!xml missing for image {}\".format(test_img))\n",
        "            #os.remove(test_img)\n",
        "\n",
        "# Check that each train image has an annotation\n",
        "def check_train_anns(train_dir):\n",
        "    ann_dir = 'annotations/'\n",
        "    train_imgs = os.listdir(train_dir)\n",
        "    # Loop through train images to see if xml for each one\n",
        "    for train_img in train_imgs:\n",
        "        base = os.path.splitext(os.path.basename(train_img))[0]\n",
        "        train_xml = ann_dir + base + '.xml'\n",
        "        if os.path.exists(train_xml):\n",
        "            print(\"xml exists for {}\".format(train_img))\n",
        "        else:\n",
        "            print(\"!!!xml missing for image {}\".format(train_img))\n",
        "            #os.remove(file)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mWleD4FoU9Zn"
      },
      "source": [
        "#### A) Split into train and test datasets"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uPtEYkDaK6NL"
      },
      "source": [
        "# Make test dataset\n",
        "\n",
        "# Select 30% of images for test dataset\n",
        "# TO DO: Enter image classes as a list\n",
        "img_classes = ['scat', 'footprint'] #@param\n",
        "for img_class in img_classes:\n",
        "    # Make list of test images\n",
        "    img_files = list_dir_images(img_class)\n",
        "    test_imgs = split_train_test(img_files, img_class)\n",
        "    # Move test images to test_images/\n",
        "    move_test_images(test_imgs, img_class)\n",
        "\n",
        "# Move matching 30% of test annotations to test_ann/\n",
        "move_test_anns(test_imgs)\n",
        "\n",
        "# Summary of test image dataset\n",
        "print(\"Number of test images:\")\n",
        "!ls test_images | wc -l\n",
        "\n",
        "print(\"Number of test annotations:\")\n",
        "!ls test_ann | wc -l"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bd0PlNaYEJAq"
      },
      "source": [
        "# Make train dataset\n",
        "\n",
        "# Move train images from class folders to images/\n",
        "!mv -v images/footprint/* images\n",
        "!mv -v images/scat/* images\n",
        "\n",
        "# Remove empty folders for image classes\n",
        "!rm -r images/footprint\n",
        "!rm -r images/scat\n",
        "\n",
        "# Check that each train image has an annotation\n",
        "train_dir = 'images' \n",
        "check_train_anns(train_dir)\n",
        "\n",
        "# Summary of train image dataset\n",
        "print(\"Number of train images:\")\n",
        "!ls images | wc -l\n",
        "\n",
        "print(\"Number of train annotations:\")\n",
        "!ls annotations | wc -l"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AOxjL-KOfFMw"
      },
      "source": [
        "#### B) Augment images and bounding boxes  \n",
        "Some code modified from [asetkn's GitHub](https://github.com/asetkn/Tutorial-Image-and-Multiple-Bounding-Boxes-Augmentation-for-Deep-Learning-in-4-Steps/blob/master/Tutorial-Image-and-Multiple-Bounding-Boxes-Augmentation-for-Deep-Learning-in-4-Steps.ipynb)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fVNLDelUpKDL"
      },
      "source": [
        "# Define functions\n",
        "\n",
        "# TO DO: Type in the path to your working directory in form field to right\n",
        "wd = \"/content/drive/MyDrive/train/tf2\" #@param {type:\"string\"}\n",
        "%cd $wd\n",
        "\n",
        "# Inspect N-images from directory\n",
        "def inspect_images(path, num=5):\n",
        "    image_fns = os.listdir(path)[:num]\n",
        "    image_fpaths = [path + image_fn for image_fn in image_fns]\n",
        "    for image_fpath in image_fpaths:\n",
        "        print(\"Showing image \", image_fpath)\n",
        "        ia.imshow(imageio.imread(image_fpath))\n",
        "\n",
        "# Inspect an image annotation file\n",
        "def inspect_ann(annpath):\n",
        "    ann_fn = os.listdir(annpath)[1]\n",
        "    ann_fpath = annpath + ann_fn\n",
        "    shutil.copy(ann_fpath, '/content/ann0.txt')\n",
        "    ann_text = open(\"/content/ann0.txt\", \"r\")\n",
        "    print(\"\\nShowing sample annotation \", ann_fpath)\n",
        "    print(ann_text.read())\n",
        "    ann_text.close()\n",
        "\n",
        "# Extract info from annotation xmls into csv file\n",
        "# Modified from https://github.com/datitran/raccoon_dataset/blob/master/xml_to_csv.py\n",
        "def xml_to_csv(path, imtype):\n",
        "    xml_list = []\n",
        "    for xml_file in glob.glob(path + '/*.xml'):\n",
        "        tree = ET.parse(xml_file)\n",
        "        root = tree.getroot()\n",
        "        for member in root.findall('object'):\n",
        "            value = (root.find('filename').text,\n",
        "                     int(root.find('size')[0].text),\n",
        "                     int(root.find('size')[1].text),\n",
        "                     member[0].text,\n",
        "                     int(member[4][0].text),\n",
        "                     int(member[4][1].text),\n",
        "                     int(member[4][2].text),\n",
        "                     int(member[4][3].text))\n",
        "            xml_list.append(value)\n",
        "    column_name = ['filename', 'width', 'height', 'class', 'xmin', 'ymin', 'xmax', 'ymax']\n",
        "    xml_df = pd.DataFrame(xml_list, columns=column_name)\n",
        "    outfpath = 'pre-processing/' + imtype + '_labels_notaug' + '.csv'\n",
        "    xml_df.to_csv(outfpath, index=None)\n",
        "    print('Successfully converted xmls to: ', outfpath)\n",
        "\n",
        "    return xml_df, outfpath"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "284hddFRbjHY"
      },
      "source": [
        "##### Convert annotation xmls to csv"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TsB2s1QNfK3Z"
      },
      "source": [
        "# Data Inspection & convert annotations to csv\n",
        "\n",
        "imtypes = ['train', 'test'] \n",
        "for imtype in imtypes:\n",
        "    if imtype == \"train\":\n",
        "        path = 'images/'\n",
        "        annpath = 'annotations/'\n",
        "    else:\n",
        "        path = 'test_images/'\n",
        "        annpath = 'test_ann/'\n",
        "    print(\"\\nInspecting {} images\\n\".format(imtype))\n",
        "    # Inspect five images\n",
        "    inspect_images(path, 5)\n",
        "    \n",
        "    # Inspect an annotation file \n",
        "    inspect_ann(annpath)\n",
        "\n",
        "    # Convert xml annotations to labels.csv & save results\n",
        "    labels, outfpath = xml_to_csv(annpath, imtype)\n",
        "\n",
        "    # Check that the number of images and annotations in labels.csv match\n",
        "    print(\"Number of {} images: \".format(imtype))\n",
        "    !sudo ls $path | wc -l\n",
        "\n",
        "    print(\"\\nNumber of files with annotations in {}: \\n{}\".format(outfpath, len(labels.groupby('filename'))))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pq01xCEvlwr1"
      },
      "source": [
        "# Optional: Only run in case mismatch in images in folder and images in train or test labels csv\n",
        "from os import listdir\n",
        "from os.path import isfile, join\n",
        "\n",
        "# TO DO: Choose which training dataset to inspect\n",
        "path = \"test_images/\" #@param [\"images/\", \"test_images/\"]\n",
        "fns_orig = [f for f in listdir(path) if isfile(join(path, f))]\n",
        "non_fns = [f for f in listdir(path) if not isfile(join(path, f))]\n",
        "if 'test' in path:\n",
        "    outfpath = 'pre-processing/test_labels_notaug.csv'\n",
        "else:\n",
        "    outfpath = 'pre-processing/train_labels_notaug.csv'\n",
        "df = pd.read_csv(outfpath)\n",
        "fns_csv = df.filename.unique()\n",
        "\n",
        "print(\"Number of image files in {}: {}\\n\".format(path, len(fns_orig)))\n",
        "print(\"Number of image files in {}: {}\\n\".format(outfpath, len(fns_csv)))\n",
        "print(\"Invalid files found in {}: {}\".format(path, non_fns))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9JYfhtvGjcvD"
      },
      "source": [
        "# TO DO: Enter invalid filename(s) to delete and run\n",
        "filename_to_del = \".ipynb_checkpoints\" #@param {type:\"string\"}\n",
        "\n",
        "# TO DO: Is it a file or a directory?\n",
        "ftype = \"d\" #@param [\"f\", \"d\"]\n",
        "\n",
        "!find {path} -name {filename_to_del} -type {ftype} -delete"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LwqF5jCS8hdV"
      },
      "source": [
        "##### Augmentation of images and bounding boxes"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cEzpQstT8jrw"
      },
      "source": [
        "# Define image augmentation pipeline\n",
        "# modified from https://github.com/aleju/imgaug\n",
        "seq = iaa.SomeOf(2, [    \n",
        "    iaa.Affine(scale=(0.5, 1.5)),\n",
        "    iaa.Affine(rotate=(-60, 60)), # rotate by -60 to 60 degrees\n",
        "    iaa.Affine(translate_percent={\"x\": (-0.3, 0.3), \"y\": (-0.3, 0.3)}),\n",
        "    iaa.Fliplr(0.8),\n",
        "    iaa.Multiply((0.5, 1.5)),\n",
        "    iaa.GaussianBlur(sigma=(1.0, 3.0)), # blur using gaussian kernel with sigma of 0-3\n",
        "    iaa.AdditiveGaussianNoise(scale=(0.03*255, 0.05*255))\n",
        "])\n",
        "\n",
        "# Convert bounding boxes to dataframe\n",
        "def bbs_obj_to_df(bbs_object):\n",
        "    bbs_array = bbs_object.to_xyxy_array()\n",
        "    df_bbs = pd.DataFrame(bbs_array, columns=['xmin', 'ymin', 'xmax', 'ymax'])\n",
        "    return df_bbs\n",
        "\n",
        "# Augment images from dataframe info and save results\n",
        "def augment_image(df, path, seq=seq):\n",
        "    # Output dataframe for augmented image info\n",
        "    aug_bbs = pd.DataFrame(columns=['filename','width','height','class', \\\n",
        "                                       'xmin', 'ymin', 'xmax', 'ymax'])\n",
        "    grouped = df.groupby('filename')\n",
        "    for filename in df['filename'].unique():\n",
        "        \n",
        "        # Group df by filename\n",
        "        group_df = grouped.get_group(filename)\n",
        "        group_df = group_df.reset_index()\n",
        "        group_df = group_df.drop(['index'], axis=1)   \n",
        "        \n",
        "        # Read in image\n",
        "        fpath = path + filename\n",
        "        image = imageio.imread(fpath)\n",
        "        print(\"Augmenting image: \", filename)\n",
        "        \n",
        "        # Load image bounding box coordinates to imgaug format        \n",
        "        bb_array = group_df.drop(['filename', 'width', 'height', 'class'], axis=1).values\n",
        "        bbs = BoundingBoxesOnImage.from_xyxy_array(bb_array, shape=image.shape)\n",
        "    \n",
        "        # Augment image using settings defined above in seq\n",
        "        image_aug, bbs_aug = seq(image=image, bounding_boxes=bbs)\n",
        "        \n",
        "        # Write augmented image to file\n",
        "        fpath_aug = path + 'aug_' + filename\n",
        "        imageio.imwrite(fpath_aug, image_aug)  \n",
        "        \n",
        "        # Add augmented values for img height, width, and filename to new df\n",
        "        aug_df = group_df.drop(['xmin', 'ymin', 'xmax', 'ymax'], axis=1)    \n",
        "        for i, _ in aug_df.iterrows():\n",
        "                aug_df.at[i, 'width'] = image_aug.shape[1]\n",
        "                aug_df.at[i, 'height'] = image_aug.shape[0]\n",
        "        # Add 'aug_' prefix to filenames\n",
        "        aug_df['filename'] = aug_df['filename'].apply(lambda x: 'aug_' + x)\n",
        "        \n",
        "        # Write augmented bboxes to new df\n",
        "        bbs_df = bbs_obj_to_df(bbs_aug)\n",
        "        # Concat all new augmented info into new data frame\n",
        "        aug_bbs_df = pd.concat([aug_df, bbs_df], axis=1)\n",
        "        # Append rows to aug_bbs data frame\n",
        "        aug_bbs = pd.concat([aug_bbs, aug_bbs_df])            \n",
        "    \n",
        "    # Return augmented df\n",
        "    aug_bbs = aug_bbs.reset_index()\n",
        "    aug_bbs = aug_bbs.drop(['index'], axis=1)\n",
        "    \n",
        "    return aug_bbs\n",
        "\n",
        "# Remove out of bounds values\n",
        "def remove_oob(crops):\n",
        "    # Set negative values to 0\n",
        "    crops.xmin[crops.xmin < 0] = 0\n",
        "    crops.ymin[crops.ymin < 0] = 0\n",
        "\n",
        "    # Remove out of bounds cropping dimensions\n",
        "    ## When crop height > image height, set crop height equal to image height\n",
        "    idx = crops.index[crops.ymax > crops.height]\n",
        "    crops.ymin.iloc[idx] = 0\n",
        "    crops.ymax.iloc[idx] = crops.height.iloc[idx]\n",
        "    ## When crop width > image width, set crop width equal to image width\n",
        "    idx = crops.index[crops.xmax > crops.width]\n",
        "    crops.xmin.iloc[idx] = 0\n",
        "    crops.xmax.iloc[idx] = crops.width.iloc[idx]\n",
        "\n",
        "    # Write relevant results to csv formatted for training and annotations needed by Tensorflow and YOLO\n",
        "    crops_oobrem = crops[['xmin', 'ymin', 'xmax', 'ymax', 'filename', 'width', \\\n",
        "                          'height', 'class']]\n",
        "\n",
        "    return crops_oobrem"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IWEXx1tXBVLS"
      },
      "source": [
        "# Augment train images and bounding boxes\n",
        "outfpath = 'pre-processing/train_labels_notaug.csv'\n",
        "df = pd.read_csv(outfpath)\n",
        "img_path = 'images/'\n",
        "augmented_df = augment_image(df, img_path)\n",
        "print(\"Dataframe with augmented images: \\n\", augmented_df.head())\n",
        "\n",
        "# Combine augmented and not augmented dfs & save to file\n",
        "all_imgs_df = pd.concat([df, augmented_df])\n",
        "outfpath = 'pre-processing/train_labels_augall.csv'\n",
        "all_imgs_df.to_csv(outfpath, index=False)\n",
        "\n",
        "# Remove out of bounds values resulting from augmentation\n",
        "all_oobrem = remove_oob(all_imgs_df)\n",
        "\n",
        "# Save results for use training object detectors\n",
        "outfpath = os.path.splitext(outfpath)[0] + '_oob_rem_fin' + '.csv' \n",
        "all_oobrem.to_csv(outfpath, sep=',', index=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ki7W0Hc1n9-W"
      },
      "source": [
        "# Test images and bounding boxes are not augmented\n",
        "\n",
        "# Remove out of bounds values resulting from augmentation\n",
        "outfpath = 'pre-processing/test_labels_notaug.csv'\n",
        "df = pd.read_csv(outfpath)\n",
        "all_oobrem = remove_oob(df)\n",
        "\n",
        "# Save results for use training object detectors\n",
        "outfpath = os.path.splitext(outfpath)[0] + '_oob_rem_fin' + '.csv' \n",
        "all_oobrem.to_csv(outfpath, sep=',', index=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7QbIV_A2d80j"
      },
      "source": [
        "#### C) Loop through images and annotations to confirm all files are valid to avoid problems training downstream"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YMHcCfaD7J5t"
      },
      "source": [
        "# Search for problematic images\n",
        "# modified from https://github.com/AjayZinngg/random-scripts/blob/master/check_images.py \n",
        "# Notes on possible image errors during training https://github.com/tensorflow/models/issues/5474\n",
        "# more notes on errors https://github.com/tensorflow/models/issues/1754\n",
        "\n",
        "# Change to your training directory within Google Drive\n",
        "%cd $wd\n",
        "\n",
        "csv_files = ['pre-processing/train_labels_augall_oob_rem_fin.csv', 'pre-processing/test_labels_notaug_oob_rem_fin.csv']\n",
        "folders = ['images', 'test_images']\n",
        "\n",
        "for i in range(len(folders)):\n",
        "    FOLDER = folders[i]\n",
        "    CSV_FILE = csv_files[i]\n",
        "\n",
        "    with open(CSV_FILE, 'r') as fid:\n",
        "        \n",
        "        print('Checking file:', CSV_FILE, 'in folder:', FOLDER)\n",
        "        \n",
        "        file = csv.reader(fid, delimiter=',')\n",
        "        first = True\n",
        "        \n",
        "        cnt = 0\n",
        "        error_cnt = 0\n",
        "        error = False\n",
        "\n",
        "        for row in file:\n",
        "            if error == True:\n",
        "                error_cnt += 1\n",
        "                error = False\n",
        "                \n",
        "            if first == True:\n",
        "                first = False\n",
        "                continue\n",
        "            \n",
        "            cnt += 1\n",
        "            \n",
        "            xmin, ymin, xmax, ymax, name, width, height = int(float(row[0])), int(float(row[1])), int(float(row[2])), int(float(row[3])), row[4], int(float(row[5])), int(float(row[6]))\n",
        "            \n",
        "            path = os.path.join(FOLDER, name)\n",
        "            img = cv2.imread(path)\n",
        "            \n",
        "            if type(img) == type(None):\n",
        "                error = True\n",
        "                print('Could not read image', path)\n",
        "                continue\n",
        "            \n",
        "            org_height, org_width = img.shape[:2]\n",
        "            \n",
        "            if org_width != width:\n",
        "                error = True\n",
        "                print('Width mismatch for image: ', name, width, '!=', org_width)\n",
        "            \n",
        "            if org_height != height:\n",
        "                error = True\n",
        "                print('Height mismatch for image: ', name, height, '!=', org_height)\n",
        "            \n",
        "            if xmin > org_width:\n",
        "                error = True\n",
        "                print('XMIN > org_width for file', name)\n",
        "                \n",
        "            if xmin <= 0:\n",
        "                error = True\n",
        "                print('XMIN < 0 for file', name)\n",
        "                \n",
        "            if xmax > org_width:\n",
        "                error = True\n",
        "                print('XMAX > org_width for file', name)\n",
        "\n",
        "            if xmax > org_height: #added because training errors for OOBs when none present\n",
        "                error = True\n",
        "                print('XMAX > org_height for file', name)\n",
        "            \n",
        "            if ymin > org_height:\n",
        "                error = True\n",
        "                print('YMIN > org_height for file', name)\n",
        "            \n",
        "            if ymin <= 0:\n",
        "                error = True\n",
        "                print('YMIN < 0 for file', name)\n",
        "            \n",
        "            if ymax > org_height:\n",
        "                error = True\n",
        "                print('YMAX > org_height for file', name)\n",
        "            \n",
        "            if xmin >= xmax:\n",
        "                error = True\n",
        "                print('xmin >= xmax for file', name)\n",
        "                \n",
        "            if ymin >= ymax:\n",
        "                error = True\n",
        "                print('ymin >= ymax for file', name)\n",
        "            \n",
        "            if error == True:\n",
        "                print('Error for file: %s' % name)\n",
        "                print()\n",
        "\n",
        "        print('Checked %d bounding boxes and realized %d errors' % (cnt, error_cnt))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5FaP3u0_Qkrv"
      },
      "source": [
        "# Manually delete OOB files & img info found above\n",
        "csv_fpath = \"pre-processing/train_labels_augall_oob_rem_fin.csv\" #@param [\"pre-processing/train_labels_augall_oob_rem_fin.csv\", \"pre-processing/test_labels_notaug_oob_rem_fin.csv\"] {allow-input: true}\n",
        "df = pd.read_csv(csv_fpath)\n",
        "file_to_del = \"aug_85.jpeg\" #@param {type:\"string\"}\n",
        "if 'train' in csv_fpath:\n",
        "    path_to_del = 'images/' + file_to_del\n",
        "    os.remove(path_to_del)\n",
        "else:\n",
        "    path_to_del = 'test_images/' + file_to_del\n",
        "    os.remove(path_to_del)\n",
        "\n",
        "# Update results in train/test csv\n",
        "df1 = df[df.filename != file_to_del]\n",
        "df1.to_csv(csv_fpath, index=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xxezeb_JXgQG"
      },
      "source": [
        "### 8) Generate xmls (annotations) for new annotated image dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jW88jqYm9neC",
        "cellView": "code"
      },
      "source": [
        "# Run this block 1x per class\n",
        "\n",
        "# Convert train and test csvs to xmls with updated filepaths\n",
        "# modified from here https://gist.github.com/calisir/568190a5e55a79e08be318c285688457\n",
        "%cd $wd\n",
        "\n",
        "imtype = \"test\" #@param [\"train\", \"test\"]\n",
        "\n",
        "# Read in train or test image label data\n",
        "if imtype == \"train\":\n",
        "  folder = \"images\" \n",
        "  fpath = \"images/\" \n",
        "  labfile = \"pre-processing/train_labels_augall_oob_rem_fin.csv\"\n",
        "else:\n",
        "  folder = \"test_images\" \n",
        "  fpath = \"test_images/\" \n",
        "  labfile = \"pre-processing/test_labels_notaug_oob_rem_fin.csv\"\n",
        "df1 = pd.read_csv(labfile)\n",
        "df = df1.groupby('filename', as_index=False).agg(lambda x: list(x))\n",
        "\n",
        "# Make folders for annotations\n",
        "!mkdir pre-processing/train_ann\n",
        "!mkdir pre-processing/test_ann\n",
        "\n",
        "# Define functions\n",
        "\n",
        "def indent(elem, level=0):\n",
        "    i = \"\\n\" + level*\"  \"\n",
        "    if len(elem):\n",
        "        if not elem.text or not elem.text.strip():\n",
        "            elem.text = i + \"  \"\n",
        "        if not elem.tail or not elem.tail.strip():\n",
        "            elem.tail = i\n",
        "        for elem in elem:\n",
        "            indent(elem, level+1)\n",
        "        if not elem.tail or not elem.tail.strip():\n",
        "            elem.tail = i\n",
        "    else:\n",
        "        if level and (not elem.tail or not elem.tail.strip()):\n",
        "            elem.tail = i\n",
        "\n",
        "for i in range(0, len(df)):\n",
        "    height = df['height'].iloc[i][0]\n",
        "    width = df['width'].iloc[i][0]\n",
        "    depth = 3\n",
        "\n",
        "    annotation = ET.Element('annotation')\n",
        "    ET.SubElement(annotation, 'folder').text = folder\n",
        "    ET.SubElement(annotation, 'filename').text = str(df['filename'].iloc[i])\n",
        "    ET.SubElement(annotation, 'path').text = fpath + str(df['filename'].iloc[i])\n",
        "    \n",
        "    source = ET.SubElement(annotation, 'source')\n",
        "    ET.SubElement(source, 'database').text = 'Unknown'\n",
        "    \n",
        "    size = ET.SubElement(annotation, 'size')\n",
        "    ET.SubElement(size, 'width').text = str(width)\n",
        "    ET.SubElement(size, 'height').text = str(height)\n",
        "    ET.SubElement(size, 'depth').text = str(depth)\n",
        "\n",
        "    ET.SubElement(annotation, 'segmented').text = '0'\n",
        "    \n",
        "    # To handle images with >1 annotation\n",
        "    for x in range(0, len(df['xmin'].iloc[i])):\n",
        "      ob = ET.SubElement(annotation, 'object')\n",
        "      ET.SubElement(ob, 'name').text = str(df['class'].iloc[i][x])\n",
        "      ET.SubElement(ob, 'pose').text = 'Unspecified'\n",
        "      ET.SubElement(ob, 'truncated').text = '0'\n",
        "      ET.SubElement(ob, 'difficult').text = '0'\n",
        "\n",
        "      bbox = ET.SubElement(ob, 'bndbox')\n",
        "      ET.SubElement(bbox, 'xmin').text = str(int(df['xmin'].iloc[i][x]))\n",
        "      ET.SubElement(bbox, 'ymin').text = str(int(df['ymin'].iloc[i][x]))\n",
        "      ET.SubElement(bbox, 'xmax').text = str(int(df['xmax'].iloc[i][x]))\n",
        "      ET.SubElement(bbox, 'ymax').text = str(int(df['ymax'].iloc[i][x]))\n",
        "\n",
        "    fileName = str(df['filename'].iloc[i])\n",
        "    tree = ET.ElementTree(annotation)\n",
        "    indent(annotation)\n",
        "    if imtype == \"train\":\n",
        "      outf = \"pre-processing/train_ann/\"\n",
        "    else:\n",
        "      outf = \"pre-processing/test_ann/\"\n",
        "    outpath = outf + os.path.splitext(fileName)[0] + \".xml\"\n",
        "    tree.write(outpath, encoding='utf8', xml_declaration=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nRYGgY50STmd"
      },
      "source": [
        "# Check that all train images have corresponding annotation\n",
        "ann_dir = 'pre-processing/train_ann/'\n",
        "train_dir = 'images/'\n",
        "files = os.listdir(train_dir)\n",
        "\n",
        "# Check for duplicate xmls\n",
        "import collections\n",
        "print([item for item, count in collections.Counter(files).items() if count > 1])\n",
        "#!ls -l -a /content/drive/'My Drive'/train/pre-processing/train_ann/\n",
        "\n",
        "# Loop through train images to see if xml for each one\n",
        "for file in files:\n",
        "  base = os.path.splitext(os.path.basename(file))[0]\n",
        "  train_xml = ann_dir + base + '.xml'\n",
        "  if os.path.exists(train_xml):\n",
        "    print(\"xml exists for {}\".format(file))\n",
        "  else:\n",
        "    print(\"!!!xml missing for image {}\".format(file))\n",
        "    #os.remove(file)\n",
        "\n",
        "# Check for xmls that don't have corresp img\n",
        "xmls = os.listdir('pre-processing/train_ann/')\n",
        "imgs = os.listdir('images/')\n",
        "xbases = []\n",
        "ibases = []\n",
        "for xml in xmls:\n",
        "  xbase = os.path.splitext(os.path.basename(xml))[0]\n",
        "  xbases.append(xbase)\n",
        "for img in imgs:\n",
        "  ibase = os.path.splitext(os.path.basename(img))[0]\n",
        "  ibases.append(ibase)\n",
        "\n",
        "# yields the elements in `list_2` that are NOT in `list_1`\n",
        "diffs = np.setdiff1d(xbases,ibases)\n",
        "print(\"xml(s) that need to be deleted bc have no corresp img: {}\".format(diffs))\n",
        "\n",
        "print(\"Number of train images:\")\n",
        "!ls images | wc -l\n",
        "\n",
        "print(\"Number of train annotations:\")\n",
        "!ls pre-processing/train_ann/ | wc -l"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tTdkuEpc8Dko"
      },
      "source": [
        "# Inspect number of images and annotations for train and test (should be 1 image/annotation in each group and test should be ~20-30% of train)\n",
        "!ls pre-processing/train_ann | wc -l\n",
        "!ls images | wc -l\n",
        "\n",
        "!ls pre-processing/test_ann | wc -l\n",
        "!ls test_images | wc -l"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vOxw1XtKByyT"
      },
      "source": [
        "# Move final datasets to train and test folders for object detection\n",
        "!mv pre-processing/train_ann/* annotations\n",
        "#!rm -r /pre-processing/train_ann\n",
        "\n",
        "!mv pre-processing/test_ann/* test_ann\n",
        "#!rm -r pre-processing/test_ann"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}